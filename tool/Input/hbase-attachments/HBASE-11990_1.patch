diff --git hbase-client/src/main/java/org/apache/hadoop/hbase/client/Scan.java hbase-client/src/main/java/org/apache/hadoop/hbase/client/Scan.java
index bf968df..65dd39f 100644
--- hbase-client/src/main/java/org/apache/hadoop/hbase/client/Scan.java
+++ hbase-client/src/main/java/org/apache/hadoop/hbase/client/Scan.java
@@ -344,7 +344,8 @@ public class Scan extends Query {
   /**
    * Set the stop row.
    * @param stopRow row to end at (exclusive)
-   * Note: In order to make stopRow inclusive add a trailing 0 byte
+   * Note: In order to make stopRow inclusive add 1
+   * (or use {@link #setStopRowInclusive(byte[])} to do it for you)
    * @return this
    */
   public Scan setStopRow(byte [] stopRow) {
@@ -353,6 +354,45 @@ public class Scan extends Query {
   }
 
   /**
+   * Set the stop row inclusive.
+   * @param stopRow row to end at (inclusive)
+   * @return this
+   */
+  public Scan setStopRowInclusive(byte [] stopRow) {
+    this.stopRow = stopRow.clone();
+    // Essentially we are treating it like an 'unsigned very very long' and doing +1 manually.
+    int offset = stopRow.length-1;
+    while(offset >= 0) {
+      if (this.stopRow[offset] == (byte)0xFF) {
+        this.stopRow[offset] = 0x00;
+        offset--;
+      } else {
+        this.stopRow[offset]++;
+        break;
+      }
+    }
+    if (offset == -1) {
+      // We got an 0xFFFF... (only FFs) stopRow value which is
+      // the last possible prefix before the end of the table.
+      // So set it to stop at the 'end of the table'
+      this.stopRow = HConstants.EMPTY_END_ROW;
+    }
+
+    return this;
+  }
+
+  /**
+   * Set the start and stop row to exactly retrieve the specified row prefix.
+   * @param rowPrefix Only scan the rows where the rowkey starts with this prefix
+   * @return this
+   */
+  public Scan setRowPrefix(byte [] rowPrefix) {
+    this.setStartRow(rowPrefix);
+    this.setStopRowInclusive(rowPrefix);
+    return this;
+  }
+
+  /**
    * Get all available versions.
    * @return this
    */
diff --git hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestScan.java hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestScan.java
index 9565764..f37a5b0 100644
--- hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestScan.java
+++ hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestScan.java
@@ -23,6 +23,7 @@ import java.io.IOException;
 import java.util.Arrays;
 import java.util.Set;
 
+import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.SmallTests;
 import org.apache.hadoop.hbase.protobuf.ProtobufUtil;
 import org.apache.hadoop.hbase.protobuf.generated.ClientProtos;
@@ -107,5 +108,32 @@ public class TestScan {
     Set<byte[]> qualifiers = scan.getFamilyMap().get(family);
     Assert.assertEquals(1, qualifiers.size());
   }
+
+  @Test
+  public void testScanStartStopRow() {
+    Scan scan = new Scan();
+
+    byte[] testRow1    = {0x12,0x23};
+    byte[] testRow1Inc = {0x12,0x24};
+    scan.setStartRow(testRow1);
+    Assert.assertArrayEquals("Basic startRow setter failed", testRow1, scan.getStartRow());
+    scan.setStopRow(testRow1);
+    Assert.assertArrayEquals("Basic stopRow setter failed", testRow1, scan.getStopRow());
+    scan.setStopRowInclusive(testRow1);
+    Assert.assertArrayEquals("Failed handling stopRowInclusive increment", testRow1Inc, scan.getStopRow());
+
+    byte[] testRow2    = {0x12,(byte)0xFF,(byte)0xFF};
+    byte[] testRow2Inc = {0x13,0x00,0x00};
+    scan.setStopRow(testRow2);
+    Assert.assertArrayEquals(testRow2, scan.getStopRow());
+
+    scan.setStopRowInclusive(testRow2);
+    Assert.assertArrayEquals("Failed handling stopRowInclusive overflow", testRow2Inc, scan.getStopRow());
+
+    byte[] testRow3    = {(byte)0xFF,(byte)0xFF,(byte)0xFF};
+    scan.setStopRowInclusive(testRow3);
+    Assert.assertArrayEquals("Failed handling stopRowInclusive complete overflow", HConstants.EMPTY_END_ROW, scan.getStopRow());
+  }
+
 }
 
