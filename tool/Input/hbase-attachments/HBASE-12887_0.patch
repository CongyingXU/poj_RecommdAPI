From 9bdb81f0a1db308a8a452379455b6bbfe70ea20d Mon Sep 17 00:00:00 2001
From: Nick Dimiduk <ndimiduk@apache.org>
Date: Tue, 20 Jan 2015 12:44:36 -0800
Subject: [PATCH] HBASE-12887 Cleanup many checkstyle errors in o.a.h.h.client

---
 .../hbase/classification/InterfaceAudience.java    |  2 +-
 .../ExcludePrivateAnnotationsStandardDoclet.java   |  4 +-
 .../IncludePublicAnnotationsStandardDoclet.java    |  4 +-
 .../classification/tools/RootDocProcessor.java     |  8 ++-
 .../classification/tools/StabilityOptions.java     |  5 +-
 .../apache/hadoop/hbase/client/AsyncProcess.java   | 27 ++++----
 .../hadoop/hbase/client/ClientIdGenerator.java     |  4 +-
 .../apache/hadoop/hbase/client/ClientScanner.java  |  7 +-
 .../hbase/client/ClientSmallReversedScanner.java   |  3 +-
 .../hadoop/hbase/client/ClusterConnection.java     | 11 ++--
 .../hadoop/hbase/client/ClusterStatusListener.java |  1 -
 .../hadoop/hbase/client/ConnectionManager.java     | 64 ++++++++++++++----
 .../hadoop/hbase/client/ConnectionUtils.java       |  4 +-
 .../apache/hadoop/hbase/client/FailureInfo.java    |  9 ++-
 .../org/apache/hadoop/hbase/client/HBaseAdmin.java | 11 ++--
 .../apache/hadoop/hbase/client/HConnectable.java   |  2 +-
 .../apache/hadoop/hbase/client/HConnection.java    | 77 +++++++++++++++++-----
 .../hadoop/hbase/client/HConnectionManager.java    | 26 +++++---
 .../org/apache/hadoop/hbase/client/HTable.java     | 25 ++++---
 .../hadoop/hbase/client/HTableMultiplexer.java     | 18 ++---
 .../org/apache/hadoop/hbase/client/MetaCache.java  |  6 +-
 .../apache/hadoop/hbase/client/MetaScanner.java    |  5 +-
 .../apache/hadoop/hbase/client/MultiAction.java    |  3 +-
 .../hadoop/hbase/client/MultiServerCallable.java   |  2 +-
 .../org/apache/hadoop/hbase/client/Mutation.java   |  2 +-
 .../hadoop/hbase/client/RegistryFactory.java       |  7 +-
 .../org/apache/hadoop/hbase/client/Result.java     | 28 ++++----
 .../RetriesExhaustedWithDetailsException.java      |  2 +-
 .../hbase/client/ReversedScannerCallable.java      |  3 +-
 .../hadoop/hbase/client/ScannerCallable.java       |  4 +-
 .../hbase/client/ServerStatisticTracker.java       |  3 +-
 .../hbase/client/UnmodifyableHTableDescriptor.java |  8 ---
 .../apache/hadoop/hbase/client/HTableWrapper.java  | 17 ++++-
 33 files changed, 267 insertions(+), 135 deletions(-)

diff --git a/hbase-annotations/src/main/java/org/apache/hadoop/hbase/classification/InterfaceAudience.java b/hbase-annotations/src/main/java/org/apache/hadoop/hbase/classification/InterfaceAudience.java
index a76b2d9..6e67758 100644
--- a/hbase-annotations/src/main/java/org/apache/hadoop/hbase/classification/InterfaceAudience.java
+++ b/hbase-annotations/src/main/java/org/apache/hadoop/hbase/classification/InterfaceAudience.java
@@ -44,7 +44,7 @@ import java.lang.annotation.RetentionPolicy;
  */
 @InterfaceAudience.Public
 @InterfaceStability.Evolving
-public class InterfaceAudience {
+public final class InterfaceAudience {
   /**
    * Intended for use by any project or application.
    */
diff --git a/hbase-annotations/src/main/java/org/apache/hadoop/hbase/classification/tools/ExcludePrivateAnnotationsStandardDoclet.java b/hbase-annotations/src/main/java/org/apache/hadoop/hbase/classification/tools/ExcludePrivateAnnotationsStandardDoclet.java
index f93e13f..221f730 100644
--- a/hbase-annotations/src/main/java/org/apache/hadoop/hbase/classification/tools/ExcludePrivateAnnotationsStandardDoclet.java
+++ b/hbase-annotations/src/main/java/org/apache/hadoop/hbase/classification/tools/ExcludePrivateAnnotationsStandardDoclet.java
@@ -31,7 +31,9 @@ import com.sun.tools.doclets.standard.Standard;
  * It delegates to the Standard Doclet, and takes the same options.
  */
 @InterfaceAudience.Private
-public class ExcludePrivateAnnotationsStandardDoclet {
+public final class ExcludePrivateAnnotationsStandardDoclet {
+
+  private ExcludePrivateAnnotationsStandardDoclet() {}
 
   public static LanguageVersion languageVersion() {
     return LanguageVersion.JAVA_1_5;
diff --git a/hbase-annotations/src/main/java/org/apache/hadoop/hbase/classification/tools/IncludePublicAnnotationsStandardDoclet.java b/hbase-annotations/src/main/java/org/apache/hadoop/hbase/classification/tools/IncludePublicAnnotationsStandardDoclet.java
index def4f1a..5f1079e 100644
--- a/hbase-annotations/src/main/java/org/apache/hadoop/hbase/classification/tools/IncludePublicAnnotationsStandardDoclet.java
+++ b/hbase-annotations/src/main/java/org/apache/hadoop/hbase/classification/tools/IncludePublicAnnotationsStandardDoclet.java
@@ -36,7 +36,9 @@ import com.sun.tools.doclets.standard.Standard;
  * It delegates to the Standard Doclet, and takes the same options.
  */
 @InterfaceAudience.Private
-public class IncludePublicAnnotationsStandardDoclet {
+public final class IncludePublicAnnotationsStandardDoclet {
+
+  private IncludePublicAnnotationsStandardDoclet() {}
 
   public static LanguageVersion languageVersion() {
     return LanguageVersion.JAVA_1_5;
diff --git a/hbase-annotations/src/main/java/org/apache/hadoop/hbase/classification/tools/RootDocProcessor.java b/hbase-annotations/src/main/java/org/apache/hadoop/hbase/classification/tools/RootDocProcessor.java
index 2ea1022..97d9343 100644
--- a/hbase-annotations/src/main/java/org/apache/hadoop/hbase/classification/tools/RootDocProcessor.java
+++ b/hbase-annotations/src/main/java/org/apache/hadoop/hbase/classification/tools/RootDocProcessor.java
@@ -47,11 +47,13 @@ import org.apache.hadoop.hbase.classification.InterfaceStability;
  * <p>
  * Based on code from http://www.sixlegs.com/blog/java/exclude-javadoc-tag.html.
  */
-class RootDocProcessor {
+final class RootDocProcessor {
 
   static String stability = StabilityOptions.UNSTABLE_OPTION;
   static boolean treatUnannotatedClassesAsPrivate = false;
 
+  private RootDocProcessor() {}
+
   public static RootDoc process(RootDoc root) {
     return (RootDoc) process(root, RootDoc.class);
   }
@@ -215,7 +217,9 @@ class RootDocProcessor {
     }
 
     private Object unwrap(Object proxy) {
-      if (proxy instanceof Proxy) return ((ExcludeHandler) Proxy.getInvocationHandler(proxy)).target;
+      if (proxy instanceof Proxy) {
+        return ((ExcludeHandler) Proxy.getInvocationHandler(proxy)).target;
+      }
       return proxy;
     }
 
diff --git a/hbase-annotations/src/main/java/org/apache/hadoop/hbase/classification/tools/StabilityOptions.java b/hbase-annotations/src/main/java/org/apache/hadoop/hbase/classification/tools/StabilityOptions.java
index 809d96c..71af5d2 100644
--- a/hbase-annotations/src/main/java/org/apache/hadoop/hbase/classification/tools/StabilityOptions.java
+++ b/hbase-annotations/src/main/java/org/apache/hadoop/hbase/classification/tools/StabilityOptions.java
@@ -22,7 +22,10 @@ import com.sun.javadoc.DocErrorReporter;
 import java.util.ArrayList;
 import java.util.List;
 
-class StabilityOptions {
+final class StabilityOptions {
+
+  private StabilityOptions() {}
+
   public static final String STABLE_OPTION = "-stable";
   public static final String EVOLVING_OPTION = "-evolving";
   public static final String UNSTABLE_OPTION = "-unstable";
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncProcess.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncProcess.java
index 8b1db8f..826c91f 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncProcess.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncProcess.java
@@ -127,7 +127,7 @@ class AsyncProcess {
 
   /** Return value from a submit that didn't contain any requests. */
   private static final AsyncRequestFuture NO_REQS_RESULT = new AsyncRequestFuture() {
-    public final Object[] result = new Object[0];
+    final Object[] result = new Object[0];
     @Override
     public boolean hasError() { return false; }
     @Override
@@ -243,7 +243,8 @@ class AsyncProcess {
   }
 
   public AsyncProcess(ClusterConnection hc, Configuration conf, ExecutorService pool,
-      RpcRetryingCallerFactory rpcCaller, boolean useGlobalErrors, RpcControllerFactory rpcFactory) {
+      RpcRetryingCallerFactory rpcCaller, boolean useGlobalErrors,
+      RpcControllerFactory rpcFactory) {
     if (hc == null) {
       throw new IllegalArgumentException("HConnection cannot be null.");
     }
@@ -311,7 +312,7 @@ class AsyncProcess {
   }
 
   /**
-   * See {@link #submit(ExecutorService, TableName, List, boolean, org.apache.hadoop.hbase.client.coprocessor.Batch.Callback, boolean)}.
+   * See {@link #submit(ExecutorService, TableName, List, boolean, Batch.Callback, boolean)}.
    * Uses default ExecutorService for this AP (must have been created with one).
    */
   public <CResult> AsyncRequestFuture submit(TableName tableName, List<? extends Row> rows,
@@ -514,7 +515,7 @@ class AsyncProcess {
   }
 
   /**
-   * See {@link #submitAll(ExecutorService, TableName, List, org.apache.hadoop.hbase.client.coprocessor.Batch.Callback, Object[])}.
+   * See {@link #submitAll(ExecutorService, TableName, List, Batch.Callback, Object[])}.
    * Uses default ExecutorService for this AP (must have been created with one).
    */
   public <CResult> AsyncRequestFuture submitAll(TableName tableName,
@@ -1345,11 +1346,11 @@ class AsyncProcess {
       if (results == null) {
          decActionCounter(index);
          return; // Simple case, no replica requests.
-      } else if ((state = trySetResultSimple(
-          index, action.getAction(), false, result, null, isStale)) == null) {
+      }
+      state = trySetResultSimple(index, action.getAction(), false, result, null, isStale);
+      if (state == null) {
         return; // Simple case, no replica requests.
       }
-      assert state != null;
       // At this point we know that state is set to replica tracking class.
       // It could be that someone else is also looking at it; however, we know there can
       // only be one state object, and only one thread can set callCount to 0. Other threads
@@ -1385,11 +1386,11 @@ class AsyncProcess {
         errors.add(throwable, row, server);
         decActionCounter(index);
         return; // Simple case, no replica requests.
-      } else if ((state = trySetResultSimple(
-          index, row, true, throwable, server, false)) == null) {
+      }
+      state = trySetResultSimple(index, row, true, throwable, server, false);
+      if (state == null) {
         return; // Simple case, no replica requests.
       }
-      assert state != null;
       BatchErrors target = null; // Error will be added to final errors, or temp replica errors.
       boolean isActionDone = false;
       synchronized (state) {
@@ -1455,7 +1456,8 @@ class AsyncProcess {
         results[index] = result;
       } else {
         synchronized (replicaResultLock) {
-          if ((resObj = results[index]) == null) {
+          resObj = results[index];
+          if (resObj == null) {
             if (isFromReplica) {
               throw new AssertionError("Unexpected stale result for " + row);
             }
@@ -1720,7 +1722,8 @@ class AsyncProcess {
   }
 
   /**
-   * For manageError. Only used to make logging more clear, we don't actually care why we don't retry.
+   * For {@link AsyncRequestFutureImpl#manageError(int, Row, Retry, Throwable, ServerName)}. Only
+   * used to make logging more clear, we don't actually care why we don't retry.
    */
   private enum Retry {
     YES,
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientIdGenerator.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientIdGenerator.java
index ac6c82e..7c859a1 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientIdGenerator.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientIdGenerator.java
@@ -32,9 +32,11 @@ import org.apache.hadoop.hbase.util.Bytes;
  * such as an IP address, PID, and composite deterministic ID.
  */
 @InterfaceAudience.Private
-class ClientIdGenerator {
+final class ClientIdGenerator {
   static final Log LOG = LogFactory.getLog(ClientIdGenerator.class);
 
+  private ClientIdGenerator() {}
+
   /**
    * @return a unique ID incorporating IP address, PID, TID and timer. Might be an overkill...
    * Note though that new UUID in java by default is just a random number.
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java
index afc9bc4..d31642a 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java
@@ -465,9 +465,12 @@ public class ClientScanner extends AbstractClientScanner {
            // We used to catch this error, interpret, and rethrow. However, we
            // have since decided that it's not nice for a scanner's close to
            // throw exceptions. Chances are it was just due to lease time out.
+          if (LOG.isDebugEnabled()) {
+            LOG.debug("scanner failed to close", e);
+          }
         } catch (IOException e) {
-           /* An exception other than UnknownScanner is unexpected. */
-           LOG.warn("scanner failed to close. Exception follows: " + e);
+          /* An exception other than UnknownScanner is unexpected. */
+          LOG.warn("scanner failed to close.", e);
         }
         callable = null;
       }
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientSmallReversedScanner.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientSmallReversedScanner.java
index 86ff424..35b3d88 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientSmallReversedScanner.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientSmallReversedScanner.java
@@ -62,7 +62,8 @@ public class ClientSmallReversedScanner extends ReversedClientScanner {
       final TableName tableName, ClusterConnection connection,
       RpcRetryingCallerFactory rpcFactory, RpcControllerFactory controllerFactory,
       ExecutorService pool, int primaryOperationTimeout) throws IOException {
-    super(conf, scan, tableName, connection, rpcFactory, controllerFactory, pool, primaryOperationTimeout);
+    super(conf, scan, tableName, connection, rpcFactory, controllerFactory, pool,
+        primaryOperationTimeout);
   }
 
   /**
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClusterConnection.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClusterConnection.java
index 45b99eb..f0398f9 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClusterConnection.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClusterConnection.java
@@ -40,8 +40,10 @@ import org.apache.hadoop.hbase.protobuf.generated.MasterProtos.MasterService;
 // classes and unit tests only.
 public interface ClusterConnection extends HConnection {
 
-  /** @return - true if the master server is running
-   * @deprecated this has been deprecated without a replacement */
+  /**
+   * @return - true if the master server is running
+   * @deprecated this has been deprecated without a replacement
+   */
   @Override
   @Deprecated
   boolean isMasterRunning()
@@ -194,8 +196,8 @@ public interface ClusterConnection extends HConnection {
   * @return region locations for this row.
   * @throws IOException
   */
- RegionLocations locateRegion(TableName tableName,
-                              byte[] row, boolean useCache, boolean retry, int replicaId) throws IOException;
+ RegionLocations locateRegion(TableName tableName, byte[] row, boolean useCache, boolean retry,
+     int replicaId) throws IOException;
 
   /**
    * Returns a {@link MasterKeepAliveConnection} to the active master
@@ -250,6 +252,7 @@ public interface ClusterConnection extends HConnection {
    * connection.
    * @return The shared instance. Never returns null.
    * @throws MasterNotRunningException
+   * @deprecated Since 0.96.0
    */
   @Override
   @Deprecated
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClusterStatusListener.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClusterStatusListener.java
index 2e2ea65..5756232 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClusterStatusListener.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClusterStatusListener.java
@@ -37,7 +37,6 @@ import java.lang.reflect.Constructor;
 import java.lang.reflect.InvocationTargetException;
 import java.net.InetAddress;
 import java.net.NetworkInterface;
-import java.net.Inet6Address;
 import java.net.UnknownHostException;
 import java.util.ArrayList;
 import java.util.List;
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ConnectionManager.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ConnectionManager.java
index 5db92eb..166bcdd 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ConnectionManager.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ConnectionManager.java
@@ -189,7 +189,7 @@ import com.google.protobuf.ServiceException;
 @SuppressWarnings("serial")
 @InterfaceAudience.Private
 // NOTE: DO NOT make this class public. It was made package-private on purpose.
-class ConnectionManager {
+final class ConnectionManager {
   static final Log LOG = LogFactory.getLog(ConnectionManager.class);
 
   public static final String RETRIES_BY_SERVER_KEY = "hbase.client.retries.by.server";
@@ -269,6 +269,7 @@ class ConnectionManager {
    * @param conf configuration
    * @return HConnection object for <code>conf</code>
    * @throws ZooKeeperConnectionException
+   * @deprecated connection caching is going away.
    */
   @Deprecated
   public static HConnection getConnection(final Configuration conf) throws IOException {
@@ -400,6 +401,9 @@ class ConnectionManager {
     return createConnection(conf, false, pool, user);
   }
 
+  /**
+   * @deprecated instead use one of the {@link ConnectionFactory#createConnection()} methods.
+   */
   @Deprecated
   static HConnection createConnection(final Configuration conf, final boolean managed)
       throws IOException {
@@ -407,6 +411,9 @@ class ConnectionManager {
     return createConnection(conf, managed, null, provider.getCurrent());
   }
 
+  /**
+   * @deprecated instead use one of the {@link ConnectionFactory#createConnection()} methods.
+   */
   @Deprecated
   static ClusterConnection createConnection(final Configuration conf, final boolean managed,
       final ExecutorService pool, final User user)
@@ -420,7 +427,7 @@ class ConnectionManager {
    * then close connection to the zookeeper ensemble and let go of all associated resources.
    *
    * @param conf configuration whose identity is used to find {@link HConnection} instance.
-   * @deprecated
+   * @deprecated connection caching is going away.
    */
   @Deprecated
   public static void deleteConnection(Configuration conf) {
@@ -432,7 +439,7 @@ class ConnectionManager {
    * This will then close connection to the zookeeper ensemble and let go of all resources.
    *
    * @param connection
-   * @deprecated
+   * @deprecated connection caching is going away.
    */
   @Deprecated
   public static void deleteStaleConnection(HConnection connection) {
@@ -443,7 +450,7 @@ class ConnectionManager {
    * Delete information for all connections. Close or not the connection, depending on the
    *  staleConnection boolean and the ref count. By default, you should use it with
    *  staleConnection to true.
-   * @deprecated
+   * @deprecated connection caching is going away.
    */
   @Deprecated
   public static void deleteAllConnections(boolean staleConnection) {
@@ -466,7 +473,9 @@ class ConnectionManager {
     deleteAllConnections(false);
   }
 
-
+  /**
+   * @deprecated connection caching is going away.
+ 