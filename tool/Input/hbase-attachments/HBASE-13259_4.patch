From a43803020dfe37a8ae5fbbcbbc9685c2a40cfdf1 Mon Sep 17 00:00:00 2001
From: Zee <zee@localhost.localdomain>
Date: Tue, 17 Mar 2015 12:08:19 -0700
Subject: [PATCH] mmap based IOEngine.

---
 .../apache/hadoop/hbase/util/ByteBufferArray.java  |  68 ++++++++++++-
 .../hadoop/hbase/io/hfile/bucket/BucketCache.java  |   2 +
 .../hbase/io/hfile/bucket/FileMmapEngine.java      | 108 +++++++++++++++++++++
 .../hbase/io/hfile/bucket/TestFileMmapEngine.java  |  65 +++++++++++++
 4 files changed, 238 insertions(+), 5 deletions(-)
 create mode 100644 hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/FileMmapEngine.java
 create mode 100644 hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/bucket/TestFileMmapEngine.java

diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/util/ByteBufferArray.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/util/ByteBufferArray.java
index 3d6d260..4e045d3 100644
--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/util/ByteBufferArray.java
+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/util/ByteBufferArray.java
@@ -18,6 +18,9 @@
  */
 package org.apache.hadoop.hbase.util;
 
+import java.io.IOException;
+import java.io.RandomAccessFile;
+import java.nio.channels.FileChannel;
 import java.nio.ByteBuffer;
 import java.util.concurrent.locks.Lock;
 import java.util.concurrent.locks.ReentrantLock;
@@ -37,6 +40,7 @@ public final class ByteBufferArray {
   static final Log LOG = LogFactory.getLog(ByteBufferArray.class);
 
   static final int DEFAULT_BUFFER_SIZE = 4 * 1024 * 1024;
+  private FileChannel fileChannel;
   private ByteBuffer buffers[];
   private Lock locks[];
   private int bufferSize;
@@ -49,8 +53,42 @@ public final class ByteBufferArray {
    * @param capacity total size of the byte buffer array
    * @param directByteBuffer true if we allocate direct buffer
    */
-  public ByteBufferArray(long capacity, boolean directByteBuffer) {
+  public ByteBufferArray(long capacity, boolean directByteBuffer) throws IOException {
+    this(capacity, directByteBuffer, null);
+  }
+
+  /**
+   * We allocate a number of byte buffers as the capacity. In order not to out
+   * of the array bounds for the last byte(see {@link ByteBufferArray#multiple}), 
+   * we will allocate one additional buffer with capacity 0;
+   * @param capacity total size of the byte buffer array
+   * @param directByteBuffer true if we allocate direct buffer
+   * @param filePath file to mmap() as backing store
+   */
+  public ByteBufferArray(long capacity, boolean directByteBuffer, String filePath) throws IOException {
     this.bufferSize = DEFAULT_BUFFER_SIZE;
+
+    if (filePath != null) {
+      long fileSize = 0;
+      RandomAccessFile raf = null;
+      try {
+        raf = new RandomAccessFile(filePath, "rw");
+        fileSize = roundUp(capacity, bufferSize);
+        raf.setLength(fileSize);
+        fileChannel = raf.getChannel();
+        LOG.info("Allocating " + StringUtils.byteDesc(fileSize)
+            + ", on the path:" + filePath);
+      } catch (java.io.FileNotFoundException fex) {
+        LOG.error("Can't create bucket cache file " + filePath, fex);
+        throw fex;
+      } catch (IOException ioex) {
+        LOG.error("Can't extend bucket cache file; insufficient space for "
+            + StringUtils.byteDesc(fileSize), ioex);
+        if (raf != null) raf.close();
+        throw ioex;
+      }
+    }
+
     if (this.bufferSize > (capacity / 16))
       this.bufferSize = (int) roundUp(capacity / 16, 32768);
     this.bufferCount = (int) (roundUp(capacity, bufferSize) / bufferSize);
@@ -62,12 +100,21 @@ public final class ByteBufferArray {
     for (int i = 0; i <= bufferCount; i++) {
       locks[i] = new ReentrantLock();
       if (i < bufferCount) {
-        buffers[i] = directByteBuffer ? ByteBuffer.allocateDirect(bufferSize)
-            : ByteBuffer.allocate(bufferSize);
+        if (fileChannel != null) {
+          buffers[i] = fileChannel.map(java.nio.channels.FileChannel.MapMode.READ_WRITE, i*(long)bufferSize, (long)bufferSize);
+          LOG.debug("MappedByteBuffer: " + buffers[i].toString());
+        } else {
+          buffers[i] = directByteBuffer ? ByteBuffer.allocateDirect(bufferSize)
+              : ByteBuffer.allocate(bufferSize);
+        }
       } else {
-        buffers[i] = ByteBuffer.allocate(0);
+        if (fileChannel != null) {
+          buffers[i] = fileChannel.map(java.nio.channels.FileChannel.MapMode.READ_WRITE, i*(long)bufferSize, 0);
+          LOG.info("MappedByteBuffer: " + buffers[i].toString());
+        } else {
+          buffers[i] = ByteBuffer.allocate(0);
+        }
       }
-
     }
   }
 
@@ -76,6 +123,17 @@ public final class ByteBufferArray {
   }
 
   /**
+   * Force all the changes made to the buffer array back to the backing store.
+   */
+  public void sync() {
+    if (fileChannel != null) {
+      for (ByteBuffer bb : buffers) {
+        ((java.nio.MappedByteBuffer)bb).force();
+      }
+    }
+  }
+
+  /**
    * Transfers bytes from this buffer array into the given destination array
    * @param start start position in the ByteBufferArray
    * @param len The maximum number of bytes to be written to the given array
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java
index 7dda0e6..91a1292 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java
@@ -305,6 +305,8 @@ public class BucketCache implements BlockCache, HeapSize {
       throws IOException {
     if (ioEngineName.startsWith("file:"))
       return new FileIOEngine(ioEngineName.substring(5), capacity);
+    else if (ioEngineName.startsWith("mmap:"))
+      return new FileMmapEngine(ioEngineName.substring(5), capacity);
     else if (ioEngineName.startsWith("offheap"))
       return new ByteBufferIOEngine(capacity, true);
     else if (ioEngineName.startsWith("heap"))
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/FileMmapEngine.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/FileMmapEngine.java
new file mode 100644
index 0000000..bf86fd5
--- /dev/null
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/FileMmapEngine.java
@@ -0,0 +1,108 @@
+/**
+ * Copyright The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements. See the NOTICE file distributed with this
+ * work for additional information regarding copyright ownership. The ASF
+ * licenses this file to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+ * License for the specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.hadoop.hbase.io.hfile.bucket;
+
+import java.io.IOException;
+import java.io.RandomAccessFile;
+import java.nio.ByteBuffer;
+import java.nio.channels.FileChannel;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hbase.classification.InterfaceAudience;
+import org.apache.hadoop.util.StringUtils;
+import org.apache.hadoop.hbase.util.ByteBufferArray;
+
+/**
+ * IO engine that stores data to a file on the local file system.
+ */
+@InterfaceAudience.Private
+public class FileMmapEngine implements IOEngine {
+  static final Log LOG = LogFactory.getLog(FileMmapEngine.class);
+
+  private final String path;
+  private long size;
+  private ByteBufferArray bufferArray;
+
+  public FileMmapEngine(String filePath, long fileSize) throws IOException {
+    this.path = filePath;
+    this.size = fileSize;
+    bufferArray = new ByteBufferArray(fileSize, true, filePath);
+  }
+
+  @Override
+  public String toString() {
+    return "ioengine=" + this.getClass().getSimpleName() + ", path=" + this.path +
+      ", size=" + String.format("%,d", this.size);
+  }
+
+  /**
+   * File IO engine is always able to support persistent storage for the cache
+   * @return true
+   */
+  @Override
+  public boolean isPersistent() {
+    return true;
+  }
+
+  /**
+   * Transfers data from file to the given byte buffer
+   * @param dstBuffer the given byte buffer into which bytes are to be written
+   * @param offset The offset in the file where the first byte to be read
+   * @return number of bytes read
+   * @throws IOException
+   */
+  @Override
+  public int read(ByteBuffer dstBuffer, long offset) throws IOException {
+  	assert dstBuffer.hasArray();
+    return bufferArray.getMultiple(offset, dstBuffer.remaining(), dstBuffer.array(),
+        dstBuffer.arrayOffset());
+  }
+
+  /**
+   * Transfers data from the given byte buffer to file
+   * @param srcBuffer the given byte buffer from which bytes are to be read
+   * @param offset The offset in the file where the first byte to be written
+   * @throws IOException
+   */
+  @Override
+  public void write(ByteBuffer srcBuffer, long offset) throws IOException {
+    assert srcBuffer.hasArray();
+    bufferArray.putMultiple(offset, srcBuffer.remaining(), srcBuffer.array(),
+        srcBuffer.arrayOffset());
+  }
+
+  /**
+   * Sync the data to file after writing
+   * @throws IOException
+   */
+  @Override
+  public void sync() throws IOException {
+    bufferArray.sync();
+  }
+
+  /**
+   * Close the file
+   */
+  @Override
+  public void shutdown() {
+    // Ideally we call ByteBufferArray.close() where we munmap() the segments and close the FileChannel.
+    // For now do nothing.
+  }
+}
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/bucket/TestFileMmapEngine.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/bucket/TestFileMmapEngine.java
new file mode 100644
index 0000000..231a888
--- /dev/null
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/bucket/TestFileMmapEngine.java
@@ -0,0 +1,65 @@
+/**
+ * Copyright The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements. See the NOTICE file distributed with this
+ * work for additional information regarding copyright ownership. The ASF
+ * licenses this file to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+ * License for the specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.hadoop.hbase.io.hfile.bucket;
+
+import static org.junit.Assert.assertTrue;
+
+import java.io.File;
+import java.io.IOException;
+import java.nio.ByteBuffer;
+
+import org.apache.hadoop.hbase.SmallTests;
+import org.apache.hadoop.hbase.io.hfile.bucket.FileMmapEngine;
+import org.junit.Test;
+import org.junit.experimental.categories.Category;
+
+/**
+ * Basic test for {@link FileMmapEngine}
+ */
+@Category(SmallTests.class)
+public class TestFileMmapEngine {
+  @Test
+  public void testFileMmapEngine() throws IOException {
+    int size = 2 * 1024 * 1024; // 2 MB
+    String filePath = "testFileMmapEngine";
+    try {
+      FileMmapEngine fileMmapEngine = new FileMmapEngine(filePath, size);
+      for (int i = 0; i < 50; i++) {
+        int len = (int) Math.floor(Math.random() * 100);
+        long offset = (long) Math.floor(Math.random() * size % (size - len));
+        byte[] data1 = new byte[len];
+        for (int j = 0; j < data1.length; ++j) {
+          data1[j] = (byte) (Math.random() * 255);
+        }
+        byte[] data2 = new byte[len];
+        fileMmapEngine.write(ByteBuffer.wrap(data1), offset);
+        fileMmapEngine.read(ByteBuffer.wrap(data2), offset);
+        for (int j = 0; j < data1.length; ++j) {
+          assertTrue(data1[j] == data2[j]);
+        }
+      }
+    } finally {
+      File file = new File(filePath);
+      if (file.exists()) {
+        file.delete();
+      }
+    }
+
+  }
+}
-- 
1.9.3

