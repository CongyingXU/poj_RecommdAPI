From 760dd439c6f81cd39248be533425ff75e3cf30b2 Mon Sep 17 00:00:00 2001
From: Elliott Clark <eclark@apache.org>
Date: Tue, 15 Dec 2015 15:35:16 -0800
Subject: [PATCH] HBASE-14983 Create metrics for per block type hit/miss ratios

---
 .../hadoop/hbase/io/hfile/MemcachedBlockCache.java |   5 +-
 .../regionserver/MetricsRegionServerSource.java    |  23 +++
 .../regionserver/MetricsRegionServerWrapper.java   |  44 +++++
 .../MetricsRegionServerSourceImpl.java             |  41 +++++
 .../hadoop/hbase/io/hfile/BlockCacheKey.java       |  19 +-
 .../apache/hadoop/hbase/io/hfile/CacheStats.java   | 198 ++++++++++++++++++++-
 .../hadoop/hbase/io/hfile/CombinedBlockCache.java  | 110 ++++++++++++
 .../hadoop/hbase/io/hfile/HFileBlockIndex.java     |   2 +-
 .../hadoop/hbase/io/hfile/HFileReaderImpl.java     |   6 +-
 .../hadoop/hbase/io/hfile/HFileWriterImpl.java     |   4 +-
 .../hadoop/hbase/io/hfile/LruBlockCache.java       |   4 +-
 .../hadoop/hbase/io/hfile/bucket/BucketCache.java  |   6 +-
 .../MetricsRegionServerWrapperImpl.java            | 176 ++++++++++++++++++
 .../hbase/io/hfile/TestCombinedBlockCache.java     |  16 +-
 .../hadoop/hbase/io/hfile/TestLruBlockCache.java   |  44 ++---
 .../MetricsRegionServerWrapperStub.java            | 110 ++++++++++++
 16 files changed, 755 insertions(+), 53 deletions(-)

diff --git a/hbase-external-blockcache/src/main/java/org/apache/hadoop/hbase/io/hfile/MemcachedBlockCache.java b/hbase-external-blockcache/src/main/java/org/apache/hadoop/hbase/io/hfile/MemcachedBlockCache.java
index f820193..e813399 100644
--- a/hbase-external-blockcache/src/main/java/org/apache/hadoop/hbase/io/hfile/MemcachedBlockCache.java
+++ b/hbase-external-blockcache/src/main/java/org/apache/hadoop/hbase/io/hfile/MemcachedBlockCache.java
@@ -149,14 +149,13 @@ public class MemcachedBlockCache implements BlockCache {
       // Update stats if this request doesn't have it turned off 100% of the time
       if (updateCacheMetrics) {
         if (result == null) {
-          cacheStats.miss(caching, cacheKey.isPrimary());
+          cacheStats.miss(caching, cacheKey.isPrimary(), cacheKey.getBlockType());
         } else {
-          cacheStats.hit(caching, cacheKey.isPrimary());
+          cacheStats.hit(caching, cacheKey.isPrimary(), cacheKey.getBlockType());
         }
       }
     }
 
-
     return result;
   }
 
diff --git a/hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSource.java b/hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSource.java
index ee0217a..3bfc2fa 100644
--- a/hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSource.java
+++ b/hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSource.java
@@ -230,6 +230,29 @@ public interface MetricsRegionServerSource extends BaseSource {
   String BLOCK_CACHE_FAILED_INSERTION_COUNT = "blockCacheFailedInsertionCount";
   String BLOCK_CACHE_FAILED_INSERTION_COUNT_DESC = "Number of times that a block cache " +
       "insertion failed. Usually due to size restrictions.";
+  String BLOCK_CACHE_DATA_MISS_COUNT = "blockCacheDataMissCount";
+  String BLOCK_CACHE_ENCODED_DATA_MISS_COUNT = "blockCacheEncodedDataMissCount";
+  String BLOCK_CACHE_LEAF_INDEX_MISS_COUNT = "blockCacheLeafIndexMissCount";
+  String BLOCK_CACHE_BLOOM_CHUNK_MISS_COUNT = "blockCacheBloomChunkMissCount";
+  String BLOCK_CACHE_META_MISS_COUNT = "blockCacheMetaMissCount";
+  String BLOCK_CACHE_ROOT_INDEX_MISS_COUNT = "blockCacheRootIndexMissCount";
+  String BLOCK_CACHE_INTERMEDIATE_INDEX_MISS_COUNT = "blockCacheIntermediateIndexMissCount";
+  String BLOCK_CACHE_FILE_INFO_MISS_COUNT = "blockCacheFileInfoMissCount";
+  String BLOCK_CACHE_GENERAL_BLOOM_META_MISS_COUNT = "blockCacheGeneralBloomMetaMissCount";
+  String BLOCK_CACHE_DELETE_FAMILY_BLOOM_MISS_COUNT = "blockCacheDeleteFamilyBloomMissCount";
+  String BLOCK_CACHE_TRAILER_MISS_COUNT = "blockCacheTrailerMissCount";
+  String BLOCK_CACHE_DATA_HIT_COUNT = "blockCacheDataHitCount";
+  String BLOCK_CACHE_ENCODED_DATA_HIT_COUNT = "blockCacheEncodedDataHitCount";
+  String BLOCK_CACHE_LEAF_INDEX_HIT_COUNT = "blockCacheLeafIndexHitCount";
+  String BLOCK_CACHE_BLOOM_CHUNK_HIT_COUNT = "blockCacheBloomChunkHitCount";
+  String BLOCK_CACHE_META_HIT_COUNT = "blockCacheMetaHitCount";
+  String BLOCK_CACHE_ROOT_INDEX_HIT_COUNT = "blockCacheRootIndexHitCount";
+  String BLOCK_CACHE_INTERMEDIATE_INDEX_HIT_COUNT = "blockCacheIntermediateIndexHitCount";
+  String BLOCK_CACHE_FILE_INFO_HIT_COUNT = "blockCacheFileInfoHitCount";
+  String BLOCK_CACHE_GENERAL_BLOOM_META_HIT_COUNT = "blockCacheGeneralBloomMetaHitCount";
+  String BLOCK_CACHE_DELETE_FAMILY_BLOOM_HIT_COUNT = "blockCacheDeleteFamilyBloomHitCount";
+  String BLOCK_CACHE_TRAILER_HIT_COUNT = "blockCacheTrailerHitCount";
+  
   String RS_START_TIME_NAME = "regionServerStartTime";
   String ZOOKEEPER_QUORUM_NAME = "zookeeperQuorum";
   String SERVER_NAME_NAME = "serverName";
diff --git a/hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerWrapper.java b/hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerWrapper.java
index 02dec8d..29a5022 100644
--- a/hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerWrapper.java
+++ b/hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerWrapper.java
@@ -367,4 +367,48 @@ public interface MetricsRegionServerWrapper {
    * @return Count of requests blocked because the memstore size is larger than blockingMemStoreSize
    */
   long getBlockedRequestsCount();
+
+  long getDataMissCount();
+
+  long getEncodedDataMissCount();
+
+  long getLeafIndexMissCount();
+
+  long getBloomChunkMissCount();
+
+  long getMetaMissCount();
+
+  long getRootIndexMissCount();
+
+  long getIntermediateIndexMissCount();
+
+  long getFileInfoMissCount();
+
+  long getGeneralBloomMetaMissCount();
+
+  long getDeleteFamilyBloomMissCount();
+
+  long getTrailerMissCount();
+
+  long getDataHitCount();
+
+  long getEncodedDataHitCount();
+
+  long getLeafIndexHitCount();
+
+  long getBloomChunkHitCount();
+
+  long getMetaHitCount();
+
+  long getRootIndexHitCount();
+
+  long getIntermediateIndexHitCount();
+
+  long getFileInfoHitCount();
+
+  long getGeneralBloomMetaHitCount();
+
+  long getDeleteFamilyBloomHitCount();
+
+  long getTrailerHitCount();
 }
diff --git a/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java b/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java
index f40811c..db810c9 100644
--- a/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java
+++ b/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java
@@ -36,6 +36,7 @@ public class MetricsRegionServerSourceImpl
     extends BaseSourceImpl implements MetricsRegionServerSource {
 
 
+
   final MetricsRegionServerWrapper rsWrap;
   private final MetricHistogram putHisto;
   private final MetricHistogram deleteHisto;
@@ -229,6 +230,7 @@ public class MetricsRegionServerSourceImpl
               rsWrap.getCompactionQueueSize())
           .addGauge(Interns.info(FLUSH_QUEUE_LENGTH, FLUSH_QUEUE_LENGTH_DESC),
               rsWrap.getFlushQueueSize())
+
           .addGauge(Interns.info(BLOCK_CACHE_FREE_SIZE, BLOCK_CACHE_FREE_DESC),
               rsWrap.getBlockCacheFreeSize())
           .addGauge(Interns.info(BLOCK_CACHE_COUNT, BLOCK_CACHE_COUNT_DESC),
@@ -253,6 +255,45 @@ public class MetricsRegionServerSourceImpl
               BLOCK_CACHE_EXPRESS_HIT_PERCENT_DESC), rsWrap.getBlockCacheHitCachingPercent())
           .addCounter(Interns.info(BLOCK_CACHE_FAILED_INSERTION_COUNT,
               BLOCK_CACHE_FAILED_INSERTION_COUNT_DESC),rsWrap.getBlockCacheFailedInsertions())
+          .addCounter(Interns.info(BLOCK_CACHE_DATA_MISS_COUNT, ""), rsWrap.getDataMissCount())
+          .addCounter(Interns.info(BLOCK_CACHE_ENCODED_DATA_MISS_COUNT, ""),
+              rsWrap.getEncodedDataMissCount())
+          .addCounter(Interns.info(BLOCK_CACHE_LEAF_INDEX_MISS_COUNT, ""),
+              rsWrap.getLeafIndexMissCount())
+          .addCounter(Interns.info(BLOCK_CACHE_BLOOM_CHUNK_MISS_COUNT, ""),
+              rsWrap.getBloomChunkMissCount())
+          .addCounter(Interns.info(BLOCK_CACHE_META_MISS_COUNT, ""), rsWrap.getMetaMissCount())
+          .addCounter(Interns.info(BLOCK_CACHE_ROOT_INDEX_MISS_COUNT, ""),
+              rsWrap.getRootIndexMissCount())
+          .addCounter(Interns.info(BLOCK_CACHE_INTERMEDIATE_INDEX_MISS_COUNT, ""),
+              rsWrap.getIntermediateIndexMissCount())
+          .addCounter(Interns.info(BLOCK_CACHE_FILE_INFO_MISS_COUNT, ""),
+              rsWrap.getFileInfoMissCount())
+          .addCounter(Interns.info(BLOCK_CACHE_GENERAL_BLOOM_META_MISS_COUNT, ""),
+              rsWrap.getGeneralBloomMetaMissCount())
+          .addCounter(Interns.info(BLOCK_CACHE_DELETE_FAMILY_BLOOM_MISS_COUNT, ""),
+              rsWrap.getDeleteFamilyBloomMissCount())
+          .addCounter(Interns.info(BLOCK_CACHE_TRAILER_MISS_COUNT, ""),
+              rsWrap.getTrailerMissCount())
+          .addCounter(Interns.info(BLOCK_CACHE_DATA_HIT_COUNT, ""), rsWrap.getDataHitCount())
+          .addCounter(Interns.info(BLOCK_CACHE_ENCODED_DATA_HIT_COUNT, ""),
+              rsWrap.getEncodedDataHitCount())
+          .addCounter(Interns.info(BLOCK_CACHE_LEAF_INDEX_HIT_COUNT, ""),
+              rsWrap.getLeafIndexHitCount())
+          .addCounter(Interns.info(BLOCK_CACHE_BLOOM_CHUNK_HIT_COUNT, ""),
+              rsWrap.getBloomChunkHitCount())
+          .addCounter(Interns.info(BLOCK_CACHE_META_HIT_COUNT, ""), rsWrap.getMetaHitCount())
+          .addCounter(Interns.info(BLOCK_CACHE_ROOT_INDEX_HIT_COUNT, ""),
+              rsWrap.getRootIndexHitCount())
+          .addCounter(Interns.info(BLOCK_CACHE_INTERMEDIATE_INDEX_HIT_COUNT, ""),
+              rsWrap.getIntermediateIndexHitCount())
+          .addCounter(Interns.info(BLOCK_CACHE_FILE_INFO_HIT_COUNT, ""),
+              rsWrap.getFileInfoHitCount())
+          .addCounter(Interns.info(BLOCK_CACHE_GENERAL_BLOOM_META_HIT_COUNT, ""),
+              rsWrap.getGeneralBloomMetaHitCount())
+          .addCounter(Interns.info(BLOCK_CACHE_DELETE_FAMILY_BLOOM_HIT_COUNT, ""),
+              rsWrap.getDeleteFamilyBloomHitCount())
+          .addCounter(Interns.info(BLOCK_CACHE_TRAILER_HIT_COUNT, ""), rsWrap.getTrailerHitCount())
           .addCounter(Interns.info(UPDATES_BLOCKED_TIME, UPDATES_BLOCKED_DESC),
               rsWrap.getUpdatesBlockedTime())
           .addCounter(Interns.info(FLUSHED_CELLS, FLUSHED_CELLS_DESC),
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/BlockCacheKey.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/BlockCacheKey.java
index 180cbb4..64405de 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/BlockCacheKey.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/BlockCacheKey.java
@@ -30,6 +30,7 @@ public class BlockCacheKey implements HeapSize, java.io.Serializable {
   private static final long serialVersionUID = -5199992013113130534L;
   private final String hfileName;
   private final long offset;
+  private final BlockType blockType;
   private final boolean isPrimaryReplicaBlock;
 
   /**
@@ -38,13 +39,14 @@ public class BlockCacheKey implements HeapSize, java.io.Serializable {
    * @param offset Offset of the block into the file
    */
   public BlockCacheKey(String hfileName, long offset) {
-    this(hfileName, offset, true);
+    this(hfileName, offset, true, BlockType.DATA);
   }
 
-  public BlockCacheKey(String hfileName, long offset, boolean isPrimaryReplica) {
+  public BlockCacheKey(String hfileName, long offset, boolean isPrimaryReplica, BlockType blockType) {
     this.isPrimaryReplicaBlock = isPrimaryReplica;
     this.hfileName = hfileName;
     this.offset = offset;
+    this.blockType = blockType;
   }
 
   @Override
@@ -69,9 +71,12 @@ public class BlockCacheKey implements HeapSize, java.io.Serializable {
     return String.format("%s_%d", hfileName, offset);
   }
 
-  public static final long FIXED_OVERHEAD = ClassSize.align(ClassSize.OBJECT +Bytes.SIZEOF_BOOLEAN +
-          ClassSize.REFERENCE + // this.hfileName
-          Bytes.SIZEOF_LONG);    // this.offset
+  public static final long FIXED_OVERHEAD = ClassSize.align(
+      ClassSize.OBJECT +
+      Bytes.SIZEOF_BOOLEAN +
+      ClassSize.REFERENCE + // this.hfileName
+      ClassSize.REFERENCE + // this.blockType
+      Bytes.SIZEOF_LONG);    // this.offset
 
   /**
    * Strings have two bytes per character due to default Java Unicode encoding
@@ -98,4 +103,8 @@ public class BlockCacheKey implements HeapSize, java.io.Serializable {
   public long getOffset() {
     return offset;
   }
+
+  public BlockType getBlockType() {
+    return blockType;
+  }
 }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/CacheStats.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/CacheStats.java
index fff6585..592d419 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/CacheStats.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/CacheStats.java
@@ -24,6 +24,7 @@ import org.apache.hadoop.hbase.classification.InterfaceAudience;
 
 import com.yammer.metrics.core.Histogram;
 import com.yammer.metrics.core.MetricsRegistry;
+import org.apache.hadoop.yarn.webapp.hamlet.HamletSpec;
 
 /**
  * Class that implements cache metrics.
@@ -77,6 +78,31 @@ public class CacheStats {
   /** The total number of blocks that were not inserted. */
   private final AtomicLong failedInserts = new AtomicLong(0);
 
+  /** Per Block Type Counts */
+  private final AtomicLong dataMissCount = new AtomicLong(0);
+  private final AtomicLong encodedDataMissCount = new AtomicLong(0);
+  private final AtomicLong leafIndexMissCount = new AtomicLong(0);
+  private final AtomicLong bloomChunkMissCount = new AtomicLong(0);
+  private final AtomicLong metaMissCount = new AtomicLong(0);
+  private final AtomicLong rootIndexMissCount = new AtomicLong(0);
+  private final AtomicLong intermediateIndexMissCount = new AtomicLong(0);
+  private final AtomicLong fileInfoMissCount = new AtomicLong(0);
+  private final AtomicLong generalBloomMetaMissCount = new AtomicLong(0);
+  private final AtomicLong deleteFamilyBloomMissCount = new AtomicLong(0);
+  private final AtomicLong trailerMissCount = new AtomicLong(0);
+
+  private final AtomicLong dataHitCount = new AtomicLong(0);
+  private final AtomicLong encodedDataHitCount = new AtomicLong(0);
+  private final AtomicLong leafIndexHitCount = new AtomicLong(0);
+  private final AtomicLong bloomChunkHitCount = new AtomicLong(0);
+  private final AtomicLong metaHitCount = new AtomicLong(0);
+  private final AtomicLong rootIndexHitCount = new AtomicLong(0);
+  private final AtomicLong intermediateIndexHitCount = new AtomicLong(0);
+  private final AtomicLong fileInfoHitCount = new AtomicLong(0);
+  private final AtomicLong generalBloomMetaHitCount = new AtomicLong(0);
+  private final AtomicLong deleteFamilyBloomHitCount = new AtomicLong(0);
+  private final AtomicLong trailerHitCount = new AtomicLong(0);
+
   /** The number of metrics periods to include in window */
   private final int numPeriodsInWindow;
   /** Hit counts for each period in window */
@@ -129,20 +155,94 @@ public class CacheStats {
       ", evictedAgeStdDev=" + snapshot.getStdDev();
   }
 
-  public void miss(boolean caching, boolean primary) {
+  public void miss(boolean caching, boolean primary, BlockType type) {
     missCount.incrementAndGet();
     if (primary) primaryMissCount.incrementAndGet();
     if (caching) missCachingCount.incrementAndGet();
+    if (type == null) {
+      return;
+    }
+    switch (type) {
+      case DATA:
+        dataMissCount.incrementAndGet();
+        break;
+      case ENCODED_DATA:
+        encodedDataMissCount.incrementAndGet();
+        break;
+      case LEAF_INDEX:
+        leafIndexMissCount.incrementAndGet();
+        break;
+      case BLOOM_CHUNK:
+        bloomChunkMissCount.incrementAndGet();
+        break;
+      case META:
+        metaMissCount.incrementAndGet();
+        break;
+      case INTERMEDIATE_INDEX:
+        intermediateIndexMissCount.incrementAndGet();
+        break;
+      case ROOT_INDEX:
+        rootIndexMissCount.incrementAndGet();
+        break;
+      case FILE_INFO:
+        fileInfoMissCount.incrementAndGet();
+        break;
+      case GENERAL_BLOOM_META:
+        generalBloomMetaMissCount.incrementAndGet();
+        break;
+      case DELETE_FAMILY_BLOOM_META:
+        deleteFamilyBloomMissCount.incrementAndGet();
+        break;
+      case TRAILER:
+        trailerMissCount.incrementAndGet();
+        break;
+    }
   }
 
-  public void hit(boolean caching) {
-    hit(caching, true);
-  }
 
-  public void hit(boolean caching, boolean primary) {
+  public void hit(boolean caching, boolean primary, BlockType type) {
     hitCount.incrementAndGet();
     if (primary) primaryHitCount.incrementAndGet();
     if (caching) hitCachingCount.incrementAndGet();
+
+    if (type == null) {
+      return;
+    }
+    switch (type) {
+      case DATA:
+        dataHitCount.incrementAndGet();
+        break;
+      case ENCODED_DATA:
+        encodedDataHitCount.incrementAndGet();
+        break;
+      case LEAF_INDEX:
+        leafIndexHitCount.incrementAndGet();
+        break;
+      case BLOOM_CHUNK:
+        bloomChunkHitCount.incrementAndGet();
+        break;
+      case META:
+        metaHitCount.incrementAndGet();
+        break;
+      case INTERMEDIATE_INDEX:
+        intermediateIndexHitCount.incrementAndGet();
+        break;
+      case ROOT_INDEX:
+        rootIndexHitCount.incrementAndGet();
+        break;
+      case FILE_INFO:
+        fileInfoHitCount.incrementAndGet();
+        break;
+      case GENERAL_BLOOM_META:
+        generalBloomMetaHitCount.incrementAndGet();
+        break;
+      case DELETE_FAMILY_BLOOM_META:
+        deleteFamilyBloomHitCount.incrementAndGet();
+        break;
+      case TRAILER:
+        trailerHitCount.incrementAndGet();
+        break;
+    }
   }
 
   public void evict() {
@@ -161,6 +261,94 @@ public class CacheStats {
     return failedInserts.incrementAndGet();
   }
 
+  public long getDataMissCount() {
+    return dataMissCount.get();
+  }
+
+  public long getEncodedDataMissCount() {
+    return encodedDataMissCount.get();
+  }
+
+  public long getLeafIndexMissCount() {
+    return leafIndexMissCount.get();
+  }
+
+  public long getBloomChunkMissCount() {
+    return bloomChunkMissCount.get();
+  }
+
+  public long getMetaMissCount() {
+    return metaMissCount.get();
+  }
+
+  public long getRootIndexMissCount() {
+    return rootIndexMissCount.get();
+  }
+
+  public long getIntermediateIndexMissCount() {
+    return intermediateIndexMissCount.get();
+  }
+
+  public long getFileInfoMissCount() {
+    return fileInfoMissCount.get();
+  }
+
+  public long getGeneralBloomMetaMissCount() {
+    return generalBloomMetaMissCount.get();
+  }
+
+  public long getDeleteFamilyBloomMissCount() {
+    return deleteFamilyBloomMissCount.get();
+  }
+
+  public long getTrailerMissCount() {
+    return trailerMissCount.get();
+  }
+
+  public long getDataHitCount() {
+    return dataHitCount.get();
+  }
+
+  public long getEncodedDataHitCount() {
+    return encodedDataHitCount.get();
+  }
+
+  public long getLeafIndexHitCount() {
+    return leafIndexHitCount.get();
+  }
+
+  public long getBloomChunkHitCount() {
+    return bloomChunkHitCount.get();
+  }
+
+  public long getMetaHitCount() {
+    return metaHitCount.get();
+  }
+
+  public long getRootIndexHitCount() {
+    return rootIndexHitCount.get();
+  }
+
+  public long getIntermediateIndexHitCount() {
+    return intermediateIndexHitCount.get();
+  }
+
+  public long getFileInfoHitCount() {
+    return fileInfoHitCount.get();
+  }
+
+  public long getGeneralBloomMetaHitCount() {
+    return generalBloomMetaHitCount.get();
+  }
+
+  public long getDeleteFamilyBloomHitCount() {
+    return deleteFamilyBloomHitCount.get();
+  }
+
+  public long getTrailerHitCount() {
+    return trailerHitCount.get();
+  }
+
   public long getRequestCount() {
     return getHitCount() + getMissCount();
   }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/CombinedBlockCache.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/CombinedBlockCache.java
index 22bffee..4d56f66 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/CombinedBlockCache.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/CombinedBlockCache.java
@@ -142,6 +142,116 @@ public class CombinedBlockCache implements ResizableBlockCache, HeapSize {
     }
 
     @Override
+    public long getDataMissCount() {
+      return lruCacheStats.getDataMissCount() + bucketCacheStats.getDataMissCount();
+    }
+
+    @Override
+    public long getEncodedDataMissCount() {
+      return lruCacheStats.getEncodedDataMissCount() + bucketCacheStats.getEncodedDataMissCount();
+    }
+
+    @Override
+    public long getLeafIndexMissCount() {
+      return lruCacheStats.getLeafIndexMissCount() + bucketCacheStats.getLeafIndexMissCount();
+    }
+
+    @Override
+    public long getBloomChunkMissCount() {
+      return lruCacheStats.getBloomChunkMissCount() + bucketCacheStats.getBloomChunkMissCount();
+    }
+
+    @Override
+    public long getMetaMissCount() {
+      return lruCacheStats.getMetaMissCount() + bucketCacheStats.getMetaMissCount();
+    }
+
+    @Override
+    public long getRootIndexMissCount() {
+      return lruCacheStats.getRootIndexMissCount() + bucketCacheStats.getRootIndexMissCount();
+    }
+
+    @Override
+    public long getIntermediateIndexMissCount() {
+      return lruCacheStats.getIntermediateIndexMissCount() + bucketCacheStats.getIntermediateIndexMissCount();
+    }
+
+    @Override
+    public long getFileInfoMissCount() {
+      return lruCacheStats.getFileInfoMissCount() + bucketCacheStats.getFileInfoMissCount();
+    }
+
+    @Override
+    public long getGeneralBloomMetaMissCount() {
+      return lruCacheStats.getGeneralBloomMetaMissCount() + bucketCacheStats.getGeneralBloomMetaMissCount();
+    }
+
+    @Override
+    public long getDeleteFamilyBloomMissCount() {
+      return lruCacheStats.getDeleteFamilyBloomMissCount() + bucketCacheStats.getDeleteFamilyBloomMissCount();
+    }
+
+    @Override
+    public long getTrailerMissCount() {
+      return lruCacheStats.getTrailerMissCount() + bucketCacheStats.getTrailerMissCount();
+    }
+
+    @Override
+    public long getDataHitCount() {
+      return lruCacheStats.getDataHitCount() + bucketCacheStats.getDataHitCount();
+    }
+
+    @Override
+    public long getEncodedDataHitCount() {
+      return lruCacheStats.getEncodedDataHitCount() + bucketCacheStats.getEncodedDataHitCount();
+    }
+
+    @Override
+    public long getLeafIndexHitCount() {
+      return lruCacheStats.getLeafIndexHitCount() + bucketCacheStats.getLeafIndexHitCount();
+    }
+
+    @Override
+    public long getBloomChunkHitCount() {
+      return lruCacheStats.getBloomChunkHitCount() + bucketCacheStats.getBloomChunkHitCount();
+    }
+
+    @Override
+    public long getMetaHitCount() {
+      return lruCacheStats.getMetaHitCount() + bucketCacheStats.getMetaHitCount();
+    }
+
+    @Override
+    public long getRootIndexHitCount() {
+      return lruCacheStats.getRootIndexHitCount() + bucketCacheStats.getRootIndexHitCount();
+    }
+
+    @Override
+    public long getIntermediateIndexHitCount() {
+      return lruCacheStats.getIntermediateIndexHitCount() + bucketCacheStats.getIntermediateIndexHitCount();
+    }
+
+    @Override
+    public long getFileInfoHitCount() {
+      return lruCacheStats.getFileInfoHitCount() + bucketCacheStats.getFileInfoHitCount();
+    }
+
+    @Override
+    public long getGeneralBloomMetaHitCount() {
+      return lruCacheStats.getGeneralBloomMetaHitCount() + bucketCacheStats.getGeneralBloomMetaHitCount();
+    }
+
+    @Override
+    public long getDeleteFamilyBloomHitCount() {
+      return lruCacheStats.getDeleteFamilyBloomHitCount() + bucketCacheStats.getDeleteFamilyBloomHitCount();
+    }
+
+    @Override
+    public long getTrailerHitCount() {
+      return lruCacheStats.getTrailerHitCount() + bucketCacheStats.getTrailerHitCount();
+    }
+
+    @Override
     public long getRequestCount() {
       return lruCacheStats.getRequestCount()
           + bucketCacheStats.getRequestCount();
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlockIndex.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlockIndex.java
index 1bdba3b..bff947e 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlockIndex.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlockIndex.java
@@ -1170,7 +1170,7 @@ public class HFileBlockIndex {
       if (cacheConf != null) {
         HFileBlock blockForCaching = blockWriter.getBlockForCaching(cacheConf);
         cacheConf.getBlockCache().cacheBlock(new BlockCacheKey(nameForCaching,
-          beginOffset), blockForCaching);
+          beginOffset, true, blockForCaching.getBlockType()), blockForCaching);
       }
 
       // Add intermediate index block size
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderImpl.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderImpl.java
index 4e2ca7d..e67b661 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderImpl.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderImpl.java
@@ -351,7 +351,7 @@ public class HFileReaderImpl implements HFile.Reader, Configurable {
     BlockCache blockCache = this.cacheConf.getBlockCache();
     if (blockCache != null && block != null) {
       BlockCacheKey cacheKey = new BlockCacheKey(this.getFileContext().getHFileName(),
-          block.getOffset(), this.isPrimaryReplicaReader());
+          block.getOffset(), this.isPrimaryReplicaReader(), block.getBlockType());
       blockCache.returnBlock(cacheKey, block);
     }
   }
@@ -1409,7 +1409,7 @@ public class HFileReaderImpl implements HFile.Reader, Configurable {
       // Check cache for block. If found return.
       long metaBlockOffset = metaBlockIndexReader.getRootBlockOffset(block);
       BlockCacheKey cacheKey = new BlockCacheKey(name, metaBlockOffset,
-        this.isPrimaryReplicaReader());
+        this.isPrimaryReplicaReader(), BlockType.META);
 
       cacheBlock &= cacheConf.shouldCacheDataOnRead();
       if (cacheConf.isBlockCacheEnabled()) {
@@ -1457,7 +1457,7 @@ public class HFileReaderImpl implements HFile.Reader, Configurable {
     // from doing).
 
     BlockCacheKey cacheKey = new BlockCacheKey(name, dataBlockOffset,
-      this.isPrimaryReplicaReader());
+      this.isPrimaryReplicaReader(), expectedBlockType);
 
     boolean useLock = false;
     IdLock.Entry lockEntry = null;
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterImpl.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterImpl.java
index 66c7f1d..f6938f9 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterImpl.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterImpl.java
@@ -482,7 +482,9 @@ public class HFileWriterImpl implements HFile.Writer {
    */
   private void doCacheOnWrite(long offset) {
     HFileBlock cacheFormatBlock = fsBlockWriter.getBlockForCaching(cacheConf);
-    cacheConf.getBlockCache().cacheBlock(new BlockCacheKey(name, offset), cacheFormatBlock);
+    cacheConf.getBlockCache().cacheBlock(
+        new BlockCacheKey(name, offset, true, cacheFormatBlock.getBlockType()),
+        cacheFormatBlock);
   }
 
   /**
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java
index 68ce16c..837da6e 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java
@@ -438,7 +438,7 @@ public class LruBlockCache implements ResizableBlockCache, HeapSize {
       boolean updateCacheMetrics) {
     LruCachedBlock cb = map.get(cacheKey);
     if (cb == null) {
-      if (!repeat && updateCacheMetrics) stats.miss(caching, cacheKey.isPrimary());
+      if (!repeat && updateCacheMetrics) stats.miss(caching, cacheKey.isPrimary(), cacheKey.getBlockType());
       // If there is another block cache then try and read there.
       // However if this is a retry ( second time in double checked locking )
       // And it's already a miss then the l2 will also be a miss.
@@ -453,7 +453,7 @@ public class LruBlockCache implements ResizableBlockCache, HeapSize {
       }
       return null;
     }
-    if (updateCacheMetrics) stats.hit(caching, cacheKey.isPrimary());
+    if (updateCacheMetrics) stats.hit(caching, cacheKey.isPrimary(), cacheKey.getBlockType());
     cb.access(count.incrementAndGet());
     return cb.getBuffer();
   }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java
index 6024958..244a28f 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java
@@ -401,7 +401,7 @@ public class BucketCache implements BlockCache, HeapSize {
     RAMQueueEntry re = ramCache.get(key);
     if (re != null) {
       if (updateCacheMetrics) {
-        cacheStats.hit(caching, key.isPrimary());
+        cacheStats.hit(caching, key.isPrimary(), key.getBlockType());
       }
       re.access(accessCount.incrementAndGet());
       return re.getData();
@@ -423,7 +423,7 @@ public class BucketCache implements BlockCache, HeapSize {
               bucketEntry.deserializerReference(this.deserialiserMap));
           long timeTaken = System.nanoTime() - start;
           if (updateCacheMetrics) {
-            cacheStats.hit(caching, key.isPrimary());
+            cacheStats.hit(caching, key.isPrimary(), key.getBlockType());
             cacheStats.ioHit(timeTaken);
           }
           if (cachedBlock.getMemoryType() == MemoryType.SHARED) {
@@ -443,7 +443,7 @@ public class BucketCache implements BlockCache, HeapSize {
       }
     }
     if (!repeat && updateCacheMetrics) {
-      cacheStats.miss(caching, key.isPrimary());
+      cacheStats.miss(caching, key.isPrimary(), key.getBlockType());
     }
     return null;
   }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerWrapperImpl.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerWrapperImpl.java
index f3e8916..ae8a0e6 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerWrapperImpl.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerWrapperImpl.java
@@ -748,4 +748,180 @@ class MetricsRegionServerWrapperImpl
   public long getBlockedRequestsCount() {
     return blockedRequestsCount;
   }
+
+  @Override
+  public long getDataMissCount() {
+    if (this.cacheStats == null) {
+      return 0;
+    }
+    return cacheStats.getDataMissCount();
+  }
+
+  @Override
+  public long getEncodedDataMissCount() {
+    if (this.cacheStats == null) {
+      return 0;
+    }
+    return cacheStats.getEncodedDataMissCount();
+  }
+
+  @Override
+  public long getLeafIndexMissCount() {
+    if (this.cacheStats == null) {
+      return 0;
+    }
+    return cacheStats.getLeafIndexMissCount();
+  }
+
+  @Override
+  public long getBloomChunkMissCount() {
+    if (this.cacheStats == null) {
+      return 0;
+    }
+    return cacheStats.getBloomChunkMissCount();
+  }
+
+  @Override
+  public long getMetaMissCount() {
+    if (this.cacheStats == null) {
+      return 0;
+    }
+    return cacheStats.getMetaMissCount();
+  }
+
+  @Override
+  public long getRootIndexMissCount() {
+    if (this.cacheStats == null) {
+      return 0;
+    }
+    return cacheStats.getRootIndexMissCount();
+  }
+
+  @Override
+  public long getIntermediateIndexMissCount() {
+    if (this.cacheStats == null) {
+      return 0;
+    }
+    return cacheStats.getIntermediateIndexMissCount();
+  }
+
+  @Override
+  public long getFileInfoMissCount() {
+    if (this.cacheStats == null) {
+      return 0;
+    }
+    return cacheStats.getFileInfoMissCount();
+  }
+
+  @Override
+  public long getGeneralBloomMetaMissCount() {
+    if (this.cacheStats == null) {
+      return 0;
+    }
+    return cacheStats.getGeneralBloomMetaMissCount();
+  }
+
+  @Override
+  public long getDeleteFamilyBloomMissCount() {
+    if (this.cacheStats == null) {
+      return 0;
+    }
+    return cacheStats.getDeleteFamilyBloomMissCount();
+  }
+
+  @Override
+  public long getTrailerMissCount() {
+    if (this.cacheStats == null) {
+      return 0;
+    }
+    return cacheStats.getTrailerMissCount();
+  }
+
+  @Override
+  public long getDataHitCount() {
+    if (this.cacheStats == null) {
+      return 0;
+    }
+    return cacheStats.getDataHitCount();
+  }
+
+  @Override
+  public long getEncodedDataHitCount() {
+    if (this.cacheStats == null) {
+      return 0;
+    }
+    return cacheStats.getEncodedDataHitCount();
+  }
+
+  @Override
+  public long getLeafIndexHitCount() {
+    if (this.cacheStats == null) {
+      return 0;
+    }
+    return cacheStats.getLeafIndexHitCount();
+  }
+
+  @Override
+  public long getBloomChunkHitCount() {
+    if (this.cacheStats == null) {
+      return 0;
+    }
+    return cacheStats.getBloomChunkHitCount();
+  }
+
+  @Override
+  public long getMetaHitCount() {
+    if (this.cacheStats == null) {
+      return 0;
+    }
+    return cacheStats.getMetaHitCount();
+  }
+
+  @Override
+  public long getRootIndexHitCount() {
+    if (this.cacheStats == null) {
+      return 0;
+    }
+    return cacheStats.getRootIndexHitCount();
+  }
+
+  @Override
+  public long getIntermediateIndexHitCount() {
+    if (this.cacheStats == null) {
+      return 0;
+    }
+    return cacheStats.getIntermediateIndexHitCount();
+  }
+
+  @Override
+  public long getFileInfoHitCount() {
+    if (this.cacheStats == null) {
+      return 0;
+    }
+    return cacheStats.getFileInfoHitCount();
+  }
+
+  @Override
+  public long getGeneralBloomMetaHitCount() {
+    if (this.cacheStats == null) {
+      return 0;
+    }
+    return cacheStats.getGeneralBloomMetaHitCount();
+  }
+
+  @Override
+  public long getDeleteFamilyBloomHitCount() {
+    if (this.cacheStats == null) {
+      return 0;
+    }
+    return cacheStats.getDeleteFamilyBloomHitCount();
+  }
+
+  @Override
+  public long getTrailerHitCount() {
+    if (this.cacheStats == null) {
+      return 0;
+    }
+    return cacheStats.getTrailerHitCount();
+  }
 }
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestCombinedBlockCache.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestCombinedBlockCache.java
index 50bf331..8041dff 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestCombinedBlockCache.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestCombinedBlockCache.java
@@ -38,11 +38,11 @@ public class TestCombinedBlockCache {
     // period 1:
     // lru cache: 1 hit caching, 1 miss caching
     // bucket cache: 2 hit non-caching,1 miss non-caching/primary,1 fail insert
-    lruCacheStats.hit(true);
-    lruCacheStats.miss(true, false);
-    bucketCacheStats.hit(false);
-    bucketCacheStats.hit(false);
-    bucketCacheStats.miss(false, true);
+    lruCacheStats.hit(true, true, BlockType.DATA);
+    lruCacheStats.miss(true, false, BlockType.DATA);
+    bucketCacheStats.hit(false,true, BlockType.DATA);
+    bucketCacheStats.hit(false,true, BlockType.DATA);
+    bucketCacheStats.miss(false, true, BlockType.DATA);
     
     assertEquals(5, stats.getRequestCount());
     assertEquals(2, stats.getRequestCachingCount());
@@ -84,9 +84,9 @@ public class TestCombinedBlockCache {
     
     // period 2:
     // lru cache: 3 hit caching
-    lruCacheStats.hit(true);
-    lruCacheStats.hit(true);
-    lruCacheStats.hit(true);
+    lruCacheStats.hit(true, true, BlockType.DATA);
+    lruCacheStats.hit(true, true, BlockType.DATA);
+    lruCacheStats.hit(true, true, BlockType.DATA);
     stats.rollMetricsPeriod();
     assertEquals(6, stats.getSumHitCountsPastNPeriods());
     assertEquals(8, stats.getSumRequestCountsPastNPeriods());
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestLruBlockCache.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestLruBlockCache.java
index 4c0f98f..d7f9aba 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestLruBlockCache.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestLruBlockCache.java
@@ -660,48 +660,48 @@ public class TestLruBlockCache {
 
     // period 1, 1 hit caching, 1 hit non-caching, 2 miss non-caching
     // should be (2/4)=0.5 and (1/1)=1
-    stats.hit(false);
-    stats.hit(true);
-    stats.miss(false, false);
-    stats.miss(false, false);
+    stats.hit(false, true, BlockType.DATA);
+    stats.hit(true, true, BlockType.DATA);
+    stats.miss(false, false, BlockType.DATA);
+    stats.miss(false, false, BlockType.DATA);
     stats.rollMetricsPeriod();
     assertEquals(0.5, stats.getHitRatioPastNPeriods(), delta);
     assertEquals(1.0, stats.getHitCachingRatioPastNPeriods(), delta);
 
     // period 2, 1 miss caching, 3 miss non-caching
     // should be (2/8)=0.25 and (1/2)=0.5
-    stats.miss(true, false);
-    stats.miss(false, false);
-    stats.miss(false, false);
-    stats.miss(false, false);
+    stats.miss(true, false, BlockType.DATA);
+    stats.miss(false, false, BlockType.DATA);
+    stats.miss(false, false, BlockType.DATA);
+    stats.miss(false, false, BlockType.DATA);
     stats.rollMetricsPeriod();
     assertEquals(0.25, stats.getHitRatioPastNPeriods(), delta);
     assertEquals(0.5, stats.getHitCachingRatioPastNPeriods(), delta);
 
     // period 3, 2 hits of each type
     // should be (6/12)=0.5 and (3/4)=0.75
-    stats.hit(false);
-    stats.hit(true);
-    stats.hit(false);
-    stats.hit(true);
+    stats.hit(false, true, BlockType.DATA);
+    stats.hit(true, true, BlockType.DATA);
+    stats.hit(false, true, BlockType.DATA);
+    stats.hit(true, true, BlockType.DATA);
     stats.rollMetricsPeriod();
     assertEquals(0.5, stats.getHitRatioPastNPeriods(), delta);
     assertEquals(0.75, stats.getHitCachingRatioPastNPeriods(), delta);
 
     // period 4, evict period 1, two caching misses
     // should be (4/10)=0.4 and (2/5)=0.4
-    stats.miss(true, false);
-    stats.miss(true, false);
+    stats.miss(true, false, BlockType.DATA);
+    stats.miss(true, false, BlockType.DATA);
     stats.rollMetricsPeriod();
     assertEquals(0.4, stats.getHitRatioPastNPeriods(), delta);
     assertEquals(0.4, stats.getHitCachingRatioPastNPeriods(), delta);
 
     // period 5, evict period 2, 2 caching misses, 2 non-caching hit
     // should be (6/10)=0.6 and (2/6)=1/3
-    stats.miss(true, false);
-    stats.miss(true, false);
-    stats.hit(false);
-    stats.hit(false);
+    stats.miss(true, false, BlockType.DATA);
+    stats.miss(true, false, BlockType.DATA);
+    stats.hit(false, true, BlockType.DATA);
+    stats.hit(false, true, BlockType.DATA);
     stats.rollMetricsPeriod();
     assertEquals(0.6, stats.getHitRatioPastNPeriods(), delta);
     assertEquals((double)1/3, stats.getHitCachingRatioPastNPeriods(), delta);
@@ -726,10 +726,10 @@ public class TestLruBlockCache {
 
     // period 9, one of each
     // should be (2/4)=0.5 and (1/2)=0.5
-    stats.miss(true, false);
-    stats.miss(false, false);
-    stats.hit(true);
-    stats.hit(false);
+    stats.miss(true, false, BlockType.DATA);
+    stats.miss(false, false, BlockType.DATA);
+    stats.hit(true, true, BlockType.DATA);
+    stats.hit(false, true, BlockType.DATA);
     stats.rollMetricsPeriod();
     assertEquals(0.5, stats.getHitRatioPastNPeriods(), delta);
     assertEquals(0.5, stats.getHitCachingRatioPastNPeriods(), delta);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerWrapperStub.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerWrapperStub.java
index 0d93284..d414696 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerWrapperStub.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerWrapperStub.java
@@ -286,6 +286,116 @@ public class MetricsRegionServerWrapperStub implements MetricsRegionServerWrappe
   }
 
   @Override
+  public long getDataMissCount() {
+    return 0;
+  }
+
+  @Override
+  public long getEncodedDataMissCount() {
+    return 0;
+  }
+
+  @Override
+  public long getLeafIndexMissCount() {
+    return 0;
+  }
+
+  @Override
+  public long getBloomChunkMissCount() {
+    return 0;
+  }
+
+  @Override
+  public long getMetaMissCount() {
+    return 0;
+  }
+
+  @Override
+  public long getRootIndexMissCount() {
+    return 0;
+  }
+
+  @Override
+  public long getIntermediateIndexMissCount() {
+    return 0;
+  }
+
+  @Override
+  public long getFileInfoMissCount() {
+    return 0;
+  }
+
+  @Override
+  public long getGeneralBloomMetaMissCount() {
+    return 0;
+  }
+
+  @Override
+  public long getDeleteFamilyBloomMissCount() {
+    return 0;
+  }
+
+  @Override
+  public long getTrailerMissCount() {
+    return 0;
+  }
+
+  @Override
+  public long getDataHitCount() {
+    return 0;
+  }
+
+  @Override
+  public long getEncodedDataHitCount() {
+    return 0;
+  }
+
+  @Override
+  public long getLeafIndexHitCount() {
+    return 0;
+  }
+
+  @Override
+  public long getBloomChunkHitCount() {
+    return 0;
+  }
+
+  @Override
+  public long getMetaHitCount() {
+    return 0;
+  }
+
+  @Override
+  public long getRootIndexHitCount() {
+    return 0;
+  }
+
+  @Override
+  public long getIntermediateIndexHitCount() {
+    return 0;
+  }
+
+  @Override
+  public long getFileInfoHitCount() {
+    return 0;
+  }
+
+  @Override
+  public long getGeneralBloomMetaHitCount() {
+    return 0;
+  }
+
+  @Override
+  public long getDeleteFamilyBloomHitCount() {
+    return 0;
+  }
+
+  @Override
+  public long getTrailerHitCount() {
+    return 0;
+  }
+
+  @Override
   public int getSplitQueueSize() {
     return 0;
   }
-- 
2.6.3

