// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: Quota.proto

package org.apache.hadoop.hbase.protobuf.generated;

public final class QuotaProtos {
  private QuotaProtos() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
  }
  /**
   * Protobuf enum {@code hbase.pb.QuotaScope}
   */
  public enum QuotaScope
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>CLUSTER = 1;</code>
     */
    CLUSTER(0, 1),
    /**
     * <code>MACHINE = 2;</code>
     */
    MACHINE(1, 2),
    ;

    /**
     * <code>CLUSTER = 1;</code>
     */
    public static final int CLUSTER_VALUE = 1;
    /**
     * <code>MACHINE = 2;</code>
     */
    public static final int MACHINE_VALUE = 2;


    public final int getNumber() { return value; }

    public static QuotaScope valueOf(int value) {
      switch (value) {
        case 1: return CLUSTER;
        case 2: return MACHINE;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<QuotaScope>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<QuotaScope>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<QuotaScope>() {
            public QuotaScope findValueByNumber(int number) {
              return QuotaScope.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.getDescriptor().getEnumTypes().get(0);
    }

    private static final QuotaScope[] VALUES = values();

    public static QuotaScope valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private QuotaScope(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.QuotaScope)
  }

  /**
   * Protobuf enum {@code hbase.pb.ThrottleType}
   */
  public enum ThrottleType
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>REQUEST_NUMBER = 1;</code>
     */
    REQUEST_NUMBER(0, 1),
    /**
     * <code>REQUEST_SIZE = 2;</code>
     */
    REQUEST_SIZE(1, 2),
    /**
     * <code>WRITE_NUMBER = 3;</code>
     */
    WRITE_NUMBER(2, 3),
    /**
     * <code>WRITE_SIZE = 4;</code>
     */
    WRITE_SIZE(3, 4),
    /**
     * <code>READ_NUMBER = 5;</code>
     */
    READ_NUMBER(4, 5),
    /**
     * <code>READ_SIZE = 6;</code>
     */
    READ_SIZE(5, 6),
    ;

    /**
     * <code>REQUEST_NUMBER = 1;</code>
     */
    public static final int REQUEST_NUMBER_VALUE = 1;
    /**
     * <code>REQUEST_SIZE = 2;</code>
     */
    public static final int REQUEST_SIZE_VALUE = 2;
    /**
     * <code>WRITE_NUMBER = 3;</code>
     */
    public static final int WRITE_NUMBER_VALUE = 3;
    /**
     * <code>WRITE_SIZE = 4;</code>
     */
    public static final int WRITE_SIZE_VALUE = 4;
    /**
     * <code>READ_NUMBER = 5;</code>
     */
    public static final int READ_NUMBER_VALUE = 5;
    /**
     * <code>READ_SIZE = 6;</code>
     */
    public static final int READ_SIZE_VALUE = 6;


    public final int getNumber() { return value; }

    public static ThrottleType valueOf(int value) {
      switch (value) {
        case 1: return REQUEST_NUMBER;
        case 2: return REQUEST_SIZE;
        case 3: return WRITE_NUMBER;
        case 4: return WRITE_SIZE;
        case 5: return READ_NUMBER;
        case 6: return READ_SIZE;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ThrottleType>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<ThrottleType>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ThrottleType>() {
            public ThrottleType findValueByNumber(int number) {
              return ThrottleType.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.getDescriptor().getEnumTypes().get(1);
    }

    private static final ThrottleType[] VALUES = values();

    public static ThrottleType valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private ThrottleType(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.ThrottleType)
  }

  /**
   * Protobuf enum {@code hbase.pb.QuotaType}
   */
  public enum QuotaType
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>THROTTLE = 1;</code>
     */
    THROTTLE(0, 1),
    /**
     * <code>SPACE = 2;</code>
     */
    SPACE(1, 2),
    ;

    /**
     * <code>THROTTLE = 1;</code>
     */
    public static final int THROTTLE_VALUE = 1;
    /**
     * <code>SPACE = 2;</code>
     */
    public static final int SPACE_VALUE = 2;


    public final int getNumber() { return value; }

    public static QuotaType valueOf(int value) {
      switch (value) {
        case 1: return THROTTLE;
        case 2: return SPACE;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<QuotaType>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<QuotaType>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<QuotaType>() {
            public QuotaType findValueByNumber(int number) {
              return QuotaType.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.getDescriptor().getEnumTypes().get(2);
    }

    private static final QuotaType[] VALUES = values();

    public static QuotaType valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private QuotaType(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.QuotaType)
  }

  /**
   * Protobuf enum {@code hbase.pb.SpaceViolationPolicy}
   *
   * <pre>
   * Defines what action should be taken when the SpaceQuota is violated
   * </pre>
   */
  public enum SpaceViolationPolicy
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>DISABLE = 1;</code>
     *
     * <pre>
     * Disable the table(s)
     * </pre>
     */
    DISABLE(0, 1),
    /**
     * <code>NO_WRITES_COMPACTIONS = 2;</code>
     *
     * <pre>
     * No writes, bulk-loads, or compactions
     * </pre>
     */
    NO_WRITES_COMPACTIONS(1, 2),
    /**
     * <code>NO_WRITES = 3;</code>
     *
     * <pre>
     * No writes or bulk-loads
     * </pre>
     */
    NO_WRITES(2, 3),
    /**
     * <code>NO_INSERTS = 4;</code>
     *
     * <pre>
     * No puts or bulk-loads, but deletes are allowed
     * </pre>
     */
    NO_INSERTS(3, 4),
    ;

    /**
     * <code>DISABLE = 1;</code>
     *
     * <pre>
     * Disable the table(s)
     * </pre>
     */
    public static final int DISABLE_VALUE = 1;
    /**
     * <code>NO_WRITES_COMPACTIONS = 2;</code>
     *
     * <pre>
     * No writes, bulk-loads, or compactions
     * </pre>
     */
    public static final int NO_WRITES_COMPACTIONS_VALUE = 2;
    /**
     * <code>NO_WRITES = 3;</code>
     *
     * <pre>
     * No writes or bulk-loads
     * </pre>
     */
    public static final int NO_WRITES_VALUE = 3;
    /**
     * <code>NO_INSERTS = 4;</code>
     *
     * <pre>
     * No puts or bulk-loads, but deletes are allowed
     * </pre>
     */
    public static final int NO_INSERTS_VALUE = 4;


    public final int getNumber() { return value; }

    public static SpaceViolationPolicy valueOf(int value) {
      switch (value) {
        case 1: return DISABLE;
        case 2: return NO_WRITES_COMPACTIONS;
        case 3: return NO_WRITES;
        case 4: return NO_INSERTS;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<SpaceViolationPolicy>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<SpaceViolationPolicy>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<SpaceViolationPolicy>() {
            public SpaceViolationPolicy findValueByNumber(int number) {
              return SpaceViolationPolicy.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.getDescriptor().getEnumTypes().get(3);
    }

    private static final SpaceViolationPolicy[] VALUES = values();

    public static SpaceViolationPolicy valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private SpaceViolationPolicy(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.SpaceViolationPolicy)
  }

  public interface TimedQuotaOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .hbase.pb.TimeUnit time_unit = 1;
    /**
     * <code>required .hbase.pb.TimeUnit time_unit = 1;</code>
     */
    boolean hasTimeUnit();
    /**
     * <code>required .hbase.pb.TimeUnit time_unit = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeUnit getTimeUnit();

    // optional uint64 soft_limit = 2;
    /**
     * <code>optional uint64 soft_limit = 2;</code>
     */
    boolean hasSoftLimit();
    /**
     * <code>optional uint64 soft_limit = 2;</code>
     */
    long getSoftLimit();

    // optional float share = 3;
    /**
     * <code>optional float share = 3;</code>
     */
    boolean hasShare();
    /**
     * <code>optional float share = 3;</code>
     */
    float getShare();

    // optional .hbase.pb.QuotaScope scope = 4 [default = MACHINE];
    /**
     * <code>optional .hbase.pb.QuotaScope scope = 4 [default = MACHINE];</code>
     */
    boolean hasScope();
    /**
     * <code>optional .hbase.pb.QuotaScope scope = 4 [default = MACHINE];</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaScope getScope();
  }
  /**
   * Protobuf type {@code hbase.pb.TimedQuota}
   */
  public static final class TimedQuota extends
      com.google.protobuf.GeneratedMessage
      implements TimedQuotaOrBuilder {
    // Use TimedQuota.newBuilder() to construct.
    private TimedQuota(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private TimedQuota(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final TimedQuota defaultInstance;
    public static TimedQuota getDefaultInstance() {
      return defaultInstance;
    }

    public TimedQuota getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private TimedQuota(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeUnit value = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeUnit.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                timeUnit_ = value;
              }
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              softLimit_ = input.readUInt64();
              break;
            }
            case 29: {
              bitField0_ |= 0x00000004;
              share_ = input.readFloat();
              break;
            }
            case 32: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaScope value = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaScope.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(4, rawValue);
              } else {
                bitField0_ |= 0x00000008;
                scope_ = value;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_TimedQuota_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_TimedQuota_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder.class);
    }

    public static com.google.protobuf.Parser<TimedQuota> PARSER =
        new com.google.protobuf.AbstractParser<TimedQuota>() {
      public TimedQuota parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new TimedQuota(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<TimedQuota> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required .hbase.pb.TimeUnit time_unit = 1;
    public static final int TIME_UNIT_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeUnit timeUnit_;
    /**
     * <code>required .hbase.pb.TimeUnit time_unit = 1;</code>
     */
    public boolean hasTimeUnit() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.TimeUnit time_unit = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeUnit getTimeUnit() {
      return timeUnit_;
    }

    // optional uint64 soft_limit = 2;
    public static final int SOFT_LIMIT_FIELD_NUMBER = 2;
    private long softLimit_;
    /**
     * <code>optional uint64 soft_limit = 2;</code>
     */
    public boolean hasSoftLimit() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional uint64 soft_limit = 2;</code>
     */
    public long getSoftLimit() {
      return softLimit_;
    }

    // optional float share = 3;
    public static final int SHARE_FIELD_NUMBER = 3;
    private float share_;
    /**
     * <code>optional float share = 3;</code>
     */
    public boolean hasShare() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional float share = 3;</code>
     */
    public float getShare() {
      return share_;
    }

    // optional .hbase.pb.QuotaScope scope = 4 [default = MACHINE];
    public static final int SCOPE_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaScope scope_;
    /**
     * <code>optional .hbase.pb.QuotaScope scope = 4 [default = MACHINE];</code>
     */
    public boolean hasScope() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hbase.pb.QuotaScope scope = 4 [default = MACHINE];</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaScope getScope() {
      return scope_;
    }

    private void initFields() {
      timeUnit_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeUnit.NANOSECONDS;
      softLimit_ = 0L;
      share_ = 0F;
      scope_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaScope.MACHINE;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasTimeUnit()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(1, timeUnit_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeUInt64(2, softLimit_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeFloat(3, share_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeEnum(4, scope_.getNumber());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, timeUnit_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(2, softLimit_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(3, share_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(4, scope_.getNumber());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota other = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota) obj;

      boolean result = true;
      result = result && (hasTimeUnit() == other.hasTimeUnit());
      if (hasTimeUnit()) {
        result = result &&
            (getTimeUnit() == other.getTimeUnit());
      }
      result = result && (hasSoftLimit() == other.hasSoftLimit());
      if (hasSoftLimit()) {
        result = result && (getSoftLimit()
            == other.getSoftLimit());
      }
      result = result && (hasShare() == other.hasShare());
      if (hasShare()) {
        result = result && (Float.floatToIntBits(getShare())    == Float.floatToIntBits(other.getShare()));
      }
      result = result && (hasScope() == other.hasScope());
      if (hasScope()) {
        result = result &&
            (getScope() == other.getScope());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasTimeUnit()) {
        hash = (37 * hash) + TIME_UNIT_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getTimeUnit());
      }
      if (hasSoftLimit()) {
        hash = (37 * hash) + SOFT_LIMIT_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getSoftLimit());
      }
      if (hasShare()) {
        hash = (37 * hash) + SHARE_FIELD_NUMBER;
        hash = (53 * hash) + Float.floatToIntBits(
            getShare());
      }
      if (hasScope()) {
        hash = (37 * hash) + SCOPE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getScope());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.TimedQuota}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_TimedQuota_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_TimedQuota_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        timeUnit_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeUnit.NANOSECONDS;
        bitField0_ = (bitField0_ & ~0x00000001);
        softLimit_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        share_ = 0F;
        bitField0_ = (bitField0_ & ~0x00000004);
        scope_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaScope.MACHINE;
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_TimedQuota_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota build() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota result = new org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.timeUnit_ = timeUnit_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.softLimit_ = softLimit_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.share_ = share_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.scope_ = scope_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance()) return this;
        if (other.hasTimeUnit()) {
          setTimeUnit(other.getTimeUnit());
        }
        if (other.hasSoftLimit()) {
          setSoftLimit(other.getSoftLimit());
        }
        if (other.hasShare()) {
          setShare(other.getShare());
        }
        if (other.hasScope()) {
          setScope(other.getScope());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasTimeUnit()) {

          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .hbase.pb.TimeUnit time_unit = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeUnit timeUnit_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeUnit.NANOSECONDS;
      /**
       * <code>required .hbase.pb.TimeUnit time_unit = 1;</code>
       */
      public boolean hasTimeUnit() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.TimeUnit time_unit = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeUnit getTimeUnit() {
        return timeUnit_;
      }
      /**
       * <code>required .hbase.pb.TimeUnit time_unit = 1;</code>
       */
      public Builder setTimeUnit(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeUnit value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        timeUnit_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TimeUnit time_unit = 1;</code>
       */
      public Builder clearTimeUnit() {
        bitField0_ = (bitField0_ & ~0x00000001);
        timeUnit_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeUnit.NANOSECONDS;
        onChanged();
        return this;
      }

      // optional uint64 soft_limit = 2;
      private long softLimit_ ;
      /**
       * <code>optional uint64 soft_limit = 2;</code>
       */
      public boolean hasSoftLimit() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional uint64 soft_limit = 2;</code>
       */
      public long getSoftLimit() {
        return softLimit_;
      }
      /**
       * <code>optional uint64 soft_limit = 2;</code>
       */
      public Builder setSoftLimit(long value) {
        bitField0_ |= 0x00000002;
        softLimit_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 soft_limit = 2;</code>
       */
      public Builder clearSoftLimit() {
        bitField0_ = (bitField0_ & ~0x00000002);
        softLimit_ = 0L;
        onChanged();
        return this;
      }

      // optional float share = 3;
      private float share_ ;
      /**
       * <code>optional float share = 3;</code>
       */
      public boolean hasShare() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional float share = 3;</code>
       */
      public float getShare() {
        return share_;
      }
      /**
       * <code>optional float share = 3;</code>
       */
      public Builder setShare(float value) {
        bitField0_ |= 0x00000004;
        share_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional float share = 3;</code>
       */
      public Builder clearShare() {
        bitField0_ = (bitField0_ & ~0x00000004);
        share_ = 0F;
        onChanged();
        return this;
      }

      // optional .hbase.pb.QuotaScope scope = 4 [default = MACHINE];
      private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaScope scope_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaScope.MACHINE;
      /**
       * <code>optional .hbase.pb.QuotaScope scope = 4 [default = MACHINE];</code>
       */
      public boolean hasScope() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hbase.pb.QuotaScope scope = 4 [default = MACHINE];</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaScope getScope() {
        return scope_;
      }
      /**
       * <code>optional .hbase.pb.QuotaScope scope = 4 [default = MACHINE];</code>
       */
      public Builder setScope(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaScope value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000008;
        scope_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.QuotaScope scope = 4 [default = MACHINE];</code>
       */
      public Builder clearScope() {
        bitField0_ = (bitField0_ & ~0x00000008);
        scope_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaScope.MACHINE;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.TimedQuota)
    }

    static {
      defaultInstance = new TimedQuota(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.TimedQuota)
  }

  public interface ThrottleOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hbase.pb.TimedQuota req_num = 1;
    /**
     * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
     */
    boolean hasReqNum();
    /**
     * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getReqNum();
    /**
     * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getReqNumOrBuilder();

    // optional .hbase.pb.TimedQuota req_size = 2;
    /**
     * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
     */
    boolean hasReqSize();
    /**
     * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getReqSize();
    /**
     * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getReqSizeOrBuilder();

    // optional .hbase.pb.TimedQuota write_num = 3;
    /**
     * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
     */
    boolean hasWriteNum();
    /**
     * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getWriteNum();
    /**
     * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getWriteNumOrBuilder();

    // optional .hbase.pb.TimedQuota write_size = 4;
    /**
     * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
     */
    boolean hasWriteSize();
    /**
     * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getWriteSize();
    /**
     * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getWriteSizeOrBuilder();

    // optional .hbase.pb.TimedQuota read_num = 5;
    /**
     * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
     */
    boolean hasReadNum();
    /**
     * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getReadNum();
    /**
     * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getReadNumOrBuilder();

    // optional .hbase.pb.TimedQuota read_size = 6;
    /**
     * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
     */
    boolean hasReadSize();
    /**
     * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getReadSize();
    /**
     * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getReadSizeOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.Throttle}
   */
  public static final class Throttle extends
      com.google.protobuf.GeneratedMessage
      implements ThrottleOrBuilder {
    // Use Throttle.newBuilder() to construct.
    private Throttle(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private Throttle(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final Throttle defaultInstance;
    public static Throttle getDefaultInstance() {
      return defaultInstance;
    }

    public Throttle getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private Throttle(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = reqNum_.toBuilder();
              }
              reqNum_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(reqNum_);
                reqNum_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = reqSize_.toBuilder();
              }
              reqSize_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(reqSize_);
                reqSize_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = writeNum_.toBuilder();
              }
              writeNum_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(writeNum_);
                writeNum_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 34: {
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = writeSize_.toBuilder();
              }
              writeSize_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(writeSize_);
                writeSize_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 42: {
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder subBuilder = null;
              if (((bitField0_ & 0x00000010) == 0x00000010)) {
                subBuilder = readNum_.toBuilder();
              }
              readNum_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(readNum_);
                readNum_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000010;
              break;
            }
            case 50: {
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder subBuilder = null;
              if (((bitField0_ & 0x00000020) == 0x00000020)) {
                subBuilder = readSize_.toBuilder();
              }
              readSize_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(readSize_);
                readSize_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000020;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_Throttle_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_Throttle_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.Builder.class);
    }

    public static com.google.protobuf.Parser<Throttle> PARSER =
        new com.google.protobuf.AbstractParser<Throttle>() {
      public Throttle parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Throttle(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<Throttle> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hbase.pb.TimedQuota req_num = 1;
    public static final int REQ_NUM_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota reqNum_;
    /**
     * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
     */
    public boolean hasReqNum() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getReqNum() {
      return reqNum_;
    }
    /**
     * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getReqNumOrBuilder() {
      return reqNum_;
    }

    // optional .hbase.pb.TimedQuota req_size = 2;
    public static final int REQ_SIZE_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota reqSize_;
    /**
     * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
     */
    public boolean hasReqSize() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getReqSize() {
      return reqSize_;
    }
    /**
     * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getReqSizeOrBuilder() {
      return reqSize_;
    }

    // optional .hbase.pb.TimedQuota write_num = 3;
    public static final int WRITE_NUM_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota writeNum_;
    /**
     * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
     */
    public boolean hasWriteNum() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getWriteNum() {
      return writeNum_;
    }
    /**
     * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getWriteNumOrBuilder() {
      return writeNum_;
    }

    // optional .hbase.pb.TimedQuota write_size = 4;
    public static final int WRITE_SIZE_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota writeSize_;
    /**
     * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
     */
    public boolean hasWriteSize() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getWriteSize() {
      return writeSize_;
    }
    /**
     * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getWriteSizeOrBuilder() {
      return writeSize_;
    }

    // optional .hbase.pb.TimedQuota read_num = 5;
    public static final int READ_NUM_FIELD_NUMBER = 5;
    private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota readNum_;
    /**
     * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
     */
    public boolean hasReadNum() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getReadNum() {
      return readNum_;
    }
    /**
     * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getReadNumOrBuilder() {
      return readNum_;
    }

    // optional .hbase.pb.TimedQuota read_size = 6;
    public static final int READ_SIZE_FIELD_NUMBER = 6;
    private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota readSize_;
    /**
     * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
     */
    public boolean hasReadSize() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getReadSize() {
      return readSize_;
    }
    /**
     * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getReadSizeOrBuilder() {
      return readSize_;
    }

    private void initFields() {
      reqNum_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
      reqSize_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
      writeNum_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
      writeSize_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
      readNum_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
      readSize_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (hasReqNum()) {
        if (!getReqNum().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasReqSize()) {
        if (!getReqSize().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasWriteNum()) {
        if (!getWriteNum().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasWriteSize()) {
        if (!getWriteSize().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasReadNum()) {
        if (!getReadNum().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasReadSize()) {
        if (!getReadSize().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, reqNum_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, reqSize_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, writeNum_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, writeSize_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeMessage(5, readNum_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeMessage(6, readSize_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, reqNum_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, reqSize_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, writeNum_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, writeSize_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, readNum_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, readSize_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle other = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle) obj;

      boolean result = true;
      result = result && (hasReqNum() == other.hasReqNum());
      if (hasReqNum()) {
        result = result && getReqNum()
            .equals(other.getReqNum());
      }
      result = result && (hasReqSize() == other.hasReqSize());
      if (hasReqSize()) {
        result = result && getReqSize()
            .equals(other.getReqSize());
      }
      result = result && (hasWriteNum() == other.hasWriteNum());
      if (hasWriteNum()) {
        result = result && getWriteNum()
            .equals(other.getWriteNum());
      }
      result = result && (hasWriteSize() == other.hasWriteSize());
      if (hasWriteSize()) {
        result = result && getWriteSize()
            .equals(other.getWriteSize());
      }
      result = result && (hasReadNum() == other.hasReadNum());
      if (hasReadNum()) {
        result = result && getReadNum()
            .equals(other.getReadNum());
      }
      result = result && (hasReadSize() == other.hasReadSize());
      if (hasReadSize()) {
        result = result && getReadSize()
            .equals(other.getReadSize());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasReqNum()) {
        hash = (37 * hash) + REQ_NUM_FIELD_NUMBER;
        hash = (53 * hash) + getReqNum().hashCode();
      }
      if (hasReqSize()) {
        hash = (37 * hash) + REQ_SIZE_FIELD_NUMBER;
        hash = (53 * hash) + getReqSize().hashCode();
      }
      if (hasWriteNum()) {
        hash = (37 * hash) + WRITE_NUM_FIELD_NUMBER;
        hash = (53 * hash) + getWriteNum().hashCode();
      }
      if (hasWriteSize()) {
        hash = (37 * hash) + WRITE_SIZE_FIELD_NUMBER;
        hash = (53 * hash) + getWriteSize().hashCode();
      }
      if (hasReadNum()) {
        hash = (37 * hash) + READ_NUM_FIELD_NUMBER;
        hash = (53 * hash) + getReadNum().hashCode();
      }
      if (hasReadSize()) {
        hash = (37 * hash) + READ_SIZE_FIELD_NUMBER;
        hash = (53 * hash) + getReadSize().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.Throttle}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_Throttle_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_Throttle_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getReqNumFieldBuilder();
          getReqSizeFieldBuilder();
          getWriteNumFieldBuilder();
          getWriteSizeFieldBuilder();
          getReadNumFieldBuilder();
          getReadSizeFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (reqNumBuilder_ == null) {
          reqNum_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
        } else {
          reqNumBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (reqSizeBuilder_ == null) {
          reqSize_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
        } else {
          reqSizeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (writeNumBuilder_ == null) {
          writeNum_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
        } else {
          writeNumBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        if (writeSizeBuilder_ == null) {
          writeSize_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
        } else {
          writeSizeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        if (readNumBuilder_ == null) {
          readNum_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
        } else {
          readNumBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        if (readSizeBuilder_ == null) {
          readSize_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
        } else {
          readSizeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_Throttle_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle build() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle result = new org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (reqNumBuilder_ == null) {
          result.reqNum_ = reqNum_;
        } else {
          result.reqNum_ = reqNumBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (reqSizeBuilder_ == null) {
          result.reqSize_ = reqSize_;
        } else {
          result.reqSize_ = reqSizeBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (writeNumBuilder_ == null) {
          result.writeNum_ = writeNum_;
        } else {
          result.writeNum_ = writeNumBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (writeSizeBuilder_ == null) {
          result.writeSize_ = writeSize_;
        } else {
          result.writeSize_ = writeSizeBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        if (readNumBuilder_ == null) {
          result.readNum_ = readNum_;
        } else {
          result.readNum_ = readNumBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        if (readSizeBuilder_ == null) {
          result.readSize_ = readSize_;
        } else {
          result.readSize_ = readSizeBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.getDefaultInstance()) return this;
        if (other.hasReqNum()) {
          mergeReqNum(other.getReqNum());
        }
        if (other.hasReqSize()) {
          mergeReqSize(other.getReqSize());
        }
        if (other.hasWriteNum()) {
          mergeWriteNum(other.getWriteNum());
        }
        if (other.hasWriteSize()) {
          mergeWriteSize(other.getWriteSize());
        }
        if (other.hasReadNum()) {
          mergeReadNum(other.getReadNum());
        }
        if (other.hasReadSize()) {
          mergeReadSize(other.getReadSize());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (hasReqNum()) {
          if (!getReqNum().isInitialized()) {

            return false;
          }
        }
        if (hasReqSize()) {
          if (!getReqSize().isInitialized()) {

            return false;
          }
        }
        if (hasWriteNum()) {
          if (!getWriteNum().isInitialized()) {

            return false;
          }
        }
        if (hasWriteSize()) {
          if (!getWriteSize().isInitialized()) {

            return false;
          }
        }
        if (hasReadNum()) {
          if (!getReadNum().isInitialized()) {

            return false;
          }
        }
        if (hasReadSize()) {
          if (!getReadSize().isInitialized()) {

            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hbase.pb.TimedQuota req_num = 1;
      private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota reqNum_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder> reqNumBuilder_;
      /**
       * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
       */
      public boolean hasReqNum() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getReqNum() {
        if (reqNumBuilder_ == null) {
          return reqNum_;
        } else {
          return reqNumBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
       */
      public Builder setReqNum(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (reqNumBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          reqNum_ = value;
          onChanged();
        } else {
          reqNumBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
       */
      public Builder setReqNum(
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder builderForValue) {
        if (reqNumBuilder_ == null) {
          reqNum_ = builderForValue.build();
          onChanged();
        } else {
          reqNumBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
       */
      public Builder mergeReqNum(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (reqNumBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              reqNum_ != org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance()) {
            reqNum_ =
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.newBuilder(reqNum_).mergeFrom(value).buildPartial();
          } else {
            reqNum_ = value;
          }
          onChanged();
        } else {
          reqNumBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
       */
      public Builder clearReqNum() {
        if (reqNumBuilder_ == null) {
          reqNum_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
          onChanged();
        } else {
          reqNumBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder getReqNumBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getReqNumFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getReqNumOrBuilder() {
        if (reqNumBuilder_ != null) {
          return reqNumBuilder_.getMessageOrBuilder();
        } else {
          return reqNum_;
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder>
          getReqNumFieldBuilder() {
        if (reqNumBuilder_ == null) {
          reqNumBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder>(
                  reqNum_,
                  getParentForChildren(),
                  isClean());
          reqNum_ = null;
        }
        return reqNumBuilder_;
      }

      // optional .hbase.pb.TimedQuota req_size = 2;
      private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota reqSize_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder> reqSizeBuilder_;
      /**
       * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
       */
      public boolean hasReqSize() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getReqSize() {
        if (reqSizeBuilder_ == null) {
          return reqSize_;
        } else {
          return reqSizeBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
       */
      public Builder setReqSize(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (reqSizeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          reqSize_ = value;
          onChanged();
        } else {
          reqSizeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
       */
      public Builder setReqSize(
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder builderForValue) {
        if (reqSizeBuilder_ == null) {
          reqSize_ = builderForValue.build();
          onChanged();
        } else {
          reqSizeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
       */
      public Builder mergeReqSize(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (reqSizeBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              reqSize_ != org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance()) {
            reqSize_ =
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.newBuilder(reqSize_).mergeFrom(value).buildPartial();
          } else {
            reqSize_ = value;
          }
          onChanged();
        } else {
          reqSizeBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
       */
      public Builder clearReqSize() {
        if (reqSizeBuilder_ == null) {
          reqSize_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
          onChanged();
        } else {
          reqSizeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder getReqSizeBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getReqSizeFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getReqSizeOrBuilder() {
        if (reqSizeBuilder_ != null) {
          return reqSizeBuilder_.getMessageOrBuilder();
        } else {
          return reqSize_;
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder>
          getReqSizeFieldBuilder() {
        if (reqSizeBuilder_ == null) {
          reqSizeBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder>(
                  reqSize_,
                  getParentForChildren(),
                  isClean());
          reqSize_ = null;
        }
        return reqSizeBuilder_;
      }

      // optional .hbase.pb.TimedQuota write_num = 3;
      private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota writeNum_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder> writeNumBuilder_;
      /**
       * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
       */
      public boolean hasWriteNum() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getWriteNum() {
        if (writeNumBuilder_ == null) {
          return writeNum_;
        } else {
          return writeNumBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
       */
      public Builder setWriteNum(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (writeNumBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          writeNum_ = value;
          onChanged();
        } else {
          writeNumBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
       */
      public Builder setWriteNum(
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder builderForValue) {
        if (writeNumBuilder_ == null) {
          writeNum_ = builderForValue.build();
          onChanged();
        } else {
          writeNumBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
       */
      public Builder mergeWriteNum(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (writeNumBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              writeNum_ != org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance()) {
            writeNum_ =
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.newBuilder(writeNum_).mergeFrom(value).buildPartial();
          } else {
            writeNum_ = value;
          }
          onChanged();
        } else {
          writeNumBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
       */
      public Builder clearWriteNum() {
        if (writeNumBuilder_ == null) {
          writeNum_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
          onChanged();
        } else {
          writeNumBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder getWriteNumBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getWriteNumFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getWriteNumOrBuilder() {
        if (writeNumBuilder_ != null) {
          return writeNumBuilder_.getMessageOrBuilder();
        } else {
          return writeNum_;
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder>
          getWriteNumFieldBuilder() {
        if (writeNumBuilder_ == null) {
          writeNumBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder>(
                  writeNum_,
                  getParentForChildren(),
                  isClean());
          writeNum_ = null;
        }
        return writeNumBuilder_;
      }

      // optional .hbase.pb.TimedQuota write_size = 4;
      private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota writeSize_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder> writeSizeBuilder_;
      /**
       * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
       */
      public boolean hasWriteSize() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getWriteSize() {
        if (writeSizeBuilder_ == null) {
          return writeSize_;
        } else {
          return writeSizeBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
       */
      public Builder setWriteSize(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (writeSizeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          writeSize_ = value;
          onChanged();
        } else {
          writeSizeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
       */
      public Builder setWriteSize(
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder builderForValue) {
        if (writeSizeBuilder_ == null) {
          writeSize_ = builderForValue.build();
          onChanged();
        } else {
          writeSizeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
       */
      public Builder mergeWriteSize(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (writeSizeBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              writeSize_ != org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance()) {
            writeSize_ =
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.newBuilder(writeSize_).mergeFrom(value).buildPartial();
          } else {
            writeSize_ = value;
          }
          onChanged();
        } else {
          writeSizeBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
       */
      public Builder clearWriteSize() {
        if (writeSizeBuilder_ == null) {
          writeSize_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
          onChanged();
        } else {
          writeSizeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder getWriteSizeBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getWriteSizeFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getWriteSizeOrBuilder() {
        if (writeSizeBuilder_ != null) {
          return writeSizeBuilder_.getMessageOrBuilder();
        } else {
          return writeSize_;
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder>
          getWriteSizeFieldBuilder() {
        if (writeSizeBuilder_ == null) {
          writeSizeBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder>(
                  writeSize_,
                  getParentForChildren(),
                  isClean());
          writeSize_ = null;
        }
        return writeSizeBuilder_;
      }

      // optional .hbase.pb.TimedQuota read_num = 5;
      private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota readNum_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder> readNumBuilder_;
      /**
       * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
       */
      public boolean hasReadNum() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getReadNum() {
        if (readNumBuilder_ == null) {
          return readNum_;
        } else {
          return readNumBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
       */
      public Builder setReadNum(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (readNumBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          readNum_ = value;
          onChanged();
        } else {
          readNumBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
       */
      public Builder setReadNum(
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder builderForValue) {
        if (readNumBuilder_ == null) {
          readNum_ = builderForValue.build();
          onChanged();
        } else {
          readNumBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
       */
      public Builder mergeReadNum(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (readNumBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010) &&
              readNum_ != org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance()) {
            readNum_ =
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.newBuilder(readNum_).mergeFrom(value).buildPartial();
          } else {
            readNum_ = value;
          }
          onChanged();
        } else {
          readNumBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
       */
      public Builder clearReadNum() {
        if (readNumBuilder_ == null) {
          readNum_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
          onChanged();
        } else {
          readNumBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder getReadNumBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getReadNumFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getReadNumOrBuilder() {
        if (readNumBuilder_ != null) {
          return readNumBuilder_.getMessageOrBuilder();
        } else {
          return readNum_;
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder>
          getReadNumFieldBuilder() {
        if (readNumBuilder_ == null) {
          readNumBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder>(
                  readNum_,
                  getParentForChildren(),
                  isClean());
          readNum_ = null;
        }
        return readNumBuilder_;
      }

      // optional .hbase.pb.TimedQuota read_size = 6;
      private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota readSize_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder> readSizeBuilder_;
      /**
       * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
       */
      public boolean hasReadSize() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getReadSize() {
        if (readSizeBuilder_ == null) {
          return readSize_;
        } else {
          return readSizeBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
       */
      public Builder setReadSize(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (readSizeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          readSize_ = value;
          onChanged();
        } else {
          readSizeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
       */
      public Builder setReadSize(
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder builderForValue) {
        if (readSizeBuilder_ == null) {
          readSize_ = builderForValue.build();
          onChanged();
        } else {
          readSizeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
       */
      public Builder mergeReadSize(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (readSizeBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020) &&
              readSize_ != org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance()) {
            readSize_ =
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.newBuilder(readSize_).mergeFrom(value).buildPartial();
          } else {
            readSize_ = value;
          }
          onChanged();
        } else {
          readSizeBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
       */
      public Builder clearReadSize() {
        if (readSizeBuilder_ == null) {
          readSize_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
          onChanged();
        } else {
          readSizeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder getReadSizeBuilder() {
        bitField0_ |= 0x00000020;
        onChanged();
        return getReadSizeFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getReadSizeOrBuilder() {
        if (readSizeBuilder_ != null) {
          return readSizeBuilder_.getMessageOrBuilder();
        } else {
          return readSize_;
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder>
          getReadSizeFieldBuilder() {
        if (readSizeBuilder_ == null) {
          readSizeBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder>(
                  readSize_,
                  getParentForChildren(),
                  isClean());
          readSize_ = null;
        }
        return readSizeBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.Throttle)
    }

    static {
      defaultInstance = new Throttle(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.Throttle)
  }

  public interface ThrottleRequestOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hbase.pb.ThrottleType type = 1;
    /**
     * <code>optional .hbase.pb.ThrottleType type = 1;</code>
     */
    boolean hasType();
    /**
     * <code>optional .hbase.pb.ThrottleType type = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleType getType();

    // optional .hbase.pb.TimedQuota timed_quota = 2;
    /**
     * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
     */
    boolean hasTimedQuota();
    /**
     * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getTimedQuota();
    /**
     * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getTimedQuotaOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.ThrottleRequest}
   */
  public static final class ThrottleRequest extends
      com.google.protobuf.GeneratedMessage
      implements ThrottleRequestOrBuilder {
    // Use ThrottleRequest.newBuilder() to construct.
    private ThrottleRequest(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ThrottleRequest(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ThrottleRequest defaultInstance;
    public static ThrottleRequest getDefaultInstance() {
      return defaultInstance;
    }

    public ThrottleRequest getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ThrottleRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleType value = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleType.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                type_ = value;
              }
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = timedQuota_.toBuilder();
              }
              timedQuota_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(timedQuota_);
                timedQuota_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_ThrottleRequest_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_ThrottleRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest.Builder.class);
    }

    public static com.google.protobuf.Parser<ThrottleRequest> PARSER =
        new com.google.protobuf.AbstractParser<ThrottleRequest>() {
      public ThrottleRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ThrottleRequest(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ThrottleRequest> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hbase.pb.ThrottleType type = 1;
    public static final int TYPE_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleType type_;
    /**
     * <code>optional .hbase.pb.ThrottleType type = 1;</code>
     */
    public boolean hasType() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hbase.pb.ThrottleType type = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleType getType() {
      return type_;
    }

    // optional .hbase.pb.TimedQuota timed_quota = 2;
    public static final int TIMED_QUOTA_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota timedQuota_;
    /**
     * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
     */
    public boolean hasTimedQuota() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getTimedQuota() {
      return timedQuota_;
    }
    /**
     * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getTimedQuotaOrBuilder() {
      return timedQuota_;
    }

    private void initFields() {
      type_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleType.REQUEST_NUMBER;
      timedQuota_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (hasTimedQuota()) {
        if (!getTimedQuota().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(1, type_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, timedQuota_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, type_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, timedQuota_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest other = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest) obj;

      boolean result = true;
      result = result && (hasType() == other.hasType());
      if (hasType()) {
        result = result &&
            (getType() == other.getType());
      }
      result = result && (hasTimedQuota() == other.hasTimedQuota());
      if (hasTimedQuota()) {
        result = result && getTimedQuota()
            .equals(other.getTimedQuota());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasType()) {
        hash = (37 * hash) + TYPE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getType());
      }
      if (hasTimedQuota()) {
        hash = (37 * hash) + TIMED_QUOTA_FIELD_NUMBER;
        hash = (53 * hash) + getTimedQuota().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ThrottleRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_ThrottleRequest_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_ThrottleRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getTimedQuotaFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        type_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleType.REQUEST_NUMBER;
        bitField0_ = (bitField0_ & ~0x00000001);
        if (timedQuotaBuilder_ == null) {
          timedQuota_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
        } else {
          timedQuotaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_ThrottleRequest_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest build() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest result = new org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.type_ = type_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (timedQuotaBuilder_ == null) {
          result.timedQuota_ = timedQuota_;
        } else {
          result.timedQuota_ = timedQuotaBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest.getDefaultInstance()) return this;
        if (other.hasType()) {
          setType(other.getType());
        }
        if (other.hasTimedQuota()) {
          mergeTimedQuota(other.getTimedQuota());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (hasTimedQuota()) {
          if (!getTimedQuota().isInitialized()) {

            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hbase.pb.ThrottleType type = 1;
      private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleType type_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleType.REQUEST_NUMBER;
      /**
       * <code>optional .hbase.pb.ThrottleType type = 1;</code>
       */
      public boolean hasType() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hbase.pb.ThrottleType type = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleType getType() {
        return type_;
      }
      /**
       * <code>optional .hbase.pb.ThrottleType type = 1;</code>
       */
      public Builder setType(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        type_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ThrottleType type = 1;</code>
       */
      public Builder clearType() {
        bitField0_ = (bitField0_ & ~0x00000001);
        type_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleType.REQUEST_NUMBER;
        onChanged();
        return this;
      }

      // optional .hbase.pb.TimedQuota timed_quota = 2;
      private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota timedQuota_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder> timedQuotaBuilder_;
      /**
       * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
       */
      public boolean hasTimedQuota() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getTimedQuota() {
        if (timedQuotaBuilder_ == null) {
          return timedQuota_;
        } else {
          return timedQuotaBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
       */
      public Builder setTimedQuota(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (timedQuotaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          timedQuota_ = value;
          onChanged();
        } else {
          timedQuotaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
       */
      public Builder setTimedQuota(
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder builderForValue) {
        if (timedQuotaBuilder_ == null) {
          timedQuota_ = builderForValue.build();
          onChanged();
        } else {
          timedQuotaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
       */
      public Builder mergeTimedQuota(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (timedQuotaBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              timedQuota_ != org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance()) {
            timedQuota_ =
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.newBuilder(timedQuota_).mergeFrom(value).buildPartial();
          } else {
            timedQuota_ = value;
          }
          onChanged();
        } else {
          timedQuotaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
       */
      public Builder clearTimedQuota() {
        if (timedQuotaBuilder_ == null) {
          timedQuota_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
          onChanged();
        } else {
          timedQuotaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder getTimedQuotaBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTimedQuotaFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getTimedQuotaOrBuilder() {
        if (timedQuotaBuilder_ != null) {
          return timedQuotaBuilder_.getMessageOrBuilder();
        } else {
          return timedQuota_;
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder>
          getTimedQuotaFieldBuilder() {
        if (timedQuotaBuilder_ == null) {
          timedQuotaBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder>(
                  timedQuota_,
                  getParentForChildren(),
                  isClean());
          timedQuota_ = null;
        }
        return timedQuotaBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.ThrottleRequest)
    }

    static {
      defaultInstance = new ThrottleRequest(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ThrottleRequest)
  }

  public interface QuotasOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional bool bypass_globals = 1 [default = false];
    /**
     * <code>optional bool bypass_globals = 1 [default = false];</code>
     */
    boolean hasBypassGlobals();
    /**
     * <code>optional bool bypass_globals = 1 [default = false];</code>
     */
    boolean getBypassGlobals();

    // optional .hbase.pb.Throttle throttle = 2;
    /**
     * <code>optional .hbase.pb.Throttle throttle = 2;</code>
     */
    boolean hasThrottle();
    /**
     * <code>optional .hbase.pb.Throttle throttle = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle getThrottle();
    /**
     * <code>optional .hbase.pb.Throttle throttle = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleOrBuilder getThrottleOrBuilder();

    // optional .hbase.pb.SpaceQuota space = 3;
    /**
     * <code>optional .hbase.pb.SpaceQuota space = 3;</code>
     */
    boolean hasSpace();
    /**
     * <code>optional .hbase.pb.SpaceQuota space = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota getSpace();
    /**
     * <code>optional .hbase.pb.SpaceQuota space = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaOrBuilder getSpaceOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.Quotas}
   */
  public static final class Quotas extends
      com.google.protobuf.GeneratedMessage
      implements QuotasOrBuilder {
    // Use Quotas.newBuilder() to construct.
    private Quotas(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private Quotas(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final Quotas defaultInstance;
    public static Quotas getDefaultInstance() {
      return defaultInstance;
    }

    public Quotas getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private Quotas(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              bypassGlobals_ = input.readBool();
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = throttle_.toBuilder();
              }
              throttle_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(throttle_);
                throttle_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = space_.toBuilder();
              }
              space_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(space_);
                space_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_Quotas_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_Quotas_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas.Builder.class);
    }

    public static com.google.protobuf.Parser<Quotas> PARSER =
        new com.google.protobuf.AbstractParser<Quotas>() {
      public Quotas parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Quotas(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<Quotas> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional bool bypass_globals = 1 [default = false];
    public static final int BYPASS_GLOBALS_FIELD_NUMBER = 1;
    private boolean bypassGlobals_;
    /**
     * <code>optional bool bypass_globals = 1 [default = false];</code>
     */
    public boolean hasBypassGlobals() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional bool bypass_globals = 1 [default = false];</code>
     */
    public boolean getBypassGlobals() {
      return bypassGlobals_;
    }

    // optional .hbase.pb.Throttle throttle = 2;
    public static final int THROTTLE_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle throttle_;
    /**
     * <code>optional .hbase.pb.Throttle throttle = 2;</code>
     */
    public boolean hasThrottle() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hbase.pb.Throttle throttle = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle getThrottle() {
      return throttle_;
    }
    /**
     * <code>optional .hbase.pb.Throttle throttle = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleOrBuilder getThrottleOrBuilder() {
      return throttle_;
    }

    // optional .hbase.pb.SpaceQuota space = 3;
    public static final int SPACE_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota space_;
    /**
     * <code>optional .hbase.pb.SpaceQuota space = 3;</code>
     */
    public boolean hasSpace() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hbase.pb.SpaceQuota space = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota getSpace() {
      return space_;
    }
    /**
     * <code>optional .hbase.pb.SpaceQuota space = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaOrBuilder getSpaceOrBuilder() {
      return space_;
    }

    private void initFields() {
      bypassGlobals_ = false;
      throttle_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.getDefaultInstance();
      space_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (hasThrottle()) {
        if (!getThrottle().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBool(1, bypassGlobals_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, throttle_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, space_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, bypassGlobals_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, throttle_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, space_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas other = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas) obj;

      boolean result = true;
      result = result && (hasBypassGlobals() == other.hasBypassGlobals());
      if (hasBypassGlobals()) {
        result = result && (getBypassGlobals()
            == other.getBypassGlobals());
      }
      result = result && (hasThrottle() == other.hasThrottle());
      if (hasThrottle()) {
        result = result && getThrottle()
            .equals(other.getThrottle());
      }
      result = result && (hasSpace() == other.hasSpace());
      if (hasSpace()) {
        result = result && getSpace()
            .equals(other.getSpace());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasBypassGlobals()) {
        hash = (37 * hash) + BYPASS_GLOBALS_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getBypassGlobals());
      }
      if (hasThrottle()) {
        hash = (37 * hash) + THROTTLE_FIELD_NUMBER;
        hash = (53 * hash) + getThrottle().hashCode();
      }
      if (hasSpace()) {
        hash = (37 * hash) + SPACE_FIELD_NUMBER;
        hash = (53 * hash) + getSpace().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.Quotas}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotasOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_Quotas_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_Quotas_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getThrottleFieldBuilder();
          getSpaceFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        bypassGlobals_ = false;
        bitField0_ = (bitField0_ & ~0x00000001);
        if (throttleBuilder_ == null) {
          throttle_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.getDefaultInstance();
        } else {
          throttleBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (spaceBuilder_ == null) {
          space_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.getDefaultInstance();
        } else {
          spaceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_Quotas_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas build() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas result = new org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.bypassGlobals_ = bypassGlobals_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (throttleBuilder_ == null) {
          result.throttle_ = throttle_;
        } else {
          result.throttle_ = throttleBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (spaceBuilder_ == null) {
          result.space_ = space_;
        } else {
          result.space_ = spaceBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas.getDefaultInstance()) return this;
        if (other.hasBypassGlobals()) {
          setBypassGlobals(other.getBypassGlobals());
        }
        if (other.hasThrottle()) {
          mergeThrottle(other.getThrottle());
        }
        if (other.hasSpace()) {
          mergeSpace(other.getSpace());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (hasThrottle()) {
          if (!getThrottle().isInitialized()) {

            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional bool bypass_globals = 1 [default = false];
      private boolean bypassGlobals_ ;
      /**
       * <code>optional bool bypass_globals = 1 [default = false];</code>
       */
      public boolean hasBypassGlobals() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional bool bypass_globals = 1 [default = false];</code>
       */
      public boolean getBypassGlobals() {
        return bypassGlobals_;
      }
      /**
       * <code>optional bool bypass_globals = 1 [default = false];</code>
       */
      public Builder setBypassGlobals(boolean value) {
        bitField0_ |= 0x00000001;
        bypassGlobals_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool bypass_globals = 1 [default = false];</code>
       */
      public Builder clearBypassGlobals() {
        bitField0_ = (bitField0_ & ~0x00000001);
        bypassGlobals_ = false;
        onChanged();
        return this;
      }

      // optional .hbase.pb.Throttle throttle = 2;
      private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle throttle_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleOrBuilder> throttleBuilder_;
      /**
       * <code>optional .hbase.pb.Throttle throttle = 2;</code>
       */
      public boolean hasThrottle() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hbase.pb.Throttle throttle = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle getThrottle() {
        if (throttleBuilder_ == null) {
          return throttle_;
        } else {
          return throttleBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.Throttle throttle = 2;</code>
       */
      public Builder setThrottle(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle value) {
        if (throttleBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          throttle_ = value;
          onChanged();
        } else {
          throttleBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.Throttle throttle = 2;</code>
       */
      public Builder setThrottle(
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.Builder builderForValue) {
        if (throttleBuilder_ == null) {
          throttle_ = builderForValue.build();
          onChanged();
        } else {
          throttleBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.Throttle throttle = 2;</code>
       */
      public Builder mergeThrottle(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle value) {
        if (throttleBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              throttle_ != org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.getDefaultInstance()) {
            throttle_ =
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.newBuilder(throttle_).mergeFrom(value).buildPartial();
          } else {
            throttle_ = value;
          }
          onChanged();
        } else {
          throttleBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.Throttle throttle = 2;</code>
       */
      public Builder clearThrottle() {
        if (throttleBuilder_ == null) {
          throttle_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.getDefaultInstance();
          onChanged();
        } else {
          throttleBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hbase.pb.Throttle throttle = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.Builder getThrottleBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getThrottleFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.Throttle throttle = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleOrBuilder getThrottleOrBuilder() {
        if (throttleBuilder_ != null) {
          return throttleBuilder_.getMessageOrBuilder();
        } else {
          return throttle_;
        }
      }
      /**
       * <code>optional .hbase.pb.Throttle throttle = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleOrBuilder>
          getThrottleFieldBuilder() {
        if (throttleBuilder_ == null) {
          throttleBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleOrBuilder>(
                  throttle_,
                  getParentForChildren(),
                  isClean());
          throttle_ = null;
        }
        return throttleBuilder_;
      }

      // optional .hbase.pb.SpaceQuota space = 3;
      private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota space_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaOrBuilder> spaceBuilder_;
      /**
       * <code>optional .hbase.pb.SpaceQuota space = 3;</code>
       */
      public boolean hasSpace() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hbase.pb.SpaceQuota space = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota getSpace() {
        if (spaceBuilder_ == null) {
          return space_;
        } else {
          return spaceBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.SpaceQuota space = 3;</code>
       */
      public Builder setSpace(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota value) {
        if (spaceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          space_ = value;
          onChanged();
        } else {
          spaceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.SpaceQuota space = 3;</code>
       */
      public Builder setSpace(
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.Builder builderForValue) {
        if (spaceBuilder_ == null) {
          space_ = builderForValue.build();
          onChanged();
        } else {
          spaceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.SpaceQuota space = 3;</code>
       */
      public Builder mergeSpace(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota value) {
        if (spaceBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              space_ != org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.getDefaultInstance()) {
            space_ =
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.newBuilder(space_).mergeFrom(value).buildPartial();
          } else {
            space_ = value;
          }
          onChanged();
        } else {
          spaceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.SpaceQuota space = 3;</code>
       */
      public Builder clearSpace() {
        if (spaceBuilder_ == null) {
          space_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.getDefaultInstance();
          onChanged();
        } else {
          spaceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hbase.pb.SpaceQuota space = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.Builder getSpaceBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getSpaceFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.SpaceQuota space = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaOrBuilder getSpaceOrBuilder() {
        if (spaceBuilder_ != null) {
          return spaceBuilder_.getMessageOrBuilder();
        } else {
          return space_;
        }
      }
      /**
       * <code>optional .hbase.pb.SpaceQuota space = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaOrBuilder>
          getSpaceFieldBuilder() {
        if (spaceBuilder_ == null) {
          spaceBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaOrBuilder>(
                  space_,
                  getParentForChildren(),
                  isClean());
          space_ = null;
        }
        return spaceBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.Quotas)
    }

    static {
      defaultInstance = new Quotas(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.Quotas)
  }

  public interface QuotaUsageOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.QuotaUsage}
   */
  public static final class QuotaUsage extends
      com.google.protobuf.GeneratedMessage
      implements QuotaUsageOrBuilder {
    // Use QuotaUsage.newBuilder() to construct.
    private QuotaUsage(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private QuotaUsage(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final QuotaUsage defaultInstance;
    public static QuotaUsage getDefaultInstance() {
      return defaultInstance;
    }

    public QuotaUsage getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private QuotaUsage(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_QuotaUsage_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_QuotaUsage_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage.Builder.class);
    }

    public static com.google.protobuf.Parser<QuotaUsage> PARSER =
        new com.google.protobuf.AbstractParser<QuotaUsage>() {
      public QuotaUsage parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new QuotaUsage(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<QuotaUsage> getParserForType() {
      return PARSER;
    }

    private void initFields() {
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage other = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage) obj;

      boolean result = true;
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.QuotaUsage}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsageOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_QuotaUsage_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_QuotaUsage_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_QuotaUsage_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage build() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage result = new org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage(this);
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.QuotaUsage)
    }

    static {
      defaultInstance = new QuotaUsage(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.QuotaUsage)
  }

  public interface SpaceQuotaOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional uint64 soft_limit = 1;
    /**
     * <code>optional uint64 soft_limit = 1;</code>
     *
     * <pre>
     * The limit of bytes for this quota
     * </pre>
     */
    boolean hasSoftLimit();
    /**
     * <code>optional uint64 soft_limit = 1;</code>
     *
     * <pre>
     * The limit of bytes for this quota
     * </pre>
     */
    long getSoftLimit();

    // optional .hbase.pb.SpaceViolationPolicy violation_policy = 2;
    /**
     * <code>optional .hbase.pb.SpaceViolationPolicy violation_policy = 2;</code>
     *
     * <pre>
     * The action to take when the quota is violated
     * </pre>
     */
    boolean hasViolationPolicy();
    /**
     * <code>optional .hbase.pb.SpaceViolationPolicy violation_policy = 2;</code>
     *
     * <pre>
     * The action to take when the quota is violated
     * </pre>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceViolationPolicy getViolationPolicy();

    // optional bool remove = 3 [default = false];
    /**
     * <code>optional bool remove = 3 [default = false];</code>
     *
     * <pre>
     * When true, remove the quota.
     * </pre>
     */
    boolean hasRemove();
    /**
     * <code>optional bool remove = 3 [default = false];</code>
     *
     * <pre>
     * When true, remove the quota.
     * </pre>
     */
    boolean getRemove();
  }
  /**
   * Protobuf type {@code hbase.pb.SpaceQuota}
   *
   * <pre>
   * Defines a limit on the amount of filesystem space used by a table/namespace
   * </pre>
   */
  public static final class SpaceQuota extends
      com.google.protobuf.GeneratedMessage
      implements SpaceQuotaOrBuilder {
    // Use SpaceQuota.newBuilder() to construct.
    private SpaceQuota(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private SpaceQuota(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final SpaceQuota defaultInstance;
    public static SpaceQuota getDefaultInstance() {
      return defaultInstance;
    }

    public SpaceQuota getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private SpaceQuota(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              softLimit_ = input.readUInt64();
              break;
            }
            case 16: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceViolationPolicy value = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceViolationPolicy.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(2, rawValue);
              } else {
                bitField0_ |= 0x00000002;
                violationPolicy_ = value;
              }
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              remove_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_SpaceQuota_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_SpaceQuota_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.Builder.class);
    }

    public static com.google.protobuf.Parser<SpaceQuota> PARSER =
        new com.google.protobuf.AbstractParser<SpaceQuota>() {
      public SpaceQuota parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new SpaceQuota(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<SpaceQuota> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional uint64 soft_limit = 1;
    public static final int SOFT_LIMIT_FIELD_NUMBER = 1;
    private long softLimit_;
    /**
     * <code>optional uint64 soft_limit = 1;</code>
     *
     * <pre>
     * The limit of bytes for this quota
     * </pre>
     */
    public boolean hasSoftLimit() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional uint64 soft_limit = 1;</code>
     *
     * <pre>
     * The limit of bytes for this quota
     * </pre>
     */
    public long getSoftLimit() {
      return softLimit_;
    }

    // optional .hbase.pb.SpaceViolationPolicy violation_policy = 2;
    public static final int VIOLATION_POLICY_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceViolationPolicy violationPolicy_;
    /**
     * <code>optional .hbase.pb.SpaceViolationPolicy violation_policy = 2;</code>
     *
     * <pre>
     * The action to take when the quota is violated
     * </pre>
     */
    public boolean hasViolationPolicy() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hbase.pb.SpaceViolationPolicy violation_policy = 2;</code>
     *
     * <pre>
     * The action to take when the quota is violated
     * </pre>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceViolationPolicy getViolationPolicy() {
      return violationPolicy_;
    }

    // optional bool remove = 3 [default = false];
    public static final int REMOVE_FIELD_NUMBER = 3;
    private boolean remove_;
    /**
     * <code>optional bool remove = 3 [default = false];</code>
     *
     * <pre>
     * When true, remove the quota.
     * </pre>
     */
    public boolean hasRemove() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional bool remove = 3 [default = false];</code>
     *
     * <pre>
     * When true, remove the quota.
     * </pre>
     */
    public boolean getRemove() {
      return remove_;
    }

    private void initFields() {
      softLimit_ = 0L;
      violationPolicy_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceViolationPolicy.DISABLE;
      remove_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeUInt64(1, softLimit_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeEnum(2, violationPolicy_.getNumber());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBool(3, remove_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(1, softLimit_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, violationPolicy_.getNumber());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, remove_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota other = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota) obj;

      boolean result = true;
      result = result && (hasSoftLimit() == other.hasSoftLimit());
      if (hasSoftLimit()) {
        result = result && (getSoftLimit()
            == other.getSoftLimit());
      }
      result = result && (hasViolationPolicy() == other.hasViolationPolicy());
      if (hasViolationPolicy()) {
        result = result &&
            (getViolationPolicy() == other.getViolationPolicy());
      }
      result = result && (hasRemove() == other.hasRemove());
      if (hasRemove()) {
        result = result && (getRemove()
            == other.getRemove());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasSoftLimit()) {
        hash = (37 * hash) + SOFT_LIMIT_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getSoftLimit());
      }
      if (hasViolationPolicy()) {
        hash = (37 * hash) + VIOLATION_POLICY_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getViolationPolicy());
      }
      if (hasRemove()) {
        hash = (37 * hash) + REMOVE_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getRemove());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.SpaceQuota}
     *
     * <pre>
     * Defines a limit on the amount of filesystem space used by a table/namespace
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_SpaceQuota_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_SpaceQuota_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        softLimit_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000001);
        violationPolicy_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceViolationPolicy.DISABLE;
        bitField0_ = (bitField0_ & ~0x00000002);
        remove_ = false;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_SpaceQuota_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota build() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota result = new org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.softLimit_ = softLimit_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.violationPolicy_ = violationPolicy_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.remove_ = remove_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.getDefaultInstance()) return this;
        if (other.hasSoftLimit()) {
          setSoftLimit(other.getSoftLimit());
        }
        if (other.hasViolationPolicy()) {
          setViolationPolicy(other.getViolationPolicy());
        }
        if (other.hasRemove()) {
          setRemove(other.getRemove());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional uint64 soft_limit = 1;
      private long softLimit_ ;
      /**
       * <code>optional uint64 soft_limit = 1;</code>
       *
       * <pre>
       * The limit of bytes for this quota
       * </pre>
       */
      public boolean hasSoftLimit() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional uint64 soft_limit = 1;</code>
       *
       * <pre>
       * The limit of bytes for this quota
       * </pre>
       */
      public long getSoftLimit() {
        return softLimit_;
      }
      /**
       * <code>optional uint64 soft_limit = 1;</code>
       *
       * <pre>
       * The limit of bytes for this quota
       * </pre>
       */
      public Builder setSoftLimit(long value) {
        bitField0_ |= 0x00000001;
        softLimit_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 soft_limit = 1;</code>
       *
       * <pre>
       * The limit of bytes for this quota
       * </pre>
       */
      public Builder clearSoftLimit() {
        bitField0_ = (bitField0_ & ~0x00000001);
        softLimit_ = 0L;
        onChanged();
        return this;
      }

      // optional .hbase.pb.SpaceViolationPolicy violation_policy = 2;
      private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceViolationPolicy violationPolicy_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceViolationPolicy.DISABLE;
      /**
       * <code>optional .hbase.pb.SpaceViolationPolicy violation_policy = 2;</code>
       *
       * <pre>
       * The action to take when the quota is violated
       * </pre>
       */
      public boolean hasViolationPolicy() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hbase.pb.SpaceViolationPolicy violation_policy = 2;</code>
       *
       * <pre>
       * The action to take when the quota is violated
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceViolationPolicy getViolationPolicy() {
        return violationPolicy_;
      }
      /**
       * <code>optional .hbase.pb.SpaceViolationPolicy violation_policy = 2;</code>
       *
       * <pre>
       * The action to take when the quota is violated
       * </pre>
       */
      public Builder setViolationPolicy(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceViolationPolicy value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000002;
        violationPolicy_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.SpaceViolationPolicy violation_policy = 2;</code>
       *
       * <pre>
       * The action to take when the quota is violated
       * </pre>
       */
      public Builder clearViolationPolicy() {
        bitField0_ = (bitField0_ & ~0x00000002);
        violationPolicy_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceViolationPolicy.DISABLE;
        onChanged();
        return this;
      }

      // optional bool remove = 3 [default = false];
      private boolean remove_ ;
      /**
       * <code>optional bool remove = 3 [default = false];</code>
       *
       * <pre>
       * When true, remove the quota.
       * </pre>
       */
      public boolean hasRemove() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional bool remove = 3 [default = false];</code>
       *
       * <pre>
       * When true, remove the quota.
       * </pre>
       */
      public boolean getRemove() {
        return remove_;
      }
      /**
       * <code>optional bool remove = 3 [default = false];</code>
       *
       * <pre>
       * When true, remove the quota.
       * </pre>
       */
      public Builder setRemove(boolean value) {
        bitField0_ |= 0x00000004;
        remove_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool remove = 3 [default = false];</code>
       *
       * <pre>
       * When true, remove the quota.
       * </pre>
       */
      public Builder clearRemove() {
        bitField0_ = (bitField0_ & ~0x00000004);
        remove_ = false;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.SpaceQuota)
    }

    static {
      defaultInstance = new SpaceQuota(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.SpaceQuota)
  }

  public interface SpaceLimitRequestOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hbase.pb.SpaceQuota quota = 1;
    /**
     * <code>optional .hbase.pb.SpaceQuota quota = 1;</code>
     */
    boolean hasQuota();
    /**
     * <code>optional .hbase.pb.SpaceQuota quota = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota getQuota();
    /**
     * <code>optional .hbase.pb.SpaceQuota quota = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaOrBuilder getQuotaOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.SpaceLimitRequest}
   *
   * <pre>
   * The Request to limit space usage (to allow for schema evolution not tied to SpaceQuota).
   * </pre>
   */
  public static final class SpaceLimitRequest extends
      com.google.protobuf.GeneratedMessage
      implements SpaceLimitRequestOrBuilder {
    // Use SpaceLimitRequest.newBuilder() to construct.
    private SpaceLimitRequest(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private SpaceLimitRequest(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final SpaceLimitRequest defaultInstance;
    public static SpaceLimitRequest getDefaultInstance() {
      return defaultInstance;
    }

    public SpaceLimitRequest getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private SpaceLimitRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = quota_.toBuilder();
              }
              quota_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(quota_);
                quota_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_SpaceLimitRequest_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_SpaceLimitRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest.Builder.class);
    }

    public static com.google.protobuf.Parser<SpaceLimitRequest> PARSER =
        new com.google.protobuf.AbstractParser<SpaceLimitRequest>() {
      public SpaceLimitRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new SpaceLimitRequest(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<SpaceLimitRequest> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hbase.pb.SpaceQuota quota = 1;
    public static final int QUOTA_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota quota_;
    /**
     * <code>optional .hbase.pb.SpaceQuota quota = 1;</code>
     */
    public boolean hasQuota() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hbase.pb.SpaceQuota quota = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota getQuota() {
      return quota_;
    }
    /**
     * <code>optional .hbase.pb.SpaceQuota quota = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaOrBuilder getQuotaOrBuilder() {
      return quota_;
    }

    private void initFields() {
      quota_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, quota_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, quota_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest other = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest) obj;

      boolean result = true;
      result = result && (hasQuota() == other.hasQuota());
      if (hasQuota()) {
        result = result && getQuota()
            .equals(other.getQuota());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasQuota()) {
        hash = (37 * hash) + QUOTA_FIELD_NUMBER;
        hash = (53 * hash) + getQuota().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.SpaceLimitRequest}
     *
     * <pre>
     * The Request to limit space usage (to allow for schema evolution not tied to SpaceQuota).
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_SpaceLimitRequest_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_SpaceLimitRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getQuotaFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (quotaBuilder_ == null) {
          quota_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.getDefaultInstance();
        } else {
          quotaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_SpaceLimitRequest_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest build() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest result = new org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (quotaBuilder_ == null) {
          result.quota_ = quota_;
        } else {
          result.quota_ = quotaBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest.getDefaultInstance()) return this;
        if (other.hasQuota()) {
          mergeQuota(other.getQuota());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceLimitRequest) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hbase.pb.SpaceQuota quota = 1;
      private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota quota_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaOrBuilder> quotaBuilder_;
      /**
       * <code>optional .hbase.pb.SpaceQuota quota = 1;</code>
       */
      public boolean hasQuota() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hbase.pb.SpaceQuota quota = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota getQuota() {
        if (quotaBuilder_ == null) {
          return quota_;
        } else {
          return quotaBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.SpaceQuota quota = 1;</code>
       */
      public Builder setQuota(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota value) {
        if (quotaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          quota_ = value;
          onChanged();
        } else {
          quotaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.SpaceQuota quota = 1;</code>
       */
      public Builder setQuota(
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.Builder builderForValue) {
        if (quotaBuilder_ == null) {
          quota_ = builderForValue.build();
          onChanged();
        } else {
          quotaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.SpaceQuota quota = 1;</code>
       */
      public Builder mergeQuota(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota value) {
        if (quotaBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              quota_ != org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.getDefaultInstance()) {
            quota_ =
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.newBuilder(quota_).mergeFrom(value).buildPartial();
          } else {
            quota_ = value;
          }
          onChanged();
        } else {
          quotaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.SpaceQuota quota = 1;</code>
       */
      public Builder clearQuota() {
        if (quotaBuilder_ == null) {
          quota_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.getDefaultInstance();
          onChanged();
        } else {
          quotaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hbase.pb.SpaceQuota quota = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.Builder getQuotaBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getQuotaFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.SpaceQuota quota = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaOrBuilder getQuotaOrBuilder() {
        if (quotaBuilder_ != null) {
          return quotaBuilder_.getMessageOrBuilder();
        } else {
          return quota_;
        }
      }
      /**
       * <code>optional .hbase.pb.SpaceQuota quota = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaOrBuilder>
          getQuotaFieldBuilder() {
        if (quotaBuilder_ == null) {
          quotaBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaOrBuilder>(
                  quota_,
                  getParentForChildren(),
                  isClean());
          quota_ = null;
        }
        return quotaBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.SpaceLimitRequest)
    }

    static {
      defaultInstance = new SpaceLimitRequest(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.SpaceLimitRequest)
  }

  public interface SpaceQuotaStatusOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hbase.pb.SpaceViolationPolicy violation_policy = 1;
    /**
     * <code>optional .hbase.pb.SpaceViolationPolicy violation_policy = 1;</code>
     */
    boolean hasViolationPolicy();
    /**
     * <code>optional .hbase.pb.SpaceViolationPolicy violation_policy = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceViolationPolicy getViolationPolicy();

    // optional bool in_violation = 2;
    /**
     * <code>optional bool in_violation = 2;</code>
     */
    boolean hasInViolation();
    /**
     * <code>optional bool in_violation = 2;</code>
     */
    boolean getInViolation();
  }
  /**
   * Protobuf type {@code hbase.pb.SpaceQuotaStatus}
   *
   * <pre>
   * Represents the state of a quota on a table. Either the quota is not in violation
   * or it is in violatino there is a violation policy which should be in effect.
   * </pre>
   */
  public static final class SpaceQuotaStatus extends
      com.google.protobuf.GeneratedMessage
      implements SpaceQuotaStatusOrBuilder {
    // Use SpaceQuotaStatus.newBuilder() to construct.
    private SpaceQuotaStatus(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private SpaceQuotaStatus(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final SpaceQuotaStatus defaultInstance;
    public static SpaceQuotaStatus getDefaultInstance() {
      return defaultInstance;
    }

    public SpaceQuotaStatus getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private SpaceQuotaStatus(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceViolationPolicy value = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceViolationPolicy.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                violationPolicy_ = value;
              }
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              inViolation_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_SpaceQuotaStatus_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_SpaceQuotaStatus_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus.Builder.class);
    }

    public static com.google.protobuf.Parser<SpaceQuotaStatus> PARSER =
        new com.google.protobuf.AbstractParser<SpaceQuotaStatus>() {
      public SpaceQuotaStatus parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new SpaceQuotaStatus(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<SpaceQuotaStatus> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hbase.pb.SpaceViolationPolicy violation_policy = 1;
    public static final int VIOLATION_POLICY_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceViolationPolicy violationPolicy_;
    /**
     * <code>optional .hbase.pb.SpaceViolationPolicy violation_policy = 1;</code>
     */
    public boolean hasViolationPolicy() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hbase.pb.SpaceViolationPolicy violation_policy = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceViolationPolicy getViolationPolicy() {
      return violationPolicy_;
    }

    // optional bool in_violation = 2;
    public static final int IN_VIOLATION_FIELD_NUMBER = 2;
    private boolean inViolation_;
    /**
     * <code>optional bool in_violation = 2;</code>
     */
    public boolean hasInViolation() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bool in_violation = 2;</code>
     */
    public boolean getInViolation() {
      return inViolation_;
    }

    private void initFields() {
      violationPolicy_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceViolationPolicy.DISABLE;
      inViolation_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(1, violationPolicy_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBool(2, inViolation_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, violationPolicy_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, inViolation_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus other = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus) obj;

      boolean result = true;
      result = result && (hasViolationPolicy() == other.hasViolationPolicy());
      if (hasViolationPolicy()) {
        result = result &&
            (getViolationPolicy() == other.getViolationPolicy());
      }
      result = result && (hasInViolation() == other.hasInViolation());
      if (hasInViolation()) {
        result = result && (getInViolation()
            == other.getInViolation());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasViolationPolicy()) {
        hash = (37 * hash) + VIOLATION_POLICY_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getViolationPolicy());
      }
      if (hasInViolation()) {
        hash = (37 * hash) + IN_VIOLATION_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getInViolation());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.SpaceQuotaStatus}
     *
     * <pre>
     * Represents the state of a quota on a table. Either the quota is not in violation
     * or it is in violatino there is a violation policy which should be in effect.
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatusOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_SpaceQuotaStatus_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_SpaceQuotaStatus_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        violationPolicy_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceViolationPolicy.DISABLE;
        bitField0_ = (bitField0_ & ~0x00000001);
        inViolation_ = false;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_SpaceQuotaStatus_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus build() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus result = new org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.violationPolicy_ = violationPolicy_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.inViolation_ = inViolation_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus.getDefaultInstance()) return this;
        if (other.hasViolationPolicy()) {
          setViolationPolicy(other.getViolationPolicy());
        }
        if (other.hasInViolation()) {
          setInViolation(other.getInViolation());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hbase.pb.SpaceViolationPolicy violation_policy = 1;
      private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceViolationPolicy violationPolicy_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceViolationPolicy.DISABLE;
      /**
       * <code>optional .hbase.pb.SpaceViolationPolicy violation_policy = 1;</code>
       */
      public boolean hasViolationPolicy() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hbase.pb.SpaceViolationPolicy violation_policy = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceViolationPolicy getViolationPolicy() {
        return violationPolicy_;
      }
      /**
       * <code>optional .hbase.pb.SpaceViolationPolicy violation_policy = 1;</code>
       */
      public Builder setViolationPolicy(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceViolationPolicy value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        violationPolicy_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.SpaceViolationPolicy violation_policy = 1;</code>
       */
      public Builder clearViolationPolicy() {
        bitField0_ = (bitField0_ & ~0x00000001);
        violationPolicy_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceViolationPolicy.DISABLE;
        onChanged();
        return this;
      }

      // optional bool in_violation = 2;
      private boolean inViolation_ ;
      /**
       * <code>optional bool in_violation = 2;</code>
       */
      public boolean hasInViolation() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional bool in_violation = 2;</code>
       */
      public boolean getInViolation() {
        return inViolation_;
      }
      /**
       * <code>optional bool in_violation = 2;</code>
       */
      public Builder setInViolation(boolean value) {
        bitField0_ |= 0x00000002;
        inViolation_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool in_violation = 2;</code>
       */
      public Builder clearInViolation() {
        bitField0_ = (bitField0_ & ~0x00000002);
        inViolation_ = false;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.SpaceQuotaStatus)
    }

    static {
      defaultInstance = new SpaceQuotaStatus(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.SpaceQuotaStatus)
  }

  public interface SpaceQuotaSnapshotOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hbase.pb.SpaceQuotaStatus quota_status = 1;
    /**
     * <code>optional .hbase.pb.SpaceQuotaStatus quota_status = 1;</code>
     */
    boolean hasQuotaStatus();
    /**
     * <code>optional .hbase.pb.SpaceQuotaStatus quota_status = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus getQuotaStatus();
    /**
     * <code>optional .hbase.pb.SpaceQuotaStatus quota_status = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatusOrBuilder getQuotaStatusOrBuilder();

    // optional uint64 quota_usage = 2;
    /**
     * <code>optional uint64 quota_usage = 2;</code>
     */
    boolean hasQuotaUsage();
    /**
     * <code>optional uint64 quota_usage = 2;</code>
     */
    long getQuotaUsage();

    // optional uint64 quota_limit = 3;
    /**
     * <code>optional uint64 quota_limit = 3;</code>
     */
    boolean hasQuotaLimit();
    /**
     * <code>optional uint64 quota_limit = 3;</code>
     */
    long getQuotaLimit();
  }
  /**
   * Protobuf type {@code hbase.pb.SpaceQuotaSnapshot}
   *
   * <pre>
   * Message stored in the value of hbase:quota table to denote the status of a table WRT
   * the quota applicable to it.
   * </pre>
   */
  public static final class SpaceQuotaSnapshot extends
      com.google.protobuf.GeneratedMessage
      implements SpaceQuotaSnapshotOrBuilder {
    // Use SpaceQuotaSnapshot.newBuilder() to construct.
    private SpaceQuotaSnapshot(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private SpaceQuotaSnapshot(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final SpaceQuotaSnapshot defaultInstance;
    public static SpaceQuotaSnapshot getDefaultInstance() {
      return defaultInstance;
    }

    public SpaceQuotaSnapshot getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private SpaceQuotaSnapshot(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = quotaStatus_.toBuilder();
              }
              quotaStatus_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(quotaStatus_);
                quotaStatus_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              quotaUsage_ = input.readUInt64();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              quotaLimit_ = input.readUInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_SpaceQuotaSnapshot_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_SpaceQuotaSnapshot_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot.Builder.class);
    }

    public static com.google.protobuf.Parser<SpaceQuotaSnapshot> PARSER =
        new com.google.protobuf.AbstractParser<SpaceQuotaSnapshot>() {
      public SpaceQuotaSnapshot parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new SpaceQuotaSnapshot(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<SpaceQuotaSnapshot> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hbase.pb.SpaceQuotaStatus quota_status = 1;
    public static final int QUOTA_STATUS_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus quotaStatus_;
    /**
     * <code>optional .hbase.pb.SpaceQuotaStatus quota_status = 1;</code>
     */
    public boolean hasQuotaStatus() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hbase.pb.SpaceQuotaStatus quota_status = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus getQuotaStatus() {
      return quotaStatus_;
    }
    /**
     * <code>optional .hbase.pb.SpaceQuotaStatus quota_status = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatusOrBuilder getQuotaStatusOrBuilder() {
      return quotaStatus_;
    }

    // optional uint64 quota_usage = 2;
    public static final int QUOTA_USAGE_FIELD_NUMBER = 2;
    private long quotaUsage_;
    /**
     * <code>optional uint64 quota_usage = 2;</code>
     */
    public boolean hasQuotaUsage() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional uint64 quota_usage = 2;</code>
     */
    public long getQuotaUsage() {
      return quotaUsage_;
    }

    // optional uint64 quota_limit = 3;
    public static final int QUOTA_LIMIT_FIELD_NUMBER = 3;
    private long quotaLimit_;
    /**
     * <code>optional uint64 quota_limit = 3;</code>
     */
    public boolean hasQuotaLimit() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional uint64 quota_limit = 3;</code>
     */
    public long getQuotaLimit() {
      return quotaLimit_;
    }

    private void initFields() {
      quotaStatus_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus.getDefaultInstance();
      quotaUsage_ = 0L;
      quotaLimit_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, quotaStatus_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeUInt64(2, quotaUsage_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeUInt64(3, quotaLimit_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, quotaStatus_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(2, quotaUsage_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(3, quotaLimit_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot other = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot) obj;

      boolean result = true;
      result = result && (hasQuotaStatus() == other.hasQuotaStatus());
      if (hasQuotaStatus()) {
        result = result && getQuotaStatus()
            .equals(other.getQuotaStatus());
      }
      result = result && (hasQuotaUsage() == other.hasQuotaUsage());
      if (hasQuotaUsage()) {
        result = result && (getQuotaUsage()
            == other.getQuotaUsage());
      }
      result = result && (hasQuotaLimit() == other.hasQuotaLimit());
      if (hasQuotaLimit()) {
        result = result && (getQuotaLimit()
            == other.getQuotaLimit());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasQuotaStatus()) {
        hash = (37 * hash) + QUOTA_STATUS_FIELD_NUMBER;
        hash = (53 * hash) + getQuotaStatus().hashCode();
      }
      if (hasQuotaUsage()) {
        hash = (37 * hash) + QUOTA_USAGE_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getQuotaUsage());
      }
      if (hasQuotaLimit()) {
        hash = (37 * hash) + QUOTA_LIMIT_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getQuotaLimit());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.SpaceQuotaSnapshot}
     *
     * <pre>
     * Message stored in the value of hbase:quota table to denote the status of a table WRT
     * the quota applicable to it.
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshotOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_SpaceQuotaSnapshot_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_SpaceQuotaSnapshot_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getQuotaStatusFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (quotaStatusBuilder_ == null) {
          quotaStatus_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus.getDefaultInstance();
        } else {
          quotaStatusBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        quotaUsage_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        quotaLimit_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_SpaceQuotaSnapshot_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot build() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot result = new org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (quotaStatusBuilder_ == null) {
          result.quotaStatus_ = quotaStatus_;
        } else {
          result.quotaStatus_ = quotaStatusBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.quotaUsage_ = quotaUsage_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.quotaLimit_ = quotaLimit_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot.getDefaultInstance()) return this;
        if (other.hasQuotaStatus()) {
          mergeQuotaStatus(other.getQuotaStatus());
        }
        if (other.hasQuotaUsage()) {
          setQuotaUsage(other.getQuotaUsage());
        }
        if (other.hasQuotaLimit()) {
          setQuotaLimit(other.getQuotaLimit());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaSnapshot) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hbase.pb.SpaceQuotaStatus quota_status = 1;
      private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus quotaStatus_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatusOrBuilder> quotaStatusBuilder_;
      /**
       * <code>optional .hbase.pb.SpaceQuotaStatus quota_status = 1;</code>
       */
      public boolean hasQuotaStatus() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hbase.pb.SpaceQuotaStatus quota_status = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus getQuotaStatus() {
        if (quotaStatusBuilder_ == null) {
          return quotaStatus_;
        } else {
          return quotaStatusBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.SpaceQuotaStatus quota_status = 1;</code>
       */
      public Builder setQuotaStatus(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus value) {
        if (quotaStatusBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          quotaStatus_ = value;
          onChanged();
        } else {
          quotaStatusBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.SpaceQuotaStatus quota_status = 1;</code>
       */
      public Builder setQuotaStatus(
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus.Builder builderForValue) {
        if (quotaStatusBuilder_ == null) {
          quotaStatus_ = builderForValue.build();
          onChanged();
        } else {
          quotaStatusBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.SpaceQuotaStatus quota_status = 1;</code>
       */
      public Builder mergeQuotaStatus(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus value) {
        if (quotaStatusBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              quotaStatus_ != org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus.getDefaultInstance()) {
            quotaStatus_ =
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus.newBuilder(quotaStatus_).mergeFrom(value).buildPartial();
          } else {
            quotaStatus_ = value;
          }
          onChanged();
        } else {
          quotaStatusBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.SpaceQuotaStatus quota_status = 1;</code>
       */
      public Builder clearQuotaStatus() {
        if (quotaStatusBuilder_ == null) {
          quotaStatus_ = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus.getDefaultInstance();
          onChanged();
        } else {
          quotaStatusBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hbase.pb.SpaceQuotaStatus quota_status = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus.Builder getQuotaStatusBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getQuotaStatusFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.SpaceQuotaStatus quota_status = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatusOrBuilder getQuotaStatusOrBuilder() {
        if (quotaStatusBuilder_ != null) {
          return quotaStatusBuilder_.getMessageOrBuilder();
        } else {
          return quotaStatus_;
        }
      }
      /**
       * <code>optional .hbase.pb.SpaceQuotaStatus quota_status = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatusOrBuilder>
          getQuotaStatusFieldBuilder() {
        if (quotaStatusBuilder_ == null) {
          quotaStatusBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatus.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.SpaceQuotaStatusOrBuilder>(
                  quotaStatus_,
                  getParentForChildren(),
                  isClean());
          quotaStatus_ = null;
        }
        return quotaStatusBuilder_;
      }

      // optional uint64 quota_usage = 2;
      private long quotaUsage_ ;
      /**
       * <code>optional uint64 quota_usage = 2;</code>
       */
      public boolean hasQuotaUsage() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional uint64 quota_usage = 2;</code>
       */
      public long getQuotaUsage() {
        return quotaUsage_;
      }
      /**
       * <code>optional uint64 quota_usage = 2;</code>
       */
      public Builder setQuotaUsage(long value) {
        bitField0_ |= 0x00000002;
        quotaUsage_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 quota_usage = 2;</code>
       */
      public Builder clearQuotaUsage() {
        bitField0_ = (bitField0_ & ~0x00000002);
        quotaUsage_ = 0L;
        onChanged();
        return this;
      }

      // optional uint64 quota_limit = 3;
      private long quotaLimit_ ;
      /**
       * <code>optional uint64 quota_limit = 3;</code>
       */
      public boolean hasQuotaLimit() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional uint64 quota_limit = 3;</code>
       */
      public long getQuotaLimit() {
        return quotaLimit_;
      }
      /**
       * <code>optional uint64 quota_limit = 3;</code>
       */
      public Builder setQuotaLimit(long value) {
        bitField0_ |= 0x00000004;
        quotaLimit_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 quota_limit = 3;</code>
       */
      public Builder clearQuotaLimit() {
        bitField0_ = (bitField0_ & ~0x00000004);
        quotaLimit_ = 0L;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.SpaceQuotaSnapshot)
    }

    static {
      defaultInstance = new SpaceQuotaSnapshot(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.SpaceQuotaSnapshot)
  }

  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_TimedQuota_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_TimedQuota_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_Throttle_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_Throttle_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ThrottleRequest_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_ThrottleRequest_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_Quotas_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_Quotas_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_QuotaUsage_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_QuotaUsage_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_SpaceQuota_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_SpaceQuota_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_SpaceLimitRequest_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_SpaceLimitRequest_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_SpaceQuotaStatus_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_SpaceQuotaStatus_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_SpaceQuotaSnapshot_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_SpaceQuotaSnapshot_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\013Quota.proto\022\010hbase.pb\032\013HBase.proto\"\204\001\n" +
      "\nTimedQuota\022%\n\ttime_unit\030\001 \002(\0162\022.hbase.p" +
      "b.TimeUnit\022\022\n\nsoft_limit\030\002 \001(\004\022\r\n\005share\030" +
      "\003 \001(\002\022,\n\005scope\030\004 \001(\0162\024.hbase.pb.QuotaSco" +
      "pe:\007MACHINE\"\375\001\n\010Throttle\022%\n\007req_num\030\001 \001(" +
      "\0132\024.hbase.pb.TimedQuota\022&\n\010req_size\030\002 \001(" +
      "\0132\024.hbase.pb.TimedQuota\022\'\n\twrite_num\030\003 \001" +
      "(\0132\024.hbase.pb.TimedQuota\022(\n\nwrite_size\030\004" +
      " \001(\0132\024.hbase.pb.TimedQuota\022&\n\010read_num\030\005" +
      " \001(\0132\024.hbase.pb.TimedQuota\022\'\n\tread_size\030",
      "\006 \001(\0132\024.hbase.pb.TimedQuota\"b\n\017ThrottleR" +
      "equest\022$\n\004type\030\001 \001(\0162\026.hbase.pb.Throttle" +
      "Type\022)\n\013timed_quota\030\002 \001(\0132\024.hbase.pb.Tim" +
      "edQuota\"r\n\006Quotas\022\035\n\016bypass_globals\030\001 \001(" +
      "\010:\005false\022$\n\010throttle\030\002 \001(\0132\022.hbase.pb.Th" +
      "rottle\022#\n\005space\030\003 \001(\0132\024.hbase.pb.SpaceQu" +
      "ota\"\014\n\nQuotaUsage\"q\n\nSpaceQuota\022\022\n\nsoft_" +
      "limit\030\001 \001(\004\0228\n\020violation_policy\030\002 \001(\0162\036." +
      "hbase.pb.SpaceViolationPolicy\022\025\n\006remove\030" +
      "\003 \001(\010:\005false\"8\n\021SpaceLimitRequest\022#\n\005quo",
      "ta\030\001 \001(\0132\024.hbase.pb.SpaceQuota\"b\n\020SpaceQ" +
      "uotaStatus\0228\n\020violation_policy\030\001 \001(\0162\036.h" +
      "base.pb.SpaceViolationPolicy\022\024\n\014in_viola" +
      "tion\030\002 \001(\010\"p\n\022SpaceQuotaSnapshot\0220\n\014quot" +
      "a_status\030\001 \001(\0132\032.hbase.pb.SpaceQuotaStat" +
      "us\022\023\n\013quota_usage\030\002 \001(\004\022\023\n\013quota_limit\030\003" +
      " \001(\004*&\n\nQuotaScope\022\013\n\007CLUSTER\020\001\022\013\n\007MACHI" +
      "NE\020\002*v\n\014ThrottleType\022\022\n\016REQUEST_NUMBER\020\001" +
      "\022\020\n\014REQUEST_SIZE\020\002\022\020\n\014WRITE_NUMBER\020\003\022\016\n\n" +
      "WRITE_SIZE\020\004\022\017\n\013READ_NUMBER\020\005\022\r\n\tREAD_SI",
      "ZE\020\006*$\n\tQuotaType\022\014\n\010THROTTLE\020\001\022\t\n\005SPACE" +
      "\020\002*]\n\024SpaceViolationPolicy\022\013\n\007DISABLE\020\001\022" +
      "\031\n\025NO_WRITES_COMPACTIONS\020\002\022\r\n\tNO_WRITES\020" +
      "\003\022\016\n\nNO_INSERTS\020\004BA\n*org.apache.hadoop.h" +
      "base.protobuf.generatedB\013QuotaProtosH\001\210\001" +
      "\001\240\001\001"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
      new com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner() {
        public com.google.protobuf.ExtensionRegistry assignDescriptors(
            com.google.protobuf.Descriptors.FileDescriptor root) {
          descriptor = root;
          internal_static_hbase_pb_TimedQuota_descriptor =
            getDescriptor().getMessageTypes().get(0);
          internal_static_hbase_pb_TimedQuota_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_TimedQuota_descriptor,
              new java.lang.String[] { "TimeUnit", "SoftLimit", "Share", "Scope", });
          internal_static_hbase_pb_Throttle_descriptor =
            getDescriptor().getMessageTypes().get(1);
          internal_static_hbase_pb_Throttle_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_Throttle_descriptor,
              new java.lang.String[] { "ReqNum", "ReqSize", "WriteNum", "WriteSize", "ReadNum", "ReadSize", });
          internal_static_hbase_pb_ThrottleRequest_descriptor =
            getDescriptor().getMessageTypes().get(2);
          internal_static_hbase_pb_ThrottleRequest_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_ThrottleRequest_descriptor,
              new java.lang.String[] { "Type", "TimedQuota", });
          internal_static_hbase_pb_Quotas_descriptor =
            getDescriptor().getMessageTypes().get(3);
          internal_static_hbase_pb_Quotas_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_Quotas_descriptor,
              new java.lang.String[] { "BypassGlobals", "Throttle", "Space", });
          internal_static_hbase_pb_QuotaUsage_descriptor =
            getDescriptor().getMessageTypes().get(4);
          internal_static_hbase_pb_QuotaUsage_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_QuotaUsage_descriptor,
              new java.lang.String[] { });
          internal_static_hbase_pb_SpaceQuota_descriptor =
            getDescriptor().getMessageTypes().get(5);
          internal_static_hbase_pb_SpaceQuota_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_SpaceQuota_descriptor,
              new java.lang.String[] { "SoftLimit", "ViolationPolicy", "Remove", });
          internal_static_hbase_pb_SpaceLimitRequest_descriptor =
            getDescriptor().getMessageTypes().get(6);
          internal_static_hbase_pb_SpaceLimitRequest_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_SpaceLimitRequest_descriptor,
              new java.lang.String[] { "Quota", });
          internal_static_hbase_pb_SpaceQuotaStatus_descriptor =
            getDescriptor().getMessageTypes().get(7);
          internal_static_hbase_pb_SpaceQuotaStatus_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_SpaceQuotaStatus_descriptor,
              new java.lang.String[] { "ViolationPolicy", "InViolation", });
          internal_static_hbase_pb_SpaceQuotaSnapshot_descriptor =
            getDescriptor().getMessageTypes().get(8);
          internal_static_hbase_pb_SpaceQuotaSnapshot_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_SpaceQuotaSnapshot_descriptor,
              new java.lang.String[] { "QuotaStatus", "QuotaUsage", "QuotaLimit", });
          return null;
        }
      };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.getDescriptor(),
        }, assigner);
  }

  // @@protoc_insertion_point(outer_class_scope)
}
