From 647006f16c7bc8304349e0dd24532280d55c500e Mon Sep 17 00:00:00 2001
From: David <dharju@salesforce.com>
Date: Wed, 14 Jun 2017 14:39:57 -0700
Subject: [PATCH] HBASE-18023 Log multi-* requests for more than threshold
 number of rows

---
 .../java/org/apache/hadoop/hbase/HConstants.java   |  4 ++
 hbase-common/src/main/resources/hbase-default.xml  |  7 ++
 .../apache/hadoop/hbase/regionserver/HRegion.java  | 10 +++
 .../hadoop/hbase/regionserver/TestHRegion.java     | 78 ++++++++++++++++++++++
 4 files changed, 99 insertions(+)

diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java
index d67cb550d0..2e4077b4b5 100644
--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java
+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java
@@ -1362,7 +1362,11 @@ public final class HConstants {
       "hbase.snapshot.restore.failsafe.name";
   public static final String DEFAULT_SNAPSHOT_RESTORE_FAILSAFE_NAME =
       "hbase-failsafe-{snapshot.name}-{restore.timestamp}";
+  
+  public static final String BATCH_SIZE_THRESHOLD_NAME = "hbase.batch.size.threshold";
 
+  public static final int BATCH_SIZE_THRESHOLD_DEFAULT = 1000;
+  
   private HConstants() {
     // Can't be instantiated with this ctor.
   }
diff --git a/hbase-common/src/main/resources/hbase-default.xml b/hbase-common/src/main/resources/hbase-default.xml
index 70c638b913..a619126f9c 100644
--- a/hbase-common/src/main/resources/hbase-default.xml
+++ b/hbase-common/src/main/resources/hbase-default.xml
@@ -1758,4 +1758,11 @@ possible configurations would overwhelm and obscure the important.
        Timeout for regionservers to keep threads in snapshot request pool waiting
     </description>
    </property>
+   <property>
+    <name>hbase.batch.size.threshold</name>
+    <value>1000</value>
+    <description>
+      Number of rows in a batch operation above which a warning will be logged.
+    </description>
+  </property>
 </configuration>
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java
index 7f9c766351..0145de8836 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java
@@ -3171,6 +3171,15 @@ public class HRegion implements HeapSize, PropagatingConfigurationObserver, Regi
     }
   }
 
+  private void checkBatchSizeAndLogLargeSize(BatchOperation<?> batchOp) {
+      int threshold = conf.getInt(HConstants.BATCH_SIZE_THRESHOLD_NAME, HConstants.BATCH_SIZE_THRESHOLD_DEFAULT);
+      if (batchOp.operations.length > threshold) {
+          LOG.warn("Large batch operation detected (greater than "+threshold+") (See https://issues.apache.org/jira/browse/HBASE-18023)."
+                  + " Length: "+batchOp.operations.length
+                  + " Client: "+RpcServer.getRequestUserName()+"/"+RpcServer.getRemoteAddress());
+      }
+  }
+  
   /**
    * Called to do a piece of the batch that came in to {@link #batchMutate(Mutation[], long, long)}
    * In here we also handle replay of edits on region recover.
@@ -3200,6 +3209,7 @@ public class HRegion implements HeapSize, PropagatingConfigurationObserver, Regi
     List<RowLock> acquiredRowLocks = Lists.newArrayListWithCapacity(batchOp.operations.length);
     MemstoreSize memstoreSize = new MemstoreSize();
     final ObservedExceptionsInBatch observedExceptions = new ObservedExceptionsInBatch();
+    checkBatchSizeAndLogLargeSize(batchOp);
     try {
       // STEP 1. Try to acquire as many locks as we can, and ensure we acquire at least one.
       int numReadyToWrite = 0;
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java
index 4f46c88ccd..dc63babf40 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java
@@ -123,6 +123,7 @@ import org.apache.hadoop.hbase.filter.PrefixFilter;
 import org.apache.hadoop.hbase.filter.SingleColumnValueExcludeFilter;
 import org.apache.hadoop.hbase.filter.SingleColumnValueFilter;
 import org.apache.hadoop.hbase.io.hfile.HFile;
+import org.apache.hadoop.hbase.ipc.RpcServer;
 import org.apache.hadoop.hbase.monitoring.MonitoredRPCHandler;
 import org.apache.hadoop.hbase.monitoring.MonitoredTask;
 import org.apache.hadoop.hbase.monitoring.TaskMonitor;
@@ -162,6 +163,10 @@ import org.apache.hadoop.hbase.wal.WALFactory;
 import org.apache.hadoop.hbase.wal.WALKey;
 import org.apache.hadoop.hbase.wal.WALProvider;
 import org.apache.hadoop.hbase.wal.WALProvider.Writer;
+import org.apache.log4j.Appender;
+import org.apache.log4j.Level;
+import org.apache.log4j.LogManager;
+import org.apache.log4j.spi.LoggingEvent;
 import org.apache.hadoop.hbase.wal.WALSplitter;
 import org.junit.After;
 import org.junit.Assert;
@@ -172,8 +177,11 @@ import org.junit.Test;
 import org.junit.experimental.categories.Category;
 import org.junit.rules.TestName;
 import org.junit.rules.TestRule;
+import org.junit.runner.RunWith;
 import org.mockito.ArgumentCaptor;
 import org.mockito.ArgumentMatcher;
+import org.mockito.Captor;
+import org.mockito.Mock;
 import org.mockito.Mockito;
 import org.mockito.invocation.InvocationOnMock;
 import org.mockito.stubbing.Answer;
@@ -190,6 +198,10 @@ public class TestHRegion {
   // Do not spin up clusters in here. If you need to spin up a cluster, do it
   // over in TestHRegionOnCluster.
   private static final Log LOG = LogFactory.getLog(TestHRegion.class);
+  
+  org.apache.log4j.Appender mockAppender = mock(org.apache.log4j.Appender.class);
+  private ArgumentCaptor<LoggingEvent> captorLoggingEvent = ArgumentCaptor.forClass(LoggingEvent.class);
+  
   @Rule
   public TestName name = new TestName();
   @ClassRule
@@ -229,6 +241,7 @@ public class TestHRegion {
     dir = TEST_UTIL.getDataTestDir("TestHRegion").toString();
     method = name.getMethodName();
     tableName = TableName.valueOf(method);
+    LogManager.getRootLogger().addAppender(mockAppender);
   }
 
   @After
@@ -236,6 +249,7 @@ public class TestHRegion {
     EnvironmentEdgeManagerTestHelper.reset();
     LOG.info("Cleaning test directory: " + TEST_UTIL.getDataTestDir());
     TEST_UTIL.cleanupTestDir();
+    LogManager.getRootLogger().removeAppender(mockAppender);
   }
 
   /**
@@ -1925,6 +1939,70 @@ public class TestHRegion {
       this.region = null;
     }
   }
+  
+  private void batchMutations(HRegion region, int numMutations) throws IOException {
+      byte[] row1 = Bytes.toBytes("row1");
+      byte[] qf1 = Bytes.toBytes("qualifier");
+      byte[] val1 = Bytes.toBytes("value1");
+      
+      Mutation [] mutations = new Mutation[numMutations];
+      for (int i = 0; i < numMutations; i++) {
+          Put put = new Put(row1);
+          put.addColumn(fam1, qf1, val1);
+          mutations[i] = put;
+      }
+      region.batchMutate(mutations);
+  }
+  
+  /*
+   * Tests HBASE-18023 Log multi-* requests for more than threshold number of rows (non-emittance)
+   */
+  @Test
+  public void testLogLineNotEmittedOnThresholdNonBreach() throws IOException {
+      byte[][] families = { fam1, fam2 };
+      try{
+          this.region = initHRegion(tableName, method, CONF, families);
+          int amount = CONF.getInt(HConstants.BATCH_SIZE_THRESHOLD_NAME, HConstants.BATCH_SIZE_THRESHOLD_DEFAULT);
+          batchMutations(region, amount);
+          
+          verify(mockAppender, Mockito.atLeastOnce()).doAppend(captorLoggingEvent.capture());
+          List<LoggingEvent> list = captorLoggingEvent.getAllValues();
+          for (LoggingEvent loggingEvent : list) {
+              assertFalse("Found unexpected logging event: \""+loggingEvent.getRenderedMessage()+"\"",loggingEvent.getRenderedMessage().contains("Large batch operation detected"));
+          }
+      }
+      finally {
+        HBaseTestingUtility.closeRegionAndWAL(this.region);
+        this.region = null;
+      }
+  }
+  
+  /*
+   * Tests HBASE-18023 Log multi-* requests for more than threshold number of rows
+   */
+  @Test
+  public void testLogLineEmittedOnThresholdBreach() throws IOException {
+      byte[][] families = { fam1, fam2 };
+      try{
+          this.region = initHRegion(tableName, method, CONF, families);
+          int amount = 1 + CONF.getInt(HConstants.BATCH_SIZE_THRESHOLD_NAME, HConstants.BATCH_SIZE_THRESHOLD_DEFAULT);
+          batchMutations(region, amount);
+          
+          verify(mockAppender, Mockito.atLeastOnce()).doAppend(captorLoggingEvent.capture());
+          LoggingEvent loggingEvent = captorLoggingEvent.getValue();
+          //Check log level
+          assertEquals(loggingEvent.getLevel(), Level.WARN);
+          //Check the message being logged
+          assertEquals(loggingEvent.getRenderedMessage(), 
+                  "Large batch operation detected (greater than "+(amount-1)+") (See https://issues.apache.org/jira/browse/HBASE-18023)."
+                          + " Length: "+amount
+                          + " Client: "+RpcServer.getRequestUserName()+"/"+RpcServer.getRemoteAddress());
+      }
+      finally {
+        HBaseTestingUtility.closeRegionAndWAL(this.region);
+        this.region = null;
+      }
+  }
 
   @Test
   public void testCheckAndPut_ThatPutWasWritten() throws IOException {
-- 
2.11.0

