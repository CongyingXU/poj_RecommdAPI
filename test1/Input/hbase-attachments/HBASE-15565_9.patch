diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Admin.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Admin.java
index 402e43c..c04da97 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Admin.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Admin.java
@@ -38,7 +38,7 @@ import org.apache.hadoop.hbase.TableExistsException;
 import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.TableNotFoundException;
 import org.apache.hadoop.hbase.backup.BackupRequest;
-import org.apache.hadoop.hbase.backup.BackupType;
+import org.apache.hadoop.hbase.backup.RestoreRequest;
 import org.apache.hadoop.hbase.classification.InterfaceAudience;
 import org.apache.hadoop.hbase.classification.InterfaceStability;
 import org.apache.hadoop.hbase.client.security.SecurityCapability;
@@ -954,6 +954,13 @@ public interface Admin extends Abortable, Closeable {
   public String backupTablesSync(final BackupRequest request) throws IOException;
 
   /**
+   * Restore operation.
+   * @param request RestoreRequest instance
+   * @throws IOException 
+   */
+  public void restoreTables(final RestoreRequest request) throws IOException;
+
+  /**
    * Modify an existing table, more IRB friendly version. Asynchronous operation.  This means that
    * it may be a while before your schema change is updated across all of the table.
    * You can use Future.get(long, TimeUnit) to wait on the operation to complete.
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
index 66259ce..ee8f340 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
@@ -64,6 +64,7 @@ import org.apache.hadoop.hbase.ZooKeeperConnectionException;
 import org.apache.hadoop.hbase.backup.BackupRequest;
 import org.apache.hadoop.hbase.backup.BackupType;
 import org.apache.hadoop.hbase.backup.BackupClientUtil;
+import org.apache.hadoop.hbase.backup.RestoreRequest;
 import org.apache.hadoop.hbase.classification.InterfaceAudience;
 import org.apache.hadoop.hbase.classification.InterfaceStability;
 import org.apache.hadoop.hbase.client.security.SecurityCapability;
@@ -151,6 +152,8 @@ import org.apache.hadoop.hbase.protobuf.generated.MasterProtos.ModifyTableRespon
 import org.apache.hadoop.hbase.protobuf.generated.MasterProtos.MoveRegionRequest;
 import org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreSnapshotRequest;
 import org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreSnapshotResponse;
+import org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest;
+import org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse;
 import org.apache.hadoop.hbase.protobuf.generated.MasterProtos.SecurityCapabilitiesRequest;
 import org.apache.hadoop.hbase.protobuf.generated.MasterProtos.SetBalancerRunningRequest;
 import org.apache.hadoop.hbase.protobuf.generated.MasterProtos.SetNormalizerRunningRequest;
@@ -1653,6 +1656,26 @@ public class HBaseAdmin implements Admin {
     }
   }
 
+  /**
+   * Restore operation.
+   * @param request RestoreRequest instance
+   * @throws IOException 
+   */
+  public void restoreTables(final RestoreRequest userRequest) throws IOException {
+    RestoreTablesResponse response = executeCallable(
+      new MasterCallable<RestoreTablesResponse>(getConnection()) {
+        @Override
+        public RestoreTablesResponse call(int callTimeout) throws ServiceException {
+          RestoreTablesRequest request = RequestConverter.buildRestoreTablesRequest(
+            userRequest.getBackupRootDir(), userRequest.getBackupId(),
+            userRequest.getDependencyCheckOnly(), userRequest.getAutoRestore(),
+            userRequest.getTableList(), userRequest.getTargetTableList(),
+            userRequest.getOverwrite());
+          return master.restoreTables(null, request);
+        }
+      });
+  }
+
   @Override
   public Future<Void> modifyTable(final TableName tableName, final HTableDescriptor htd)
   throws IOException {
diff --git a/hbase-protocol/src/main/protobuf/Master.proto b/hbase-protocol/src/main/protobuf/Master.proto
index 507c2b9..f182d3c 100644
--- a/hbase-protocol/src/main/protobuf/Master.proto
+++ b/hbase-protocol/src/main/protobuf/Master.proto
@@ -554,6 +554,19 @@ message BackupTablesResponse {
   optional string backup_id = 2;
 }
 
+message RestoreTablesRequest {
+  required string backup_id = 1;
+  repeated TableName table_list = 2;
+  repeated TableName target_table_list = 3;
+  required string backup_root_dir = 4;
+  required bool dependency_check_only = 5;
+  optional bool auto_restore = 6;
+  optional bool overwrite = 7;
+}
+
+message RestoreTablesResponse {
+}
+
 message AbortBackupRequest {
   required string backup_id = 1;
   optional bool mayInterruptIfRunning = 2 [default = true];
@@ -842,6 +855,10 @@ service MasterService {
   rpc backupTables(BackupTablesRequest)
     returns(BackupTablesResponse);
 
+  /** restore table set */
+  rpc restoreTables(RestoreTablesRequest)
+    returns(RestoreTablesResponse);
+
   /** Abort a backup */
   rpc AbortBackup(AbortBackupRequest)
     returns(AbortBackupResponse);
diff --git a/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/MasterProtos.java b/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/MasterProtos.java
index b7cbdc1..239fc2a 100644
--- a/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/MasterProtos.java
+++ b/hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/MasterProtos.java
@@ -52880,13 +52880,13 @@ public final class MasterProtos {
      */
     long getProcId();
 
-    // optional bool mayInterruptIfRunning = 2 [default = true];
+    // optional bool may_interrupt_if_running = 2 [default = true];
     /**
-     * <code>optional bool mayInterruptIfRunning = 2 [default = true];</code>
+     * <code>optional bool may_interrupt_if_running = 2 [default = true];</code>
      */
     boolean hasMayInterruptIfRunning();
     /**
-     * <code>optional bool mayInterruptIfRunning = 2 [default = true];</code>
+     * <code>optional bool may_interrupt_if_running = 2 [default = true];</code>
      */
     boolean getMayInterruptIfRunning();
   }
@@ -53007,17 +53007,17 @@ public final class MasterProtos {
       return procId_;
     }
 
-    // optional bool mayInterruptIfRunning = 2 [default = true];
-    public static final int MAYINTERRUPTIFRUNNING_FIELD_NUMBER = 2;
+    // optional bool may_interrupt_if_running = 2 [default = true];
+    public static final int MAY_INTERRUPT_IF_RUNNING_FIELD_NUMBER = 2;
     private boolean mayInterruptIfRunning_;
     /**
-     * <code>optional bool mayInterruptIfRunning = 2 [default = true];</code>
+     * <code>optional bool may_interrupt_if_running = 2 [default = true];</code>
      */
     public boolean hasMayInterruptIfRunning() {
       return ((bitField0_ & 0x00000002) == 0x00000002);
     }
     /**
-     * <code>optional bool mayInterruptIfRunning = 2 [default = true];</code>
+     * <code>optional bool may_interrupt_if_running = 2 [default = true];</code>
      */
     public boolean getMayInterruptIfRunning() {
       return mayInterruptIfRunning_;
@@ -53117,7 +53117,7 @@ public final class MasterProtos {
         hash = (53 * hash) + hashLong(getProcId());
       }
       if (hasMayInterruptIfRunning()) {
-        hash = (37 * hash) + MAYINTERRUPTIFRUNNING_FIELD_NUMBER;
+        hash = (37 * hash) + MAY_INTERRUPT_IF_RUNNING_FIELD_NUMBER;
         hash = (53 * hash) + hashBoolean(getMayInterruptIfRunning());
       }
       hash = (29 * hash) + getUnknownFields().hashCode();
@@ -53355,22 +53355,22 @@ public final class MasterProtos {
         return this;
       }
 
-      // optional bool mayInterruptIfRunning = 2 [default = true];
+      // optional bool may_interrupt_if_running = 2 [default = true];
       private boolean mayInterruptIfRunning_ = true;
       /**
-       * <code>optional bool mayInterruptIfRunning = 2 [default = true];</code>
+       * <code>optional bool may_interrupt_if_running = 2 [default = true];</code>
        */
       public boolean hasMayInterruptIfRunning() {
         return ((bitField0_ & 0x00000002) == 0x00000002);
       }
       /**
-       * <code>optional bool mayInterruptIfRunning = 2 [default = true];</code>
+       * <code>optional bool may_interrupt_if_running = 2 [default = true];</code>
        */
       public boolean getMayInterruptIfRunning() {
         return mayInterruptIfRunning_;
       }
       /**
-       * <code>optional bool mayInterruptIfRunning = 2 [default = true];</code>
+       * <code>optional bool may_interrupt_if_running = 2 [default = true];</code>
        */
       public Builder setMayInterruptIfRunning(boolean value) {
         bitField0_ |= 0x00000002;
@@ -53379,7 +53379,7 @@ public final class MasterProtos {
         return this;
       }
       /**
-       * <code>optional bool mayInterruptIfRunning = 2 [default = true];</code>
+       * <code>optional bool may_interrupt_if_running = 2 [default = true];</code>
        */
       public Builder clearMayInterruptIfRunning() {
         bitField0_ = (bitField0_ & ~0x00000002);
@@ -60998,7 +60998,7 @@ public final class MasterProtos {
     // @@protoc_insertion_point(class_scope:hbase.pb.BackupTablesResponse)
   }
 
-  public interface AbortBackupRequestOrBuilder
+  public interface RestoreTablesRequestOrBuilder
       extends com.google.protobuf.MessageOrBuilder {
 
     // required string backup_id = 1;
@@ -61016,35 +61016,120 @@ public final class MasterProtos {
     com.google.protobuf.ByteString
         getBackupIdBytes();
 
-    // optional bool mayInterruptIfRunning = 2 [default = true];
+    // repeated .hbase.pb.TableName table_list = 2;
     /**
-     * <code>optional bool mayInterruptIfRunning = 2 [default = true];</code>
+     * <code>repeated .hbase.pb.TableName table_list = 2;</code>
      */
-    boolean hasMayInterruptIfRunning();
+    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName> 
+        getTableListList();
     /**
-     * <code>optional bool mayInterruptIfRunning = 2 [default = true];</code>
+     * <code>repeated .hbase.pb.TableName table_list = 2;</code>
      */
-    boolean getMayInterruptIfRunning();
+    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableList(int index);
+    /**
+     * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+     */
+    int getTableListCount();
+    /**
+     * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+     */
+    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
+        getTableListOrBuilderList();
+    /**
+     * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+     */
+    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableListOrBuilder(
+        int index);
+
+    // repeated .hbase.pb.TableName target_table_list = 3;
+    /**
+     * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+     */
+    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName> 
+        getTargetTableListList();
+    /**
+     * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+     */
+    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTargetTableList(int index);
+    /**
+     * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+     */
+    int getTargetTableListCount();
+    /**
+     * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+     */
+    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
+        getTargetTableListOrBuilderList();
+    /**
+     * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+     */
+    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTargetTableListOrBuilder(
+        int index);
+
+    // required string backup_root_dir = 4;
+    /**
+     * <code>required string backup_root_dir = 4;</code>
+     */
+    boolean hasBackupRootDir();
+    /**
+     * <code>required string backup_root_dir = 4;</code>
+     */
+    java.lang.String getBackupRootDir();
+    /**
+     * <code>required string backup_root_dir = 4;</code>
+     */
+    com.google.protobuf.ByteString
+        getBackupRootDirBytes();
+
+    // required bool dependency_check_only = 5;
+    /**
+     * <code>required bool dependency_check_only = 5;</code>
+     */
+    boolean hasDependencyCheckOnly();
+    /**
+     * <code>required bool dependency_check_only = 5;</code>
+     */
+    boolean getDependencyCheckOnly();
+
+    // optional bool auto_restore = 6;
+    /**
+     * <code>optional bool auto_restore = 6;</code>
+     */
+    boolean hasAutoRestore();
+    /**
+     * <code>optional bool auto_restore = 6;</code>
+     */
+    boolean getAutoRestore();
+
+    // optional bool overwrite = 7;
+    /**
+     * <code>optional bool overwrite = 7;</code>
+     */
+    boolean hasOverwrite();
+    /**
+     * <code>optional bool overwrite = 7;</code>
+     */
+    boolean getOverwrite();
   }
   /**
-   * Protobuf type {@code hbase.pb.AbortBackupRequest}
+   * Protobuf type {@code hbase.pb.RestoreTablesRequest}
    */
-  public static final class AbortBackupRequest extends
+  public static final class RestoreTablesRequest extends
       com.google.protobuf.GeneratedMessage
-      implements AbortBackupRequestOrBuilder {
-    // Use AbortBackupRequest.newBuilder() to construct.
-    private AbortBackupRequest(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
+      implements RestoreTablesRequestOrBuilder {
+    // Use RestoreTablesRequest.newBuilder() to construct.
+    private RestoreTablesRequest(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
       super(builder);
       this.unknownFields = builder.getUnknownFields();
     }
-    private AbortBackupRequest(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }
+    private RestoreTablesRequest(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }
 
-    private static final AbortBackupRequest defaultInstance;
-    public static AbortBackupRequest getDefaultInstance() {
+    private static final RestoreTablesRequest defaultInstance;
+    public static RestoreTablesRequest getDefaultInstance() {
       return defaultInstance;
     }
 
-    public AbortBackupRequest getDefaultInstanceForType() {
+    public RestoreTablesRequest getDefaultInstanceForType() {
       return defaultInstance;
     }
 
@@ -61054,7 +61139,7 @@ public final class MasterProtos {
         getUnknownFields() {
       return this.unknownFields;
     }
-    private AbortBackupRequest(
+    private RestoreTablesRequest(
         com.google.protobuf.CodedInputStream input,
         com.google.protobuf.ExtensionRegistryLite extensionRegistry)
         throws com.google.protobuf.InvalidProtocolBufferException {
@@ -61082,9 +61167,40 @@ public final class MasterProtos {
               backupId_ = input.readBytes();
               break;
             }
-            case 16: {
+            case 18: {
+              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
+                tableList_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName>();
+                mutable_bitField0_ |= 0x00000002;
+              }
+              tableList_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.PARSER, extensionRegistry));
+              break;
+            }
+            case 26: {
+              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
+                targetTableList_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName>();
+                mutable_bitField0_ |= 0x00000004;
+              }
+              targetTableList_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.PARSER, extensionRegistry));
+              break;
+            }
+            case 34: {
               bitField0_ |= 0x00000002;
-              mayInterruptIfRunning_ = input.readBool();
+              backupRootDir_ = input.readBytes();
+              break;
+            }
+            case 40: {
+              bitField0_ |= 0x00000004;
+              dependencyCheckOnly_ = input.readBool();
+              break;
+            }
+            case 48: {
+              bitField0_ |= 0x00000008;
+              autoRestore_ = input.readBool();
+              break;
+            }
+            case 56: {
+              bitField0_ |= 0x00000010;
+              overwrite_ = input.readBool();
               break;
             }
           }
@@ -61095,34 +61211,40 @@ public final class MasterProtos {
         throw new com.google.protobuf.InvalidProtocolBufferException(
             e.getMessage()).setUnfinishedMessage(this);
       } finally {
+        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
+          tableList_ = java.util.Collections.unmodifiableList(tableList_);
+        }
+        if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
+          targetTableList_ = java.util.Collections.unmodifiableList(targetTableList_);
+        }
         this.unknownFields = unknownFields.build();
         makeExtensionsImmutable();
       }
     }
     public static final com.google.protobuf.Descriptors.Descriptor
         getDescriptor() {
-      return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.internal_static_hbase_pb_AbortBackupRequest_descriptor;
+      return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.internal_static_hbase_pb_RestoreTablesRequest_descriptor;
     }
 
     protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
         internalGetFieldAccessorTable() {
-      return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.internal_static_hbase_pb_AbortBackupRequest_fieldAccessorTable
+      return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.internal_static_hbase_pb_RestoreTablesRequest_fieldAccessorTable
           .ensureFieldAccessorsInitialized(
-              org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupRequest.class, org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupRequest.Builder.class);
+              org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest.class, org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest.Builder.class);
     }
 
-    public static com.google.protobuf.Parser<AbortBackupRequest> PARSER =
-        new com.google.protobuf.AbstractParser<AbortBackupRequest>() {
-      public AbortBackupRequest parsePartialFrom(
+    public static com.google.protobuf.Parser<RestoreTablesRequest> PARSER =
+        new com.google.protobuf.AbstractParser<RestoreTablesRequest>() {
+      public RestoreTablesRequest parsePartialFrom(
           com.google.protobuf.CodedInputStream input,
           com.google.protobuf.ExtensionRegistryLite extensionRegistry)
           throws com.google.protobuf.InvalidProtocolBufferException {
-        return new AbortBackupRequest(input, extensionRegistry);
+        return new RestoreTablesRequest(input, extensionRegistry);
       }
     };
 
     @java.lang.Override
-    public com.google.protobuf.Parser<AbortBackupRequest> getParserForType() {
+    public com.google.protobuf.Parser<RestoreTablesRequest> getParserForType() {
       return PARSER;
     }
 
@@ -61170,25 +61292,177 @@ public final class MasterProtos {
       }
     }
 
-    // optional bool mayInterruptIfRunning = 2 [default = true];
-    public static final int MAYINTERRUPTIFRUNNING_FIELD_NUMBER = 2;
-    private boolean mayInterruptIfRunning_;
+    // repeated .hbase.pb.TableName table_list = 2;
+    public static final int TABLE_LIST_FIELD_NUMBER = 2;
+    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName> tableList_;
     /**
-     * <code>optional bool mayInterruptIfRunning = 2 [default = true];</code>
+     * <code>repeated .hbase.pb.TableName table_list = 2;</code>
      */
-    public boolean hasMayInterruptIfRunning() {
+    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName> getTableListList() {
+      return tableList_;
+    }
+    /**
+     * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+     */
+    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
+        getTableListOrBuilderList() {
+      return tableList_;
+    }
+    /**
+     * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+     */
+    public int getTableListCount() {
+      return tableList_.size();
+    }
+    /**
+     * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+     */
+    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableList(int index) {
+      return tableList_.get(index);
+    }
+    /**
+     * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+     */
+    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableListOrBuilder(
+        int index) {
+      return tableList_.get(index);
+    }
+
+    // repeated .hbase.pb.TableName target_table_list = 3;
+    public static final int TARGET_TABLE_LIST_FIELD_NUMBER = 3;
+    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName> targetTableList_;
+    /**
+     * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+     */
+    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName> getTargetTableListList() {
+      return targetTableList_;
+    }
+    /**
+     * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+     */
+    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
+        getTargetTableListOrBuilderList() {
+      return targetTableList_;
+    }
+    /**
+     * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+     */
+    public int getTargetTableListCount() {
+      return targetTableList_.size();
+    }
+    /**
+     * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+     */
+    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTargetTableList(int index) {
+      return targetTableList_.get(index);
+    }
+    /**
+     * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+     */
+    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTargetTableListOrBuilder(
+        int index) {
+      return targetTableList_.get(index);
+    }
+
+    // required string backup_root_dir = 4;
+    public static final int BACKUP_ROOT_DIR_FIELD_NUMBER = 4;
+    private java.lang.Object backupRootDir_;
+    /**
+     * <code>required string backup_root_dir = 4;</code>
+     */
+    public boolean hasBackupRootDir() {
       return ((bitField0_ & 0x00000002) == 0x00000002);
     }
     /**
-     * <code>optional bool mayInterruptIfRunning = 2 [default = true];</code>
+     * <code>required string backup_root_dir = 4;</code>
      */
-    public boolean getMayInterruptIfRunning() {
-      return mayInterruptIfRunning_;
+    public java.lang.String getBackupRootDir() {
+      java.lang.Object ref = backupRootDir_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        if (bs.isValidUtf8()) {
+          backupRootDir_ = s;
+        }
+        return s;
+      }
+    }
+    /**
+     * <code>required string backup_root_dir = 4;</code>
+     */
+    public com.google.protobuf.ByteString
+        getBackupRootDirBytes() {
+      java.lang.Object ref = backupRootDir_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        backupRootDir_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    // required bool dependency_check_only = 5;
+    public static final int DEPENDENCY_CHECK_ONLY_FIELD_NUMBER = 5;
+    private boolean dependencyCheckOnly_;
+    /**
+     * <code>required bool dependency_check_only = 5;</code>
+     */
+    public boolean hasDependencyCheckOnly() {
+      return ((bitField0_ & 0x00000004) == 0x00000004);
+    }
+    /**
+     * <code>required bool dependency_check_only = 5;</code>
+     */
+    public boolean getDependencyCheckOnly() {
+      return dependencyCheckOnly_;
+    }
+
+    // optional bool auto_restore = 6;
+    public static final int AUTO_RESTORE_FIELD_NUMBER = 6;
+    private boolean autoRestore_;
+    /**
+     * <code>optional bool auto_restore = 6;</code>
+     */
+    public boolean hasAutoRestore() {
+      return ((bitField0_ & 0x00000008) == 0x00000008);
+    }
+    /**
+     * <code>optional bool auto_restore = 6;</code>
+     */
+    public boolean getAutoRestore() {
+      return autoRestore_;
+    }
+
+    // optional bool overwrite = 7;
+    public static final int OVERWRITE_FIELD_NUMBER = 7;
+    private boolean overwrite_;
+    /**
+     * <code>optional bool overwrite = 7;</code>
+     */
+    public boolean hasOverwrite() {
+      return ((bitField0_ & 0x00000010) == 0x00000010);
+    }
+    /**
+     * <code>optional bool overwrite = 7;</code>
+     */
+    public boolean getOverwrite() {
+      return overwrite_;
     }
 
     private void initFields() {
       backupId_ = "";
-      mayInterruptIfRunning_ = true;
+      tableList_ = java.util.Collections.emptyList();
+      targetTableList_ = java.util.Collections.emptyList();
+      backupRootDir_ = "";
+      dependencyCheckOnly_ = false;
+      autoRestore_ = false;
+      overwrite_ = false;
     }
     private byte memoizedIsInitialized = -1;
     public final boolean isInitialized() {
@@ -61199,6 +61473,26 @@ public final class MasterProtos {
         memoizedIsInitialized = 0;
         return false;
       }
+      if (!hasBackupRootDir()) {
+        memoizedIsInitialized = 0;
+        return false;
+      }
+      if (!hasDependencyCheckOnly()) {
+        memoizedIsInitialized = 0;
+        return false;
+      }
+      for (int i = 0; i < getTableListCount(); i++) {
+        if (!getTableList(i).isInitialized()) {
+          memoizedIsInitialized = 0;
+          return false;
+        }
+      }
+      for (int i = 0; i < getTargetTableListCount(); i++) {
+        if (!getTargetTableList(i).isInitialized()) {
+          memoizedIsInitialized = 0;
+          return false;
+        }
+      }
       memoizedIsInitialized = 1;
       return true;
     }
@@ -61209,8 +61503,23 @@ public final class MasterProtos {
       if (((bitField0_ & 0x00000001) == 0x00000001)) {
         output.writeBytes(1, getBackupIdBytes());
       }
+      for (int i = 0; i < tableList_.size(); i++) {
+        output.writeMessage(2, tableList_.get(i));
+      }
+      for (int i = 0; i < targetTableList_.size(); i++) {
+        output.writeMessage(3, targetTableList_.get(i));
+      }
       if (((bitField0_ & 0x00000002) == 0x00000002)) {
-        output.writeBool(2, mayInterruptIfRunning_);
+        output.writeBytes(4, getBackupRootDirBytes());
+      }
+      if (((bitField0_ & 0x00000004) == 0x00000004)) {
+        output.writeBool(5, dependencyCheckOnly_);
+      }
+      if (((bitField0_ & 0x00000008) == 0x00000008)) {
+        output.writeBool(6, autoRestore_);
+      }
+      if (((bitField0_ & 0x00000010) == 0x00000010)) {
+        output.writeBool(7, overwrite_);
       }
       getUnknownFields().writeTo(output);
     }
@@ -61225,9 +61534,29 @@ public final class MasterProtos {
         size += com.google.protobuf.CodedOutputStream
           .computeBytesSize(1, getBackupIdBytes());
       }
+      for (int i = 0; i < tableList_.size(); i++) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeMessageSize(2, tableList_.get(i));
+      }
+      for (int i = 0; i < targetTableList_.size(); i++) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeMessageSize(3, targetTableList_.get(i));
+      }
       if (((bitField0_ & 0x00000002) == 0x00000002)) {
         size += com.google.protobuf.CodedOutputStream
-          .computeBoolSize(2, mayInterruptIfRunning_);
+          .computeBytesSize(4, getBackupRootDirBytes());
+      }
+      if (((bitField0_ & 0x00000004) == 0x00000004)) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeBoolSize(5, dependencyCheckOnly_);
+      }
+      if (((bitField0_ & 0x00000008) == 0x00000008)) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeBoolSize(6, autoRestore_);
+      }
+      if (((bitField0_ & 0x00000010) == 0x00000010)) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeBoolSize(7, overwrite_);
       }
       size += getUnknownFields().getSerializedSize();
       memoizedSerializedSize = size;
@@ -61246,10 +61575,10 @@ public final class MasterProtos {
       if (obj == this) {
        return true;
       }
-      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupRequest)) {
+      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest)) {
         return super.equals(obj);
       }
-      org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupRequest other = (org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupRequest) obj;
+      org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest other = (org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest) obj;
 
       boolean result = true;
       result = result && (hasBackupId() == other.hasBackupId());
@@ -61257,10 +61586,29 @@ public final class MasterProtos {
         result = result && getBackupId()
             .equals(other.getBackupId());
       }
-      result = result && (hasMayInterruptIfRunning() == other.hasMayInterruptIfRunning());
-      if (hasMayInterruptIfRunning()) {
-        result = result && (getMayInterruptIfRunning()
-            == other.getMayInterruptIfRunning());
+      result = result && getTableListList()
+          .equals(other.getTableListList());
+      result = result && getTargetTableListList()
+          .equals(other.getTargetTableListList());
+      result = result && (hasBackupRootDir() == other.hasBackupRootDir());
+      if (hasBackupRootDir()) {
+        result = result && getBackupRootDir()
+            .equals(other.getBackupRootDir());
+      }
+      result = result && (hasDependencyCheckOnly() == other.hasDependencyCheckOnly());
+      if (hasDependencyCheckOnly()) {
+        result = result && (getDependencyCheckOnly()
+            == other.getDependencyCheckOnly());
+      }
+      result = result && (hasAutoRestore() == other.hasAutoRestore());
+      if (hasAutoRestore()) {
+        result = result && (getAutoRestore()
+            == other.getAutoRestore());
+      }
+      result = result && (hasOverwrite() == other.hasOverwrite());
+      if (hasOverwrite()) {
+        result = result && (getOverwrite()
+            == other.getOverwrite());
       }
       result = result &&
           getUnknownFields().equals(other.getUnknownFields());
@@ -61279,27 +61627,1745 @@ public final class MasterProtos {
         hash = (37 * hash) + BACKUP_ID_FIELD_NUMBER;
         hash = (53 * hash) + getBackupId().hashCode();
       }
-      if (hasMayInterruptIfRunning()) {
-        hash = (37 * hash) + MAYINTERRUPTIFRUNNING_FIELD_NUMBER;
-        hash = (53 * hash) + hashBoolean(getMayInterruptIfRunning());
+      if (getTableListCount() > 0) {
+        hash = (37 * hash) + TABLE_LIST_FIELD_NUMBER;
+        hash = (53 * hash) + getTableListList().hashCode();
+      }
+      if (getTargetTableListCount() > 0) {
+        hash = (37 * hash) + TARGET_TABLE_LIST_FIELD_NUMBER;
+        hash = (53 * hash) + getTargetTableListList().hashCode();
+      }
+      if (hasBackupRootDir()) {
+        hash = (37 * hash) + BACKUP_ROOT_DIR_FIELD_NUMBER;
+        hash = (53 * hash) + getBackupRootDir().hashCode();
+      }
+      if (hasDependencyCheckOnly()) {
+        hash = (37 * hash) + DEPENDENCY_CHECK_ONLY_FIELD_NUMBER;
+        hash = (53 * hash) + hashBoolean(getDependencyCheckOnly());
+      }
+      if (hasAutoRestore()) {
+        hash = (37 * hash) + AUTO_RESTORE_FIELD_NUMBER;
+        hash = (53 * hash) + hashBoolean(getAutoRestore());
+      }
+      if (hasOverwrite()) {
+        hash = (37 * hash) + OVERWRITE_FIELD_NUMBER;
+        hash = (53 * hash) + hashBoolean(getOverwrite());
       }
       hash = (29 * hash) + getUnknownFields().hashCode();
       memoizedHashCode = hash;
       return hash;
     }
 
-    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupRequest parseFrom(
+    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest parseFrom(
         com.google.protobuf.ByteString data)
         throws com.google.protobuf.InvalidProtocolBufferException {
       return PARSER.parseFrom(data);
     }
-    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupRequest parseFrom(
+    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest parseFrom(
         com.google.protobuf.ByteString data,
         com.google.protobuf.ExtensionRegistryLite extensionRegistry)
         throws com.google.protobuf.InvalidProtocolBufferException {
       return PARSER.parseFrom(data, extensionRegistry);
     }
-    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupRequest parseFrom(byte[] data)
+    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest parseFrom(byte[] data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest parseFrom(
+        byte[] data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest parseFrom(java.io.InputStream input)
+        throws java.io.IOException {
+      return PARSER.parseFrom(input);
+    }
+    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest parseFrom(
+        java.io.InputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return PARSER.parseFrom(input, extensionRegistry);
+    }
+    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest parseDelimitedFrom(java.io.InputStream input)
+        throws java.io.IOException {
+      return PARSER.parseDelimitedFrom(input);
+    }
+    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest parseDelimitedFrom(
+        java.io.InputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return PARSER.parseDelimitedFrom(input, extensionRegistry);
+    }
+    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest parseFrom(
+        com.google.protobuf.CodedInputStream input)
+        throws java.io.IOException {
+      return PARSER.parseFrom(input);
+    }
+    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest parseFrom(
+        com.google.protobuf.CodedInputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return PARSER.parseFrom(input, extensionRegistry);
+    }
+
+    public static Builder newBuilder() { return Builder.create(); }
+    public Builder newBuilderForType() { return newBuilder(); }
+    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest prototype) {
+      return newBuilder().mergeFrom(prototype);
+    }
+    public Builder toBuilder() { return newBuilder(this); }
+
+    @java.lang.Override
+    protected Builder newBuilderForType(
+        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
+      Builder builder = new Builder(parent);
+      return builder;
+    }
+    /**
+     * Protobuf type {@code hbase.pb.RestoreTablesRequest}
+     */
+    public static final class Builder extends
+        com.google.protobuf.GeneratedMessage.Builder<Builder>
+       implements org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequestOrBuilder {
+      public static final com.google.protobuf.Descriptors.Descriptor
+          getDescriptor() {
+        return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.internal_static_hbase_pb_RestoreTablesRequest_descriptor;
+      }
+
+      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
+          internalGetFieldAccessorTable() {
+        return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.internal_static_hbase_pb_RestoreTablesRequest_fieldAccessorTable
+            .ensureFieldAccessorsInitialized(
+                org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest.class, org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest.Builder.class);
+      }
+
+      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest.newBuilder()
+      private Builder() {
+        maybeForceBuilderInitialization();
+      }
+
+      private Builder(
+          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
+        super(parent);
+        maybeForceBuilderInitialization();
+      }
+      private void maybeForceBuilderInitialization() {
+        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
+          getTableListFieldBuilder();
+          getTargetTableListFieldBuilder();
+        }
+      }
+      private static Builder create() {
+        return new Builder();
+      }
+
+      public Builder clear() {
+        super.clear();
+        backupId_ = "";
+        bitField0_ = (bitField0_ & ~0x00000001);
+        if (tableListBuilder_ == null) {
+          tableList_ = java.util.Collections.emptyList();
+          bitField0_ = (bitField0_ & ~0x00000002);
+        } else {
+          tableListBuilder_.clear();
+        }
+        if (targetTableListBuilder_ == null) {
+          targetTableList_ = java.util.Collections.emptyList();
+          bitField0_ = (bitField0_ & ~0x00000004);
+        } else {
+          targetTableListBuilder_.clear();
+        }
+        backupRootDir_ = "";
+        bitField0_ = (bitField0_ & ~0x00000008);
+        dependencyCheckOnly_ = false;
+        bitField0_ = (bitField0_ & ~0x00000010);
+        autoRestore_ = false;
+        bitField0_ = (bitField0_ & ~0x00000020);
+        overwrite_ = false;
+        bitField0_ = (bitField0_ & ~0x00000040);
+        return this;
+      }
+
+      public Builder clone() {
+        return create().mergeFrom(buildPartial());
+      }
+
+      public com.google.protobuf.Descriptors.Descriptor
+          getDescriptorForType() {
+        return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.internal_static_hbase_pb_RestoreTablesRequest_descriptor;
+      }
+
+      public org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest getDefaultInstanceForType() {
+        return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest.getDefaultInstance();
+      }
+
+      public org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest build() {
+        org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest result = buildPartial();
+        if (!result.isInitialized()) {
+          throw newUninitializedMessageException(result);
+        }
+        return result;
+      }
+
+      public org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest buildPartial() {
+        org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest result = new org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest(this);
+        int from_bitField0_ = bitField0_;
+        int to_bitField0_ = 0;
+        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
+          to_bitField0_ |= 0x00000001;
+        }
+        result.backupId_ = backupId_;
+        if (tableListBuilder_ == null) {
+          if (((bitField0_ & 0x00000002) == 0x00000002)) {
+            tableList_ = java.util.Collections.unmodifiableList(tableList_);
+            bitField0_ = (bitField0_ & ~0x00000002);
+          }
+          result.tableList_ = tableList_;
+        } else {
+          result.tableList_ = tableListBuilder_.build();
+        }
+        if (targetTableListBuilder_ == null) {
+          if (((bitField0_ & 0x00000004) == 0x00000004)) {
+            targetTableList_ = java.util.Collections.unmodifiableList(targetTableList_);
+            bitField0_ = (bitField0_ & ~0x00000004);
+          }
+          result.targetTableList_ = targetTableList_;
+        } else {
+          result.targetTableList_ = targetTableListBuilder_.build();
+        }
+        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
+          to_bitField0_ |= 0x00000002;
+        }
+        result.backupRootDir_ = backupRootDir_;
+        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
+          to_bitField0_ |= 0x00000004;
+        }
+        result.dependencyCheckOnly_ = dependencyCheckOnly_;
+        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
+          to_bitField0_ |= 0x00000008;
+        }
+        result.autoRestore_ = autoRestore_;
+        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
+          to_bitField0_ |= 0x00000010;
+        }
+        result.overwrite_ = overwrite_;
+        result.bitField0_ = to_bitField0_;
+        onBuilt();
+        return result;
+      }
+
+      public Builder mergeFrom(com.google.protobuf.Message other) {
+        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest) {
+          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest)other);
+        } else {
+          super.mergeFrom(other);
+          return this;
+        }
+      }
+
+      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest other) {
+        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest.getDefaultInstance()) return this;
+        if (other.hasBackupId()) {
+          bitField0_ |= 0x00000001;
+          backupId_ = other.backupId_;
+          onChanged();
+        }
+        if (tableListBuilder_ == null) {
+          if (!other.tableList_.isEmpty()) {
+            if (tableList_.isEmpty()) {
+              tableList_ = other.tableList_;
+              bitField0_ = (bitField0_ & ~0x00000002);
+            } else {
+              ensureTableListIsMutable();
+              tableList_.addAll(other.tableList_);
+            }
+            onChanged();
+          }
+        } else {
+          if (!other.tableList_.isEmpty()) {
+            if (tableListBuilder_.isEmpty()) {
+              tableListBuilder_.dispose();
+              tableListBuilder_ = null;
+              tableList_ = other.tableList_;
+              bitField0_ = (bitField0_ & ~0x00000002);
+              tableListBuilder_ = 
+                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
+                   getTableListFieldBuilder() : null;
+            } else {
+              tableListBuilder_.addAllMessages(other.tableList_);
+            }
+          }
+        }
+        if (targetTableListBuilder_ == null) {
+          if (!other.targetTableList_.isEmpty()) {
+            if (targetTableList_.isEmpty()) {
+              targetTableList_ = other.targetTableList_;
+              bitField0_ = (bitField0_ & ~0x00000004);
+            } else {
+              ensureTargetTableListIsMutable();
+              targetTableList_.addAll(other.targetTableList_);
+            }
+            onChanged();
+          }
+        } else {
+          if (!other.targetTableList_.isEmpty()) {
+            if (targetTableListBuilder_.isEmpty()) {
+              targetTableListBuilder_.dispose();
+              targetTableListBuilder_ = null;
+              targetTableList_ = other.targetTableList_;
+              bitField0_ = (bitField0_ & ~0x00000004);
+              targetTableListBuilder_ = 
+                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
+                   getTargetTableListFieldBuilder() : null;
+            } else {
+              targetTableListBuilder_.addAllMessages(other.targetTableList_);
+            }
+          }
+        }
+        if (other.hasBackupRootDir()) {
+          bitField0_ |= 0x00000008;
+          backupRootDir_ = other.backupRootDir_;
+          onChanged();
+        }
+        if (other.hasDependencyCheckOnly()) {
+          setDependencyCheckOnly(other.getDependencyCheckOnly());
+        }
+        if (other.hasAutoRestore()) {
+          setAutoRestore(other.getAutoRestore());
+        }
+        if (other.hasOverwrite()) {
+          setOverwrite(other.getOverwrite());
+        }
+        this.mergeUnknownFields(other.getUnknownFields());
+        return this;
+      }
+
+      public final boolean isInitialized() {
+        if (!hasBackupId()) {
+          
+          return false;
+        }
+        if (!hasBackupRootDir()) {
+          
+          return false;
+        }
+        if (!hasDependencyCheckOnly()) {
+          
+          return false;
+        }
+        for (int i = 0; i < getTableListCount(); i++) {
+          if (!getTableList(i).isInitialized()) {
+            
+            return false;
+          }
+        }
+        for (int i = 0; i < getTargetTableListCount(); i++) {
+          if (!getTargetTableList(i).isInitialized()) {
+            
+            return false;
+          }
+        }
+        return true;
+      }
+
+      public Builder mergeFrom(
+          com.google.protobuf.CodedInputStream input,
+          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+          throws java.io.IOException {
+        org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest parsedMessage = null;
+        try {
+          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
+        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
+          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest) e.getUnfinishedMessage();
+          throw e;
+        } finally {
+          if (parsedMessage != null) {
+            mergeFrom(parsedMessage);
+          }
+        }
+        return this;
+      }
+      private int bitField0_;
+
+      // required string backup_id = 1;
+      private java.lang.Object backupId_ = "";
+      /**
+       * <code>required string backup_id = 1;</code>
+       */
+      public boolean hasBackupId() {
+        return ((bitField0_ & 0x00000001) == 0x00000001);
+      }
+      /**
+       * <code>required string backup_id = 1;</code>
+       */
+      public java.lang.String getBackupId() {
+        java.lang.Object ref = backupId_;
+        if (!(ref instanceof java.lang.String)) {
+          java.lang.String s = ((com.google.protobuf.ByteString) ref)
+              .toStringUtf8();
+          backupId_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>required string backup_id = 1;</code>
+       */
+      public com.google.protobuf.ByteString
+          getBackupIdBytes() {
+        java.lang.Object ref = backupId_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          backupId_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>required string backup_id = 1;</code>
+       */
+      public Builder setBackupId(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  bitField0_ |= 0x00000001;
+        backupId_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>required string backup_id = 1;</code>
+       */
+      public Builder clearBackupId() {
+        bitField0_ = (bitField0_ & ~0x00000001);
+        backupId_ = getDefaultInstance().getBackupId();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>required string backup_id = 1;</code>
+       */
+      public Builder setBackupIdBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  bitField0_ |= 0x00000001;
+        backupId_ = value;
+        onChanged();
+        return this;
+      }
+
+      // repeated .hbase.pb.TableName table_list = 2;
+      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName> tableList_ =
+        java.util.Collections.emptyList();
+      private void ensureTableListIsMutable() {
+        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
+          tableList_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName>(tableList_);
+          bitField0_ |= 0x00000002;
+         }
+      }
+
+      private com.google.protobuf.RepeatedFieldBuilder<
+          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableListBuilder_;
+
+      /**
+       * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+       */
+      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName> getTableListList() {
+        if (tableListBuilder_ == null) {
+          return java.util.Collections.unmodifiableList(tableList_);
+        } else {
+          return tableListBuilder_.getMessageList();
+        }
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+       */
+      public int getTableListCount() {
+        if (tableListBuilder_ == null) {
+          return tableList_.size();
+        } else {
+          return tableListBuilder_.getCount();
+        }
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+       */
+      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableList(int index) {
+        if (tableListBuilder_ == null) {
+          return tableList_.get(index);
+        } else {
+          return tableListBuilder_.getMessage(index);
+        }
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+       */
+      public Builder setTableList(
+          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName value) {
+        if (tableListBuilder_ == null) {
+          if (value == null) {
+            throw new NullPointerException();
+          }
+          ensureTableListIsMutable();
+          tableList_.set(index, value);
+          onChanged();
+        } else {
+          tableListBuilder_.setMessage(index, value);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+       */
+      public Builder setTableList(
+          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
+        if (tableListBuilder_ == null) {
+          ensureTableListIsMutable();
+          tableList_.set(index, builderForValue.build());
+          onChanged();
+        } else {
+          tableListBuilder_.setMessage(index, builderForValue.build());
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+       */
+      public Builder addTableList(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName value) {
+        if (tableListBuilder_ == null) {
+          if (value == null) {
+            throw new NullPointerException();
+          }
+          ensureTableListIsMutable();
+          tableList_.add(value);
+          onChanged();
+        } else {
+          tableListBuilder_.addMessage(value);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+       */
+      public Builder addTableList(
+          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName value) {
+        if (tableListBuilder_ == null) {
+          if (value == null) {
+            throw new NullPointerException();
+          }
+          ensureTableListIsMutable();
+          tableList_.add(index, value);
+          onChanged();
+        } else {
+          tableListBuilder_.addMessage(index, value);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+       */
+      public Builder addTableList(
+          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
+        if (tableListBuilder_ == null) {
+          ensureTableListIsMutable();
+          tableList_.add(builderForValue.build());
+          onChanged();
+        } else {
+          tableListBuilder_.addMessage(builderForValue.build());
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+       */
+      public Builder addTableList(
+          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
+        if (tableListBuilder_ == null) {
+          ensureTableListIsMutable();
+          tableList_.add(index, builderForValue.build());
+          onChanged();
+        } else {
+          tableListBuilder_.addMessage(index, builderForValue.build());
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+       */
+      public Builder addAllTableList(
+          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName> values) {
+        if (tableListBuilder_ == null) {
+          ensureTableListIsMutable();
+          super.addAll(values, tableList_);
+          onChanged();
+        } else {
+          tableListBuilder_.addAllMessages(values);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+       */
+      public Builder clearTableList() {
+        if (tableListBuilder_ == null) {
+          tableList_ = java.util.Collections.emptyList();
+          bitField0_ = (bitField0_ & ~0x00000002);
+          onChanged();
+        } else {
+          tableListBuilder_.clear();
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+       */
+      public Builder removeTableList(int index) {
+        if (tableListBuilder_ == null) {
+          ensureTableListIsMutable();
+          tableList_.remove(index);
+          onChanged();
+        } else {
+          tableListBuilder_.remove(index);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+       */
+      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder getTableListBuilder(
+          int index) {
+        return getTableListFieldBuilder().getBuilder(index);
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+       */
+      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableListOrBuilder(
+          int index) {
+        if (tableListBuilder_ == null) {
+          return tableList_.get(index);  } else {
+          return tableListBuilder_.getMessageOrBuilder(index);
+        }
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+       */
+      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
+           getTableListOrBuilderList() {
+        if (tableListBuilder_ != null) {
+          return tableListBuilder_.getMessageOrBuilderList();
+        } else {
+          return java.util.Collections.unmodifiableList(tableList_);
+        }
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+       */
+      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder addTableListBuilder() {
+        return getTableListFieldBuilder().addBuilder(
+            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance());
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+       */
+      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder addTableListBuilder(
+          int index) {
+        return getTableListFieldBuilder().addBuilder(
+            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance());
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName table_list = 2;</code>
+       */
+      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder> 
+           getTableListBuilderList() {
+        return getTableListFieldBuilder().getBuilderList();
+      }
+      private com.google.protobuf.RepeatedFieldBuilder<
+          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
+          getTableListFieldBuilder() {
+        if (tableListBuilder_ == null) {
+          tableListBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
+              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
+                  tableList_,
+                  ((bitField0_ & 0x00000002) == 0x00000002),
+                  getParentForChildren(),
+                  isClean());
+          tableList_ = null;
+        }
+        return tableListBuilder_;
+      }
+
+      // repeated .hbase.pb.TableName target_table_list = 3;
+      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName> targetTableList_ =
+        java.util.Collections.emptyList();
+      private void ensureTargetTableListIsMutable() {
+        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
+          targetTableList_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName>(targetTableList_);
+          bitField0_ |= 0x00000004;
+         }
+      }
+
+      private com.google.protobuf.RepeatedFieldBuilder<
+          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> targetTableListBuilder_;
+
+      /**
+       * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+       */
+      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName> getTargetTableListList() {
+        if (targetTableListBuilder_ == null) {
+          return java.util.Collections.unmodifiableList(targetTableList_);
+        } else {
+          return targetTableListBuilder_.getMessageList();
+        }
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+       */
+      public int getTargetTableListCount() {
+        if (targetTableListBuilder_ == null) {
+          return targetTableList_.size();
+        } else {
+          return targetTableListBuilder_.getCount();
+        }
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+       */
+      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTargetTableList(int index) {
+        if (targetTableListBuilder_ == null) {
+          return targetTableList_.get(index);
+        } else {
+          return targetTableListBuilder_.getMessage(index);
+        }
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+       */
+      public Builder setTargetTableList(
+          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName value) {
+        if (targetTableListBuilder_ == null) {
+          if (value == null) {
+            throw new NullPointerException();
+          }
+          ensureTargetTableListIsMutable();
+          targetTableList_.set(index, value);
+          onChanged();
+        } else {
+          targetTableListBuilder_.setMessage(index, value);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+       */
+      public Builder setTargetTableList(
+          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
+        if (targetTableListBuilder_ == null) {
+          ensureTargetTableListIsMutable();
+          targetTableList_.set(index, builderForValue.build());
+          onChanged();
+        } else {
+          targetTableListBuilder_.setMessage(index, builderForValue.build());
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+       */
+      public Builder addTargetTableList(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName value) {
+        if (targetTableListBuilder_ == null) {
+          if (value == null) {
+            throw new NullPointerException();
+          }
+          ensureTargetTableListIsMutable();
+          targetTableList_.add(value);
+          onChanged();
+        } else {
+          targetTableListBuilder_.addMessage(value);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+       */
+      public Builder addTargetTableList(
+          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName value) {
+        if (targetTableListBuilder_ == null) {
+          if (value == null) {
+            throw new NullPointerException();
+          }
+          ensureTargetTableListIsMutable();
+          targetTableList_.add(index, value);
+          onChanged();
+        } else {
+          targetTableListBuilder_.addMessage(index, value);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+       */
+      public Builder addTargetTableList(
+          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
+        if (targetTableListBuilder_ == null) {
+          ensureTargetTableListIsMutable();
+          targetTableList_.add(builderForValue.build());
+          onChanged();
+        } else {
+          targetTableListBuilder_.addMessage(builderForValue.build());
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+       */
+      public Builder addTargetTableList(
+          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
+        if (targetTableListBuilder_ == null) {
+          ensureTargetTableListIsMutable();
+          targetTableList_.add(index, builderForValue.build());
+          onChanged();
+        } else {
+          targetTableListBuilder_.addMessage(index, builderForValue.build());
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+       */
+      public Builder addAllTargetTableList(
+          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName> values) {
+        if (targetTableListBuilder_ == null) {
+          ensureTargetTableListIsMutable();
+          super.addAll(values, targetTableList_);
+          onChanged();
+        } else {
+          targetTableListBuilder_.addAllMessages(values);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+       */
+      public Builder clearTargetTableList() {
+        if (targetTableListBuilder_ == null) {
+          targetTableList_ = java.util.Collections.emptyList();
+          bitField0_ = (bitField0_ & ~0x00000004);
+          onChanged();
+        } else {
+          targetTableListBuilder_.clear();
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+       */
+      public Builder removeTargetTableList(int index) {
+        if (targetTableListBuilder_ == null) {
+          ensureTargetTableListIsMutable();
+          targetTableList_.remove(index);
+          onChanged();
+        } else {
+          targetTableListBuilder_.remove(index);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+       */
+      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder getTargetTableListBuilder(
+          int index) {
+        return getTargetTableListFieldBuilder().getBuilder(index);
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+       */
+      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTargetTableListOrBuilder(
+          int index) {
+        if (targetTableListBuilder_ == null) {
+          return targetTableList_.get(index);  } else {
+          return targetTableListBuilder_.getMessageOrBuilder(index);
+        }
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+       */
+      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
+           getTargetTableListOrBuilderList() {
+        if (targetTableListBuilder_ != null) {
+          return targetTableListBuilder_.getMessageOrBuilderList();
+        } else {
+          return java.util.Collections.unmodifiableList(targetTableList_);
+        }
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+       */
+      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder addTargetTableListBuilder() {
+        return getTargetTableListFieldBuilder().addBuilder(
+            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance());
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+       */
+      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder addTargetTableListBuilder(
+          int index) {
+        return getTargetTableListFieldBuilder().addBuilder(
+            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance());
+      }
+      /**
+       * <code>repeated .hbase.pb.TableName target_table_list = 3;</code>
+       */
+      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder> 
+           getTargetTableListBuilderList() {
+        return getTargetTableListFieldBuilder().getBuilderList();
+      }
+      private com.google.protobuf.RepeatedFieldBuilder<
+          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
+          getTargetTableListFieldBuilder() {
+        if (targetTableListBuilder_ == null) {
+          targetTableListBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
+              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
+                  targetTableList_,
+                  ((bitField0_ & 0x00000004) == 0x00000004),
+                  getParentForChildren(),
+                  isClean());
+          targetTableList_ = null;
+        }
+        return targetTableListBuilder_;
+      }
+
+      // required string backup_root_dir = 4;
+      private java.lang.Object backupRootDir_ = "";
+      /**
+       * <code>required string backup_root_dir = 4;</code>
+       */
+      public boolean hasBackupRootDir() {
+        return ((bitField0_ & 0x00000008) == 0x00000008);
+      }
+      /**
+       * <code>required string backup_root_dir = 4;</code>
+       */
+      public java.lang.String getBackupRootDir() {
+        java.lang.Object ref = backupRootDir_;
+        if (!(ref instanceof java.lang.String)) {
+          java.lang.String s = ((com.google.protobuf.ByteString) ref)
+              .toStringUtf8();
+          backupRootDir_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>required string backup_root_dir = 4;</code>
+       */
+      public com.google.protobuf.ByteString
+          getBackupRootDirBytes() {
+        java.lang.Object ref = backupRootDir_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          backupRootDir_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>required string backup_root_dir = 4;</code>
+       */
+      public Builder setBackupRootDir(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  bitField0_ |= 0x00000008;
+        backupRootDir_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>required string backup_root_dir = 4;</code>
+       */
+      public Builder clearBackupRootDir() {
+        bitField0_ = (bitField0_ & ~0x00000008);
+        backupRootDir_ = getDefaultInstance().getBackupRootDir();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>required string backup_root_dir = 4;</code>
+       */
+      public Builder setBackupRootDirBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  bitField0_ |= 0x00000008;
+        backupRootDir_ = value;
+        onChanged();
+        return this;
+      }
+
+      // required bool dependency_check_only = 5;
+      private boolean dependencyCheckOnly_ ;
+      /**
+       * <code>required bool dependency_check_only = 5;</code>
+       */
+      public boolean hasDependencyCheckOnly() {
+        return ((bitField0_ & 0x00000010) == 0x00000010);
+      }
+      /**
+       * <code>required bool dependency_check_only = 5;</code>
+       */
+      public boolean getDependencyCheckOnly() {
+        return dependencyCheckOnly_;
+      }
+      /**
+       * <code>required bool dependency_check_only = 5;</code>
+       */
+      public Builder setDependencyCheckOnly(boolean value) {
+        bitField0_ |= 0x00000010;
+        dependencyCheckOnly_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>required bool dependency_check_only = 5;</code>
+       */
+      public Builder clearDependencyCheckOnly() {
+        bitField0_ = (bitField0_ & ~0x00000010);
+        dependencyCheckOnly_ = false;
+        onChanged();
+        return this;
+      }
+
+      // optional bool auto_restore = 6;
+      private boolean autoRestore_ ;
+      /**
+       * <code>optional bool auto_restore = 6;</code>
+       */
+      public boolean hasAutoRestore() {
+        return ((bitField0_ & 0x00000020) == 0x00000020);
+      }
+      /**
+       * <code>optional bool auto_restore = 6;</code>
+       */
+      public boolean getAutoRestore() {
+        return autoRestore_;
+      }
+      /**
+       * <code>optional bool auto_restore = 6;</code>
+       */
+      public Builder setAutoRestore(boolean value) {
+        bitField0_ |= 0x00000020;
+        autoRestore_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>optional bool auto_restore = 6;</code>
+       */
+      public Builder clearAutoRestore() {
+        bitField0_ = (bitField0_ & ~0x00000020);
+        autoRestore_ = false;
+        onChanged();
+        return this;
+      }
+
+      // optional bool overwrite = 7;
+      private boolean overwrite_ ;
+      /**
+       * <code>optional bool overwrite = 7;</code>
+       */
+      public boolean hasOverwrite() {
+        return ((bitField0_ & 0x00000040) == 0x00000040);
+      }
+      /**
+       * <code>optional bool overwrite = 7;</code>
+       */
+      public boolean getOverwrite() {
+        return overwrite_;
+      }
+      /**
+       * <code>optional bool overwrite = 7;</code>
+       */
+      public Builder setOverwrite(boolean value) {
+        bitField0_ |= 0x00000040;
+        overwrite_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>optional bool overwrite = 7;</code>
+       */
+      public Builder clearOverwrite() {
+        bitField0_ = (bitField0_ & ~0x00000040);
+        overwrite_ = false;
+        onChanged();
+        return this;
+      }
+
+      // @@protoc_insertion_point(builder_scope:hbase.pb.RestoreTablesRequest)
+    }
+
+    static {
+      defaultInstance = new RestoreTablesRequest(true);
+      defaultInstance.initFields();
+    }
+
+    // @@protoc_insertion_point(class_scope:hbase.pb.RestoreTablesRequest)
+  }
+
+  public interface RestoreTablesResponseOrBuilder
+      extends com.google.protobuf.MessageOrBuilder {
+  }
+  /**
+   * Protobuf type {@code hbase.pb.RestoreTablesResponse}
+   */
+  public static final class RestoreTablesResponse extends
+      com.google.protobuf.GeneratedMessage
+      implements RestoreTablesResponseOrBuilder {
+    // Use RestoreTablesResponse.newBuilder() to construct.
+    private RestoreTablesResponse(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
+      super(builder);
+      this.unknownFields = builder.getUnknownFields();
+    }
+    private RestoreTablesResponse(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }
+
+    private static final RestoreTablesResponse defaultInstance;
+    public static RestoreTablesResponse getDefaultInstance() {
+      return defaultInstance;
+    }
+
+    public RestoreTablesResponse getDefaultInstanceForType() {
+      return defaultInstance;
+    }
+
+    private final com.google.protobuf.UnknownFieldSet unknownFields;
+    @java.lang.Override
+    public final com.google.protobuf.UnknownFieldSet
+        getUnknownFields() {
+      return this.unknownFields;
+    }
+    private RestoreTablesResponse(
+        com.google.protobuf.CodedInputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      initFields();
+      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
+          com.google.protobuf.UnknownFieldSet.newBuilder();
+      try {
+        boolean done = false;
+        while (!done) {
+          int tag = input.readTag();
+          switch (tag) {
+            case 0:
+              done = true;
+              break;
+            default: {
+              if (!parseUnknownField(input, unknownFields,
+                                     extensionRegistry, tag)) {
+                done = true;
+              }
+              break;
+            }
+          }
+        }
+      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
+        throw e.setUnfinishedMessage(this);
+      } catch (java.io.IOException e) {
+        throw new com.google.protobuf.InvalidProtocolBufferException(
+            e.getMessage()).setUnfinishedMessage(this);
+      } finally {
+        this.unknownFields = unknownFields.build();
+        makeExtensionsImmutable();
+      }
+    }
+    public static final com.google.protobuf.Descriptors.Descriptor
+        getDescriptor() {
+      return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.internal_static_hbase_pb_RestoreTablesResponse_descriptor;
+    }
+
+    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
+        internalGetFieldAccessorTable() {
+      return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.internal_static_hbase_pb_RestoreTablesResponse_fieldAccessorTable
+          .ensureFieldAccessorsInitialized(
+              org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse.class, org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse.Builder.class);
+    }
+
+    public static com.google.protobuf.Parser<RestoreTablesResponse> PARSER =
+        new com.google.protobuf.AbstractParser<RestoreTablesResponse>() {
+      public RestoreTablesResponse parsePartialFrom(
+          com.google.protobuf.CodedInputStream input,
+          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+          throws com.google.protobuf.InvalidProtocolBufferException {
+        return new RestoreTablesResponse(input, extensionRegistry);
+      }
+    };
+
+    @java.lang.Override
+    public com.google.protobuf.Parser<RestoreTablesResponse> getParserForType() {
+      return PARSER;
+    }
+
+    private void initFields() {
+    }
+    private byte memoizedIsInitialized = -1;
+    public final boolean isInitialized() {
+      byte isInitialized = memoizedIsInitialized;
+      if (isInitialized != -1) return isInitialized == 1;
+
+      memoizedIsInitialized = 1;
+      return true;
+    }
+
+    public void writeTo(com.google.protobuf.CodedOutputStream output)
+                        throws java.io.IOException {
+      getSerializedSize();
+      getUnknownFields().writeTo(output);
+    }
+
+    private int memoizedSerializedSize = -1;
+    public int getSerializedSize() {
+      int size = memoizedSerializedSize;
+      if (size != -1) return size;
+
+      size = 0;
+      size += getUnknownFields().getSerializedSize();
+      memoizedSerializedSize = size;
+      return size;
+    }
+
+    private static final long serialVersionUID = 0L;
+    @java.lang.Override
+    protected java.lang.Object writeReplace()
+        throws java.io.ObjectStreamException {
+      return super.writeReplace();
+    }
+
+    @java.lang.Override
+    public boolean equals(final java.lang.Object obj) {
+      if (obj == this) {
+       return true;
+      }
+      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse)) {
+        return super.equals(obj);
+      }
+      org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse other = (org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse) obj;
+
+      boolean result = true;
+      result = result &&
+          getUnknownFields().equals(other.getUnknownFields());
+      return result;
+    }
+
+    private int memoizedHashCode = 0;
+    @java.lang.Override
+    public int hashCode() {
+      if (memoizedHashCode != 0) {
+        return memoizedHashCode;
+      }
+      int hash = 41;
+      hash = (19 * hash) + getDescriptorForType().hashCode();
+      hash = (29 * hash) + getUnknownFields().hashCode();
+      memoizedHashCode = hash;
+      return hash;
+    }
+
+    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse parseFrom(
+        com.google.protobuf.ByteString data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse parseFrom(
+        com.google.protobuf.ByteString data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse parseFrom(byte[] data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse parseFrom(
+        byte[] data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse parseFrom(java.io.InputStream input)
+        throws java.io.IOException {
+      return PARSER.parseFrom(input);
+    }
+    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse parseFrom(
+        java.io.InputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return PARSER.parseFrom(input, extensionRegistry);
+    }
+    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse parseDelimitedFrom(java.io.InputStream input)
+        throws java.io.IOException {
+      return PARSER.parseDelimitedFrom(input);
+    }
+    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse parseDelimitedFrom(
+        java.io.InputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return PARSER.parseDelimitedFrom(input, extensionRegistry);
+    }
+    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse parseFrom(
+        com.google.protobuf.CodedInputStream input)
+        throws java.io.IOException {
+      return PARSER.parseFrom(input);
+    }
+    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse parseFrom(
+        com.google.protobuf.CodedInputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return PARSER.parseFrom(input, extensionRegistry);
+    }
+
+    public static Builder newBuilder() { return Builder.create(); }
+    public Builder newBuilderForType() { return newBuilder(); }
+    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse prototype) {
+      return newBuilder().mergeFrom(prototype);
+    }
+    public Builder toBuilder() { return newBuilder(this); }
+
+    @java.lang.Override
+    protected Builder newBuilderForType(
+        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
+      Builder builder = new Builder(parent);
+      return builder;
+    }
+    /**
+     * Protobuf type {@code hbase.pb.RestoreTablesResponse}
+     */
+    public static final class Builder extends
+        com.google.protobuf.GeneratedMessage.Builder<Builder>
+       implements org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponseOrBuilder {
+      public static final com.google.protobuf.Descriptors.Descriptor
+          getDescriptor() {
+        return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.internal_static_hbase_pb_RestoreTablesResponse_descriptor;
+      }
+
+      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
+          internalGetFieldAccessorTable() {
+        return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.internal_static_hbase_pb_RestoreTablesResponse_fieldAccessorTable
+            .ensureFieldAccessorsInitialized(
+                org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse.class, org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse.Builder.class);
+      }
+
+      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse.newBuilder()
+      private Builder() {
+        maybeForceBuilderInitialization();
+      }
+
+      private Builder(
+          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
+        super(parent);
+        maybeForceBuilderInitialization();
+      }
+      private void maybeForceBuilderInitialization() {
+        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
+        }
+      }
+      private static Builder create() {
+        return new Builder();
+      }
+
+      public Builder clear() {
+        super.clear();
+        return this;
+      }
+
+      public Builder clone() {
+        return create().mergeFrom(buildPartial());
+      }
+
+      public com.google.protobuf.Descriptors.Descriptor
+          getDescriptorForType() {
+        return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.internal_static_hbase_pb_RestoreTablesResponse_descriptor;
+      }
+
+      public org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse getDefaultInstanceForType() {
+        return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse.getDefaultInstance();
+      }
+
+      public org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse build() {
+        org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse result = buildPartial();
+        if (!result.isInitialized()) {
+          throw newUninitializedMessageException(result);
+        }
+        return result;
+      }
+
+      public org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse buildPartial() {
+        org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse result = new org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse(this);
+        onBuilt();
+        return result;
+      }
+
+      public Builder mergeFrom(com.google.protobuf.Message other) {
+        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse) {
+          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse)other);
+        } else {
+          super.mergeFrom(other);
+          return this;
+        }
+      }
+
+      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse other) {
+        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse.getDefaultInstance()) return this;
+        this.mergeUnknownFields(other.getUnknownFields());
+        return this;
+      }
+
+      public final boolean isInitialized() {
+        return true;
+      }
+
+      public Builder mergeFrom(
+          com.google.protobuf.CodedInputStream input,
+          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+          throws java.io.IOException {
+        org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse parsedMessage = null;
+        try {
+          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
+        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
+          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse) e.getUnfinishedMessage();
+          throw e;
+        } finally {
+          if (parsedMessage != null) {
+            mergeFrom(parsedMessage);
+          }
+        }
+        return this;
+      }
+
+      // @@protoc_insertion_point(builder_scope:hbase.pb.RestoreTablesResponse)
+    }
+
+    static {
+      defaultInstance = new RestoreTablesResponse(true);
+      defaultInstance.initFields();
+    }
+
+    // @@protoc_insertion_point(class_scope:hbase.pb.RestoreTablesResponse)
+  }
+
+  public interface AbortBackupRequestOrBuilder
+      extends com.google.protobuf.MessageOrBuilder {
+
+    // required string backup_id = 1;
+    /**
+     * <code>required string backup_id = 1;</code>
+     */
+    boolean hasBackupId();
+    /**
+     * <code>required string backup_id = 1;</code>
+     */
+    java.lang.String getBackupId();
+    /**
+     * <code>required string backup_id = 1;</code>
+     */
+    com.google.protobuf.ByteString
+        getBackupIdBytes();
+
+    // optional bool mayInterruptIfRunning = 2 [default = true];
+    /**
+     * <code>optional bool mayInterruptIfRunning = 2 [default = true];</code>
+     */
+    boolean hasMayInterruptIfRunning();
+    /**
+     * <code>optional bool mayInterruptIfRunning = 2 [default = true];</code>
+     */
+    boolean getMayInterruptIfRunning();
+  }
+  /**
+   * Protobuf type {@code hbase.pb.AbortBackupRequest}
+   */
+  public static final class AbortBackupRequest extends
+      com.google.protobuf.GeneratedMessage
+      implements AbortBackupRequestOrBuilder {
+    // Use AbortBackupRequest.newBuilder() to construct.
+    private AbortBackupRequest(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
+      super(builder);
+      this.unknownFields = builder.getUnknownFields();
+    }
+    private AbortBackupRequest(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }
+
+    private static final AbortBackupRequest defaultInstance;
+    public static AbortBackupRequest getDefaultInstance() {
+      return defaultInstance;
+    }
+
+    public AbortBackupRequest getDefaultInstanceForType() {
+      return defaultInstance;
+    }
+
+    private final com.google.protobuf.UnknownFieldSet unknownFields;
+    @java.lang.Override
+    public final com.google.protobuf.UnknownFieldSet
+        getUnknownFields() {
+      return this.unknownFields;
+    }
+    private AbortBackupRequest(
+        com.google.protobuf.CodedInputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      initFields();
+      int mutable_bitField0_ = 0;
+      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
+          com.google.protobuf.UnknownFieldSet.newBuilder();
+      try {
+        boolean done = false;
+        while (!done) {
+          int tag = input.readTag();
+          switch (tag) {
+            case 0:
+              done = true;
+              break;
+            default: {
+              if (!parseUnknownField(input, unknownFields,
+                                     extensionRegistry, tag)) {
+                done = true;
+              }
+              break;
+            }
+            case 10: {
+              bitField0_ |= 0x00000001;
+              backupId_ = input.readBytes();
+              break;
+            }
+            case 16: {
+              bitField0_ |= 0x00000002;
+              mayInterruptIfRunning_ = input.readBool();
+              break;
+            }
+          }
+        }
+      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
+        throw e.setUnfinishedMessage(this);
+      } catch (java.io.IOException e) {
+        throw new com.google.protobuf.InvalidProtocolBufferException(
+            e.getMessage()).setUnfinishedMessage(this);
+      } finally {
+        this.unknownFields = unknownFields.build();
+        makeExtensionsImmutable();
+      }
+    }
+    public static final com.google.protobuf.Descriptors.Descriptor
+        getDescriptor() {
+      return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.internal_static_hbase_pb_AbortBackupRequest_descriptor;
+    }
+
+    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
+        internalGetFieldAccessorTable() {
+      return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.internal_static_hbase_pb_AbortBackupRequest_fieldAccessorTable
+          .ensureFieldAccessorsInitialized(
+              org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupRequest.class, org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupRequest.Builder.class);
+    }
+
+    public static com.google.protobuf.Parser<AbortBackupRequest> PARSER =
+        new com.google.protobuf.AbstractParser<AbortBackupRequest>() {
+      public AbortBackupRequest parsePartialFrom(
+          com.google.protobuf.CodedInputStream input,
+          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+          throws com.google.protobuf.InvalidProtocolBufferException {
+        return new AbortBackupRequest(input, extensionRegistry);
+      }
+    };
+
+    @java.lang.Override
+    public com.google.protobuf.Parser<AbortBackupRequest> getParserForType() {
+      return PARSER;
+    }
+
+    private int bitField0_;
+    // required string backup_id = 1;
+    public static final int BACKUP_ID_FIELD_NUMBER = 1;
+    private java.lang.Object backupId_;
+    /**
+     * <code>required string backup_id = 1;</code>
+     */
+    public boolean hasBackupId() {
+      return ((bitField0_ & 0x00000001) == 0x00000001);
+    }
+    /**
+     * <code>required string backup_id = 1;</code>
+     */
+    public java.lang.String getBackupId() {
+      java.lang.Object ref = backupId_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        if (bs.isValidUtf8()) {
+          backupId_ = s;
+        }
+        return s;
+      }
+    }
+    /**
+     * <code>required string backup_id = 1;</code>
+     */
+    public com.google.protobuf.ByteString
+        getBackupIdBytes() {
+      java.lang.Object ref = backupId_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        backupId_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    // optional bool mayInterruptIfRunning = 2 [default = true];
+    public static final int MAYINTERRUPTIFRUNNING_FIELD_NUMBER = 2;
+    private boolean mayInterruptIfRunning_;
+    /**
+     * <code>optional bool mayInterruptIfRunning = 2 [default = true];</code>
+     */
+    public boolean hasMayInterruptIfRunning() {
+      return ((bitField0_ & 0x00000002) == 0x00000002);
+    }
+    /**
+     * <code>optional bool mayInterruptIfRunning = 2 [default = true];</code>
+     */
+    public boolean getMayInterruptIfRunning() {
+      return mayInterruptIfRunning_;
+    }
+
+    private void initFields() {
+      backupId_ = "";
+      mayInterruptIfRunning_ = true;
+    }
+    private byte memoizedIsInitialized = -1;
+    public final boolean isInitialized() {
+      byte isInitialized = memoizedIsInitialized;
+      if (isInitialized != -1) return isInitialized == 1;
+
+      if (!hasBackupId()) {
+        memoizedIsInitialized = 0;
+        return false;
+      }
+      memoizedIsInitialized = 1;
+      return true;
+    }
+
+    public void writeTo(com.google.protobuf.CodedOutputStream output)
+                        throws java.io.IOException {
+      getSerializedSize();
+      if (((bitField0_ & 0x00000001) == 0x00000001)) {
+        output.writeBytes(1, getBackupIdBytes());
+      }
+      if (((bitField0_ & 0x00000002) == 0x00000002)) {
+        output.writeBool(2, mayInterruptIfRunning_);
+      }
+      getUnknownFields().writeTo(output);
+    }
+
+    private int memoizedSerializedSize = -1;
+    public int getSerializedSize() {
+      int size = memoizedSerializedSize;
+      if (size != -1) return size;
+
+      size = 0;
+      if (((bitField0_ & 0x00000001) == 0x00000001)) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeBytesSize(1, getBackupIdBytes());
+      }
+      if (((bitField0_ & 0x00000002) == 0x00000002)) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeBoolSize(2, mayInterruptIfRunning_);
+      }
+      size += getUnknownFields().getSerializedSize();
+      memoizedSerializedSize = size;
+      return size;
+    }
+
+    private static final long serialVersionUID = 0L;
+    @java.lang.Override
+    protected java.lang.Object writeReplace()
+        throws java.io.ObjectStreamException {
+      return super.writeReplace();
+    }
+
+    @java.lang.Override
+    public boolean equals(final java.lang.Object obj) {
+      if (obj == this) {
+       return true;
+      }
+      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupRequest)) {
+        return super.equals(obj);
+      }
+      org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupRequest other = (org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupRequest) obj;
+
+      boolean result = true;
+      result = result && (hasBackupId() == other.hasBackupId());
+      if (hasBackupId()) {
+        result = result && getBackupId()
+            .equals(other.getBackupId());
+      }
+      result = result && (hasMayInterruptIfRunning() == other.hasMayInterruptIfRunning());
+      if (hasMayInterruptIfRunning()) {
+        result = result && (getMayInterruptIfRunning()
+            == other.getMayInterruptIfRunning());
+      }
+      result = result &&
+          getUnknownFields().equals(other.getUnknownFields());
+      return result;
+    }
+
+    private int memoizedHashCode = 0;
+    @java.lang.Override
+    public int hashCode() {
+      if (memoizedHashCode != 0) {
+        return memoizedHashCode;
+      }
+      int hash = 41;
+      hash = (19 * hash) + getDescriptorForType().hashCode();
+      if (hasBackupId()) {
+        hash = (37 * hash) + BACKUP_ID_FIELD_NUMBER;
+        hash = (53 * hash) + getBackupId().hashCode();
+      }
+      if (hasMayInterruptIfRunning()) {
+        hash = (37 * hash) + MAYINTERRUPTIFRUNNING_FIELD_NUMBER;
+        hash = (53 * hash) + hashBoolean(getMayInterruptIfRunning());
+      }
+      hash = (29 * hash) + getUnknownFields().hashCode();
+      memoizedHashCode = hash;
+      return hash;
+    }
+
+    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupRequest parseFrom(
+        com.google.protobuf.ByteString data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupRequest parseFrom(
+        com.google.protobuf.ByteString data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupRequest parseFrom(byte[] data)
         throws com.google.protobuf.InvalidProtocolBufferException {
       return PARSER.parseFrom(data);
     }
@@ -62781,6 +64847,18 @@ public final class MasterProtos {
           com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.MasterProtos.BackupTablesResponse> done);
 
       /**
+       * <code>rpc restoreTables(.hbase.pb.RestoreTablesRequest) returns (.hbase.pb.RestoreTablesResponse);</code>
+       *
+       * <pre>
+       ** restore table set 
+       * </pre>
+       */
+      public abstract void restoreTables(
+          com.google.protobuf.RpcController controller,
+          org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest request,
+          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse> done);
+
+      /**
        * <code>rpc AbortBackup(.hbase.pb.AbortBackupRequest) returns (.hbase.pb.AbortBackupResponse);</code>
        *
        * <pre>
@@ -63262,6 +65340,14 @@ public final class MasterProtos {
         }
 
         @java.lang.Override
+        public  void restoreTables(
+            com.google.protobuf.RpcController controller,
+            org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest request,
+            com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse> done) {
+          impl.restoreTables(controller, request, done);
+        }
+
+        @java.lang.Override
         public  void abortBackup(
             com.google.protobuf.RpcController controller,
             org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupRequest request,
@@ -63408,6 +65494,8 @@ public final class MasterProtos {
             case 57:
               return impl.backupTables(controller, (org.apache.hadoop.hbase.protobuf.generated.MasterProtos.BackupTablesRequest)request);
             case 58:
+              return impl.restoreTables(controller, (org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest)request);
+            case 59:
               return impl.abortBackup(controller, (org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupRequest)request);
             default:
               throw new java.lang.AssertionError("Can't get here.");
@@ -63540,6 +65628,8 @@ public final class MasterProtos {
             case 57:
               return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.BackupTablesRequest.getDefaultInstance();
             case 58:
+              return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest.getDefaultInstance();
+            case 59:
               return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupRequest.getDefaultInstance();
             default:
               throw new java.lang.AssertionError("Can't get here.");
@@ -63672,6 +65762,8 @@ public final class MasterProtos {
             case 57:
               return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.BackupTablesResponse.getDefaultInstance();
             case 58:
+              return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse.getDefaultInstance();
+            case 59:
               return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupResponse.getDefaultInstance();
             default:
               throw new java.lang.AssertionError("Can't get here.");
@@ -64407,6 +66499,18 @@ public final class MasterProtos {
         com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.MasterProtos.BackupTablesResponse> done);
 
     /**
+     * <code>rpc restoreTables(.hbase.pb.RestoreTablesRequest) returns (.hbase.pb.RestoreTablesResponse);</code>
+     *
+     * <pre>
+     ** restore table set 
+     * </pre>
+     */
+    public abstract void restoreTables(
+        com.google.protobuf.RpcController controller,
+        org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest request,
+        com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse> done);
+
+    /**
      * <code>rpc AbortBackup(.hbase.pb.AbortBackupRequest) returns (.hbase.pb.AbortBackupResponse);</code>
      *
      * <pre>
@@ -64731,6 +66835,11 @@ public final class MasterProtos {
               done));
           return;
         case 58:
+          this.restoreTables(controller, (org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest)request,
+            com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse>specializeCallback(
+              done));
+          return;
+        case 59:
           this.abortBackup(controller, (org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupRequest)request,
             com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupResponse>specializeCallback(
               done));
@@ -64866,6 +66975,8 @@ public final class MasterProtos {
         case 57:
           return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.BackupTablesRequest.getDefaultInstance();
         case 58:
+          return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest.getDefaultInstance();
+        case 59:
           return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupRequest.getDefaultInstance();
         default:
           throw new java.lang.AssertionError("Can't get here.");
@@ -64998,6 +67109,8 @@ public final class MasterProtos {
         case 57:
           return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.BackupTablesResponse.getDefaultInstance();
         case 58:
+          return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse.getDefaultInstance();
+        case 59:
           return org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupResponse.getDefaultInstance();
         default:
           throw new java.lang.AssertionError("Can't get here.");
@@ -65890,12 +68003,27 @@ public final class MasterProtos {
             org.apache.hadoop.hbase.protobuf.generated.MasterProtos.BackupTablesResponse.getDefaultInstance()));
       }
 
+      public  void restoreTables(
+          com.google.protobuf.RpcController controller,
+          org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest request,
+          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse> done) {
+        channel.callMethod(
+          getDescriptor().getMethods().get(58),
+          controller,
+          request,
+          org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse.getDefaultInstance(),
+          com.google.protobuf.RpcUtil.generalizeCallback(
+            done,
+            org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse.class,
+            org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse.getDefaultInstance()));
+      }
+
       public  void abortBackup(
           com.google.protobuf.RpcController controller,
           org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupRequest request,
           com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupResponse> done) {
         channel.callMethod(
-          getDescriptor().getMethods().get(58),
+          getDescriptor().getMethods().get(59),
           controller,
           request,
           org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupResponse.getDefaultInstance(),
@@ -66202,6 +68330,11 @@ public final class MasterProtos {
           org.apache.hadoop.hbase.protobuf.generated.MasterProtos.BackupTablesRequest request)
           throws com.google.protobuf.ServiceException;
 
+      public org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse restoreTables(
+          com.google.protobuf.RpcController controller,
+          org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest request)
+          throws com.google.protobuf.ServiceException;
+
       public org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupResponse abortBackup(
           com.google.protobuf.RpcController controller,
           org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupRequest request)
@@ -66911,12 +69044,24 @@ public final class MasterProtos {
       }
 
 
+      public org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse restoreTables(
+          com.google.protobuf.RpcController controller,
+          org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest request)
+          throws com.google.protobuf.ServiceException {
+        return (org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse) channel.callBlockingMethod(
+          getDescriptor().getMethods().get(58),
+          controller,
+          request,
+          org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesResponse.getDefaultInstance());
+      }
+
+
       public org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupResponse abortBackup(
           com.google.protobuf.RpcController controller,
           org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupRequest request)
           throws com.google.protobuf.ServiceException {
         return (org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupResponse) channel.callBlockingMethod(
-          getDescriptor().getMethods().get(58),
+          getDescriptor().getMethods().get(59),
           controller,
           request,
           org.apache.hadoop.hbase.protobuf.generated.MasterProtos.AbortBackupResponse.getDefaultInstance());
@@ -67483,6 +69628,16 @@ public final class MasterProtos {
     com.google.protobuf.GeneratedMessage.FieldAccessorTable
       internal_static_hbase_pb_BackupTablesResponse_fieldAccessorTable;
   private static com.google.protobuf.Descriptors.Descriptor
+    internal_static_hbase_pb_RestoreTablesRequest_descriptor;
+  private static
+    com.google.protobuf.GeneratedMessage.FieldAccessorTable
+      internal_static_hbase_pb_RestoreTablesRequest_fieldAccessorTable;
+  private static com.google.protobuf.Descriptors.Descriptor
+    internal_static_hbase_pb_RestoreTablesResponse_descriptor;
+  private static
+    com.google.protobuf.GeneratedMessage.FieldAccessorTable
+      internal_static_hbase_pb_RestoreTablesResponse_fieldAccessorTable;
+  private static com.google.protobuf.Descriptors.Descriptor
     internal_static_hbase_pb_AbortBackupRequest_descriptor;
   private static
     com.google.protobuf.GeneratedMessage.FieldAccessorTable
@@ -67668,177 +69823,185 @@ public final class MasterProtos {
       "t_time\030\002 \001(\004\022\023\n\013last_update\030\003 \001(\004\022\016\n\006res" +
       "ult\030\004 \001(\014\0224\n\texception\030\005 \001(\0132!.hbase.pb." +
       "ForeignExceptionMessage\"1\n\005State\022\r\n\tNOT_" +
-      "FOUND\020\000\022\013\n\007RUNNING\020\001\022\014\n\010FINISHED\020\002\"M\n\025Ab" +
-      "ortProcedureRequest\022\017\n\007proc_id\030\001 \002(\004\022#\n\025" +
-      "mayInterruptIfRunning\030\002 \001(\010:\004true\"6\n\026Abo",
-      "rtProcedureResponse\022\034\n\024is_procedure_abor" +
-      "ted\030\001 \002(\010\"\027\n\025ListProceduresRequest\"@\n\026Li" +
-      "stProceduresResponse\022&\n\tprocedure\030\001 \003(\0132" +
-      "\023.hbase.pb.Procedure\"\315\001\n\017SetQuotaRequest" +
-      "\022\021\n\tuser_name\030\001 \001(\t\022\022\n\nuser_group\030\002 \001(\t\022" +
-      "\021\n\tnamespace\030\003 \001(\t\022\'\n\ntable_name\030\004 \001(\0132\023" +
-      ".hbase.pb.TableName\022\022\n\nremove_all\030\005 \001(\010\022" +
-      "\026\n\016bypass_globals\030\006 \001(\010\022+\n\010throttle\030\007 \001(" +
-      "\0132\031.hbase.pb.ThrottleRequest\"\022\n\020SetQuota" +
-      "Response\"J\n\037MajorCompactionTimestampRequ",
-      "est\022\'\n\ntable_name\030\001 \002(\0132\023.hbase.pb.Table" +
-      "Name\"U\n(MajorCompactionTimestampForRegio" +
-      "nRequest\022)\n\006region\030\001 \002(\0132\031.hbase.pb.Regi" +
-      "onSpecifier\"@\n MajorCompactionTimestampR" +
-      "esponse\022\034\n\024compaction_timestamp\030\001 \002(\003\"\035\n" +
-      "\033SecurityCapabilitiesRequest\"\354\001\n\034Securit" +
-      "yCapabilitiesResponse\022G\n\014capabilities\030\001 " +
-      "\003(\01621.hbase.pb.SecurityCapabilitiesRespo" +
-      "nse.Capability\"\202\001\n\nCapability\022\031\n\025SIMPLE_" +
-      "AUTHENTICATION\020\000\022\031\n\025SECURE_AUTHENTICATIO",
-      "N\020\001\022\021\n\rAUTHORIZATION\020\002\022\026\n\022CELL_AUTHORIZA" +
-      "TION\020\003\022\023\n\017CELL_VISIBILITY\020\004\"\233\001\n\023BackupTa" +
-      "blesRequest\022\"\n\004type\030\001 \002(\0162\024.hbase.pb.Bac" +
-      "kupType\022#\n\006tables\030\002 \003(\0132\023.hbase.pb.Table" +
-      "Name\022\027\n\017target_root_dir\030\003 \002(\t\022\017\n\007workers" +
-      "\030\004 \001(\003\022\021\n\tbandwidth\030\005 \001(\003\":\n\024BackupTable" +
-      "sResponse\022\017\n\007proc_id\030\001 \001(\004\022\021\n\tbackup_id\030" +
-      "\002 \001(\t\"L\n\022AbortBackupRequest\022\021\n\tbackup_id" +
-      "\030\001 \002(\t\022#\n\025mayInterruptIfRunning\030\002 \001(\010:\004t" +
-      "rue\"0\n\023AbortBackupResponse\022\031\n\021is_backup_",
-      "aborted\030\001 \002(\010*(\n\020MasterSwitchType\022\t\n\005SPL" +
-      "IT\020\000\022\t\n\005MERGE\020\0012\356)\n\rMasterService\022e\n\024Get" +
-      "SchemaAlterStatus\022%.hbase.pb.GetSchemaAl" +
-      "terStatusRequest\032&.hbase.pb.GetSchemaAlt" +
-      "erStatusResponse\022b\n\023GetTableDescriptors\022" +
-      "$.hbase.pb.GetTableDescriptorsRequest\032%." +
-      "hbase.pb.GetTableDescriptorsResponse\022P\n\r" +
-      "GetTableNames\022\036.hbase.pb.GetTableNamesRe" +
-      "quest\032\037.hbase.pb.GetTableNamesResponse\022Y" +
-      "\n\020GetClusterStatus\022!.hbase.pb.GetCluster",
-      "StatusRequest\032\".hbase.pb.GetClusterStatu" +
-      "sResponse\022V\n\017IsMasterRunning\022 .hbase.pb." +
-      "IsMasterRunningRequest\032!.hbase.pb.IsMast" +
-      "erRunningResponse\022D\n\tAddColumn\022\032.hbase.p" +
-      "b.AddColumnRequest\032\033.hbase.pb.AddColumnR" +
-      "esponse\022M\n\014DeleteColumn\022\035.hbase.pb.Delet" +
-      "eColumnRequest\032\036.hbase.pb.DeleteColumnRe" +
-      "sponse\022M\n\014ModifyColumn\022\035.hbase.pb.Modify" +
-      "ColumnRequest\032\036.hbase.pb.ModifyColumnRes" +
-      "ponse\022G\n\nMoveRegion\022\033.hbase.pb.MoveRegio",
-      "nRequest\032\034.hbase.pb.MoveRegionResponse\022k" +
-      "\n\026DispatchMergingRegions\022\'.hbase.pb.Disp" +
-      "atchMergingRegionsRequest\032(.hbase.pb.Dis" +
-      "patchMergingRegionsResponse\022M\n\014AssignReg" +
-      "ion\022\035.hbase.pb.AssignRegionRequest\032\036.hba" +
-      "se.pb.AssignRegionResponse\022S\n\016UnassignRe" +
-      "gion\022\037.hbase.pb.UnassignRegionRequest\032 ." +
-      "hbase.pb.UnassignRegionResponse\022P\n\rOffli" +
-      "neRegion\022\036.hbase.pb.OfflineRegionRequest" +
-      "\032\037.hbase.pb.OfflineRegionResponse\022J\n\013Del",
-      "eteTable\022\034.hbase.pb.DeleteTableRequest\032\035" +
-      ".hbase.pb.DeleteTableResponse\022P\n\rtruncat" +
-      "eTable\022\036.hbase.pb.TruncateTableRequest\032\037" +
-      ".hbase.pb.TruncateTableResponse\022J\n\013Enabl" +
-      "eTable\022\034.hbase.pb.EnableTableRequest\032\035.h" +
-      "base.pb.EnableTableResponse\022M\n\014DisableTa" +
-      "ble\022\035.hbase.pb.DisableTableRequest\032\036.hba" +
-      "se.pb.DisableTableResponse\022J\n\013ModifyTabl" +
-      "e\022\034.hbase.pb.ModifyTableRequest\032\035.hbase." +
-      "pb.ModifyTableResponse\022J\n\013CreateTable\022\034.",
-      "hbase.pb.CreateTableRequest\032\035.hbase.pb.C" +
-      "reateTableResponse\022A\n\010Shutdown\022\031.hbase.p" +
-      "b.ShutdownRequest\032\032.hbase.pb.ShutdownRes" +
-      "ponse\022G\n\nStopMaster\022\033.hbase.pb.StopMaste" +
-      "rRequest\032\034.hbase.pb.StopMasterResponse\022>" +
-      "\n\007Balance\022\030.hbase.pb.BalanceRequest\032\031.hb" +
-      "ase.pb.BalanceResponse\022_\n\022SetBalancerRun" +
-      "ning\022#.hbase.pb.SetBalancerRunningReques" +
-      "t\032$.hbase.pb.SetBalancerRunningResponse\022" +
-      "\\\n\021IsBalancerEnabled\022\".hbase.pb.IsBalanc",
-      "erEnabledRequest\032#.hbase.pb.IsBalancerEn" +
-      "abledResponse\022k\n\026SetSplitOrMergeEnabled\022" +
-      "\'.hbase.pb.SetSplitOrMergeEnabledRequest" +
-      "\032(.hbase.pb.SetSplitOrMergeEnabledRespon" +
-      "se\022h\n\025IsSplitOrMergeEnabled\022&.hbase.pb.I" +
-      "sSplitOrMergeEnabledRequest\032\'.hbase.pb.I" +
-      "sSplitOrMergeEnabledResponse\022D\n\tNormaliz" +
-      "e\022\032.hbase.pb.NormalizeRequest\032\033.hbase.pb" +
-      ".NormalizeResponse\022e\n\024SetNormalizerRunni" +
-      "ng\022%.hbase.pb.SetNormalizerRunningReques",
-      "t\032&.hbase.pb.SetNormalizerRunningRespons" +
-      "e\022b\n\023IsNormalizerEnabled\022$.hbase.pb.IsNo" +
-      "rmalizerEnabledRequest\032%.hbase.pb.IsNorm" +
-      "alizerEnabledResponse\022S\n\016RunCatalogScan\022" +
-      "\037.hbase.pb.RunCatalogScanRequest\032 .hbase" +
-      ".pb.RunCatalogScanResponse\022e\n\024EnableCata" +
-      "logJanitor\022%.hbase.pb.EnableCatalogJanit" +
-      "orRequest\032&.hbase.pb.EnableCatalogJanito" +
-      "rResponse\022n\n\027IsCatalogJanitorEnabled\022(.h" +
-      "base.pb.IsCatalogJanitorEnabledRequest\032)",
-      ".hbase.pb.IsCatalogJanitorEnabledRespons" +
-      "e\022^\n\021ExecMasterService\022#.hbase.pb.Coproc" +
-      "essorServiceRequest\032$.hbase.pb.Coprocess" +
-      "orServiceResponse\022A\n\010Snapshot\022\031.hbase.pb" +
-      ".SnapshotRequest\032\032.hbase.pb.SnapshotResp" +
-      "onse\022h\n\025GetCompletedSnapshots\022&.hbase.pb" +
-      ".GetCompletedSnapshotsRequest\032\'.hbase.pb" +
-      ".GetCompletedSnapshotsResponse\022S\n\016Delete" +
-      "Snapshot\022\037.hbase.pb.DeleteSnapshotReques" +
-      "t\032 .hbase.pb.DeleteSnapshotResponse\022S\n\016I",
-      "sSnapshotDone\022\037.hbase.pb.IsSnapshotDoneR" +
-      "equest\032 .hbase.pb.IsSnapshotDoneResponse" +
-      "\022V\n\017RestoreSnapshot\022 .hbase.pb.RestoreSn" +
-      "apshotRequest\032!.hbase.pb.RestoreSnapshot" +
-      "Response\022h\n\025IsRestoreSnapshotDone\022&.hbas" +
-      "e.pb.IsRestoreSnapshotDoneRequest\032\'.hbas" +
-      "e.pb.IsRestoreSnapshotDoneResponse\022P\n\rEx" +
-      "ecProcedure\022\036.hbase.pb.ExecProcedureRequ" +
-      "est\032\037.hbase.pb.ExecProcedureResponse\022W\n\024" +
-      "ExecProcedureWithRet\022\036.hbase.pb.ExecProc",
-      "edureRequest\032\037.hbase.pb.ExecProcedureRes" +
-      "ponse\022V\n\017IsProcedureDone\022 .hbase.pb.IsPr" +
-      "ocedureDoneRequest\032!.hbase.pb.IsProcedur" +
-      "eDoneResponse\022V\n\017ModifyNamespace\022 .hbase" +
-      ".pb.ModifyNamespaceRequest\032!.hbase.pb.Mo" +
-      "difyNamespaceResponse\022V\n\017CreateNamespace" +
-      "\022 .hbase.pb.CreateNamespaceRequest\032!.hba" +
-      "se.pb.CreateNamespaceResponse\022V\n\017DeleteN" +
-      "amespace\022 .hbase.pb.DeleteNamespaceReque" +
-      "st\032!.hbase.pb.DeleteNamespaceResponse\022k\n",
-      "\026GetNamespaceDescriptor\022\'.hbase.pb.GetNa" +
-      "mespaceDescriptorRequest\032(.hbase.pb.GetN" +
-      "amespaceDescriptorResponse\022q\n\030ListNamesp" +
-      "aceDescriptors\022).hbase.pb.ListNamespaceD" +
-      "escriptorsRequest\032*.hbase.pb.ListNamespa" +
-      "ceDescriptorsResponse\022\206\001\n\037ListTableDescr" +
-      "iptorsByNamespace\0220.hbase.pb.ListTableDe" +
-      "scriptorsByNamespaceRequest\0321.hbase.pb.L" +
-      "istTableDescriptorsByNamespaceResponse\022t" +
-      "\n\031ListTableNamesByNamespace\022*.hbase.pb.L",
-      "istTableNamesByNamespaceRequest\032+.hbase." +
-      "pb.ListTableNamesByNamespaceResponse\022P\n\r" +
-      "GetTableState\022\036.hbase.pb.GetTableStateRe" +
-      "quest\032\037.hbase.pb.GetTableStateResponse\022A" +
-      "\n\010SetQuota\022\031.hbase.pb.SetQuotaRequest\032\032." +
-      "hbase.pb.SetQuotaResponse\022x\n\037getLastMajo" +
-      "rCompactionTimestamp\022).hbase.pb.MajorCom" +
-      "pactionTimestampRequest\032*.hbase.pb.Major" +
-      "CompactionTimestampResponse\022\212\001\n(getLastM" +
-      "ajorCompactionTimestampForRegion\0222.hbase",
-      ".pb.MajorCompactionTimestampForRegionReq" +
-      "uest\032*.hbase.pb.MajorCompactionTimestamp" +
-      "Response\022_\n\022getProcedureResult\022#.hbase.p" +
-      "b.GetProcedureResultRequest\032$.hbase.pb.G" +
-      "etProcedureResultResponse\022h\n\027getSecurity" +
-      "Capabilities\022%.hbase.pb.SecurityCapabili" +
-      "tiesRequest\032&.hbase.pb.SecurityCapabilit" +
-      "iesResponse\022S\n\016AbortProcedure\022\037.hbase.pb" +
-      ".AbortProcedureRequest\032 .hbase.pb.AbortP" +
-      "rocedureResponse\022S\n\016ListProcedures\022\037.hba",
-      "se.pb.ListProceduresRequest\032 .hbase.pb.L" +
-      "istProceduresResponse\022M\n\014backupTables\022\035." +
-      "hbase.pb.BackupTablesRequest\032\036.hbase.pb." +
-      "BackupTablesResponse\022J\n\013AbortBackup\022\034.hb" +
-      "ase.pb.AbortBackupRequest\032\035.hbase.pb.Abo" +
-      "rtBackupResponseBB\n*org.apache.hadoop.hb" +
-      "ase.protobuf.generatedB\014MasterProtosH\001\210\001" +
-      "\001\240\001\001"
+      "FOUND\020\000\022\013\n\007RUNNING\020\001\022\014\n\010FINISHED\020\002\"P\n\025Ab" +
+      "ortProcedureRequest\022\017\n\007proc_id\030\001 \002(\004\022&\n\030" +
+      "may_interrupt_if_running\030\002 \001(\010:\004true\"6\n\026",
+      "AbortProcedureResponse\022\034\n\024is_procedure_a" +
+      "borted\030\001 \002(\010\"\027\n\025ListProceduresRequest\"@\n" +
+      "\026ListProceduresResponse\022&\n\tprocedure\030\001 \003" +
+      "(\0132\023.hbase.pb.Procedure\"\315\001\n\017SetQuotaRequ" +
+      "est\022\021\n\tuser_name\030\001 \001(\t\022\022\n\nuser_group\030\002 \001" +
+      "(\t\022\021\n\tnamespace\030\003 \001(\t\022\'\n\ntable_name\030\004 \001(" +
+      "\0132\023.hbase.pb.TableName\022\022\n\nremove_all\030\005 \001" +
+      "(\010\022\026\n\016bypass_globals\030\006 \001(\010\022+\n\010throttle\030\007" +
+      " \001(\0132\031.hbase.pb.ThrottleRequest\"\022\n\020SetQu" +
+      "otaResponse\"J\n\037MajorCompactionTimestampR",
+      "equest\022\'\n\ntable_name\030\001 \002(\0132\023.hbase.pb.Ta" +
+      "bleName\"U\n(MajorCompactionTimestampForRe" +
+      "gionRequest\022)\n\006region\030\001 \002(\0132\031.hbase.pb.R" +
+      "egionSpecifier\"@\n MajorCompactionTimesta" +
+      "mpResponse\022\034\n\024compaction_timestamp\030\001 \002(\003" +
+      "\"\035\n\033SecurityCapabilitiesRequest\"\354\001\n\034Secu" +
+      "rityCapabilitiesResponse\022G\n\014capabilities" +
+      "\030\001 \003(\01621.hbase.pb.SecurityCapabilitiesRe" +
+      "sponse.Capability\"\202\001\n\nCapability\022\031\n\025SIMP" +
+      "LE_AUTHENTICATION\020\000\022\031\n\025SECURE_AUTHENTICA",
+      "TION\020\001\022\021\n\rAUTHORIZATION\020\002\022\026\n\022CELL_AUTHOR" +
+      "IZATION\020\003\022\023\n\017CELL_VISIBILITY\020\004\"\233\001\n\023Backu" +
+      "pTablesRequest\022\"\n\004type\030\001 \002(\0162\024.hbase.pb." +
+      "BackupType\022#\n\006tables\030\002 \003(\0132\023.hbase.pb.Ta" +
+      "bleName\022\027\n\017target_root_dir\030\003 \002(\t\022\017\n\007work" +
+      "ers\030\004 \001(\003\022\021\n\tbandwidth\030\005 \001(\003\":\n\024BackupTa" +
+      "blesResponse\022\017\n\007proc_id\030\001 \001(\004\022\021\n\tbackup_" +
+      "id\030\002 \001(\t\"\343\001\n\024RestoreTablesRequest\022\021\n\tbac" +
+      "kup_id\030\001 \002(\t\022\'\n\ntable_list\030\002 \003(\0132\023.hbase" +
+      ".pb.TableName\022.\n\021target_table_list\030\003 \003(\013",
+      "2\023.hbase.pb.TableName\022\027\n\017backup_root_dir" +
+      "\030\004 \002(\t\022\035\n\025dependency_check_only\030\005 \002(\010\022\024\n" +
+      "\014auto_restore\030\006 \001(\010\022\021\n\toverwrite\030\007 \001(\010\"\027" +
+      "\n\025RestoreTablesResponse\"L\n\022AbortBackupRe" +
+      "quest\022\021\n\tbackup_id\030\001 \002(\t\022#\n\025mayInterrupt" +
+      "IfRunning\030\002 \001(\010:\004true\"0\n\023AbortBackupResp" +
+      "onse\022\031\n\021is_backup_aborted\030\001 \002(\010*(\n\020Maste" +
+      "rSwitchType\022\t\n\005SPLIT\020\000\022\t\n\005MERGE\020\0012\300*\n\rMa" +
+      "sterService\022e\n\024GetSchemaAlterStatus\022%.hb" +
+      "ase.pb.GetSchemaAlterStatusRequest\032&.hba",
+      "se.pb.GetSchemaAlterStatusResponse\022b\n\023Ge" +
+      "tTableDescriptors\022$.hbase.pb.GetTableDes" +
+      "criptorsRequest\032%.hbase.pb.GetTableDescr" +
+      "iptorsResponse\022P\n\rGetTableNames\022\036.hbase." +
+      "pb.GetTableNamesRequest\032\037.hbase.pb.GetTa" +
+      "bleNamesResponse\022Y\n\020GetClusterStatus\022!.h" +
+      "base.pb.GetClusterStatusRequest\032\".hbase." +
+      "pb.GetClusterStatusResponse\022V\n\017IsMasterR" +
+      "unning\022 .hbase.pb.IsMasterRunningRequest" +
+      "\032!.hbase.pb.IsMasterRunningResponse\022D\n\tA",
+      "ddColumn\022\032.hbase.pb.AddColumnRequest\032\033.h" +
+      "base.pb.AddColumnResponse\022M\n\014DeleteColum" +
+      "n\022\035.hbase.pb.DeleteColumnRequest\032\036.hbase" +
+      ".pb.DeleteColumnResponse\022M\n\014ModifyColumn" +
+      "\022\035.hbase.pb.ModifyColumnRequest\032\036.hbase." +
+      "pb.ModifyColumnResponse\022G\n\nMoveRegion\022\033." +
+      "hbase.pb.MoveRegionRequest\032\034.hbase.pb.Mo" +
+      "veRegionResponse\022k\n\026DispatchMergingRegio" +
+      "ns\022\'.hbase.pb.DispatchMergingRegionsRequ" +
+      "est\032(.hbase.pb.DispatchMergingRegionsRes",
+      "ponse\022M\n\014AssignRegion\022\035.hbase.pb.AssignR" +
+      "egionRequest\032\036.hbase.pb.AssignRegionResp" +
+      "onse\022S\n\016UnassignRegion\022\037.hbase.pb.Unassi" +
+      "gnRegionRequest\032 .hbase.pb.UnassignRegio" +
+      "nResponse\022P\n\rOfflineRegion\022\036.hbase.pb.Of" +
+      "flineRegionRequest\032\037.hbase.pb.OfflineReg" +
+      "ionResponse\022J\n\013DeleteTable\022\034.hbase.pb.De" +
+      "leteTableRequest\032\035.hbase.pb.DeleteTableR" +
+      "esponse\022P\n\rtruncateTable\022\036.hbase.pb.Trun" +
+      "cateTableRequest\032\037.hbase.pb.TruncateTabl",
+      "eResponse\022J\n\013EnableTable\022\034.hbase.pb.Enab" +
+      "leTableRequest\032\035.hbase.pb.EnableTableRes" +
+      "ponse\022M\n\014DisableTable\022\035.hbase.pb.Disable" +
+      "TableRequest\032\036.hbase.pb.DisableTableResp" +
+      "onse\022J\n\013ModifyTable\022\034.hbase.pb.ModifyTab" +
+      "leRequest\032\035.hbase.pb.ModifyTableResponse" +
+      "\022J\n\013CreateTable\022\034.hbase.pb.CreateTableRe" +
+      "quest\032\035.hbase.pb.CreateTableResponse\022A\n\010" +
+      "Shutdown\022\031.hbase.pb.ShutdownRequest\032\032.hb" +
+      "ase.pb.ShutdownResponse\022G\n\nStopMaster\022\033.",
+      "hbase.pb.StopMasterRequest\032\034.hbase.pb.St" +
+      "opMasterResponse\022>\n\007Balance\022\030.hbase.pb.B" +
+      "alanceRequest\032\031.hbase.pb.BalanceResponse" +
+      "\022_\n\022SetBalancerRunning\022#.hbase.pb.SetBal" +
+      "ancerRunningRequest\032$.hbase.pb.SetBalanc" +
+      "erRunningResponse\022\\\n\021IsBalancerEnabled\022\"" +
+      ".hbase.pb.IsBalancerEnabledRequest\032#.hba" +
+      "se.pb.IsBalancerEnabledResponse\022k\n\026SetSp" +
+      "litOrMergeEnabled\022\'.hbase.pb.SetSplitOrM" +
+      "ergeEnabledRequest\032(.hbase.pb.SetSplitOr",
+      "MergeEnabledResponse\022h\n\025IsSplitOrMergeEn" +
+      "abled\022&.hbase.pb.IsSplitOrMergeEnabledRe" +
+      "quest\032\'.hbase.pb.IsSplitOrMergeEnabledRe" +
+      "sponse\022D\n\tNormalize\022\032.hbase.pb.Normalize" +
+      "Request\032\033.hbase.pb.NormalizeResponse\022e\n\024" +
+      "SetNormalizerRunning\022%.hbase.pb.SetNorma" +
+      "lizerRunningRequest\032&.hbase.pb.SetNormal" +
+      "izerRunningResponse\022b\n\023IsNormalizerEnabl" +
+      "ed\022$.hbase.pb.IsNormalizerEnabledRequest" +
+      "\032%.hbase.pb.IsNormalizerEnabledResponse\022",
+      "S\n\016RunCatalogScan\022\037.hbase.pb.RunCatalogS" +
+      "canRequest\032 .hbase.pb.RunCatalogScanResp" +
+      "onse\022e\n\024EnableCatalogJanitor\022%.hbase.pb." +
+      "EnableCatalogJanitorRequest\032&.hbase.pb.E" +
+      "nableCatalogJanitorResponse\022n\n\027IsCatalog" +
+      "JanitorEnabled\022(.hbase.pb.IsCatalogJanit" +
+      "orEnabledRequest\032).hbase.pb.IsCatalogJan" +
+      "itorEnabledResponse\022^\n\021ExecMasterService" +
+      "\022#.hbase.pb.CoprocessorServiceRequest\032$." +
+      "hbase.pb.CoprocessorServiceResponse\022A\n\010S",
+      "napshot\022\031.hbase.pb.SnapshotRequest\032\032.hba" +
+      "se.pb.SnapshotResponse\022h\n\025GetCompletedSn" +
+      "apshots\022&.hbase.pb.GetCompletedSnapshots" +
+      "Request\032\'.hbase.pb.GetCompletedSnapshots" +
+      "Response\022S\n\016DeleteSnapshot\022\037.hbase.pb.De" +
+      "leteSnapshotRequest\032 .hbase.pb.DeleteSna" +
+      "pshotResponse\022S\n\016IsSnapshotDone\022\037.hbase." +
+      "pb.IsSnapshotDoneRequest\032 .hbase.pb.IsSn" +
+      "apshotDoneResponse\022V\n\017RestoreSnapshot\022 ." +
+      "hbase.pb.RestoreSnapshotRequest\032!.hbase.",
+      "pb.RestoreSnapshotResponse\022h\n\025IsRestoreS" +
+      "napshotDone\022&.hbase.pb.IsRestoreSnapshot" +
+      "DoneRequest\032\'.hbase.pb.IsRestoreSnapshot" +
+      "DoneResponse\022P\n\rExecProcedure\022\036.hbase.pb" +
+      ".ExecProcedureRequest\032\037.hbase.pb.ExecPro" +
+      "cedureResponse\022W\n\024ExecProcedureWithRet\022\036" +
+      ".hbase.pb.ExecProcedureRequest\032\037.hbase.p" +
+      "b.ExecProcedureResponse\022V\n\017IsProcedureDo" +
+      "ne\022 .hbase.pb.IsProcedureDoneRequest\032!.h" +
+      "base.pb.IsProcedureDoneResponse\022V\n\017Modif",
+      "yNamespace\022 .hbase.pb.ModifyNamespaceReq" +
+      "uest\032!.hbase.pb.ModifyNamespaceResponse\022" +
+      "V\n\017CreateNamespace\022 .hbase.pb.CreateName" +
+      "spaceRequest\032!.hbase.pb.CreateNamespaceR" +
+      "esponse\022V\n\017DeleteNamespace\022 .hbase.pb.De" +
+      "leteNamespaceRequest\032!.hbase.pb.DeleteNa" +
+      "mespaceResponse\022k\n\026GetNamespaceDescripto" +
+      "r\022\'.hbase.pb.GetNamespaceDescriptorReque" +
+      "st\032(.hbase.pb.GetNamespaceDescriptorResp" +
+      "onse\022q\n\030ListNamespaceDescriptors\022).hbase",
+      ".pb.ListNamespaceDescriptorsRequest\032*.hb" +
+      "ase.pb.ListNamespaceDescriptorsResponse\022" +
+      "\206\001\n\037ListTableDescriptorsByNamespace\0220.hb" +
+      "ase.pb.ListTableDescriptorsByNamespaceRe" +
+      "quest\0321.hbase.pb.ListTableDescriptorsByN" +
+      "amespaceResponse\022t\n\031ListTableNamesByName" +
+      "space\022*.hbase.pb.ListTableNamesByNamespa" +
+      "ceRequest\032+.hbase.pb.ListTableNamesByNam" +
+      "espaceResponse\022P\n\rGetTableState\022\036.hbase." +
+      "pb.GetTableStateRequest\032\037.hbase.pb.GetTa",
+      "bleStateResponse\022A\n\010SetQuota\022\031.hbase.pb." +
+      "SetQuotaRequest\032\032.hbase.pb.SetQuotaRespo" +
+      "nse\022x\n\037getLastMajorCompactionTimestamp\022)" +
+      ".hbase.pb.MajorCompactionTimestampReques" +
+      "t\032*.hbase.pb.MajorCompactionTimestampRes" +
+      "ponse\022\212\001\n(getLastMajorCompactionTimestam" +
+      "pForRegion\0222.hbase.pb.MajorCompactionTim" +
+      "estampForRegionRequest\032*.hbase.pb.MajorC" +
+      "ompactionTimestampResponse\022_\n\022getProcedu" +
+      "reResult\022#.hbase.pb.GetProcedureResultRe",
+      "quest\032$.hbase.pb.GetProcedureResultRespo" +
+      "nse\022h\n\027getSecurityCapabilities\022%.hbase.p" +
+      "b.SecurityCapabilitiesRequest\032&.hbase.pb" +
+      ".SecurityCapabilitiesResponse\022S\n\016AbortPr" +
+      "ocedure\022\037.hbase.pb.AbortProcedureRequest" +
+      "\032 .hbase.pb.AbortProcedureResponse\022S\n\016Li" +
+      "stProcedures\022\037.hbase.pb.ListProceduresRe" +
+      "quest\032 .hbase.pb.ListProceduresResponse\022" +
+      "M\n\014backupTables\022\035.hbase.pb.BackupTablesR" +
+      "equest\032\036.hbase.pb.BackupTablesResponse\022P",
+      "\n\rrestoreTables\022\036.hbase.pb.RestoreTables" +
+      "Request\032\037.hbase.pb.RestoreTablesResponse" +
+      "\022J\n\013AbortBackup\022\034.hbase.pb.AbortBackupRe" +
+      "quest\032\035.hbase.pb.AbortBackupResponseBB\n*" +
+      "org.apache.hadoop.hbase.protobuf.generat" +
+      "edB\014MasterProtosH\001\210\001\001\240\001\001"
     };
     com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
       new com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner() {
@@ -68511,14 +70674,26 @@ public final class MasterProtos {
             com.google.protobuf.GeneratedMessage.FieldAccessorTable(
               internal_static_hbase_pb_BackupTablesResponse_descriptor,
               new java.lang.String[] { "ProcId", "BackupId", });
-          internal_static_hbase_pb_AbortBackupRequest_descriptor =
+          internal_static_hbase_pb_RestoreTablesRequest_descriptor =
             getDescriptor().getMessageTypes().get(111);
+          internal_static_hbase_pb_RestoreTablesRequest_fieldAccessorTable = new
+            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
+              internal_static_hbase_pb_RestoreTablesRequest_descriptor,
+              new java.lang.String[] { "BackupId", "TableList", "TargetTableList", "BackupRootDir", "DependencyCheckOnly", "AutoRestore", "Overwrite", });
+          internal_static_hbase_pb_RestoreTablesResponse_descriptor =
+            getDescriptor().getMessageTypes().get(112);
+          internal_static_hbase_pb_RestoreTablesResponse_fieldAccessorTable = new
+            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
+              internal_static_hbase_pb_RestoreTablesResponse_descriptor,
+              new java.lang.String[] { });
+          internal_static_hbase_pb_AbortBackupRequest_descriptor =
+            getDescriptor().getMessageTypes().get(113);
           internal_static_hbase_pb_AbortBackupRequest_fieldAccessorTable = new
             com.google.protobuf.GeneratedMessage.FieldAccessorTable(
               internal_static_hbase_pb_AbortBackupRequest_descriptor,
               new java.lang.String[] { "BackupId", "MayInterruptIfRunning", });
           internal_static_hbase_pb_AbortBackupResponse_descriptor =
-            getDescriptor().getMessageTypes().get(112);
+            getDescriptor().getMessageTypes().get(114);
           internal_static_hbase_pb_AbortBackupResponse_fieldAccessorTable = new
             com.google.protobuf.GeneratedMessage.FieldAccessorTable(
               internal_static_hbase_pb_AbortBackupResponse_descriptor,
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
index ba7f980..f34fd79 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
@@ -2629,7 +2629,7 @@ public class HMaster extends HRegionServer implements MasterServices {
     String backupId = BackupRestoreConstants.BACKUPID_PREFIX + EnvironmentEdgeManager.currentTime();
     if (type == BackupType.INCREMENTAL) {
       Set<TableName> incrTableSet =
-          BackupSystemTable.getIncrementalBackupTableSet(clusterConnection);
+          BackupSystemTable.getIncrementalBackupTableSet();
       if (incrTableSet.isEmpty()) {
         LOG.warn("Incremental backup table set contains no table.\n"
             + "Use 'backup create full' or 'backup stop' to \n "
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java
index 5babfb8..4f354f9 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java
@@ -105,6 +105,7 @@ import org.apache.hadoop.hbase.protobuf.generated.MasterProtos.ModifyTableReques
 import org.apache.hadoop.hbase.protobuf.generated.MasterProtos.MoveRegionRequest;
 import org.apache.hadoop.hbase.protobuf.generated.MasterProtos.NormalizeRequest;
 import org.apache.hadoop.hbase.protobuf.generated.MasterProtos.OfflineRegionRequest;
+import org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RestoreTablesRequest;
 import org.apache.hadoop.hbase.protobuf.generated.MasterProtos.RunCatalogScanRequest;
 import org.apache.hadoop.hbase.protobuf.generated.MasterProtos.SetBalancerRunningRequest;
 import org.apache.hadoop.hbase.protobuf.generated.MasterProtos.SetNormalizerRunningRequest;
@@ -1286,6 +1287,25 @@ public final class RequestConverter {
     return builder.build();
   }
 
+  public static RestoreTablesRequest buildRestoreTablesRequest(String backupRootDir,
+      String backupId, boolean check, boolean autoRestore, List<TableName> sTableList,
+      List<TableName> tTableList, boolean isOverwrite) {
+    RestoreTablesRequest.Builder builder = RestoreTablesRequest.newBuilder();
+    builder.setAutoRestore(autoRestore).setBackupId(backupId).setBackupRootDir(backupRootDir);
+    builder.setDependencyCheckOnly(check).setOverwrite(isOverwrite);
+    if (sTableList != null) {
+      for (TableName table : sTableList) {
+        builder.addTableList(ProtobufUtil.toProtoTableName(table));
+      }
+    }
+    if (tTableList != null) {
+      for (TableName table : tTableList) {
+        builder.addTargetTableList(ProtobufUtil.toProtoTableName(table));
+      }
+    }
+    return builder.build();
+  }
+
   /**
    * Creates a protocol buffer GetSchemaAlterStatusRequest
    *
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/backup/RestoreRequest.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/backup/RestoreRequest.java
new file mode 100644
index 0000000..4fd843a
--- /dev/null
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/backup/RestoreRequest.java
@@ -0,0 +1,100 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hbase.backup;
+
+import java.util.List;
+
+import org.apache.hadoop.hbase.TableName;
+import org.apache.hadoop.hbase.backup.BackupType;
+import org.apache.hadoop.hbase.classification.InterfaceAudience;
+import org.apache.hadoop.hbase.classification.InterfaceStability;
+
+/**
+ * POJO class for restore request
+ */
+@InterfaceAudience.Public
+@InterfaceStability.Evolving
+public final class RestoreRequest {
+  String backupId;
+  List<TableName> tableList;
+  List<TableName> targetTableList;
+  String backupRootDir;
+  boolean dependencyCheckOnly;
+  boolean autoRestore;
+  boolean overwrite;
+
+  public RestoreRequest() {
+  }
+
+  public RestoreRequest setBackupId(String backupId) {
+    this.backupId = backupId;
+    return this;
+  }
+  public String getBackupId() {
+    return this.backupId;
+  }
+
+  public RestoreRequest setTableList(List<TableName> tableList) {
+    this.tableList = tableList;
+    return this;
+  }
+  public List<TableName> getTableList() {
+    return this.tableList;
+  }
+
+  public RestoreRequest setTargetTableList(List<TableName> targetTableList) {
+    this.targetTableList = targetTableList;
+    return this;
+  }
+  public List<TableName> getTargetTableList() {
+    return this.targetTableList;
+  }
+
+  public RestoreRequest setBackupRootDir(String backupRootDir) {
+    this.backupRootDir = backupRootDir;
+    return this;
+  }
+  public String getBackupRootDir() {
+    return this.backupRootDir;
+  }
+
+  public RestoreRequest setDependencyCheckOnly(boolean dependencyCheckOnly) {
+    this.dependencyCheckOnly = dependencyCheckOnly;
+    return this;
+  }
+  public boolean getDependencyCheckOnly() {
+    return this.dependencyCheckOnly;
+  }
+
+  public RestoreRequest setAutoRestore(boolean autoRestore) {
+    this.autoRestore = autoRestore;
+    return this;
+  }
+  public boolean getAutoRestore() {
+    return this.autoRestore;
+  }
+
+  public RestoreRequest setOverwrite(boolean overwrite) {
+    this.overwrite = overwrite;
+    return this;
+  }
+  public boolean getOverwrite() {
+    return this.overwrite;
+  }
+}
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ConnectionImplementation.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ConnectionImplementation.java
index bb61727..bd6ae0e 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ConnectionImplementation.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ConnectionImplementation.java
@@ -1415,6 +1415,13 @@ class ConnectionImplementation implements ClusterConnection, Closeable {
       }
 
       @Override
+      public MasterProtos.RestoreTablesResponse restoreTables(
+          RpcController controller,
+          MasterProtos.RestoreTablesRequest request)  throws ServiceException {
+        return stub.restoreTables(controller, request);
+      }
+
+      @Override
       public MasterProtos.AddColumnResponse addColumn(
           RpcController controller,
           MasterProtos.AddColumnRequest request) throws ServiceException {
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterRpcServices.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterRpcServices.java
index e29f70f..2e39663 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterRpcServices.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterRpcServices.java
@@ -1083,6 +1083,28 @@ public class MasterRpcServices extends RSRpcServices
   }
 
   @Override
+  public MasterProtos.RestoreTablesResponse restoreTables(
+      RpcController controller,
+      MasterProtos.RestoreTablesRequest request)  throws ServiceException {
+    try {
+      RestoreTablesResponse.Builder response = RestoreTablesResponse.newBuilder();
+      List<TableName> tablesList = new ArrayList<>(request.getTableListList().size());
+      for (HBaseProtos.TableName table : request.getTableListList()) {
+        tablesList.add(ProtobufUtil.toTableName(table));
+      }
+      List<TableName> targetTablesList = new ArrayList<>(request.getTargetTableListList().size());
+      for (HBaseProtos.TableName table : request.getTargetTableListList()) {
+        targetTablesList.add(ProtobufUtil.toTableName(table));
+      }
+      long procId = master.restoreTables(request.getBackupRootDir(), request.getBackupId(),
+        request.getDependencyCheckOnly(), request.getAutoRestore(), tablesList, targetTablesList,
+        request.getOverwrite());
+      return response.setProcId(procId).build();
+    } catch (IOException e) {
+      throw new ServiceException(e);
+    }
+  }
+  @Override
   public ListTableDescriptorsByNamespaceResponse listTableDescriptorsByNamespace(RpcController c,
       ListTableDescriptorsByNamespaceRequest request) throws ServiceException {
     try {
