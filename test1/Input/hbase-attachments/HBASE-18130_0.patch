From f7d1ce9adfdd8b51847fe7dbea6e435dcece62fa Mon Sep 17 00:00:00 2001
From: Guanghao Zhang <zghao@apache.org>
Date: Sun, 28 May 2017 16:39:59 +0800
Subject: [PATCH] HBASE-18130 Refactor ReplicationSource

---
 .../regionserver/RecoveredReplicationSource.java   | 157 +++++
 .../RecoveredReplicationSourceShipperThread.java   | 130 +++++
 .../regionserver/ReplicationSource.java            | 646 ++++-----------------
 .../regionserver/ReplicationSourceFactory.java     |  39 ++
 .../regionserver/ReplicationSourceInterface.java   |  52 +-
 .../regionserver/ReplicationSourceManager.java     |  23 +-
 .../ReplicationSourceShipperThread.java            | 294 ++++++++++
 .../ReplicationSourceWALReaderThread.java          |   1 +
 .../hbase/replication/ReplicationSourceDummy.java  |  70 ++-
 .../regionserver/TestReplicationSourceManager.java |   2 +-
 10 files changed, 865 insertions(+), 549 deletions(-)
 create mode 100644 hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/RecoveredReplicationSource.java
 create mode 100644 hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/RecoveredReplicationSourceShipperThread.java
 create mode 100644 hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceFactory.java
 create mode 100644 hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipperThread.java

diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/RecoveredReplicationSource.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/RecoveredReplicationSource.java
new file mode 100644
index 0000000..a4a0143
--- /dev/null
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/RecoveredReplicationSource.java
@@ -0,0 +1,157 @@
+package org.apache.hadoop.hbase.replication.regionserver;
+
+import java.io.IOException;
+import java.util.List;
+import java.util.UUID;
+import java.util.concurrent.PriorityBlockingQueue;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.FileStatus;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.hbase.Stoppable;
+import org.apache.hadoop.hbase.replication.ReplicationEndpoint;
+import org.apache.hadoop.hbase.replication.ReplicationPeers;
+import org.apache.hadoop.hbase.replication.ReplicationQueues;
+import org.apache.hadoop.hbase.util.FSUtils;
+import org.apache.hadoop.hbase.util.Threads;
+import org.apache.hadoop.hbase.wal.AbstractFSWALProvider;
+
+public class RecoveredReplicationSource extends ReplicationSource {
+
+  private static final Log LOG = LogFactory.getLog(ReplicationSource.class);
+
+  private String actualPeerId;
+
+  @Override
+  public void init(final Configuration conf, final FileSystem fs,
+      final ReplicationSourceManager manager, final ReplicationQueues replicationQueues,
+      final ReplicationPeers replicationPeers, final Stoppable stopper,
+      final String peerClusterZnode, final UUID clusterId, ReplicationEndpoint replicationEndpoint,
+      final MetricsSource metrics) throws IOException {
+    super.init(conf, fs, manager, replicationQueues, replicationPeers, stopper, peerClusterZnode,
+      clusterId, replicationEndpoint, metrics);
+    this.actualPeerId = this.replicationQueueInfo.getPeerId();
+  }
+
+  @Override
+  protected void tryStartNewShipperThread(String walGroupId, PriorityBlockingQueue<Path> queue) {
+    final RecoveredReplicationSourceShipperThread worker = new RecoveredReplicationSourceShipperThread(
+        conf, walGroupId, queue, this);
+    ReplicationSourceShipperThread extant = workerThreads.putIfAbsent(walGroupId, worker);
+    if (extant != null) {
+      LOG.debug("Someone has beat us to start a worker thread for wal group " + walGroupId);
+    } else {
+      LOG.debug("Starting up worker for wal group " + walGroupId);
+      worker.startup(getUncaughtExceptionHandler());
+      worker.setWALReader(startNewWALReaderThread(worker.getName(), walGroupId, queue,
+        worker.getStartPosition()));
+      workerThreads.put(walGroupId, worker);
+    }
+  }
+
+  public void locateRecoveredPaths(PriorityBlockingQueue<Path> queue) throws IOException {
+    boolean hasPathChanged = false;
+    PriorityBlockingQueue<Path> newPaths =
+        new PriorityBlockingQueue<Path>(queueSizePerGroup, new LogsComparator());
+    pathsLoop: for (Path path : queue) {
+      if (fs.exists(path)) { // still in same location, don't need to do anything
+        newPaths.add(path);
+        continue;
+      }
+      // Path changed - try to find the right path.
+      hasPathChanged = true;
+      if (stopper instanceof ReplicationSyncUp.DummyServer) {
+        // In the case of disaster/recovery, HMaster may be shutdown/crashed before flush data
+        // from .logs to .oldlogs. Loop into .logs folders and check whether a match exists
+        Path newPath = getReplSyncUpPath(path);
+        newPaths.add(newPath);
+        continue;
+      } else {
+        // See if Path exists in the dead RS folder (there could be a chain of failures
+        // to look at)
+        List<String> deadRegionServers = this.replicationQueueInfo.getDeadRegionServers();
+        LOG.info("NB dead servers : " + deadRegionServers.size());
+        final Path walDir = FSUtils.getWALRootDir(conf);
+        for (String curDeadServerName : deadRegionServers) {
+          final Path deadRsDirectory =
+              new Path(walDir, AbstractFSWALProvider.getWALDirectoryName(curDeadServerName));
+          Path[] locs = new Path[] { new Path(deadRsDirectory, path.getName()), new Path(
+              deadRsDirectory.suffix(AbstractFSWALProvider.SPLITTING_EXT), path.getName()) };
+          for (Path possibleLogLocation : locs) {
+            LOG.info("Possible location " + possibleLogLocation.toUri().toString());
+            if (manager.getFs().exists(possibleLogLocation)) {
+              // We found the right new location
+              LOG.info("Log " + path + " still exists at " + possibleLogLocation);
+              newPaths.add(possibleLogLocation);
+              continue pathsLoop;
+            }
+          }
+        }
+        // didn't find a new location
+        LOG.error(
+          String.format("WAL Path %s doesn't exist and couldn't find its new location", path));
+        newPaths.add(path);
+      }
+    }
+
+    if (hasPathChanged) {
+      if (newPaths.size() != queue.size()) { // this shouldn't happen
+        LOG.error("Recovery queue size is incorrect");
+        throw new IOException("Recovery queue size error");
+      }
+      // put the correct locations in the queue
+      // since this is a recovered queue with no new incoming logs,
+      // there shouldn't be any concurrency issues
+      queue.clear();
+      for (Path path : newPaths) {
+        queue.add(path);
+      }
+    }
+  }
+
+  // N.B. the ReplicationSyncUp tool sets the manager.getWALDir to the root of the wal
+  // area rather than to the wal area for a particular region server.
+  private Path getReplSyncUpPath(Path path) throws IOException {
+    FileStatus[] rss = fs.listStatus(manager.getLogDir());
+    for (FileStatus rs : rss) {
+      Path p = rs.getPath();
+      FileStatus[] logs = fs.listStatus(p);
+      for (FileStatus log : logs) {
+        p = new Path(p, log.getPath().getName());
+        if (p.getName().equals(path.getName())) {
+          LOG.info("Log " + p.getName() + " found at " + p);
+          return p;
+        }
+      }
+    }
+    LOG.error("Didn't find path for: " + path.getName());
+    return path;
+  }
+
+  public void tryFinish() {
+    // use synchronize to make sure one last thread will clean the queue
+    synchronized (workerThreads) {
+      Threads.sleep(100);// wait a short while for other worker thread to fully exit
+      boolean allOtherTaskDone = true;
+      for (ReplicationSourceShipperThread worker : workerThreads.values()) {
+        if (worker.isActive()) {
+          allOtherTaskDone = false;
+          break;
+        }
+      }
+      if (allOtherTaskDone) {
+        manager.closeRecoveredQueue(this);
+        LOG.info("Finished recovering queue " + peerClusterZnode + " with the following stats: "
+            + getStats());
+      }
+    }
+  }
+
+  @Override
+  public String getPeerId() {
+    return this.actualPeerId;
+  }
+}
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/RecoveredReplicationSourceShipperThread.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/RecoveredReplicationSourceShipperThread.java
new file mode 100644
index 0000000..a351a56
--- /dev/null
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/RecoveredReplicationSourceShipperThread.java
@@ -0,0 +1,130 @@
+package org.apache.hadoop.hbase.replication.regionserver;
+
+import java.io.IOException;
+import java.util.concurrent.PriorityBlockingQueue;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.hbase.replication.ReplicationException;
+import org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReaderThread.WALEntryBatch;
+import org.apache.hadoop.hbase.util.Threads;
+
+public class RecoveredReplicationSourceShipperThread extends ReplicationSourceShipperThread {
+
+  private static final Log LOG = LogFactory.getLog(RecoveredReplicationSourceShipperThread.class);
+  protected RecoveredReplicationSource source;
+
+  // How long should we sleep for each retry
+  private long sleepForRetries;
+  // Maximum number of retries before taking bold actions
+  private int maxRetriesMultiplier;
+
+  public RecoveredReplicationSourceShipperThread(Configuration conf, String walGroupId,
+      PriorityBlockingQueue<Path> queue, RecoveredReplicationSource source) {
+    super(conf, walGroupId, queue, source);
+    this.source = source;
+    this.sleepForRetries =
+        this.conf.getLong("replication.source.sleepforretries", 1000);    // 1 second
+    this.maxRetriesMultiplier =
+        this.conf.getInt("replication.source.maxretriesmultiplier", 300); // 5 minutes @ 1 sec per
+  }
+
+  @Override
+  public void run() {
+    // Loop until we close down
+    while (isActive()) {
+      int sleepMultiplier = 1;
+      // Sleep until replication is enabled again
+      if (!source.isPeerEnabled()) {
+        if (source.sleepForRetries("Replication is disabled", sleepMultiplier)) {
+          sleepMultiplier++;
+        }
+        continue;
+      }
+
+      while (entryReader == null) {
+        if (source.sleepForRetries("Replication WAL entry reader thread not initialized",
+          sleepMultiplier)) {
+          sleepMultiplier++;
+        }
+      }
+
+      try {
+        WALEntryBatch entryBatch = entryReader.take();
+        shipEdits(entryBatch);
+        source.releaseBufferQuota((int) entryBatch.getHeapSize());
+        if (entryBatch.getWalEntries().isEmpty()
+            && entryBatch.getLastSeqIds().isEmpty()) {
+          LOG.debug("Finished recovering queue for group " + walGroupId + " of peer "
+              + source.getPeerClusterZnode());
+          source.getSourceMetrics().incrCompletedRecoveryQueue();
+          setWorkerRunning(false);
+          continue;
+        }
+      } catch (InterruptedException e) {
+        LOG.trace("Interrupted while waiting for next replication entry batch", e);
+        Thread.currentThread().interrupt();
+      }
+    }
+
+    source.tryFinish();
+  }
+
+  @Override
+  public long getStartPosition() {
+    long startPosition = getRecoveredQueueStartPos();
+    int numRetries = 0;
+    while (numRetries <= maxRetriesMultiplier) {
+      try {
+        source.locateRecoveredPaths(queue);
+        break;
+      } catch (IOException e) {
+        LOG.error("Error while locating recovered queue paths, attempt #" + numRetries);
+        numRetries++;
+      }
+    }
+    return startPosition;
+  }
+
+  // If this is a recovered queue, the queue is already full and the first log
+  // normally has a position (unless the RS failed between 2 logs)
+  private long getRecoveredQueueStartPos() {
+    long startPosition = 0;
+    String peerClusterZnode = source.getPeerClusterZnode();
+    try {
+      startPosition = source.getReplicationQueues().getLogPosition(peerClusterZnode,
+        this.queue.peek().getName());
+      if (LOG.isTraceEnabled()) {
+        LOG.trace("Recovered queue started with log " + this.queue.peek() + " at position "
+            + startPosition);
+      }
+    } catch (ReplicationException e) {
+      terminate("Couldn't get the position of this recovered queue " + peerClusterZnode, e);
+    }
+    return startPosition;
+  }
+
+  @Override
+  protected void updateLogPosition(long lastReadPosition) {
+    source.getSourceManager().logPositionAndCleanOldLogs(currentPath, source.getPeerClusterZnode(),
+      lastReadPosition, true, false);
+    lastLoggedPosition = lastReadPosition;
+  }
+
+  private void terminate(String reason, Exception cause) {
+    if (cause == null) {
+      LOG.info("Closing worker for wal group " + this.walGroupId + " because: " + reason);
+
+    } else {
+      LOG.error("Closing worker for wal group " + this.walGroupId
+          + " because an error occurred: " + reason, cause);
+    }
+    entryReader.interrupt();
+    Threads.shutdown(entryReader, sleepForRetries);
+    this.interrupt();
+    Threads.shutdown(this, sleepForRetries);
+    LOG.info("ReplicationSourceWorker " + this.getName() + " terminated");
+  }
+}
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java
index 72da9bd..22c6226 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java
@@ -18,9 +18,6 @@
  */
 package org.apache.hadoop.hbase.replication.regionserver;
 
-import com.google.common.cache.CacheBuilder;
-import com.google.common.cache.CacheLoader;
-import com.google.common.cache.LoadingCache;
 import com.google.common.collect.Lists;
 import com.google.common.util.concurrent.ListenableFuture;
 import com.google.common.util.concurrent.Service;
@@ -42,19 +39,14 @@ import org.apache.commons.lang.StringUtils;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.FileStatus;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.hbase.Cell;
-import org.apache.hadoop.hbase.CellUtil;
 import org.apache.hadoop.hbase.HBaseConfiguration;
 import org.apache.hadoop.hbase.HConstants;
-import org.apache.hadoop.hbase.MetaTableAccessor;
 import org.apache.hadoop.hbase.Stoppable;
 import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.classification.InterfaceAudience;
 import org.apache.hadoop.hbase.regionserver.RSRpcServices;
-import org.apache.hadoop.hbase.regionserver.wal.WALEdit;
 import org.apache.hadoop.hbase.replication.ChainWALEntryFilter;
 import org.apache.hadoop.hbase.replication.ClusterMarkingEntryFilter;
 import org.apache.hadoop.hbase.replication.ReplicationEndpoint;
@@ -65,16 +57,10 @@ import org.apache.hadoop.hbase.replication.ReplicationQueueInfo;
 import org.apache.hadoop.hbase.replication.ReplicationQueues;
 import org.apache.hadoop.hbase.replication.SystemTableWALEntryFilter;
 import org.apache.hadoop.hbase.replication.WALEntryFilter;
-import org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReaderThread.WALEntryBatch;
-import org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor;
-import org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor;
 import org.apache.hadoop.hbase.util.Bytes;
-import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;
-import org.apache.hadoop.hbase.util.FSUtils;
 import org.apache.hadoop.hbase.util.Pair;
 import org.apache.hadoop.hbase.util.Threads;
 import org.apache.hadoop.hbase.wal.AbstractFSWALProvider;
-import org.apache.hadoop.hbase.wal.WAL.Entry;
 
 /**
  * Class that handles the source of a replication stream.
@@ -96,33 +82,30 @@ public class ReplicationSource extends Thread implements ReplicationSourceInterf
   // each presents a queue for one wal group
   private Map<String, PriorityBlockingQueue<Path>> queues = new HashMap<>();
   // per group queue size, keep no more than this number of logs in each wal group
-  private int queueSizePerGroup;
+  protected int queueSizePerGroup;
   private ReplicationQueues replicationQueues;
   private ReplicationPeers replicationPeers;
 
-  private Configuration conf;
-  private ReplicationQueueInfo replicationQueueInfo;
+  protected Configuration conf;
+  protected ReplicationQueueInfo replicationQueueInfo;
   // id of the peer cluster this source replicates to
   private String peerId;
 
-  String actualPeerId;
   // The manager of all sources to which we ping back our progress
-  private ReplicationSourceManager manager;
+  protected ReplicationSourceManager manager;
   // Should we stop everything?
-  private Stoppable stopper;
+  protected Stoppable stopper;
   // How long should we sleep for each retry
   private long sleepForRetries;
-  private FileSystem fs;
+  protected FileSystem fs;
   // id of this cluster
   private UUID clusterId;
   // id of the other cluster
   private UUID peerClusterId;
   // total number of edits we replicated
   private AtomicLong totalReplicatedEdits = new AtomicLong(0);
-  // total number of edits we replicated
-  private AtomicLong totalReplicatedOperations = new AtomicLong(0);
   // The znode we currently play with
-  private String peerClusterZnode;
+  protected String peerClusterZnode;
   // Maximum number of retries before taking bold actions
   private int maxRetriesMultiplier;
   // Indicates if this particular source is running
@@ -139,7 +122,7 @@ public class ReplicationSource extends Thread implements ReplicationSourceInterf
   private ReplicationThrottler throttler;
   private long defaultBandwidth;
   private long currentBandwidth;
-  private ConcurrentHashMap<String, ReplicationSourceShipperThread> workerThreads = new ConcurrentHashMap<>();
+  protected ConcurrentHashMap<String, ReplicationSourceShipperThread> workerThreads = new ConcurrentHashMap<>();
 
   private AtomicLong totalBufferUsed;
 
@@ -182,8 +165,6 @@ public class ReplicationSource extends Thread implements ReplicationSourceInterf
     this.replicationQueueInfo = new ReplicationQueueInfo(peerClusterZnode);
     // ReplicationQueueInfo parses the peerId out of the znode for us
     this.peerId = this.replicationQueueInfo.getPeerId();
-    ReplicationQueueInfo replicationQueueInfo = new ReplicationQueueInfo(peerId);
-    this.actualPeerId = replicationQueueInfo.getPeerId();
     this.logQueueWarnThreshold = this.conf.getInt("replication.source.log.queue.warn", 2);
     this.replicationEndpoint = replicationEndpoint;
 
@@ -213,15 +194,7 @@ public class ReplicationSource extends Thread implements ReplicationSourceInterf
         // new wal group observed after source startup, start a new worker thread to track it
         // notice: it's possible that log enqueued when this.running is set but worker thread
         // still not launched, so it's necessary to check workerThreads before start the worker
-        final ReplicationSourceShipperThread worker =
-            new ReplicationSourceShipperThread(logPrefix, queue, replicationQueueInfo, this);
-        ReplicationSourceShipperThread extant = workerThreads.putIfAbsent(logPrefix, worker);
-        if (extant != null) {
-          LOG.debug("Someone has beat us to start a worker thread for wal group " + logPrefix);
-        } else {
-          LOG.debug("Starting up worker for wal group " + logPrefix);
-          worker.startup();
-        }
+        tryStartNewShipperThread(logPrefix, queue);
       }
     }
     queue.put(log);
@@ -262,15 +235,6 @@ public class ReplicationSource extends Thread implements ReplicationSourceInterf
     }
   }
 
-  private void uninitialize() {
-    LOG.debug("Source exiting " + this.peerId);
-    metrics.clear();
-    if (replicationEndpoint.state() == Service.State.STARTING
-        || replicationEndpoint.state() == Service.State.RUNNING) {
-      replicationEndpoint.stopAndWait();
-    }
-  }
-
   @Override
   public void run() {
     // mark we are running now
@@ -322,25 +286,130 @@ public class ReplicationSource extends Thread implements ReplicationSourceInterf
     for (Map.Entry<String, PriorityBlockingQueue<Path>> entry : queues.entrySet()) {
       String walGroupId = entry.getKey();
       PriorityBlockingQueue<Path> queue = entry.getValue();
-      final ReplicationSourceShipperThread worker =
-          new ReplicationSourceShipperThread(walGroupId, queue, replicationQueueInfo, this);
-      ReplicationSourceShipperThread extant = workerThreads.putIfAbsent(walGroupId, worker);
-      if (extant != null) {
-        LOG.debug("Someone has beat us to start a worker thread for wal group " + walGroupId);
-      } else {
-        LOG.debug("Starting up worker for wal group " + walGroupId);
-        worker.startup();
+      tryStartNewShipperThread(walGroupId, queue);
+    }
+  }
+
+  protected void tryStartNewShipperThread(String walGroupId, PriorityBlockingQueue<Path> queue) {
+    final ReplicationSourceShipperThread worker = new ReplicationSourceShipperThread(conf,
+        walGroupId, queue, this);
+    ReplicationSourceShipperThread extant = workerThreads.putIfAbsent(walGroupId, worker);
+    if (extant != null) {
+      LOG.debug("Someone has beat us to start a worker thread for wal group " + walGroupId);
+    } else {
+      LOG.debug("Starting up worker for wal group " + walGroupId);
+      worker.startup(getUncaughtExceptionHandler());
+      worker.setWALReader(startNewWALReaderThread(worker.getName(), walGroupId, queue,
+        worker.getStartPosition()));
+      workerThreads.put(walGroupId, worker);
+    }
+  }
+
+  protected ReplicationSourceWALReaderThread startNewWALReaderThread(String threadName,
+      String walGroupId, PriorityBlockingQueue<Path> queue, long startPosition) {
+    ArrayList<WALEntryFilter> filters = Lists.newArrayList(walEntryFilter,
+      new ClusterMarkingEntryFilter(clusterId, peerClusterId, replicationEndpoint));
+    ChainWALEntryFilter readerFilter = new ChainWALEntryFilter(filters);
+    ReplicationSourceWALReaderThread walReader = new ReplicationSourceWALReaderThread(manager,
+        replicationQueueInfo, queue, startPosition, fs, conf, readerFilter, metrics);
+    Threads.setDaemonThreadRunning(walReader, threadName
+        + ".replicationSource.replicationWALReaderThread." + walGroupId + "," + peerClusterZnode,
+      getUncaughtExceptionHandler());
+    return walReader;
+  }
+
+  @Override
+  public Thread.UncaughtExceptionHandler getUncaughtExceptionHandler() {
+    return new Thread.UncaughtExceptionHandler() {
+      @Override
+      public void uncaughtException(final Thread t, final Throwable e) {
+        RSRpcServices.exitIfOOME(e);
+        LOG.error("Unexpected exception in " + t.getName() + " currentPath=" + getCurrentPath(), e);
+        stopper.stop("Unexpected exception in " + t.getName());
+      }
+    };
+  }
+
+  @Override
+  public ReplicationThrottler getThrottler() {
+    return this.throttler;
+  }
+
+  @Override
+  public ReplicationEndpoint getReplicationEndpoint() {
+    return this.replicationEndpoint;
+  }
+
+  @Override
+  public ReplicationSourceManager getSourceManager() {
+    return this.manager;
+  }
+
+  @Override
+  public ReplicationQueues getReplicationQueues() {
+    return this.replicationQueues;
+  }
+
+  @Override
+  public void tryThrottle(int batchSize) throws InterruptedException {
+    checkBandwidthChangeAndResetThrottler();
+    if (throttler.isEnabled()) {
+      long sleepTicks = throttler.getNextSleepInterval(batchSize);
+      if (sleepTicks > 0) {
+        if (LOG.isTraceEnabled()) {
+          LOG.trace("To sleep " + sleepTicks + "ms for throttling control");
+        }
+        Thread.sleep(sleepTicks);
+        // reset throttler's cycle start tick when sleep for throttling occurs
+        throttler.resetStartTick();
       }
     }
   }
 
+  private void checkBandwidthChangeAndResetThrottler() {
+    long peerBandwidth = getCurrentBandwidth();
+    if (peerBandwidth != currentBandwidth) {
+      currentBandwidth = peerBandwidth;
+      throttler.setBandwidth((double) currentBandwidth / 10.0);
+      LOG.info("ReplicationSource : " + peerId
+          + " bandwidth throttling changed, currentBandWidth=" + currentBandwidth);
+    }
+  }
+
+  private long getCurrentBandwidth() {
+    ReplicationPeer replicationPeer = this.replicationPeers.getConnectedPeer(peerId);
+    long peerBandwidth = replicationPeer != null ? replicationPeer.getPeerBandwidth() : 0;
+    // user can set peer bandwidth to 0 to use default bandwidth
+    return peerBandwidth != 0 ? peerBandwidth : defaultBandwidth;
+  }
+
+  @Override
+  public void releaseBufferQuota(int size) {
+    totalBufferUsed.addAndGet(-size);
+  }
+
+  @Override
+  public void addTotalReplicatedEdits(int size) {
+    totalReplicatedEdits.addAndGet(size);
+  }
+
+  private void uninitialize() {
+    LOG.debug("Source exiting " + this.peerId);
+    metrics.clear();
+    if (replicationEndpoint.state() == Service.State.STARTING
+        || replicationEndpoint.state() == Service.State.RUNNING) {
+      replicationEndpoint.stopAndWait();
+    }
+  }
+
   /**
    * Do the sleeping logic
    * @param msg Why we sleep
    * @param sleepMultiplier by how many times the default sleeping time is augmented
    * @return True if <code>sleepMultiplier</code> is &lt; <code>maxRetriesMultiplier</code>
    */
-  protected boolean sleepForRetries(String msg, int sleepMultiplier) {
+  @Override
+  public boolean sleepForRetries(String msg, int sleepMultiplier) {
     try {
       if (LOG.isTraceEnabled()) {
         LOG.trace(msg + ", sleeping " + sleepForRetries + " times " + sleepMultiplier);
@@ -358,7 +427,8 @@ public class ReplicationSource extends Thread implements ReplicationSourceInterf
    *
    * @return true if the peer is enabled, otherwise false
    */
-  protected boolean isPeerEnabled() {
+  @Override
+  public boolean isPeerEnabled() {
     return this.replicationPeers.getStatusOfPeer(this.peerId);
   }
 
@@ -428,7 +498,7 @@ public class ReplicationSource extends Thread implements ReplicationSourceInterf
   }
 
   @Override
-  public String getPeerClusterId() {
+  public String getPeerId() {
     return this.peerId;
   }
 
@@ -441,7 +511,8 @@ public class ReplicationSource extends Thread implements ReplicationSourceInterf
     return null;
   }
 
-  private boolean isSourceActive() {
+  @Override
+  public boolean isSourceActive() {
     return !this.stopper.isStopped() && this.sourceRunning;
   }
 
@@ -492,467 +563,8 @@ public class ReplicationSource extends Thread implements ReplicationSourceInterf
    * Get Replication Source Metrics
    * @return sourceMetrics
    */
+  @Override
   public MetricsSource getSourceMetrics() {
     return this.metrics;
   }
-
-  private long getCurrentBandwidth() {
-    ReplicationPeer replicationPeer = this.replicationPeers.getConnectedPeer(peerId);
-    long peerBandwidth = replicationPeer != null ? replicationPeer.getPeerBandwidth() : 0;
-    // user can set peer bandwidth to 0 to use default bandwidth
-    return peerBandwidth != 0 ? peerBandwidth : defaultBandwidth;
-  }
-
-  // This thread reads entries from a queue and ships them.
-  // Entries are placed onto the queue by ReplicationSourceWALReaderThread
-  public class ReplicationSourceShipperThread extends Thread {
-    ReplicationSourceInterface source;
-    String walGroupId;
-    PriorityBlockingQueue<Path> queue;
-    ReplicationQueueInfo replicationQueueInfo;
-    // Last position in the log that we sent to ZooKeeper
-    private long lastLoggedPosition = -1;
-    // Path of the current log
-    private volatile Path currentPath;
-    // Indicates whether this particular worker is running
-    private boolean workerRunning = true;
-    ReplicationSourceWALReaderThread entryReader;
-    // Use guava cache to set ttl for each key
-    private LoadingCache<String, Boolean> canSkipWaitingSet = CacheBuilder.newBuilder()
-        .expireAfterAccess(1, TimeUnit.DAYS).build(
-        new CacheLoader<String, Boolean>() {
-          @Override
-          public Boolean load(String key) throws Exception {
-            return false;
-          }
-        }
-    );
-
-    public ReplicationSourceShipperThread(String walGroupId,
-        PriorityBlockingQueue<Path> queue, ReplicationQueueInfo replicationQueueInfo,
-        ReplicationSourceInterface source) {
-      this.walGroupId = walGroupId;
-      this.queue = queue;
-      this.replicationQueueInfo = replicationQueueInfo;
-      this.source = source;
-    }
-
-    @Override
-    public void run() {
-      // Loop until we close down
-      while (isWorkerActive()) {
-        int sleepMultiplier = 1;
-        // Sleep until replication is enabled again
-        if (!isPeerEnabled()) {
-          if (sleepForRetries("Replication is disabled", sleepMultiplier)) {
-            sleepMultiplier++;
-          }
-          continue;
-        }
-        while (entryReader == null) {
-          if (sleepForRetries("Replication WAL entry reader thread not initialized",
-            sleepMultiplier)) {
-            sleepMultiplier++;
-          }
-          if (sleepMultiplier == maxRetriesMultiplier) {
-            LOG.warn("Replication WAL entry reader thread not initialized");
-          }
-        }
-
-        try {
-          WALEntryBatch entryBatch = entryReader.take();
-          for (Map.Entry<String, Long> entry : entryBatch.getLastSeqIds().entrySet()) {
-            waitingUntilCanPush(entry);
-          }
-          shipEdits(entryBatch);
-          releaseBufferQuota((int) entryBatch.getHeapSize());
-          if (replicationQueueInfo.isQueueRecovered() && entryBatch.getWalEntries().isEmpty()
-              && entryBatch.getLastSeqIds().isEmpty()) {
-            LOG.debug("Finished recovering queue for group " + walGroupId + " of peer "
-                + peerClusterZnode);
-            metrics.incrCompletedRecoveryQueue();
-            setWorkerRunning(false);
-            continue;
-          }
-        } catch (InterruptedException e) {
-          LOG.trace("Interrupted while waiting for next replication entry batch", e);
-          Thread.currentThread().interrupt();
-        }
-      }
-
-      if (replicationQueueInfo.isQueueRecovered()) {
-        // use synchronize to make sure one last thread will clean the queue
-        synchronized (workerThreads) {
-          Threads.sleep(100);// wait a short while for other worker thread to fully exit
-          boolean allOtherTaskDone = true;
-          for (ReplicationSourceShipperThread worker : workerThreads.values()) {
-            if (!worker.equals(this) && worker.isAlive()) {
-              allOtherTaskDone = false;
-              break;
-            }
-          }
-          if (allOtherTaskDone) {
-            manager.closeRecoveredQueue(this.source);
-            LOG.info("Finished recovering queue " + peerClusterZnode
-                + " with the following stats: " + getStats());
-          }
-        }
-      }
-    }
-
-    private void waitingUntilCanPush(Map.Entry<String, Long> entry) {
-      String key = entry.getKey();
-      long seq = entry.getValue();
-      boolean deleteKey = false;
-      if (seq <= 0) {
-        // There is a REGION_CLOSE marker, we can not continue skipping after this entry.
-        deleteKey = true;
-        seq = -seq;
-      }
-
-      if (!canSkipWaitingSet.getUnchecked(key)) {
-        try {
-          manager.waitUntilCanBePushed(Bytes.toBytes(key), seq, actualPeerId);
-        } catch (IOException e) {
-          LOG.error("waitUntilCanBePushed fail", e);
-          stopper.stop("waitUntilCanBePushed fail");
-        } catch (InterruptedException e) {
-          LOG.warn("waitUntilCanBePushed interrupted", e);
-          Thread.currentThread().interrupt();
-        }
-        canSkipWaitingSet.put(key, true);
-      }
-      if (deleteKey) {
-        canSkipWaitingSet.invalidate(key);
-      }
-    }
-
-    private void cleanUpHFileRefs(WALEdit edit) throws IOException {
-      String peerId = peerClusterZnode;
-      if (peerId.contains("-")) {
-        // peerClusterZnode will be in the form peerId + "-" + rsZNode.
-        // A peerId will not have "-" in its name, see HBASE-11394
-        peerId = peerClusterZnode.split("-")[0];
-      }
-      List<Cell> cells = edit.getCells();
-      int totalCells = cells.size();
-      for (int i = 0; i < totalCells; i++) {
-        Cell cell = cells.get(i);
-        if (CellUtil.matchingQualifier(cell, WALEdit.BULK_LOAD)) {
-          BulkLoadDescriptor bld = WALEdit.getBulkLoadDescriptor(cell);
-          List<StoreDescriptor> stores = bld.getStoresList();
-          int totalStores = stores.size();
-          for (int j = 0; j < totalStores; j++) {
-            List<String> storeFileList = stores.get(j).getStoreFileList();
-            manager.cleanUpHFileRefs(peerId, storeFileList);
-            metrics.decrSizeOfHFileRefsQueue(storeFileList.size());
-          }
-        }
-      }
-    }
-
-    private void checkBandwidthChangeAndResetThrottler() {
-      long peerBandwidth = getCurrentBandwidth();
-      if (peerBandwidth != currentBandwidth) {
-        currentBandwidth = peerBandwidth;
-        throttler.setBandwidth((double) currentBandwidth / 10.0);
-        LOG.info("ReplicationSource : " + peerId
-            + " bandwidth throttling changed, currentBandWidth=" + currentBandwidth);
-      }
-    }
-
-    /**
-     * Do the shipping logic
-     */
-    protected void shipEdits(WALEntryBatch entryBatch) {
-      List<Entry> entries = entryBatch.getWalEntries();
-      long lastReadPosition = entryBatch.getLastWalPosition();
-      currentPath = entryBatch.getLastWalPath();
-      int sleepMultiplier = 0;
-      if (entries.isEmpty()) {
-        if (lastLoggedPosition != lastReadPosition) {
-          // Save positions to meta table before zk.
-          updateSerialRepPositions(entryBatch.getLastSeqIds());
-          updateLogPosition(lastReadPosition);
-          // if there was nothing to ship and it's not an error
-          // set "ageOfLastShippedOp" to <now> to indicate that we're current
-          metrics.setAgeOfLastShippedOp(EnvironmentEdgeManager.currentTime(), walGroupId);
-        }
-        return;
-      }
-      int currentSize = (int) entryBatch.getHeapSize();
-      while (isWorkerActive()) {
-        try {
-          checkBandwidthChangeAndResetThrottler();
-          if (throttler.isEnabled()) {
-            long sleepTicks = throttler.getNextSleepInterval(currentSize);
-            if (sleepTicks > 0) {
-              try {
-                if (LOG.isTraceEnabled()) {
-                  LOG.trace("To sleep " + sleepTicks + "ms for throttling control");
-                }
-                Thread.sleep(sleepTicks);
-              } catch (InterruptedException e) {
-                LOG.debug("Interrupted while sleeping for throttling control");
-                Thread.currentThread().interrupt();
-                // current thread might be interrupted to terminate
-                // directly go back to while() for confirm this
-                continue;
-              }
-              // reset throttler's cycle start tick when sleep for throttling occurs
-              throttler.resetStartTick();
-            }
-          }
-          // create replicateContext here, so the entries can be GC'd upon return from this call
-          // stack
-          ReplicationEndpoint.ReplicateContext replicateContext =
-              new ReplicationEndpoint.ReplicateContext();
-          replicateContext.setEntries(entries).setSize(currentSize);
-          replicateContext.setWalGroupId(walGroupId);
-
-          long startTimeNs = System.nanoTime();
-          // send the edits to the endpoint. Will block until the edits are shipped and acknowledged
-          boolean replicated = replicationEndpoint.replicate(replicateContext);
-          long endTimeNs = System.nanoTime();
-
-          if (!replicated) {
-            continue;
-          } else {
-            sleepMultiplier = Math.max(sleepMultiplier - 1, 0);
-          }
-
-          if (this.lastLoggedPosition != lastReadPosition) {
-            //Clean up hfile references
-            int size = entries.size();
-            for (int i = 0; i < size; i++) {
-              cleanUpHFileRefs(entries.get(i).getEdit());
-            }
-
-            // Save positions to meta table before zk.
-            updateSerialRepPositions(entryBatch.getLastSeqIds());
-
-            //Log and clean up WAL logs
-            updateLogPosition(lastReadPosition);
-          }
-          if (throttler.isEnabled()) {
-            throttler.addPushSize(currentSize);
-          }
-          totalReplicatedEdits.addAndGet(entries.size());
-          totalReplicatedOperations.addAndGet(entryBatch.getNbOperations());
-          // FIXME check relationship between wal group and overall
-          metrics.shipBatch(entryBatch.getNbOperations(), currentSize, entryBatch.getNbHFiles());
-          metrics.setAgeOfLastShippedOp(entries.get(entries.size() - 1).getKey().getWriteTime(),
-            walGroupId);
-          if (LOG.isTraceEnabled()) {
-            LOG.trace("Replicated " + totalReplicatedEdits + " entries in total, or "
-                + totalReplicatedOperations + " operations in "
-                + ((endTimeNs - startTimeNs) / 1000000) + " ms");
-          }
-          break;
-        } catch (Exception ex) {
-          LOG.warn(replicationEndpoint.getClass().getName() + " threw unknown exception:"
-              + org.apache.hadoop.util.StringUtils.stringifyException(ex));
-          if (sleepForRetries("ReplicationEndpoint threw exception", sleepMultiplier)) {
-            sleepMultiplier++;
-          }
-        }
-      }
-    }
-
-    private void updateSerialRepPositions(Map<String, Long> lastPositionsForSerialScope) {
-      try {
-        MetaTableAccessor.updateReplicationPositions(manager.getConnection(), actualPeerId,
-          lastPositionsForSerialScope);
-      } catch (IOException e) {
-        LOG.error("updateReplicationPositions fail", e);
-        stopper.stop("updateReplicationPositions fail");
-      }
-    }
-
-    private void updateLogPosition(long lastReadPosition) {
-      manager.logPositionAndCleanOldLogs(currentPath, peerClusterZnode, lastReadPosition,
-        this.replicationQueueInfo.isQueueRecovered(), false);
-      lastLoggedPosition = lastReadPosition;
-    }
-
-    public void startup() {
-      String n = Thread.currentThread().getName();
-      Thread.UncaughtExceptionHandler handler = new Thread.UncaughtExceptionHandler() {
-        @Override
-        public void uncaughtException(final Thread t, final Throwable e) {
-          RSRpcServices.exitIfOOME(e);
-          LOG.error("Unexpected exception in ReplicationSourceWorkerThread," + " currentPath="
-              + getCurrentPath(), e);
-          stopper.stop("Unexpected exception in ReplicationSourceWorkerThread");
-        }
-      };
-      Threads.setDaemonThreadRunning(this, n + ".replicationSource." + walGroupId + ","
-          + peerClusterZnode, handler);
-      workerThreads.put(walGroupId, this);
-
-      long startPosition = 0;
-
-      if (this.replicationQueueInfo.isQueueRecovered()) {
-        startPosition = getRecoveredQueueStartPos(startPosition);
-        int numRetries = 0;
-        while (numRetries <= maxRetriesMultiplier) {
-          try {
-            locateRecoveredPaths();
-            break;
-          } catch (IOException e) {
-            LOG.error("Error while locating recovered queue paths, attempt #" + numRetries);
-            numRetries++;
-          }
-        }
-      }
-
-      startWALReaderThread(n, handler, startPosition);
-    }
-
-    // If this is a recovered queue, the queue is already full and the first log
-    // normally has a position (unless the RS failed between 2 logs)
-    private long getRecoveredQueueStartPos(long startPosition) {
-      try {
-        startPosition =
-            (replicationQueues.getLogPosition(peerClusterZnode, this.queue.peek().getName()));
-        if (LOG.isTraceEnabled()) {
-          LOG.trace("Recovered queue started with log " + this.queue.peek() + " at position "
-              + startPosition);
-        }
-      } catch (ReplicationException e) {
-        terminate("Couldn't get the position of this recovered queue " + peerClusterZnode, e);
-      }
-      return startPosition;
-    }
-
-    // start a background thread to read and batch entries
-    private void startWALReaderThread(String threadName, Thread.UncaughtExceptionHandler handler,
-        long startPosition) {
-      ArrayList<WALEntryFilter> filters = Lists.newArrayList(walEntryFilter,
-        new ClusterMarkingEntryFilter(clusterId, peerClusterId, replicationEndpoint));
-      ChainWALEntryFilter readerFilter = new ChainWALEntryFilter(filters);
-      entryReader = new ReplicationSourceWALReaderThread(manager, replicationQueueInfo, queue,
-          startPosition, fs, conf, readerFilter, metrics);
-      Threads.setDaemonThreadRunning(entryReader, threadName
-          + ".replicationSource.replicationWALReaderThread." + walGroupId + "," + peerClusterZnode,
-        handler);
-    }
-
-    // Loops through the recovered queue and tries to find the location of each log
-    // this is necessary because the logs may have moved before recovery was initiated
-    private void locateRecoveredPaths() throws IOException {
-      boolean hasPathChanged = false;
-      PriorityBlockingQueue<Path> newPaths =
-          new PriorityBlockingQueue<Path>(queueSizePerGroup, new LogsComparator());
-      pathsLoop: for (Path path : queue) {
-        if (fs.exists(path)) { // still in same location, don't need to do anything
-          newPaths.add(path);
-          continue;
-        }
-        // Path changed - try to find the right path.
-        hasPathChanged = true;
-        if (stopper instanceof ReplicationSyncUp.DummyServer) {
-          // In the case of disaster/recovery, HMaster may be shutdown/crashed before flush data
-          // from .logs to .oldlogs. Loop into .logs folders and check whether a match exists
-          Path newPath = getReplSyncUpPath(path);
-          newPaths.add(newPath);
-          continue;
-        } else {
-          // See if Path exists in the dead RS folder (there could be a chain of failures
-          // to look at)
-          List<String> deadRegionServers = this.replicationQueueInfo.getDeadRegionServers();
-          LOG.info("NB dead servers : " + deadRegionServers.size());
-          final Path walDir = FSUtils.getWALRootDir(conf);
-          for (String curDeadServerName : deadRegionServers) {
-            final Path deadRsDirectory =
-                new Path(walDir, AbstractFSWALProvider.getWALDirectoryName(curDeadServerName));
-            Path[] locs = new Path[] { new Path(deadRsDirectory, path.getName()), new Path(
-                deadRsDirectory.suffix(AbstractFSWALProvider.SPLITTING_EXT), path.getName()) };
-            for (Path possibleLogLocation : locs) {
-              LOG.info("Possible location " + possibleLogLocation.toUri().toString());
-              if (manager.getFs().exists(possibleLogLocation)) {
-                // We found the right new location
-                LOG.info("Log " + path + " still exists at " + possibleLogLocation);
-                newPaths.add(possibleLogLocation);
-                continue pathsLoop;
-              }
-            }
-          }
-          // didn't find a new location
-          LOG.error(
-            String.format("WAL Path %s doesn't exist and couldn't find its new location", path));
-          newPaths.add(path);
-        }
-      }
-
-      if (hasPathChanged) {
-        if (newPaths.size() != queue.size()) { // this shouldn't happen
-          LOG.error("Recovery queue size is incorrect");
-          throw new IOException("Recovery queue size error");
-        }
-        // put the correct locations in the queue
-        // since this is a recovered queue with no new incoming logs,
-        // there shouldn't be any concurrency issues
-        queue.clear();
-        for (Path path : newPaths) {
-          queue.add(path);
-        }
-      }
-    }
-
-    // N.B. the ReplicationSyncUp tool sets the manager.getWALDir to the root of the wal
-    // area rather than to the wal area for a particular region server.
-    private Path getReplSyncUpPath(Path path) throws IOException {
-      FileStatus[] rss = fs.listStatus(manager.getLogDir());
-      for (FileStatus rs : rss) {
-        Path p = rs.getPath();
-        FileStatus[] logs = fs.listStatus(p);
-        for (FileStatus log : logs) {
-          p = new Path(p, log.getPath().getName());
-          if (p.getName().equals(path.getName())) {
-            LOG.info("Log " + p.getName() + " found at " + p);
-            return p;
-          }
-        }
-      }
-      LOG.error("Didn't find path for: " + path.getName());
-      return path;
-    }
-
-    public Path getCurrentPath() {
-      return this.currentPath;
-    }
-
-    public long getCurrentPosition() {
-      return this.lastLoggedPosition;
-    }
-
-    private boolean isWorkerActive() {
-      return !stopper.isStopped() && workerRunning && !isInterrupted();
-    }
-
-    private void terminate(String reason, Exception cause) {
-      if (cause == null) {
-        LOG.info("Closing worker for wal group " + this.walGroupId + " because: " + reason);
-
-      } else {
-        LOG.error("Closing worker for wal group " + this.walGroupId
-            + " because an error occurred: " + reason, cause);
-      }
-      entryReader.interrupt();
-      Threads.shutdown(entryReader, sleepForRetries);
-      this.interrupt();
-      Threads.shutdown(this, sleepForRetries);
-      LOG.info("ReplicationSourceWorker " + this.getName() + " terminated");
-    }
-
-    public void setWorkerRunning(boolean workerRunning) {
-      entryReader.setReaderRunning(workerRunning);
-      this.workerRunning = workerRunning;
-    }
-
-    private void releaseBufferQuota(int size) {
-      totalBufferUsed.addAndGet(-size);
-    }
-  }
 }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceFactory.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceFactory.java
new file mode 100644
index 0000000..e661b54
--- /dev/null
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceFactory.java
@@ -0,0 +1,39 @@
+package org.apache.hadoop.hbase.replication.regionserver;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.replication.ReplicationQueueInfo;
+
+public class ReplicationSourceFactory {
+
+  private static final Log LOG = LogFactory.getLog(ReplicationSourceFactory.class);
+
+  static ReplicationSourceInterface create(Configuration conf, String peerId) {
+    ReplicationQueueInfo replicationQueueInfo = new ReplicationQueueInfo(peerId);
+    boolean isQueueRecovered = replicationQueueInfo.isQueueRecovered();
+    ReplicationSourceInterface src;
+    try {
+      if (isQueueRecovered) {
+        @SuppressWarnings("rawtypes")
+        Class c = Class.forName(conf.get("replication.replicationsource.implementation",
+          RecoveredReplicationSource.class.getCanonicalName()));
+        src = (ReplicationSourceInterface) c.newInstance();
+      } else {
+        @SuppressWarnings("rawtypes")
+        Class c = Class.forName(conf.get("replication.replicationsource.implementation",
+          ReplicationSource.class.getCanonicalName()));
+        src = (ReplicationSourceInterface) c.newInstance();
+      }
+    } catch (Exception e) {
+      LOG.warn("Passed replication source implementation throws errors, "
+          + "defaulting to ReplicationSource", e);
+      if (isQueueRecovered) {
+        src = new RecoveredReplicationSource();
+      } else {
+        src = new ReplicationSource();
+      }
+    }
+    return src;
+  }
+}
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceInterface.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceInterface.java
index 8d5451c..8484986 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceInterface.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceInterface.java
@@ -21,6 +21,7 @@ package org.apache.hadoop.hbase.replication.regionserver;
 import java.io.IOException;
 import java.util.List;
 import java.util.UUID;
+import java.util.concurrent.PriorityBlockingQueue;
 
 import org.apache.hadoop.hbase.classification.InterfaceAudience;
 import org.apache.hadoop.conf.Configuration;
@@ -65,10 +66,15 @@ public interface ReplicationSourceInterface {
   void enqueueLog(Path log);
 
   /**
-   * Get the current log that's replicated
-   * @return the current log
+   * Add hfile names to the queue to be replicated.
+   * @param tableName Name of the table these files belongs to
+   * @param family Name of the family these files belong to
+   * @param pairs list of pairs of { HFile location in staging dir, HFile path in region dir which
+   *          will be added in the queue for replication}
+   * @throws ReplicationException If failed to add hfile references
    */
-  Path getCurrentPath();
+  void addHFileRefs(TableName tableName, byte[] family, List<Pair<Path, Path>> pairs)
+      throws ReplicationException;
 
   /**
    * Start the replication
@@ -89,6 +95,12 @@ public interface ReplicationSourceInterface {
   void terminate(String reason, Exception cause);
 
   /**
+   * Get the current log that's replicated
+   * @return the current log
+   */
+  Path getCurrentPath();
+
+  /**
    * Get the id that the source is replicating to
    *
    * @return peer cluster id
@@ -100,7 +112,7 @@ public interface ReplicationSourceInterface {
    *
    * @return peer cluster id
    */
-  String getPeerClusterId();
+  String getPeerId();
 
   /**
    * Get a string representation of the current statistics
@@ -109,15 +121,27 @@ public interface ReplicationSourceInterface {
    */
   String getStats();
 
-  /**
-   * Add hfile names to the queue to be replicated.
-   * @param tableName Name of the table these files belongs to
-   * @param family Name of the family these files belong to
-   * @param pairs list of pairs of { HFile location in staging dir, HFile path in region dir which
-   *          will be added in the queue for replication}
-   * @throws ReplicationException If failed to add hfile references
-   */
-  void addHFileRefs(TableName tableName, byte[] family, List<Pair<Path, Path>> pairs)
-      throws ReplicationException;
+  boolean isPeerEnabled();
+
+  boolean isSourceActive();
+
+  MetricsSource getSourceMetrics();
+
+  ReplicationThrottler getThrottler();
+
+  ReplicationEndpoint getReplicationEndpoint();
+
+  ReplicationSourceManager getSourceManager();
+
+  ReplicationQueues getReplicationQueues();
+
+  Thread.UncaughtExceptionHandler getUncaughtExceptionHandler();
+
+  boolean sleepForRetries(String msg, int sleepMultiplier);
+
+  void tryThrottle(int batchSize) throws InterruptedException;
+
+  void releaseBufferQuota(int size);
 
+  void addTotalReplicatedEdits(int size);
 }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java
index a38e264..cb631c1 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java
@@ -464,17 +464,8 @@ public class ReplicationSourceManager implements ReplicationListener {
       rsServerHost = ((HRegionServer) server).getRegionServerCoprocessorHost();
       tableDescriptors = ((HRegionServer) server).getTableDescriptors();
     }
-    ReplicationSourceInterface src;
-    try {
-      @SuppressWarnings("rawtypes")
-      Class c = Class.forName(conf.get("replication.replicationsource.implementation",
-          ReplicationSource.class.getCanonicalName()));
-      src = (ReplicationSourceInterface) c.newInstance();
-    } catch (Exception e) {
-      LOG.warn("Passed replication source implementation throws errors, " +
-          "defaulting to ReplicationSource", e);
-      src = new ReplicationSource();
-    }
+
+    ReplicationSourceInterface src = ReplicationSourceFactory.create(conf, peerId);
 
     ReplicationEndpoint replicationEndpoint = null;
     try {
@@ -575,7 +566,7 @@ public class ReplicationSourceManager implements ReplicationListener {
     synchronized (oldsources) {
       // First close all the recovered sources for this peer
       for (ReplicationSourceInterface src : oldsources) {
-        if (id.equals(src.getPeerClusterId())) {
+        if (id.equals(src.getPeerId())) {
           oldSourcesToDelete.add(src);
         }
       }
@@ -591,7 +582,7 @@ public class ReplicationSourceManager implements ReplicationListener {
     // synchronize on replicationPeers to avoid adding source for the to-be-removed peer
     synchronized (this.replicationPeers) {
       for (ReplicationSourceInterface src : this.sources) {
-        if (id.equals(src.getPeerClusterId())) {
+        if (id.equals(src.getPeerId())) {
           srcToRemove.add(src);
         }
       }
@@ -752,7 +743,7 @@ public class ReplicationSourceManager implements ReplicationListener {
           // synchronized on oldsources to avoid adding recovered source for the to-be-removed peer
           // see removePeer
           synchronized (oldsources) {
-            if (!this.rp.getConnectedPeerIds().contains(src.getPeerClusterId())) {
+            if (!this.rp.getConnectedPeerIds().contains(src.getPeerId())) {
               src.terminate("Recovered queue doesn't belong to any current peer");
               closeRecoveredQueue(src);
               continue;
@@ -834,11 +825,11 @@ public class ReplicationSourceManager implements ReplicationListener {
   public String getStats() {
     StringBuffer stats = new StringBuffer();
     for (ReplicationSourceInterface source : sources) {
-      stats.append("Normal source for cluster " + source.getPeerClusterId() + ": ");
+      stats.append("Normal source for cluster " + source.getPeerId() + ": ");
       stats.append(source.getStats() + "\n");
     }
     for (ReplicationSourceInterface oldSource : oldsources) {
-      stats.append("Recovered source for cluster/machine(s) " + oldSource.getPeerClusterId()+": ");
+      stats.append("Recovered source for cluster/machine(s) " + oldSource.getPeerId()+": ");
       stats.append(oldSource.getStats()+ "\n");
     }
     return stats.toString();
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipperThread.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipperThread.java
new file mode 100644
index 0000000..77658bf
--- /dev/null
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipperThread.java
@@ -0,0 +1,294 @@
+package org.apache.hadoop.hbase.replication.regionserver;
+
+import java.io.IOException;
+import java.util.List;
+import java.util.Map;
+import java.util.concurrent.PriorityBlockingQueue;
+import java.util.concurrent.TimeUnit;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.hbase.Cell;
+import org.apache.hadoop.hbase.CellUtil;
+import org.apache.hadoop.hbase.MetaTableAccessor;
+import org.apache.hadoop.hbase.classification.InterfaceAudience;
+import org.apache.hadoop.hbase.regionserver.wal.WALEdit;
+import org.apache.hadoop.hbase.replication.ReplicationEndpoint;
+import org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceWALReaderThread.WALEntryBatch;
+import org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor;
+import org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;
+import org.apache.hadoop.hbase.util.Threads;
+import org.apache.hadoop.hbase.wal.WAL.Entry;
+
+import com.google.common.cache.CacheBuilder;
+import com.google.common.cache.CacheLoader;
+import com.google.common.cache.LoadingCache;
+
+/*
+ * This thread reads entries from a queue and ships them. Entries are placed onto the queue by
+ * ReplicationSourceWALReaderThread
+ */
+@InterfaceAudience.Private
+public class ReplicationSourceShipperThread extends Thread {
+  private static final Log LOG = LogFactory.getLog(ReplicationSourceShipperThread.class);
+
+  protected Configuration conf;
+  protected String walGroupId;
+  protected PriorityBlockingQueue<Path> queue;
+  protected ReplicationSourceInterface source;
+
+  // Last position in the log that we sent to ZooKeeper
+  protected long lastLoggedPosition = -1;
+  // Path of the current log
+  protected volatile Path currentPath;
+  // Indicates whether this particular worker is running
+  private boolean workerRunning = true;
+  protected ReplicationSourceWALReaderThread entryReader;
+
+  // Use guava cache to set ttl for each key
+  private LoadingCache<String, Boolean> canSkipWaitingSet = CacheBuilder.newBuilder()
+      .expireAfterAccess(1, TimeUnit.DAYS).build(
+      new CacheLoader<String, Boolean>() {
+        @Override
+        public Boolean load(String key) throws Exception {
+          return false;
+        }
+      }
+  );
+
+  public ReplicationSourceShipperThread(Configuration conf, String walGroupId, PriorityBlockingQueue<Path> queue,
+      ReplicationSourceInterface source) {
+    this.conf = conf;
+    this.walGroupId = walGroupId;
+    this.queue = queue;
+    this.source = source;
+  }
+
+  @Override
+  public void run() {
+    // Loop until we close down
+    while (isActive()) {
+      int sleepMultiplier = 1;
+      // Sleep until replication is enabled again
+      if (!source.isPeerEnabled()) {
+        if (source.sleepForRetries("Replication is disabled", sleepMultiplier)) {
+          sleepMultiplier++;
+        }
+        continue;
+      }
+
+      while (entryReader == null) {
+        if (source.sleepForRetries("Replication WAL entry reader thread not initialized",
+          sleepMultiplier)) {
+          sleepMultiplier++;
+        }
+      }
+
+      try {
+        WALEntryBatch entryBatch = entryReader.take();
+        for (Map.Entry<String, Long> entry : entryBatch.getLastSeqIds().entrySet()) {
+          waitingUntilCanPush(entry);
+        }
+        shipEdits(entryBatch);
+        source.releaseBufferQuota((int) entryBatch.getHeapSize());
+      } catch (InterruptedException e) {
+        LOG.trace("Interrupted while waiting for next replication entry batch", e);
+        Thread.currentThread().interrupt();
+      }
+    }
+  }
+
+  /**
+   * Do the shipping logic
+   */
+  protected void shipEdits(WALEntryBatch entryBatch) {
+    List<Entry> entries = entryBatch.getWalEntries();
+    long lastReadPosition = entryBatch.getLastWalPosition();
+    currentPath = entryBatch.getLastWalPath();
+    int sleepMultiplier = 0;
+    if (entries.isEmpty()) {
+      if (lastLoggedPosition != lastReadPosition) {
+        // Save positions to meta table before zk.
+        updateSerialRepPositions(entryBatch.getLastSeqIds());
+        updateLogPosition(lastReadPosition);
+        // if there was nothing to ship and it's not an error
+        // set "ageOfLastShippedOp" to <now> to indicate that we're current
+        source.getSourceMetrics().setAgeOfLastShippedOp(EnvironmentEdgeManager.currentTime(),
+          walGroupId);
+      }
+      return;
+    }
+    int currentSize = (int) entryBatch.getHeapSize();
+    while (isActive()) {
+      try {
+        try {
+          source.tryThrottle(currentSize);
+        } catch (InterruptedException e) {
+          LOG.debug("Interrupted while sleeping for throttling control");
+          Thread.currentThread().interrupt();
+          // current thread might be interrupted to terminate
+          // directly go back to while() for confirm this
+          continue;
+        }
+
+        // create replicateContext here, so the entries can be GC'd upon return from this call
+        // stack
+        ReplicationEndpoint.ReplicateContext replicateContext =
+            new ReplicationEndpoint.ReplicateContext();
+        replicateContext.setEntries(entries).setSize(currentSize);
+        replicateContext.setWalGroupId(walGroupId);
+
+        long startTimeNs = System.nanoTime();
+        // send the edits to the endpoint. Will block until the edits are shipped and acknowledged
+        boolean replicated = source.getReplicationEndpoint().replicate(replicateContext);
+        long endTimeNs = System.nanoTime();
+
+        if (!replicated) {
+          continue;
+        } else {
+          sleepMultiplier = Math.max(sleepMultiplier - 1, 0);
+        }
+
+        if (this.lastLoggedPosition != lastReadPosition) {
+          //Clean up hfile references
+          int size = entries.size();
+          for (int i = 0; i < size; i++) {
+            cleanUpHFileRefs(entries.get(i).getEdit());
+          }
+
+          // Save positions to meta table before zk.
+          updateSerialRepPositions(entryBatch.getLastSeqIds());
+          //Log and clean up WAL logs
+          updateLogPosition(lastReadPosition);
+        }
+
+        if (source.getThrottler().isEnabled()) {
+          source.getThrottler().addPushSize(currentSize);
+        }
+
+        source.addTotalReplicatedEdits(entries.size());
+        // FIXME check relationship between wal group and overall
+        source.getSourceMetrics().shipBatch(entryBatch.getNbOperations(), currentSize, entryBatch.getNbHFiles());
+        source.getSourceMetrics().setAgeOfLastShippedOp(entries.get(entries.size() - 1).getKey().getWriteTime(),
+          walGroupId);
+        if (LOG.isTraceEnabled()) {
+          LOG.trace("Replicated " + entries.size() + " entries or " + entryBatch.getNbOperations()
+              + " operations in " + ((endTimeNs - startTimeNs) / 1000000) + " ms");
+        }
+        break;
+      } catch (Exception ex) {
+        LOG.warn(source.getReplicationEndpoint().getClass().getName() + " threw unknown exception:"
+            + org.apache.hadoop.util.StringUtils.stringifyException(ex));
+        if (source.sleepForRetries("ReplicationEndpoint threw exception", sleepMultiplier)) {
+          sleepMultiplier++;
+        }
+      }
+    }
+  }
+
+  private void waitingUntilCanPush(Map.Entry<String, Long> entry) {
+    String key = entry.getKey();
+    long seq = entry.getValue();
+    boolean deleteKey = false;
+    if (seq <= 0) {
+      // There is a REGION_CLOSE marker, we can not continue skipping after this entry.
+      deleteKey = true;
+      seq = -seq;
+    }
+
+    if (!canSkipWaitingSet.getUnchecked(key)) {
+      try {
+        source.getSourceManager().waitUntilCanBePushed(Bytes.toBytes(key), seq, source.getPeerId());
+      } catch (IOException e) {
+        LOG.error("waitUntilCanBePushed fail", e);
+        throw new RuntimeException("waitUntilCanBePushed fail");
+      } catch (InterruptedException e) {
+        LOG.warn("waitUntilCanBePushed interrupted", e);
+        Thread.currentThread().interrupt();
+      }
+      canSkipWaitingSet.put(key, true);
+    }
+    if (deleteKey) {
+      canSkipWaitingSet.invalidate(key);
+    }
+  }
+
+  private void cleanUpHFileRefs(WALEdit edit) throws IOException {
+    String peerId = source.getPeerId();
+    if (peerId.contains("-")) {
+      // peerClusterZnode will be in the form peerId + "-" + rsZNode.
+      // A peerId will not have "-" in its name, see HBASE-11394
+      peerId = peerId.split("-")[0];
+    }
+    List<Cell> cells = edit.getCells();
+    int totalCells = cells.size();
+    for (int i = 0; i < totalCells; i++) {
+      Cell cell = cells.get(i);
+      if (CellUtil.matchingQualifier(cell, WALEdit.BULK_LOAD)) {
+        BulkLoadDescriptor bld = WALEdit.getBulkLoadDescriptor(cell);
+        List<StoreDescriptor> stores = bld.getStoresList();
+        int totalStores = stores.size();
+        for (int j = 0; j < totalStores; j++) {
+          List<String> storeFileList = stores.get(j).getStoreFileList();
+          source.getSourceManager().cleanUpHFileRefs(peerId, storeFileList);
+          source.getSourceMetrics().decrSizeOfHFileRefsQueue(storeFileList.size());
+        }
+      }
+    }
+  }
+
+  protected void updateLogPosition(long lastReadPosition) {
+    source.getSourceManager().logPositionAndCleanOldLogs(currentPath, source.getPeerClusterZnode(),
+      lastReadPosition, false, false);
+    lastLoggedPosition = lastReadPosition;
+  }
+
+  private void updateSerialRepPositions(Map<String, Long> lastPositionsForSerialScope) {
+    try {
+      MetaTableAccessor.updateReplicationPositions(source.getSourceManager().getConnection(),
+        source.getPeerId(), lastPositionsForSerialScope);
+    } catch (IOException e) {
+      LOG.error("updateReplicationPositions fail", e);
+      throw new RuntimeException("updateReplicationPositions fail");
+    }
+  }
+
+  public void startup(UncaughtExceptionHandler handler) {
+    String name = Thread.currentThread().getName();
+    Threads.setDaemonThreadRunning(this, name + ".replicationSource." + walGroupId + ","
+        + source.getPeerClusterZnode(), handler);
+  }
+
+  public PriorityBlockingQueue<Path> getLogQueue() {
+    return this.queue;
+  }
+
+  public Path getCurrentPath() {
+    return this.currentPath;
+  }
+
+  public long getCurrentPosition() {
+    return this.lastLoggedPosition;
+  }
+
+  public void setWALReader(ReplicationSourceWALReaderThread entryReader) {
+    this.entryReader = entryReader;
+  }
+
+  public long getStartPosition() {
+    return 0;
+  }
+
+  protected boolean isActive() {
+    return source.isSourceActive() && workerRunning && !isInterrupted();
+  }
+
+  public void setWorkerRunning(boolean workerRunning) {
+    entryReader.setReaderRunning(workerRunning);
+    this.workerRunning = workerRunning;
+  }
+}
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceWALReaderThread.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceWALReaderThread.java
index 29808e9..ad08866 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceWALReaderThread.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceWALReaderThread.java
@@ -41,6 +41,7 @@ import org.apache.hadoop.hbase.classification.InterfaceStability;
 import org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos;
 import org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor;
 import org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor;
+import org.apache.hadoop.hbase.regionserver.RSRpcServices;
 import org.apache.hadoop.hbase.regionserver.wal.WALEdit;
 import org.apache.hadoop.hbase.replication.ReplicationQueueInfo;
 import org.apache.hadoop.hbase.replication.WALEntryFilter;
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/ReplicationSourceDummy.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/ReplicationSourceDummy.java
index 57e54d7..3c4888b 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/ReplicationSourceDummy.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/ReplicationSourceDummy.java
@@ -19,6 +19,7 @@
 package org.apache.hadoop.hbase.replication;
 
 import java.io.IOException;
+import java.lang.Thread.UncaughtExceptionHandler;
 import java.util.List;
 import java.util.UUID;
 
@@ -30,6 +31,7 @@ import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.replication.regionserver.MetricsSource;
 import org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceInterface;
 import org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager;
+import org.apache.hadoop.hbase.replication.regionserver.ReplicationThrottler;
 import org.apache.hadoop.hbase.util.Pair;
 
 /**
@@ -82,7 +84,7 @@ public class ReplicationSourceDummy implements ReplicationSourceInterface {
   }
 
   @Override
-  public String getPeerClusterId() {
+  public String getPeerId() {
     String[] parts = peerClusterId.split("-", 2);
     return parts.length != 1 ?
         parts[0] : peerClusterId;
@@ -98,4 +100,70 @@ public class ReplicationSourceDummy implements ReplicationSourceInterface {
       throws ReplicationException {
     return;
   }
+
+  @Override
+  public boolean isPeerEnabled() {
+    return true;
+  }
+
+  @Override
+  public boolean isSourceActive() {
+    return true;
+  }
+
+  @Override
+  public MetricsSource getSourceMetrics() {
+    // TODO Auto-generated method stub
+    return null;
+  }
+
+  @Override
+  public ReplicationThrottler getThrottler() {
+    // TODO Auto-generated method stub
+    return null;
+  }
+
+  @Override
+  public ReplicationEndpoint getReplicationEndpoint() {
+    // TODO Auto-generated method stub
+    return null;
+  }
+
+  @Override
+  public ReplicationSourceManager getSourceManager() {
+    return manager;
+  }
+
+  @Override
+  public ReplicationQueues getReplicationQueues() {
+    // TODO Auto-generated method stub
+    return null;
+  }
+
+  @Override
+  public UncaughtExceptionHandler getUncaughtExceptionHandler() {
+    // TODO Auto-generated method stub
+    return null;
+  }
+
+  @Override
+  public boolean sleepForRetries(String msg, int sleepMultiplier) {
+    // TODO Auto-generated method stub
+    return false;
+  }
+
+  @Override
+  public void tryThrottle(int batchSize) throws InterruptedException {
+    // TODO Auto-generated method stub
+  }
+
+  @Override
+  public void releaseBufferQuota(int size) {
+    // TODO Auto-generated method stub
+  }
+
+  @Override
+  public void addTotalReplicatedEdits(int size) {
+    // TODO Auto-generated method stub
+  }
 }
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestReplicationSourceManager.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestReplicationSourceManager.java
index 026f8e4..26aee6d 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestReplicationSourceManager.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestReplicationSourceManager.java
@@ -462,7 +462,7 @@ public abstract class TestReplicationSourceManager {
       // Make sure that the replication source was not initialized
       List<ReplicationSourceInterface> sources = manager.getSources();
       for (ReplicationSourceInterface source : sources) {
-        assertNotEquals("FakePeer", source.getPeerClusterId());
+        assertNotEquals("FakePeer", source.getPeerId());
       }
 
       // Create a replication queue for the fake peer
-- 
1.9.1
