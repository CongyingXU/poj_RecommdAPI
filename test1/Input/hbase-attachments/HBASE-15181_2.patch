From 86942b96c0a7fef006f35208c1f7144b1a4efd9e Mon Sep 17 00:00:00 2001
From: Clara <claraxiong@flurry.com>
Date: Tue, 1 Mar 2016 12:31:02 -0800
Subject: [PATCH] HBASE-15181-0.98-ADD

---
 .../compactions/DateTieredCompactionPolicy.java           | 15 ++++++++++-----
 .../hadoop/hbase/regionserver/TestCompactionPolicy.java   |  4 ++--
 2 files changed, 12 insertions(+), 7 deletions(-)

diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/DateTieredCompactionPolicy.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/DateTieredCompactionPolicy.java
index b0c7c26..ba72658 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/DateTieredCompactionPolicy.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/DateTieredCompactionPolicy.java
@@ -117,9 +117,6 @@ public class DateTieredCompactionPolicy extends RatioBasedCompactionPolicy {
   @VisibleForTesting
   public ArrayList<StoreFile> applyCompactionPolicy(ArrayList<StoreFile> candidates,
       boolean mayUseOffPeak, boolean mayBeStuck, long now) throws IOException {
-    // This might throw late arriving data out and create a sequence id gap?
-    // How can we filter bulk load file without this problem?
-    // For bulk load seq id[, what if we use creation time?
     Iterable<StoreFile> candidatesInWindow =
       filterOldStoreFiles(Lists.newArrayList(candidates), comConf.getMaxStoreFileAgeMillis(), now);
 
@@ -127,7 +124,14 @@ public class DateTieredCompactionPolicy extends RatioBasedCompactionPolicy {
         partitionFilesToBuckets(candidatesInWindow, comConf.getBaseWindowMillis(),
           comConf.getWindowsPerTier(), now);
     LOG.debug("Compaction buckets are: " + buckets);
-
+    if (buckets.size() >= storeConfigInfo.getBlockingFileCount()) {
+      LOG.warn("Number of compaction buckets:" +  buckets.size()
+        + ", exceeds blocking file count setting: "
+        + storeConfigInfo.getBlockingFileCount()
+        + ", either increase hbase.hstore.blockingStoreFiles or "
+        + "reduce the number of tiered compaction windows");
+    }
+    
     return newestBucket(buckets, comConf.getIncomingWindowMin(), now, comConf.getBaseWindowMillis(),
       mayUseOffPeak);
   }
@@ -221,8 +225,9 @@ public class DateTieredCompactionPolicy extends RatioBasedCompactionPolicy {
     return Iterables.filter(storeFiles, new Predicate<StoreFile>() {
       @Override
       public boolean apply(StoreFile storeFile) {
+        // This is for findbugs' issue with Guava. We know this won't happen.
         if (storeFile == null) {
-          throw new NullPointerException();
+          return false;
         }
         return storeFile.getMaximumTimestamp() >= cutoff;
       }
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompactionPolicy.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompactionPolicy.java
index 436a7ed..902457f 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompactionPolicy.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompactionPolicy.java
@@ -52,13 +52,13 @@ import com.google.common.collect.Lists;
 @Category(SmallTests.class)
 public class TestCompactionPolicy
 {
-    private final static Log LOG = LogFactory.getLog(TestDefaultCompactSelection.class);
+    private final static Log LOG = LogFactory.getLog(TestCompactionPolicy.class);
     protected final static HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility();
 
     protected Configuration conf;
     protected HStore store;
     private static final String DIR=
-      TEST_UTIL.getDataTestDir(TestDefaultCompactSelection.class.getSimpleName()).toString();
+      TEST_UTIL.getDataTestDir(TestCompactionPolicy.class.getSimpleName()).toString();
     protected static Path TEST_FILE;
 
     protected static final int minFiles = 3;
-- 
1.9.3 (Apple Git-50)

