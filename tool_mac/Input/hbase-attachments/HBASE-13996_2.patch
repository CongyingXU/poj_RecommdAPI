diff --git hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java
index 3e4d35b..18f7f82 100644
--- hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java
+++ hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java
@@ -24,6 +24,7 @@ import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Map;
@@ -47,9 +48,12 @@ import org.apache.hadoop.hbase.ChoreService;
 import org.apache.hadoop.hbase.DoNotRetryIOException;
 import org.apache.hadoop.hbase.HBaseConfiguration;
 import org.apache.hadoop.hbase.HColumnDescriptor;
+import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.HRegionInfo;
 import org.apache.hadoop.hbase.HRegionLocation;
 import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.MetaTableAccessor;
+import org.apache.hadoop.hbase.NamespaceDescriptor;
 import org.apache.hadoop.hbase.ScheduledChore;
 import org.apache.hadoop.hbase.ServerName;
 import org.apache.hadoop.hbase.TableName;
@@ -59,12 +63,17 @@ import org.apache.hadoop.hbase.client.Admin;
 import org.apache.hadoop.hbase.client.Connection;
 import org.apache.hadoop.hbase.client.ConnectionFactory;
 import org.apache.hadoop.hbase.client.Get;
+import org.apache.hadoop.hbase.client.Put;
 import org.apache.hadoop.hbase.client.RegionLocator;
 import org.apache.hadoop.hbase.client.ResultScanner;
 import org.apache.hadoop.hbase.client.Scan;
 import org.apache.hadoop.hbase.client.Table;
 import org.apache.hadoop.hbase.filter.FirstKeyOnlyFilter;
+import org.apache.hadoop.hbase.tool.Canary.RegionTask.TaskType;
+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;
+import org.apache.hadoop.hbase.util.Pair;
 import org.apache.hadoop.hbase.util.ReflectionUtils;
+import org.apache.hadoop.hbase.util.RegionSplitter;
 import org.apache.hadoop.util.Tool;
 import org.apache.hadoop.util.ToolRunner;
 
@@ -85,6 +94,9 @@ public final class Canary implements Tool {
     public void publishReadFailure(HRegionInfo region, Exception e);
     public void publishReadFailure(HRegionInfo region, HColumnDescriptor column, Exception e);
     public void publishReadTiming(HRegionInfo region, HColumnDescriptor column, long msTime);
+    public void publishWriteFailure(HRegionInfo region, Exception e);
+    public void publishWriteFailure(HRegionInfo region, HColumnDescriptor column, Exception e);
+    public void publishWriteTiming(HRegionInfo region, HColumnDescriptor column, long msTime);
   }
   // new extended sink for output regionserver mode info
   // do not change the Sink interface directly due to maintaining the API
@@ -112,6 +124,23 @@ public final class Canary implements Tool {
       LOG.info(String.format("read from region %s column family %s in %dms",
                region.getRegionNameAsString(), column.getNameAsString(), msTime));
     }
+
+    @Override
+    public void publishWriteFailure(HRegionInfo region, Exception e) {
+      LOG.error(String.format("write to region %s failed", region.getRegionNameAsString()), e);
+    }
+
+    @Override
+    public void publishWriteFailure(HRegionInfo region, HColumnDescriptor column, Exception e) {
+      LOG.error(String.format("write to region %s column family %s failed",
+        region.getRegionNameAsString(), column.getNameAsString()), e);
+    }
+
+    @Override
+    public void publishWriteTiming(HRegionInfo region, HColumnDescriptor column, long msTime) {
+      LOG.info(String.format("write to region %s column family %s in %dms",
+        region.getRegionNameAsString(), column.getNameAsString(), msTime));
+    }
   }
   // a ExtendedSink implementation
   public static class RegionServerStdOutSink extends StdOutSink implements ExtendedSink {
@@ -133,18 +162,34 @@ public final class Canary implements Tool {
    * failure.
    */
   static class RegionTask implements Callable<Void> {
+    public enum TaskType{
+      READ, WRITE
+    }
     private Connection connection;
     private HRegionInfo region;
     private Sink sink;
+    private TaskType taskType;
 
-    RegionTask(Connection connection, HRegionInfo region, Sink sink) {
+    RegionTask(Connection connection, HRegionInfo region, Sink sink, TaskType taskType) {
       this.connection = connection;
       this.region = region;
       this.sink = sink;
+      this.taskType = taskType;
     }
 
     @Override
     public Void call() {
+      switch (taskType) {
+      case READ:
+        return read();
+      case WRITE:
+        return write();
+      default:
+        return read();
+      }
+    }
+
+    public Void read() {
       Table table = null;
       HTableDescriptor tableDesc = null;
       try {
@@ -215,6 +260,39 @@ public final class Canary implements Tool {
       }
       return null;
     }
+
+    /**
+     * Check writes for the canary table
+     * @return
+     */
+    private Void write() {
+      Table table = null;
+      HTableDescriptor tableDesc = null;
+      try {
+        table = connection.getTable(region.getTable());
+        tableDesc = table.getTableDescriptor();
+        byte[] rowToCheck = region.getStartKey();
+        if (rowToCheck.length == 0) {
+          rowToCheck = new byte[]{0x0};
+        }
+        for (HColumnDescriptor column : tableDesc.getColumnFamilies()) {
+          Put put = new Put(rowToCheck);
+          put.addColumn(column.getName(), HConstants.EMPTY_BYTE_ARRAY, HConstants.EMPTY_BYTE_ARRAY);
+          try {
+            long startTime = System.currentTimeMillis();
+            table.put(put);
+            long time = System.currentTimeMillis() - startTime;
+            sink.publishWriteTiming(region, column, time);
+          } catch (Exception e) {
+            sink.publishWriteFailure(region, column, e);
+          }
+        }
+        table.close();
+      } catch (IOException e) {
+        sink.publishWriteFailure(region, e);
+      }
+      return null;
+    }
   }
 
   /**
@@ -307,6 +385,11 @@ public final class Canary implements Tool {
 
   private static final Log LOG = LogFactory.getLog(Canary.class);
 
+  private static final TableName CANARY_TABLE_NAME = TableName.valueOf(
+    NamespaceDescriptor.SYSTEM_NAMESPACE_NAME_STR, "canary");
+  private static final String CANARY_TABLE_FAMILY_NAME = "Test";
+  private static int DEFAULT_REGIONS_PER_SERVER = 3;
+
   private Configuration conf = null;
   private long interval = 0;
   private Sink sink = null;
@@ -586,6 +669,7 @@ public final class Canary implements Tool {
 
   // a monitor for region mode
   private static class RegionMonitor extends Monitor {
+    private long lastCheckTime = -1;
 
     public RegionMonitor(Connection connection, String[] monitorTargets, boolean useRegExp,
         Sink sink, ExecutorService executor) {
@@ -595,17 +679,30 @@ public final class Canary implements Tool {
     @Override
     public void run() {
       if (this.initAdmin()) {
+        // check canary distribution for every 10 minutes
+        if (EnvironmentEdgeManager.currentTime() - lastCheckTime > 10 * 60 * 1000) {
+          try {
+            checkCanaryTableDistribution();
+          } catch (IOException e) {
+            LOG.error("Check canary table distribution failed!", e);
+          }
+          lastCheckTime = EnvironmentEdgeManager.currentTime();
+        }
+
         try {
           List<Future<Void>> taskFutures = new LinkedList<Future<Void>>();
           if (this.targets != null && this.targets.length > 0) {
             String[] tables = generateMonitorTables(this.targets);
             this.initialized = true;
             for (String table : tables) {
-              taskFutures.addAll(Canary.sniff(admin, sink, table, executor));
+              taskFutures.addAll(Canary.sniff(admin, sink, table, executor, TaskType.READ));
             }
           } else {
-            taskFutures.addAll(sniff());
+            taskFutures.addAll(sniff(TaskType.READ));
           }
+          // sniff canary table with write operation
+          taskFutures.addAll(Canary.sniff(admin, sink, admin.getTableDescriptor(CANARY_TABLE_NAME),
+            executor, TaskType.WRITE));
           for (Future<Void> future : taskFutures) {
             try {
               future.get();
@@ -661,25 +758,86 @@ public final class Canary implements Tool {
     /*
      * canary entry point to monitor all the tables.
      */
-    private List<Future<Void>> sniff() throws Exception {
+    private List<Future<Void>> sniff(TaskType taskType) throws Exception {
       List<Future<Void>> taskFutures = new LinkedList<Future<Void>>();
       for (HTableDescriptor table : admin.listTables()) {
-        if (admin.isTableEnabled(table.getTableName())) {
-          taskFutures.addAll(Canary.sniff(admin, sink, table, executor));
+        if (admin.isTableEnabled(table.getTableName())
+            && (!table.getTableName().equals(CANARY_TABLE_NAME))) {
+          taskFutures.addAll(Canary.sniff(admin, sink, table, executor, taskType));
         }
       }
       return taskFutures;
     }
+
+    private void checkCanaryTableDistribution() throws IOException {
+      if (!admin.tableExists(CANARY_TABLE_NAME)) {
+        int numberOfServers = admin.getClusterStatus().getServers().size();
+        if (numberOfServers == 0) {
+          throw new IllegalStateException("No live regionservers");
+        }
+        createCanaryTable(numberOfServers);
+      }
+
+      if (!admin.isTableEnabled(CANARY_TABLE_NAME)) {
+        admin.enableTable(CANARY_TABLE_NAME);
+      }
+
+      int numberOfServers = admin.getClusterStatus().getServers().size();
+      List<Pair<HRegionInfo, ServerName>> pairs =
+          MetaTableAccessor.getTableRegionsAndLocations(connection, CANARY_TABLE_NAME);
+      int numberOfRegions = pairs.size();
+      if (numberOfServers < numberOfRegions * DEFAULT_REGIONS_PER_SERVER * 0.7
+          || numberOfServers > numberOfRegions * DEFAULT_REGIONS_PER_SERVER * 1.5) {
+        admin.disableTable(CANARY_TABLE_NAME);
+        admin.deleteTable(CANARY_TABLE_NAME);
+        createCanaryTable(numberOfServers);
+      }
+      HashSet<ServerName> serverSet = new HashSet<ServerName>();
+      for (Pair<HRegionInfo, ServerName> pair : pairs) {
+        serverSet.add(pair.getSecond());
+      }
+      int numberOfCoveredServers = serverSet.size();
+      if (numberOfCoveredServers < numberOfServers) {
+        admin.balancer();
+      }
+    }
+
+    private void createCanaryTable(int numberOfServers) throws IOException {
+      int totalNumberOfRegions = numberOfServers * DEFAULT_REGIONS_PER_SERVER;
+      LOG.info("Number of live regionservers: " + numberOfServers + ", "
+          + "pre-splitting the canary table into " + totalNumberOfRegions + " regions "
+          + "(default regions per server: " + DEFAULT_REGIONS_PER_SERVER + ")");
+
+      HTableDescriptor desc = new HTableDescriptor(CANARY_TABLE_NAME);
+      HColumnDescriptor family = new HColumnDescriptor(CANARY_TABLE_FAMILY_NAME);
+      family.setMaxVersions(1);
+      // set data TTL = 1day
+      family.setTimeToLive(24 * 60 * 60 * 1000);
+
+      desc.addFamily(family);
+      byte[][] splits = new RegionSplitter.HexStringSplit().split(totalNumberOfRegions);
+      admin.createTable(desc, splits);
+    }
   }
 
   /**
    * Canary entry point for specified table.
    * @throws Exception
    */
-  public static void sniff(final Admin admin, TableName tableName) throws Exception {
+  public static void sniff(final Admin admin, TableName tableName)
+      throws Exception {
+    sniff(admin, tableName, TaskType.READ);
+  }
+
+  /**
+   * Canary entry point for specified table with task type(read/write)
+   * @throws Exception
+   */
+  public static void sniff(final Admin admin, TableName tableName, TaskType taskType)
+      throws Exception {
     List<Future<Void>> taskFutures =
         Canary.sniff(admin, new StdOutSink(), tableName.getNameAsString(),
-          new ScheduledThreadPoolExecutor(1));
+          new ScheduledThreadPoolExecutor(1), taskType);
     for (Future<Void> future : taskFutures) {
       future.get();
     }
@@ -690,10 +848,10 @@ public final class Canary implements Tool {
    * @throws Exception
    */
   private static List<Future<Void>> sniff(final Admin admin, final Sink sink, String tableName,
-      ExecutorService executor) throws Exception {
+      ExecutorService executor, TaskType taskType) throws Exception {
     if (admin.isTableEnabled(TableName.valueOf(tableName))) {
       return Canary.sniff(admin, sink, admin.getTableDescriptor(TableName.valueOf(tableName)),
-        executor);
+        executor, taskType);
     } else {
       LOG.warn(String.format("Table %s is not enabled", tableName));
     }
@@ -704,7 +862,7 @@ public final class Canary implements Tool {
    * Loops over regions that owns this table, and output some information abouts the state.
    */
   private static List<Future<Void>> sniff(final Admin admin, final Sink sink,
-      HTableDescriptor tableDesc, ExecutorService executor) throws Exception {
+      HTableDescriptor tableDesc, ExecutorService executor, TaskType taskType) throws Exception {
     Table table = null;
     try {
       table = admin.getConnection().getTable(tableDesc.getTableName());
@@ -714,7 +872,7 @@ public final class Canary implements Tool {
     List<RegionTask> tasks = new ArrayList<RegionTask>();
     try {
       for (HRegionInfo region : admin.getTableRegions(tableDesc.getTableName())) {
-        tasks.add(new RegionTask(admin.getConnection(), region, sink));
+        tasks.add(new RegionTask(admin.getConnection(), region, sink, taskType));
       }
     } finally {
       table.close();
