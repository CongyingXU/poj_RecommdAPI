 .../org/apache/hadoop/hbase/HColumnDescriptor.java | 47 +----------
 .../org/apache/hadoop/hbase/HTableDescriptor.java  | 55 ++----------
 .../hbase/client/ConnectionImplementation.java     |  2 +-
 .../org/apache/hadoop/hbase/client/HBaseAdmin.java |  4 +-
 .../apache/hadoop/hbase/protobuf/ProtobufUtil.java | 98 +++++++++++++++++++++-
 .../hadoop/hbase/protobuf/RequestConverter.java    | 12 ++-
 .../org/apache/hadoop/hbase/TableDescriptor.java   |  6 +-
 .../mapreduce/TableSnapshotInputFormatImpl.java    |  6 +-
 .../hadoop/hbase/master/MasterRpcServices.java     | 14 ++--
 .../master/procedure/AddColumnFamilyProcedure.java | 11 ++-
 .../master/procedure/CreateTableProcedure.java     |  7 +-
 .../procedure/DeleteColumnFamilyProcedure.java     |  6 +-
 .../procedure/ModifyColumnFamilyProcedure.java     | 11 ++-
 .../master/procedure/ModifyTableProcedure.java     | 13 ++-
 .../master/procedure/TruncateTableProcedure.java   |  6 +-
 .../hadoop/hbase/snapshot/SnapshotManifest.java    |  5 +-
 .../hbase/snapshot/TestSnapshotManifest.java       |  5 +-
 17 files changed, 176 insertions(+), 132 deletions(-)

diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java
index 2c10308..6b3df7d 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java
@@ -1075,8 +1075,9 @@ public class HColumnDescriptor implements Comparable<HColumnDescriptor> {
    * @return This instance serialized with pb with pb magic prefix
    * @see #parseFrom(byte[])
    */
-  public byte [] toByteArray() {
-    return ProtobufUtil.prependPBMagic(convert().toByteArray());
+  public byte[] toByteArray() {
+    return ProtobufUtil.prependPBMagic(ProtobufUtil
+        .convertToColumnFamilySchema(getName(), getValues(), getConfiguration()).toByteArray());
   }
 
   /**
@@ -1096,47 +1097,7 @@ public class HColumnDescriptor implements Comparable<HColumnDescriptor> {
     } catch (IOException e) {
       throw new DeserializationException(e);
     }
-    return convert(cfs);
-  }
-
-  /**
-   * @param cfs
-   * @return An {@link HColumnDescriptor} made from the passed in <code>cfs</code>
-   */
-  public static HColumnDescriptor convert(final ColumnFamilySchema cfs) {
-    // Use the empty constructor so we preserve the initial values set on construction for things
-    // like maxVersion.  Otherwise, we pick up wrong values on deserialization which makes for
-    // unrelated-looking test failures that are hard to trace back to here.
-    HColumnDescriptor hcd = new HColumnDescriptor();
-    hcd.name = cfs.getName().toByteArray();
-    for (BytesBytesPair a: cfs.getAttributesList()) {
-      hcd.setValue(a.getFirst().toByteArray(), a.getSecond().toByteArray());
-    }
-    for (NameStringPair a: cfs.getConfigurationList()) {
-      hcd.setConfiguration(a.getName(), a.getValue());
-    }
-    return hcd;
-  }
-
-  /**
-   * @return Convert this instance to a the pb column family type
-   */
-  public ColumnFamilySchema convert() {
-    ColumnFamilySchema.Builder builder = ColumnFamilySchema.newBuilder();
-    builder.setName(ByteStringer.wrap(getName()));
-    for (Map.Entry<Bytes, Bytes> e : this.values.entrySet()) {
-      BytesBytesPair.Builder aBuilder = BytesBytesPair.newBuilder();
-      aBuilder.setFirst(ByteStringer.wrap(e.getKey().get()));
-      aBuilder.setSecond(ByteStringer.wrap(e.getValue().get()));
-      builder.addAttributes(aBuilder.build());
-    }
-    for (Map.Entry<String, String> e : this.configuration.entrySet()) {
-      NameStringPair.Builder aBuilder = NameStringPair.newBuilder();
-      aBuilder.setName(e.getKey());
-      aBuilder.setValue(e.getValue());
-      builder.addConfiguration(aBuilder.build());
-    }
-    return builder.build();
+    return ProtobufUtil.convert(cfs);
   }
 
   /**
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java
index 1bd4e07..9019fc5 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java
@@ -1519,8 +1519,10 @@ public class HTableDescriptor implements Comparable<HTableDescriptor> {
    * @return This instance serialized with pb with pb magic prefix
    * @see #parseFrom(byte[])
    */
-  public byte [] toByteArray() {
-    return ProtobufUtil.prependPBMagic(convert().toByteArray());
+  public byte[] toByteArray() {
+    return ProtobufUtil.prependPBMagic(ProtobufUtil
+        .convertToTableSchema(getTableName(), getColumnFamilies(), values, getConfiguration())
+        .toByteArray());
   }
 
   /**
@@ -1544,54 +1546,7 @@ public class HTableDescriptor implements Comparable<HTableDescriptor> {
     } catch (IOException e) {
       throw new DeserializationException(e);
     }
-    return convert(ts);
-  }
-
-  /**
-   * @return Convert the current {@link HTableDescriptor} into a pb TableSchema instance.
-   */
-  public TableSchema convert() {
-    TableSchema.Builder builder = TableSchema.newBuilder();
-    builder.setTableName(ProtobufUtil.toProtoTableName(getTableName()));
-    for (Map.Entry<Bytes, Bytes> e : this.values.entrySet()) {
-      BytesBytesPair.Builder aBuilder = BytesBytesPair.newBuilder();
-      aBuilder.setFirst(ByteStringer.wrap(e.getKey().get()));
-      aBuilder.setSecond(ByteStringer.wrap(e.getValue().get()));
-      builder.addAttributes(aBuilder.build());
-    }
-    for (HColumnDescriptor hcd: getColumnFamilies()) {
-      builder.addColumnFamilies(hcd.convert());
-    }
-    for (Map.Entry<String, String> e : this.configuration.entrySet()) {
-      NameStringPair.Builder aBuilder = NameStringPair.newBuilder();
-      aBuilder.setName(e.getKey());
-      aBuilder.setValue(e.getValue());
-      builder.addConfiguration(aBuilder.build());
-    }
-    return builder.build();
-  }
-
-  /**
-   * @param ts A pb TableSchema instance.
-   * @return An {@link HTableDescriptor} made from the passed in pb <code>ts</code>.
-   */
-  public static HTableDescriptor convert(final TableSchema ts) {
-    List<ColumnFamilySchema> list = ts.getColumnFamiliesList();
-    HColumnDescriptor [] hcds = new HColumnDescriptor[list.size()];
-    int index = 0;
-    for (ColumnFamilySchema cfs: list) {
-      hcds[index++] = HColumnDescriptor.convert(cfs);
-    }
-    HTableDescriptor htd = new HTableDescriptor(
-        ProtobufUtil.toTableName(ts.getTableName()),
-        hcds);
-    for (BytesBytesPair a: ts.getAttributesList()) {
-      htd.setValue(a.getFirst().toByteArray(), a.getSecond().toByteArray());
-    }
-    for (NameStringPair a: ts.getConfigurationList()) {
-      htd.setConfiguration(a.getName(), a.getValue());
-    }
-    return htd;
+    return ProtobufUtil.convert(ts);
   }
 
   /**
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ConnectionImplementation.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ConnectionImplementation.java
index ecaf18b..1b49fc5 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ConnectionImplementation.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ConnectionImplementation.java
@@ -2248,7 +2248,7 @@ class ConnectionImplementation implements ClusterConnection, Closeable {
       master.close();
     }
     if (!htds.getTableSchemaList().isEmpty()) {
-      return HTableDescriptor.convert(htds.getTableSchemaList().get(0));
+      return ProtobufUtil.convert(htds.getTableSchemaList().get(0));
     }
     throw new TableNotFoundException(tableName.getNameAsString());
   }
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
index c1d07ae..2863376 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java
@@ -422,7 +422,7 @@ public class HBaseAdmin implements Admin {
           htds = master.getTableDescriptors(controller, req);
 
           if (!htds.getTableSchemaList().isEmpty()) {
-            return HTableDescriptor.convert(htds.getTableSchemaList().get(0));
+            return ProtobufUtil.convert(htds.getTableSchemaList().get(0));
           }
           return null;
         }
@@ -2076,7 +2076,7 @@ public class HBaseAdmin implements Admin {
             HTableDescriptor[] res = new HTableDescriptor[list.size()];
             for(int i=0; i < list.size(); i++) {
 
-              res[i] = HTableDescriptor.convert(list.get(i));
+              res[i] = ProtobufUtil.convert(list.get(i));
             }
             return res;
           }
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java
index f9fa21c..f60c4e3 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java
@@ -59,6 +59,7 @@ import org.apache.hadoop.hbase.CellScanner;
 import org.apache.hadoop.hbase.CellUtil;
 import org.apache.hadoop.hbase.DoNotRetryIOException;
 import org.apache.hadoop.hbase.HBaseConfiguration;
+import org.apache.hadoop.hbase.HColumnDescriptor;
 import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.HRegionInfo;
 import org.apache.hadoop.hbase.HTableDescriptor;
@@ -126,9 +127,13 @@ import org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad
 import org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos;
 import org.apache.hadoop.hbase.protobuf.generated.FilterProtos;
 import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos;
+import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair;
+import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema;
 import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair;
+import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair;
 import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo;
 import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier;
+import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema;
 import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.RegionSpecifierType;
 import org.apache.hadoop.hbase.protobuf.generated.MapReduceProtos;
 import org.apache.hadoop.hbase.protobuf.generated.MasterProtos;
@@ -394,7 +399,7 @@ public final class ProtobufUtil {
 
     HTableDescriptor[] ret = new HTableDescriptor[proto.getTableSchemaCount()];
     for (int i = 0; i < proto.getTableSchemaCount(); ++i) {
-      ret[i] = HTableDescriptor.convert(proto.getTableSchema(i));
+      ret[i] = convert(proto.getTableSchema(i));
     }
     return ret;
   }
@@ -3313,4 +3318,95 @@ public final class ProtobufUtil {
         .addAllServers(hostports)
         .addAllTables(tables).build();
   }
+
+  /**
+   * @return Convert this instance to a the pb column family type
+   */
+  public static ColumnFamilySchema convertToColumnFamilySchema(byte[] name, Map<Bytes, Bytes> values,
+      Map<String, String> conf) {
+    ColumnFamilySchema.Builder builder = ColumnFamilySchema.newBuilder();
+    builder.setName(ByteStringer.wrap(name));
+    for (Map.Entry<Bytes, Bytes> e : values.entrySet()) {
+      BytesBytesPair.Builder aBuilder = BytesBytesPair.newBuilder();
+      aBuilder.setFirst(ByteStringer.wrap(e.getKey().get()));
+      aBuilder.setSecond(ByteStringer.wrap(e.getValue().get()));
+      builder.addAttributes(aBuilder.build());
+    }
+    for (Map.Entry<String, String> e : conf.entrySet()) {
+      NameStringPair.Builder aBuilder = NameStringPair.newBuilder();
+      aBuilder.setName(e.getKey());
+      aBuilder.setValue(e.getValue());
+      builder.addConfiguration(aBuilder.build());
+    }
+    return builder.build();
+  }
+
+  /**
+   * @param cfs
+   * @return An {@link HColumnDescriptor} made from the passed in <code>cfs</code>
+   */
+  public static HColumnDescriptor convert(final ColumnFamilySchema cfs) {
+    // Use the empty constructor so we preserve the initial values set on construction for things
+    // like maxVersion.  Otherwise, we pick up wrong values on deserialization which makes for
+    // unrelated-looking test failures that are hard to trace back to here.
+    // TODO : See if this creates issues. Else we are screwed
+    HColumnDescriptor hcd = new HColumnDescriptor(cfs.getName().toByteArray());
+    for (BytesBytesPair a: cfs.getAttributesList()) {
+      hcd.setValue(a.getFirst().toByteArray(), a.getSecond().toByteArray());
+    }
+    for (NameStringPair a: cfs.getConfigurationList()) {
+      hcd.setConfiguration(a.getName(), a.getValue());
+    }
+    return hcd;
+  }
+
+  /**
+   * @return Convert the current {@link HTableDescriptor} into a pb TableSchema instance.
+   */
+  public static TableSchema convertToTableSchema(TableName tableName, HColumnDescriptor[] hcds,
+      Map<Bytes, Bytes> values, Map<String, String> conf) {
+    TableSchema.Builder builder = TableSchema.newBuilder();
+    builder.setTableName(ProtobufUtil.toProtoTableName(tableName));
+    for (Map.Entry<Bytes, Bytes> e : values.entrySet()) {
+      BytesBytesPair.Builder aBuilder = BytesBytesPair.newBuilder();
+      aBuilder.setFirst(ByteStringer.wrap(e.getKey().get()));
+      aBuilder.setSecond(ByteStringer.wrap(e.getValue().get()));
+      builder.addAttributes(aBuilder.build());
+    }
+    for (HColumnDescriptor hcd : hcds) {
+      builder.addColumnFamilies(ProtobufUtil.convertToColumnFamilySchema(hcd.getName(),
+        hcd.getValues(), hcd.getConfiguration()));
+    }
+    for (Map.Entry<String, String> e : conf.entrySet()) {
+      NameStringPair.Builder aBuilder = NameStringPair.newBuilder();
+      aBuilder.setName(e.getKey());
+      aBuilder.setValue(e.getValue());
+      builder.addConfiguration(aBuilder.build());
+    }
+    return builder.build();
+  }
+
+  /**
+   * @param ts A pb TableSchema instance.
+   * @return An {@link HTableDescriptor} made from the passed in pb <code>ts</code>.
+   */
+  public static HTableDescriptor convert(final TableSchema ts) {
+    List<ColumnFamilySchema> list = ts.getColumnFamiliesList();
+    HColumnDescriptor [] hcds = new HColumnDescriptor[list.size()];
+    int index = 0;
+    for (ColumnFamilySchema cfs: list) {
+      hcds[index++] = ProtobufUtil.convert(cfs);
+    }
+    HTableDescriptor htd = new HTableDescriptor(ProtobufUtil.toTableName(ts.getTableName()));
+    for (HColumnDescriptor hcd : hcds) {
+      htd.addFamily(hcd);
+    }
+    for (BytesBytesPair a: ts.getAttributesList()) {
+      htd.setValue(a.getFirst().toByteArray(), a.getSecond().toByteArray());
+    }
+    for (NameStringPair a: ts.getConfigurationList()) {
+      htd.setConfiguration(a.getName(), a.getValue());
+    }
+    return htd;
+  }
 }
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java
index 99e993d..8350896 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java
@@ -1034,7 +1034,8 @@ public final class RequestConverter {
       final long nonce) {
     AddColumnRequest.Builder builder = AddColumnRequest.newBuilder();
     builder.setTableName(ProtobufUtil.toProtoTableName(tableName));
-    builder.setColumnFamilies(column.convert());
+    builder.setColumnFamilies(ProtobufUtil.convertToColumnFamilySchema(column.getName(),
+      column.getValues(), column.getConfiguration()));
     builder.setNonceGroup(nonceGroup);
     builder.setNonce(nonce);
     return builder.build();
@@ -1074,7 +1075,8 @@ public final class RequestConverter {
       final long nonce) {
     ModifyColumnRequest.Builder builder = ModifyColumnRequest.newBuilder();
     builder.setTableName(ProtobufUtil.toProtoTableName((tableName)));
-    builder.setColumnFamilies(column.convert());
+    builder.setColumnFamilies(ProtobufUtil.convertToColumnFamilySchema(column.getName(),
+      column.getValues(), column.getConfiguration()));
     builder.setNonceGroup(nonceGroup);
     builder.setNonce(nonce);
     return builder.build();
@@ -1236,7 +1238,8 @@ public final class RequestConverter {
       final long nonceGroup,
       final long nonce) {
     CreateTableRequest.Builder builder = CreateTableRequest.newBuilder();
-    builder.setTableSchema(hTableDesc.convert());
+    builder.setTableSchema(ProtobufUtil.convertToTableSchema(hTableDesc.getTableName(),
+      hTableDesc.getColumnFamilies(), hTableDesc.getValues(), hTableDesc.getConfiguration()));
     if (splitKeys != null) {
       for (byte [] splitKey : splitKeys) {
         builder.addSplitKeys(ByteStringer.wrap(splitKey));
@@ -1262,7 +1265,8 @@ public final class RequestConverter {
       final long nonce) {
     ModifyTableRequest.Builder builder = ModifyTableRequest.newBuilder();
     builder.setTableName(ProtobufUtil.toProtoTableName((tableName)));
-    builder.setTableSchema(hTableDesc.convert());
+    builder.setTableSchema(ProtobufUtil.convertToTableSchema(hTableDesc.getTableName(),
+      hTableDesc.getColumnFamilies(), hTableDesc.getValues(), hTableDesc.getConfiguration()));
     builder.setNonceGroup(nonceGroup);
     builder.setNonce(nonce);
     return builder.build();
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/TableDescriptor.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/TableDescriptor.java
index 3c6553c..6af357c 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/TableDescriptor.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/TableDescriptor.java
@@ -61,7 +61,9 @@ public class TableDescriptor {
   @SuppressWarnings("deprecation")
   public HBaseProtos.TableDescriptor convert() {
     HBaseProtos.TableDescriptor.Builder builder = HBaseProtos.TableDescriptor.newBuilder()
-        .setSchema(hTableDescriptor.convert());
+        .setSchema(ProtobufUtil.convertToTableSchema(hTableDescriptor.getTableName(),
+          hTableDescriptor.getColumnFamilies(), hTableDescriptor.getValues(),
+          hTableDescriptor.getConfiguration()));
     return builder.build();
   }
 
@@ -69,7 +71,7 @@ public class TableDescriptor {
    * Convert from PB
    */
   public static TableDescriptor convert(HBaseProtos.TableDescriptor proto) {
-    return new TableDescriptor(HTableDescriptor.convert(proto.getSchema()));
+    return new TableDescriptor(ProtobufUtil.convert(proto.getSchema()));
   }
 
   /**
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormatImpl.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormatImpl.java
index 1dfbfd3..5a4dda0 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormatImpl.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormatImpl.java
@@ -36,6 +36,7 @@ import org.apache.hadoop.hbase.client.IsolationLevel;
 import org.apache.hadoop.hbase.client.Result;
 import org.apache.hadoop.hbase.client.Scan;
 import org.apache.hadoop.hbase.io.ImmutableBytesWritable;
+import org.apache.hadoop.hbase.protobuf.ProtobufUtil;
 import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription;
 import org.apache.hadoop.hbase.protobuf.generated.MapReduceProtos.TableSnapshotRegionSplit;
 import org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos.SnapshotRegionManifest;
@@ -141,7 +142,8 @@ public class TableSnapshotInputFormatImpl {
     @Override
     public void write(DataOutput out) throws IOException {
       TableSnapshotRegionSplit.Builder builder = TableSnapshotRegionSplit.newBuilder()
-          .setTable(htd.convert())
+          .setTable(ProtobufUtil.convertToTableSchema(htd.getTableName(), htd.getColumnFamilies(),
+            htd.getValues(), htd.getConfiguration()))
           .setRegion(HRegionInfo.convert(regionInfo));
 
       for (String location : locations) {
@@ -168,7 +170,7 @@ public class TableSnapshotInputFormatImpl {
       byte[] buf = new byte[len];
       in.readFully(buf);
       TableSnapshotRegionSplit split = TableSnapshotRegionSplit.PARSER.parseFrom(buf);
-      this.htd = HTableDescriptor.convert(split.getTable());
+      this.htd = ProtobufUtil.convert(split.getTable());
       this.regionInfo = HRegionInfo.convert(split.getRegion());
       List<String> locationsList = split.getLocationsList();
       this.locations = locationsList.toArray(new String[locationsList.size()]);
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterRpcServices.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterRpcServices.java
index 6a60c2c..af73905 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterRpcServices.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterRpcServices.java
@@ -298,7 +298,7 @@ public class MasterRpcServices extends RSRpcServices
     try {
       long procId = master.addColumn(
           ProtobufUtil.toTableName(req.getTableName()),
-          HColumnDescriptor.convert(req.getColumnFamilies()),
+          ProtobufUtil.convert(req.getColumnFamilies()),
           req.getNonceGroup(),
           req.getNonce());
       if (procId == -1) {
@@ -373,7 +373,7 @@ public class MasterRpcServices extends RSRpcServices
   @Override
   public CreateTableResponse createTable(RpcController controller, CreateTableRequest req)
   throws ServiceException {
-    HTableDescriptor hTableDescriptor = HTableDescriptor.convert(req.getTableSchema());
+    HTableDescriptor hTableDescriptor = ProtobufUtil.convert(req.getTableSchema());
     byte [][] splitKeys = ProtobufUtil.getSplitKeysArray(req);
     try {
       long procId =
@@ -807,7 +807,8 @@ public class MasterRpcServices extends RSRpcServices
       if (descriptors != null && descriptors.size() > 0) {
         // Add the table descriptors to the response
         for (HTableDescriptor htd: descriptors) {
-          builder.addTableSchema(htd.convert());
+          builder.addTableSchema(ProtobufUtil.convertToTableSchema(htd.getTableName(),
+            htd.getColumnFamilies(), htd.getValues(), htd.getConfiguration()));
         }
       }
       return builder.build();
@@ -1059,7 +1060,8 @@ public class MasterRpcServices extends RSRpcServices
           ListTableDescriptorsByNamespaceResponse.newBuilder();
       for (HTableDescriptor htd : master
           .listTableDescriptorsByNamespace(request.getNamespaceName())) {
-        b.addTableSchema(htd.convert());
+        b.addTableSchema(ProtobufUtil.convertToTableSchema(htd.getTableName(),
+          htd.getColumnFamilies(), htd.getValues(), htd.getConfiguration()));
       }
       return b.build();
     } catch (IOException e) {
@@ -1088,7 +1090,7 @@ public class MasterRpcServices extends RSRpcServices
     try {
       long procId = master.modifyColumn(
         ProtobufUtil.toTableName(req.getTableName()),
-        HColumnDescriptor.convert(req.getColumnFamilies()),
+        ProtobufUtil.convert(req.getColumnFamilies()),
         req.getNonceGroup(),
         req.getNonce());
       if (procId == -1) {
@@ -1122,7 +1124,7 @@ public class MasterRpcServices extends RSRpcServices
     try {
       long procId = master.modifyTable(
         ProtobufUtil.toTableName(req.getTableName()),
-        HTableDescriptor.convert(req.getTableSchema()),
+        ProtobufUtil.convert(req.getTableSchema()),
         req.getNonceGroup(),
         req.getNonce());
       return ModifyTableResponse.newBuilder().setProcId(procId).build();
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/AddColumnFamilyProcedure.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/AddColumnFamilyProcedure.java
index a58355b..75f520f 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/AddColumnFamilyProcedure.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/AddColumnFamilyProcedure.java
@@ -201,9 +201,12 @@ public class AddColumnFamilyProcedure
         MasterProcedureProtos.AddColumnFamilyStateData.newBuilder()
             .setUserInfo(MasterProcedureUtil.toProtoUserInfo(user))
             .setTableName(ProtobufUtil.toProtoTableName(tableName))
-            .setColumnfamilySchema(cfDescriptor.convert());
+            .setColumnfamilySchema(ProtobufUtil.convertToColumnFamilySchema(cfDescriptor.getName(),
+              cfDescriptor.getValues(), cfDescriptor.getConfiguration()));
     if (unmodifiedHTableDescriptor != null) {
-      addCFMsg.setUnmodifiedTableSchema(unmodifiedHTableDescriptor.convert());
+      addCFMsg.setUnmodifiedTableSchema(ProtobufUtil.convertToTableSchema(
+        unmodifiedHTableDescriptor.getTableName(), unmodifiedHTableDescriptor.getColumnFamilies(),
+        unmodifiedHTableDescriptor.getValues(), unmodifiedHTableDescriptor.getConfiguration()));
     }
 
     addCFMsg.build().writeDelimitedTo(stream);
@@ -217,9 +220,9 @@ public class AddColumnFamilyProcedure
         MasterProcedureProtos.AddColumnFamilyStateData.parseDelimitedFrom(stream);
     user = MasterProcedureUtil.toUserInfo(addCFMsg.getUserInfo());
     tableName = ProtobufUtil.toTableName(addCFMsg.getTableName());
-    cfDescriptor = HColumnDescriptor.convert(addCFMsg.getColumnfamilySchema());
+    cfDescriptor = ProtobufUtil.convert(addCFMsg.getColumnfamilySchema());
     if (addCFMsg.hasUnmodifiedTableSchema()) {
-      unmodifiedHTableDescriptor = HTableDescriptor.convert(addCFMsg.getUnmodifiedTableSchema());
+      unmodifiedHTableDescriptor = ProtobufUtil.convert(addCFMsg.getUnmodifiedTableSchema());
     }
   }
 
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/CreateTableProcedure.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/CreateTableProcedure.java
index 8ce8335..32dd83a 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/CreateTableProcedure.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/CreateTableProcedure.java
@@ -44,6 +44,7 @@ import org.apache.hadoop.hbase.master.AssignmentManager;
 import org.apache.hadoop.hbase.master.MasterCoprocessorHost;
 import org.apache.hadoop.hbase.master.MasterFileSystem;
 import org.apache.hadoop.hbase.procedure2.StateMachineProcedure;
+import org.apache.hadoop.hbase.protobuf.ProtobufUtil;
 import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos;
 import org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos;
 import org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableState;
@@ -238,7 +239,9 @@ public class CreateTableProcedure
     MasterProcedureProtos.CreateTableStateData.Builder state =
       MasterProcedureProtos.CreateTableStateData.newBuilder()
         .setUserInfo(MasterProcedureUtil.toProtoUserInfo(this.user))
-        .setTableSchema(hTableDescriptor.convert());
+            .setTableSchema(ProtobufUtil.convertToTableSchema(hTableDescriptor.getTableName(),
+              hTableDescriptor.getColumnFamilies(), hTableDescriptor.getValues(),
+              hTableDescriptor.getConfiguration()));
     if (newRegions != null) {
       for (HRegionInfo hri: newRegions) {
         state.addRegionInfo(HRegionInfo.convert(hri));
@@ -254,7 +257,7 @@ public class CreateTableProcedure
     MasterProcedureProtos.CreateTableStateData state =
       MasterProcedureProtos.CreateTableStateData.parseDelimitedFrom(stream);
     user = MasterProcedureUtil.toUserInfo(state.getUserInfo());
-    hTableDescriptor = HTableDescriptor.convert(state.getTableSchema());
+    hTableDescriptor = ProtobufUtil.convert(state.getTableSchema());
     if (state.getRegionInfoCount() == 0) {
       newRegions = null;
     } else {
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/DeleteColumnFamilyProcedure.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/DeleteColumnFamilyProcedure.java
index 2e36f17..447a68b 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/DeleteColumnFamilyProcedure.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/DeleteColumnFamilyProcedure.java
@@ -220,7 +220,9 @@ public class DeleteColumnFamilyProcedure
             .setTableName(ProtobufUtil.toProtoTableName(tableName))
             .setColumnfamilyName(ByteStringer.wrap(familyName));
     if (unmodifiedHTableDescriptor != null) {
-      deleteCFMsg.setUnmodifiedTableSchema(unmodifiedHTableDescriptor.convert());
+      deleteCFMsg.setUnmodifiedTableSchema(ProtobufUtil.convertToTableSchema(
+        unmodifiedHTableDescriptor.getTableName(), unmodifiedHTableDescriptor.getColumnFamilies(),
+        unmodifiedHTableDescriptor.getValues(), unmodifiedHTableDescriptor.getConfiguration()));
     }
 
     deleteCFMsg.build().writeDelimitedTo(stream);
@@ -236,7 +238,7 @@ public class DeleteColumnFamilyProcedure
     familyName = deleteCFMsg.getColumnfamilyName().toByteArray();
 
     if (deleteCFMsg.hasUnmodifiedTableSchema()) {
-      unmodifiedHTableDescriptor = HTableDescriptor.convert(deleteCFMsg.getUnmodifiedTableSchema());
+      unmodifiedHTableDescriptor = ProtobufUtil.convert(deleteCFMsg.getUnmodifiedTableSchema());
     }
   }
 
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/ModifyColumnFamilyProcedure.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/ModifyColumnFamilyProcedure.java
index 28a5066..dc41374 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/ModifyColumnFamilyProcedure.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/ModifyColumnFamilyProcedure.java
@@ -198,9 +198,12 @@ public class ModifyColumnFamilyProcedure
         MasterProcedureProtos.ModifyColumnFamilyStateData.newBuilder()
             .setUserInfo(MasterProcedureUtil.toProtoUserInfo(user))
             .setTableName(ProtobufUtil.toProtoTableName(tableName))
-            .setColumnfamilySchema(cfDescriptor.convert());
+            .setColumnfamilySchema(ProtobufUtil.convertToColumnFamilySchema(cfDescriptor.getName(),
+              cfDescriptor.getValues(), cfDescriptor.getConfiguration()));
     if (unmodifiedHTableDescriptor != null) {
-      modifyCFMsg.setUnmodifiedTableSchema(unmodifiedHTableDescriptor.convert());
+      modifyCFMsg.setUnmodifiedTableSchema(ProtobufUtil.convertToTableSchema(
+        unmodifiedHTableDescriptor.getTableName(), unmodifiedHTableDescriptor.getColumnFamilies(),
+        unmodifiedHTableDescriptor.getValues(), unmodifiedHTableDescriptor.getConfiguration()));
     }
 
     modifyCFMsg.build().writeDelimitedTo(stream);
@@ -214,9 +217,9 @@ public class ModifyColumnFamilyProcedure
         MasterProcedureProtos.ModifyColumnFamilyStateData.parseDelimitedFrom(stream);
     user = MasterProcedureUtil.toUserInfo(modifyCFMsg.getUserInfo());
     tableName = ProtobufUtil.toTableName(modifyCFMsg.getTableName());
-    cfDescriptor = HColumnDescriptor.convert(modifyCFMsg.getColumnfamilySchema());
+    cfDescriptor = ProtobufUtil.convert(modifyCFMsg.getColumnfamilySchema());
     if (modifyCFMsg.hasUnmodifiedTableSchema()) {
-      unmodifiedHTableDescriptor = HTableDescriptor.convert(modifyCFMsg.getUnmodifiedTableSchema());
+      unmodifiedHTableDescriptor = ProtobufUtil.convert(modifyCFMsg.getUnmodifiedTableSchema());
     }
   }
 
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/ModifyTableProcedure.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/ModifyTableProcedure.java
index bd1451a..037023c 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/ModifyTableProcedure.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/ModifyTableProcedure.java
@@ -46,6 +46,7 @@ import org.apache.hadoop.hbase.client.Table;
 import org.apache.hadoop.hbase.client.TableState;
 import org.apache.hadoop.hbase.master.MasterCoprocessorHost;
 import org.apache.hadoop.hbase.procedure2.StateMachineProcedure;
+import org.apache.hadoop.hbase.protobuf.ProtobufUtil;
 import org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos;
 import org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableState;
 import org.apache.hadoop.hbase.util.ServerRegionReplicaUtil;
@@ -231,11 +232,15 @@ public class ModifyTableProcedure
     MasterProcedureProtos.ModifyTableStateData.Builder modifyTableMsg =
         MasterProcedureProtos.ModifyTableStateData.newBuilder()
             .setUserInfo(MasterProcedureUtil.toProtoUserInfo(user))
-            .setModifiedTableSchema(modifiedHTableDescriptor.convert())
+            .setModifiedTableSchema(ProtobufUtil.convertToTableSchema(
+              modifiedHTableDescriptor.getTableName(), modifiedHTableDescriptor.getColumnFamilies(),
+              modifiedHTableDescriptor.getValues(), modifiedHTableDescriptor.getConfiguration()))
             .setDeleteColumnFamilyInModify(deleteColumnFamilyInModify);
 
     if (unmodifiedHTableDescriptor != null) {
-      modifyTableMsg.setUnmodifiedTableSchema(unmodifiedHTableDescriptor.convert());
+      modifyTableMsg.setUnmodifiedTableSchema(ProtobufUtil.convertToTableSchema(
+        unmodifiedHTableDescriptor.getTableName(), unmodifiedHTableDescriptor.getColumnFamilies(),
+        unmodifiedHTableDescriptor.getValues(), unmodifiedHTableDescriptor.getConfiguration()));
     }
 
     modifyTableMsg.build().writeDelimitedTo(stream);
@@ -248,12 +253,12 @@ public class ModifyTableProcedure
     MasterProcedureProtos.ModifyTableStateData modifyTableMsg =
         MasterProcedureProtos.ModifyTableStateData.parseDelimitedFrom(stream);
     user = MasterProcedureUtil.toUserInfo(modifyTableMsg.getUserInfo());
-    modifiedHTableDescriptor = HTableDescriptor.convert(modifyTableMsg.getModifiedTableSchema());
+    modifiedHTableDescriptor = ProtobufUtil.convert(modifyTableMsg.getModifiedTableSchema());
     deleteColumnFamilyInModify = modifyTableMsg.getDeleteColumnFamilyInModify();
 
     if (modifyTableMsg.hasUnmodifiedTableSchema()) {
       unmodifiedHTableDescriptor =
-          HTableDescriptor.convert(modifyTableMsg.getUnmodifiedTableSchema());
+          ProtobufUtil.convert(modifyTableMsg.getUnmodifiedTableSchema());
     }
   }
 
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/TruncateTableProcedure.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/TruncateTableProcedure.java
index a2ced47..9ca4bc7 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/TruncateTableProcedure.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/TruncateTableProcedure.java
@@ -210,7 +210,9 @@ public class TruncateTableProcedure
         .setUserInfo(MasterProcedureUtil.toProtoUserInfo(this.user))
         .setPreserveSplits(preserveSplits);
     if (hTableDescriptor != null) {
-      state.setTableSchema(hTableDescriptor.convert());
+      state.setTableSchema(ProtobufUtil.convertToTableSchema(hTableDescriptor.getTableName(),
+        hTableDescriptor.getColumnFamilies(), hTableDescriptor.getValues(),
+        hTableDescriptor.getConfiguration()));
     } else {
       state.setTableName(ProtobufUtil.toProtoTableName(tableName));
     }
@@ -230,7 +232,7 @@ public class TruncateTableProcedure
       MasterProcedureProtos.TruncateTableStateData.parseDelimitedFrom(stream);
     user = MasterProcedureUtil.toUserInfo(state.getUserInfo());
     if (state.hasTableSchema()) {
-      hTableDescriptor = HTableDescriptor.convert(state.getTableSchema());
+      hTableDescriptor = ProtobufUtil.convert(state.getTableSchema());
       tableName = hTableDescriptor.getTableName();
     } else {
       tableName = ProtobufUtil.toTableName(state.getTableName());
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotManifest.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotManifest.java
index 82460a2..df6412e 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotManifest.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotManifest.java
@@ -360,7 +360,7 @@ public final class SnapshotManifest {
       case SnapshotManifestV2.DESCRIPTOR_VERSION: {
         SnapshotDataManifest dataManifest = readDataManifest();
         if (dataManifest != null) {
-          htd = HTableDescriptor.convert(dataManifest.getTableSchema());
+          htd = ProtobufUtil.convert(dataManifest.getTableSchema());
           regionManifests = dataManifest.getRegionManifestsList();
         } else {
           // Compatibility, load the v1 regions
@@ -465,7 +465,8 @@ public final class SnapshotManifest {
     }
 
     SnapshotDataManifest.Builder dataManifestBuilder = SnapshotDataManifest.newBuilder();
-    dataManifestBuilder.setTableSchema(htd.convert());
+    dataManifestBuilder.setTableSchema(ProtobufUtil.convertToTableSchema(htd.getTableName(),
+      htd.getColumnFamilies(), htd.getValues(), htd.getConfiguration()));
 
     if (v1Regions != null && v1Regions.size() > 0) {
       dataManifestBuilder.addAllRegionManifests(v1Regions);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestSnapshotManifest.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestSnapshotManifest.java
index 870bfd9..9e17429 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestSnapshotManifest.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/snapshot/TestSnapshotManifest.java
@@ -28,6 +28,7 @@ import org.apache.hadoop.hbase.HColumnDescriptor;
 import org.apache.hadoop.hbase.HRegionInfo;
 import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.HBaseTestingUtility;
+import org.apache.hadoop.hbase.protobuf.ProtobufUtil;
 import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription;
 import org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos.SnapshotDataManifest;
 import org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos.SnapshotRegionManifest;
@@ -104,7 +105,9 @@ public class TestSnapshotManifest {
       startKey = stopKey;
     }
 
-    dataManifestBuilder.setTableSchema(builder.getTableDescriptor().convert());
+    dataManifestBuilder.setTableSchema(ProtobufUtil.convertToTableSchema(
+      builder.getTableDescriptor().getTableName(), builder.getTableDescriptor().getColumnFamilies(),
+      builder.getTableDescriptor().getValues(), builder.getTableDescriptor().getConfiguration()));
 
     SnapshotDataManifest dataManifest = dataManifestBuilder.build();
     writeDataManifest(dataManifest);
