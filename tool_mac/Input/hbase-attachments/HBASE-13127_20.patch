diff --git a/hbase-client/src/test/java/org/apache/hadoop/hbase/TestHColumnDescriptor.java b/hbase-client/src/test/java/org/apache/hadoop/hbase/TestHColumnDescriptor.java
index 976876cf..58188d6 100644
--- a/hbase-client/src/test/java/org/apache/hadoop/hbase/TestHColumnDescriptor.java
+++ b/hbase-client/src/test/java/org/apache/hadoop/hbase/TestHColumnDescriptor.java
@@ -34,7 +34,7 @@ import org.junit.experimental.categories.Category;
 /** Tests the HColumnDescriptor with appropriate arguments */
 @Category({MiscTests.class, SmallTests.class})
 public class TestHColumnDescriptor {
-  @Test
+  @Test (timeout=180000)
   public void testPb() throws DeserializationException {
     HColumnDescriptor hcd = new HColumnDescriptor(
         new HColumnDescriptor(HConstants.CATALOG_FAMILY)
@@ -76,7 +76,7 @@ public class TestHColumnDescriptor {
     assertTrue(deserializedHcd.getBloomFilterType().equals(BloomType.ROW));
   }
 
-  @Test
+  @Test (timeout=180000)
   /** Tests HColumnDescriptor with empty familyName*/
   public void testHColumnDescriptorShouldThrowIAEWhenFamiliyNameEmpty()
       throws Exception {
@@ -90,7 +90,7 @@ public class TestHColumnDescriptor {
   /**
    * Test that we add and remove strings from configuration properly.
    */
-  @Test
+  @Test (timeout=180000)
   public void testAddGetRemoveConfiguration() throws Exception {
     HColumnDescriptor desc = new HColumnDescriptor("foo");
     String key = "Some";
@@ -101,7 +101,7 @@ public class TestHColumnDescriptor {
     assertEquals(null, desc.getConfigurationValue(key));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testClassMethodsAreBuilderStyle() {
     /* HColumnDescriptor should have a builder style setup where setXXX/addXXX methods
      * can be chainable together:
diff --git a/hbase-client/src/test/java/org/apache/hadoop/hbase/TestHTableDescriptor.java b/hbase-client/src/test/java/org/apache/hadoop/hbase/TestHTableDescriptor.java
index 43d9411..491ebc4 100644
--- a/hbase-client/src/test/java/org/apache/hadoop/hbase/TestHTableDescriptor.java
+++ b/hbase-client/src/test/java/org/apache/hadoop/hbase/TestHTableDescriptor.java
@@ -43,7 +43,7 @@ import org.junit.experimental.categories.Category;
 public class TestHTableDescriptor {
   final static Log LOG = LogFactory.getLog(TestHTableDescriptor.class);
 
-  @Test
+  @Test (timeout=180000)
   public void testPb() throws DeserializationException, IOException {
     HTableDescriptor htd = new HTableDescriptor(TableName.META_TABLE_NAME);
     final int v = 123;
@@ -64,7 +64,7 @@ public class TestHTableDescriptor {
    * Test cps in the table description
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   public void testGetSetRemoveCP() throws Exception {
     HTableDescriptor desc = new HTableDescriptor(TableName.valueOf("table"));
     // simple CP
@@ -81,7 +81,7 @@ public class TestHTableDescriptor {
    * Test cps in the table description
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   public void testSetListRemoveCP() throws Exception {
     HTableDescriptor desc = new HTableDescriptor(TableName.valueOf("testGetSetRemoveCP"));
     // simple CP
@@ -118,7 +118,7 @@ public class TestHTableDescriptor {
    * Test that we add and remove strings from settings properly.
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   public void testRemoveString() throws Exception {
     HTableDescriptor desc = new HTableDescriptor(TableName.valueOf("table"));
     String key = "Some";
@@ -137,14 +137,14 @@ public class TestHTableDescriptor {
       "-dash-.start_illegal", "new.table with space", "01 .table", "ns:-illegaldash",
       "new:.illegaldot", "new:illegalcolon1:", "new:illegalcolon1:2"};
 
-  @Test
+  @Test (timeout=180000)
   public void testLegalHTableNames() {
     for (String tn : legalTableNames) {
       TableName.isLegalFullyQualifiedTableName(Bytes.toBytes(tn));
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testIllegalHTableNames() {
     for (String tn : illegalTableNames) {
       try {
@@ -156,7 +156,7 @@ public class TestHTableDescriptor {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testLegalHTableNamesRegex() {
     for (String tn : legalTableNames) {
       TableName tName = TableName.valueOf(tn);
@@ -165,7 +165,7 @@ public class TestHTableDescriptor {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testIllegalHTableNamesRegex() {
     for (String tn : illegalTableNames) {
       LOG.info("Testing: '" + tn + "'");
@@ -176,7 +176,7 @@ public class TestHTableDescriptor {
     /**
    * Test default value handling for maxFileSize
    */
-  @Test
+  @Test (timeout=180000)
   public void testGetMaxFileSize() {
     HTableDescriptor desc = new HTableDescriptor(TableName.valueOf("table"));
     assertEquals(-1, desc.getMaxFileSize());
@@ -187,7 +187,7 @@ public class TestHTableDescriptor {
   /**
    * Test default value handling for memStoreFlushSize
    */
-  @Test
+  @Test (timeout=180000)
   public void testGetMemStoreFlushSize() {
     HTableDescriptor desc = new HTableDescriptor(TableName.valueOf("table"));
     assertEquals(-1, desc.getMemStoreFlushSize());
@@ -198,7 +198,7 @@ public class TestHTableDescriptor {
   /**
    * Test that we add and remove strings from configuration properly.
    */
-  @Test
+  @Test (timeout=180000)
   public void testAddGetRemoveConfiguration() throws Exception {
     HTableDescriptor desc = new HTableDescriptor(TableName.valueOf("table"));
     String key = "Some";
@@ -209,7 +209,7 @@ public class TestHTableDescriptor {
     assertEquals(null, desc.getConfigurationValue(key));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testClassMethodsAreBuilderStyle() {
     /* HTableDescriptor should have a builder style setup where setXXX/addXXX methods
      * can be chainable together:
@@ -226,7 +226,7 @@ public class TestHTableDescriptor {
     BuilderStyleTest.assertClassesAreBuilderStyle(HTableDescriptor.class);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testModifyFamily() {
     HTableDescriptor htd = new HTableDescriptor(TableName.valueOf("table"));
     byte[] familyName = Bytes.toBytes("cf");
diff --git a/hbase-client/src/test/java/org/apache/hadoop/hbase/TestInterfaceAudienceAnnotations.java b/hbase-client/src/test/java/org/apache/hadoop/hbase/TestInterfaceAudienceAnnotations.java
index ace11ec..2f1c3a3 100644
--- a/hbase-client/src/test/java/org/apache/hadoop/hbase/TestInterfaceAudienceAnnotations.java
+++ b/hbase-client/src/test/java/org/apache/hadoop/hbase/TestInterfaceAudienceAnnotations.java
@@ -202,7 +202,7 @@ public class TestInterfaceAudienceAnnotations {
    * Checks whether all the classes in client and common modules contain
    * {@link InterfaceAudience} annotations.
    */
-  @Test
+  @Test (timeout=180000)
   public void testInterfaceAudienceAnnotation()
       throws ClassNotFoundException, IOException, LinkageError {
 
@@ -237,7 +237,7 @@ public class TestInterfaceAudienceAnnotations {
    * Checks whether all the classes in client and common modules that are marked
    * InterfaceAudience.Public also have {@link InterfaceStability} annotations.
    */
-  @Test
+  @Test (timeout=180000)
   public void testInterfaceStabilityAnnotation()
       throws ClassNotFoundException, IOException, LinkageError {
 
diff --git a/hbase-client/src/test/java/org/apache/hadoop/hbase/TestRegionLocations.java b/hbase-client/src/test/java/org/apache/hadoop/hbase/TestRegionLocations.java
index dddfb82..2dcc4ba 100644
--- a/hbase-client/src/test/java/org/apache/hadoop/hbase/TestRegionLocations.java
+++ b/hbase-client/src/test/java/org/apache/hadoop/hbase/TestRegionLocations.java
@@ -45,7 +45,7 @@ public class TestRegionLocations {
   long regionId1 = 1000;
   long regionId2 = 2000;
 
-  @Test
+  @Test (timeout=180000)
   public void testSizeMethods() {
     RegionLocations list = new RegionLocations();
     assertTrue(list.isEmpty());
@@ -99,7 +99,7 @@ public class TestRegionLocations {
     return new RegionLocations(locations);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRemoveByServer() {
     RegionLocations list;
 
@@ -133,7 +133,7 @@ public class TestRegionLocations {
     assertNull(list.getRegionLocation(9));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRemove() {
     RegionLocations list;
 
@@ -175,7 +175,7 @@ public class TestRegionLocations {
     assertNull(list.getRegionLocation(9));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testUpdateLocation() {
     RegionLocations list;
 
@@ -211,7 +211,7 @@ public class TestRegionLocations {
     assertEquals(sn3, list.getRegionLocation(9).getServerName());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testMergeLocations() {
     RegionLocations list1, list2;
 
@@ -283,7 +283,7 @@ public class TestRegionLocations {
     assertEquals(sn3, list1.getRegionLocation(9).getServerName());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testMergeLocationsWithDifferentRegionId() {
     RegionLocations list1, list2;
 
@@ -310,7 +310,7 @@ public class TestRegionLocations {
     assertNull(list2.getRegionLocation(2));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testUpdateLocationWithDifferentRegionId() {
     RegionLocations list;
 
@@ -331,7 +331,7 @@ public class TestRegionLocations {
   }
 
 
-  @Test
+  @Test (timeout=180000)
   public void testConstructWithNullElements() {
     // RegionLocations can contain null elements as well. These null elements can
 
diff --git a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestAsyncProcess.java b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestAsyncProcess.java
index aa41939..c541558 100644
--- a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestAsyncProcess.java
+++ b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestAsyncProcess.java
@@ -385,7 +385,7 @@ public class TestAsyncProcess {
   @Rule
   public Timeout timeout = new Timeout(10000); // 10 seconds max per method tested
 
-  @Test
+  @Test (timeout=60000)
   public void testSubmit() throws Exception {
     ClusterConnection hc = createHConnection();
     AsyncProcess ap = new MyAsyncProcess(hc, conf);
@@ -397,7 +397,7 @@ public class TestAsyncProcess {
     Assert.assertTrue(puts.isEmpty());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSubmitWithCB() throws Exception {
     ClusterConnection hc = createHConnection();
     final AtomicInteger updateCalled = new AtomicInteger(0);
@@ -418,7 +418,7 @@ public class TestAsyncProcess {
     Assert.assertEquals(updateCalled.get(), 1);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSubmitBusyRegion() throws Exception {
     ClusterConnection hc = createHConnection();
     AsyncProcess ap = new MyAsyncProcess(hc, conf);
@@ -436,7 +436,7 @@ public class TestAsyncProcess {
   }
 
 
-  @Test
+  @Test (timeout=60000)
   public void testSubmitBusyRegionServer() throws Exception {
     ClusterConnection hc = createHConnection();
     AsyncProcess ap = new MyAsyncProcess(hc, conf);
@@ -457,7 +457,7 @@ public class TestAsyncProcess {
     Assert.assertTrue(puts.isEmpty());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testFail() throws Exception {
     MyAsyncProcess ap = new MyAsyncProcess(createHConnection(), conf, false);
 
@@ -483,7 +483,7 @@ public class TestAsyncProcess {
   }
 
 
-  @Test
+  @Test (timeout=60000)
   public void testSubmitTrue() throws IOException {
     final AsyncProcess ap = new MyAsyncProcess(createHConnection(), conf, false);
     ap.tasksInProgress.incrementAndGet();
@@ -522,7 +522,7 @@ public class TestAsyncProcess {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testFailAndSuccess() throws Exception {
     MyAsyncProcess ap = new MyAsyncProcess(createHConnection(), conf, false);
 
@@ -549,7 +549,7 @@ public class TestAsyncProcess {
     verifyResult(ars, true);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testFlush() throws Exception {
     MyAsyncProcess ap = new MyAsyncProcess(createHConnection(), conf, false);
 
@@ -566,7 +566,7 @@ public class TestAsyncProcess {
     Assert.assertEquals(1, ars.getFailedOperations().size());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMaxTask() throws Exception {
     final AsyncProcess ap = new MyAsyncProcess(createHConnection(), conf, false);
 
@@ -648,7 +648,7 @@ public class TestAsyncProcess {
     return hc;
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testHTablePutSuccess() throws Exception {
     BufferedMutatorImpl ht = Mockito.mock(BufferedMutatorImpl.class);
     ht.ap = new MyAsyncProcess(createHConnection(), conf, true);
@@ -697,17 +697,17 @@ public class TestAsyncProcess {
     ht.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testHTableFailedPutWithBuffer() throws Exception {
     doHTableFailedPut(true);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testHTableFailedPutWithoutBuffer() throws Exception {
     doHTableFailedPut(false);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testHTableFailedPutAndNewPut() throws Exception {
     ClusterConnection conn = createHConnection();
     BufferedMutatorImpl mutator = new BufferedMutatorImpl(conn, null, null,
@@ -737,7 +737,7 @@ public class TestAsyncProcess {
 
 
 /*
-  @Test
+  @Test (timeout=60000)
   public void testWithNoClearOnFail() throws IOException {
     HTable ht = new HTable();
     ht.ap = new MyAsyncProcess(createHConnection(), conf, true);
@@ -761,7 +761,7 @@ public class TestAsyncProcess {
   }
   */
 
-  @Test
+  @Test (timeout=60000)
   public void testBatch() throws IOException, InterruptedException {
     ClusterConnection conn = new MyConnectionImpl(conf);
     HTable ht = new HTable(conn, new BufferedMutatorParams(DUMMY_TABLE));
@@ -792,7 +792,7 @@ public class TestAsyncProcess {
     Assert.assertEquals(res[6], failure);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testErrorsServers() throws IOException {
     Configuration configuration = new Configuration(conf);
     ClusterConnection conn = new MyConnectionImpl(configuration);
@@ -819,7 +819,7 @@ public class TestAsyncProcess {
     Assert.assertEquals(NB_RETRIES + 1, ap.callsCt.get());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGlobalErrors() throws IOException {
     ClusterConnection conn = new MyConnectionImpl(conf);
     BufferedMutatorImpl mutator = (BufferedMutatorImpl) conn.getBufferedMutator(DUMMY_TABLE);
@@ -844,7 +844,7 @@ public class TestAsyncProcess {
    * This test simulates multiple regions on 2 servers. We should have 2 multi requests and
    *  2 threads: 1 per server, this whatever the number of regions.
    */
-  @Test
+  @Test (timeout=60000)
   public void testThreadCreation() throws Exception {
     final int NB_REGS = 100;
     List<HRegionLocation> hrls = new ArrayList<HRegionLocation>(NB_REGS);
@@ -877,7 +877,7 @@ public class TestAsyncProcess {
     Assert.assertEquals("nbReg=" + nbReg, nbReg, NB_REGS);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testReplicaReplicaSuccess() throws Exception {
     // Main call takes too long so replicas succeed, except for one region w/o replicas.
     // One region has no replica, so the main call succeeds for it.
@@ -888,7 +888,7 @@ public class TestAsyncProcess {
     Assert.assertEquals(2, ap.getReplicaCallCount());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testReplicaPrimarySuccessWoReplicaCalls() throws Exception {
     // Main call succeeds before replica calls are kicked off.
     MyAsyncProcessWithReplicas ap = createReplicaAp(1000, 10, 0);
@@ -898,7 +898,7 @@ public class TestAsyncProcess {
     Assert.assertEquals(0, ap.getReplicaCallCount());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testReplicaParallelCallsSucceed() throws Exception {
     // Either main or replica can succeed.
     MyAsyncProcessWithReplicas ap = createReplicaAp(0, 0, 0);
@@ -910,7 +910,7 @@ public class TestAsyncProcess {
     Assert.assertTrue(replicaCalls <= 2);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testReplicaPartialReplicaCall() throws Exception {
     // One server is slow, so the result for its region comes from replica, whereas
     // the result for other region comes from primary before replica calls happen.
@@ -923,7 +923,7 @@ public class TestAsyncProcess {
     Assert.assertEquals(1, ap.getReplicaCallCount());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testReplicaMainFailsBeforeReplicaCalls() throws Exception {
     // Main calls fail before replica calls can start - this is currently not handled.
     // It would probably never happen if we can get location (due to retries),
@@ -936,7 +936,7 @@ public class TestAsyncProcess {
     Assert.assertEquals(0, ap.getReplicaCallCount());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testReplicaReplicaSuccessWithParallelFailures() throws Exception {
     // Main calls fails after replica calls start. For two-replica region, one replica call
     // also fails. Regardless, we get replica results for both regions.
@@ -948,7 +948,7 @@ public class TestAsyncProcess {
     Assert.assertEquals(2, ap.getReplicaCallCount());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testReplicaAllCallsFailForOneRegion() throws Exception {
     // For one of the region, all 3, main and replica, calls fail. For the other, replica
     // call fails but its exception should not be visible as it did succeed.
diff --git a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestAttributes.java b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestAttributes.java
index 6656a83..4e7d3da 100644
--- a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestAttributes.java
+++ b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestAttributes.java
@@ -31,7 +31,7 @@ import org.junit.experimental.categories.Category;
 @Category({ClientTests.class, SmallTests.class})
 public class TestAttributes {
   private static final byte [] ROW = new byte [] {'r'};
-  @Test
+  @Test (timeout=180000)
   public void testPutAttributes() {
     Put put = new Put(ROW);
     Assert.assertTrue(put.getAttributesMap().isEmpty());
@@ -79,7 +79,7 @@ public class TestAttributes {
   }
 
 
-  @Test
+  @Test (timeout=180000)
   public void testDeleteAttributes() {
     Delete del = new Delete(new byte [] {'r'});
     Assert.assertTrue(del.getAttributesMap().isEmpty());
@@ -126,7 +126,7 @@ public class TestAttributes {
     Assert.assertNull(del.getAttributesMap().get("attribute1"));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testGetId() {
     Get get = new Get(ROW);
     Assert.assertNull("Make sure id is null if unset", get.toMap().get("id"));
@@ -134,7 +134,7 @@ public class TestAttributes {
     Assert.assertEquals("myId", get.toMap().get("id"));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testAppendId() {
     Append append = new Append(ROW);
     Assert.assertNull("Make sure id is null if unset", append.toMap().get("id"));
@@ -142,7 +142,7 @@ public class TestAttributes {
     Assert.assertEquals("myId", append.toMap().get("id"));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testDeleteId() {
     Delete delete = new Delete(ROW);
     Assert.assertNull("Make sure id is null if unset", delete.toMap().get("id"));
@@ -150,7 +150,7 @@ public class TestAttributes {
     Assert.assertEquals("myId", delete.toMap().get("id"));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testPutId() {
     Put put = new Put(ROW);
     Assert.assertNull("Make sure id is null if unset", put.toMap().get("id"));
@@ -158,7 +158,7 @@ public class TestAttributes {
     Assert.assertEquals("myId", put.toMap().get("id"));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testScanId() {
     Scan scan = new Scan();
     Assert.assertNull("Make sure id is null if unset", scan.toMap().get("id"));
diff --git a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestClientExponentialBackoff.java b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestClientExponentialBackoff.java
index 3a902d0..642e2e6 100644
--- a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestClientExponentialBackoff.java
+++ b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestClientExponentialBackoff.java
@@ -35,7 +35,7 @@ public class TestClientExponentialBackoff {
   ServerName server = Mockito.mock(ServerName.class);
   byte[] regionname = Bytes.toBytes("region");
 
-  @Test
+  @Test (timeout=60000)
   public void testNulls() {
     Configuration conf = new Configuration(false);
     ExponentialClientBackoffPolicy backoff = new ExponentialClientBackoffPolicy(conf);
@@ -50,7 +50,7 @@ public class TestClientExponentialBackoff {
     assertEquals(0, backoff.getBackoffTime(server, regionname, stats));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMaxLoad() {
     Configuration conf = new Configuration(false);
     ExponentialClientBackoffPolicy backoff = new ExponentialClientBackoffPolicy(conf);
@@ -83,7 +83,7 @@ public class TestClientExponentialBackoff {
    * Make sure that we get results in the order that we expect - backoff for a load of 1 should
    * less than backoff for 10, which should be less than that for 50.
    */
-  @Test
+  @Test (timeout=60000)
   public void testResultOrdering() {
     Configuration conf = new Configuration(false);
     // make the max timeout really high so we get differentiation between load factors
@@ -102,7 +102,7 @@ public class TestClientExponentialBackoff {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testHeapOccupancyPolicy() {
     Configuration conf = new Configuration(false);
     ExponentialClientBackoffPolicy backoff = new ExponentialClientBackoffPolicy(conf);
diff --git a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestClientNoCluster.java b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestClientNoCluster.java
index d155fd7..713ec86 100644
--- a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestClientNoCluster.java
+++ b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestClientNoCluster.java
@@ -140,7 +140,7 @@ public class TestClientNoCluster extends Configured implements Tool {
    * @throws IOException
    */
   @Ignore
-  @Test
+  @Test (timeout=180000)
   public void testTimeoutAndRetries() throws IOException {
     Configuration localConfig = HBaseConfiguration.create(this.conf);
     // This override mocks up our exists/get call to throw a RegionServerStoppedException.
@@ -171,7 +171,7 @@ public class TestClientNoCluster extends Configured implements Tool {
    * Test that operation timeout prevails over rpc default timeout and retries, etc.
    * @throws IOException
    */
-  @Test
+  @Test (timeout=180000)
   public void testRpcTimeout() throws IOException {
     Configuration localConfig = HBaseConfiguration.create(this.conf);
     // This override mocks up our exists/get call to throw a RegionServerStoppedException.
@@ -204,7 +204,7 @@ public class TestClientNoCluster extends Configured implements Tool {
     assertTrue(t != null);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testDoNotRetryMetaScanner() throws IOException {
     this.conf.set("hbase.client.connection.impl",
       RegionServerStoppedOnScannerOpenConnection.class.getName());
@@ -213,7 +213,7 @@ public class TestClientNoCluster extends Configured implements Tool {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testDoNotRetryOnScanNext() throws IOException {
     this.conf.set("hbase.client.connection.impl",
       RegionServerStoppedOnScannerOpenConnection.class.getName());
@@ -235,7 +235,7 @@ public class TestClientNoCluster extends Configured implements Tool {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRegionServerStoppedOnScannerOpen() throws IOException {
     this.conf.set("hbase.client.connection.impl",
       RegionServerStoppedOnScannerOpenConnection.class.getName());
diff --git a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestDelayingRunner.java b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestDelayingRunner.java
index 4348100..6202ca4 100644
--- a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestDelayingRunner.java
+++ b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestDelayingRunner.java
@@ -39,7 +39,7 @@ public class TestDelayingRunner {
       new HRegionInfo(DUMMY_TABLE, DUMMY_BYTES_1, DUMMY_BYTES_2, false, 1);
 
   @SuppressWarnings({ "rawtypes", "unchecked" })
-  @Test
+  @Test (timeout=180000)
   public void testDelayingRunner() throws Exception{
     MultiAction<Row> ma = new MultiAction<Row>();
     ma.add(hri1.getRegionName(), new Action<Row>(new Put(DUMMY_BYTES_1), 0));
diff --git a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestDeleteTimeStamp.java b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestDeleteTimeStamp.java
index e3582c1..748211b 100644
--- a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestDeleteTimeStamp.java
+++ b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestDeleteTimeStamp.java
@@ -33,7 +33,7 @@ public class TestDeleteTimeStamp {
    * Test for verifying that the timestamp in delete object is being honored.
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   public void testTimeStamp() {
     long ts = 2014L;
     Delete delete = new Delete(ROW);
diff --git a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestFastFailWithoutTestUtil.java b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestFastFailWithoutTestUtil.java
index e82e59d..2b0a616 100644
--- a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestFastFailWithoutTestUtil.java
+++ b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestFastFailWithoutTestUtil.java
@@ -56,7 +56,7 @@ import org.junit.experimental.categories.Category;
 public class TestFastFailWithoutTestUtil {
   private static final Log LOG = LogFactory.getLog(TestFastFailWithoutTestUtil.class);
 
-  @Test
+  @Test (timeout=180000)
   public void testInterceptorFactoryMethods() {
     Configuration conf = HBaseConfiguration.create();
     conf.setBoolean(HConstants.HBASE_CLIENT_FAST_FAIL_MODE_ENABLED, true);
@@ -95,7 +95,7 @@ public class TestFastFailWithoutTestUtil {
     assertTrue(context != null);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testInterceptorContextClear() {
     PreemptiveFastFailInterceptor interceptor = createPreemptiveInterceptor();
     FastFailInterceptorContext context = (FastFailInterceptorContext) interceptor
@@ -108,7 +108,7 @@ public class TestFastFailWithoutTestUtil {
     assertEquals(context.getTries(), 0);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testInterceptorContextPrepare() throws IOException {
     PreemptiveFastFailInterceptor interceptor = TestFastFailWithoutTestUtil
         .createPreemptiveInterceptor();
@@ -135,7 +135,7 @@ public class TestFastFailWithoutTestUtil {
     assertEquals(context.getServer(), server);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testInterceptorIntercept50Times() throws IOException,
       InterruptedException {
     for (int i = 0; i < 50; i++) {
@@ -249,7 +249,7 @@ public class TestFastFailWithoutTestUtil {
     };
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testExceptionsIdentifiedByInterceptor() throws IOException {
     Throwable[] networkexceptions = new Throwable[] {
         new ConnectException("Mary is unwell"),
diff --git a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestGet.java b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestGet.java
index 23e538c..52d2154 100644
--- a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestGet.java
+++ b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestGet.java
@@ -83,7 +83,7 @@ public class TestGet {
     "bGFzc1BLAQIUABQACAgIAFKDlEOtLmcoOgEAAPIBAAAVAAAAAAAAAAAAAAAAAD0CAAB0ZXN0L01v" +
     "Y2tGaWx0ZXIuY2xhc3NQSwUGAAAAAAQABAABAQAAugMAAAAA";
 
-  @Test
+  @Test (timeout=180000)
   public void testAttributesSerialization() throws IOException {
     Get get = new Get(Bytes.toBytes("row"));
     get.setAttribute("attribute1", Bytes.toBytes("value1"));
@@ -100,7 +100,7 @@ public class TestGet {
     Assert.assertEquals(3, get2.getAttributesMap().size());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testGetAttributes() {
     Get get = new Get(ROW);
     Assert.assertTrue(get.getAttributesMap().isEmpty());
@@ -147,7 +147,7 @@ public class TestGet {
     Assert.assertNull(get.getAttributesMap().get("attribute1"));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testNullQualifier() {
     Get get = new Get(ROW);
     byte[] family = Bytes.toBytes("family");
@@ -156,7 +156,7 @@ public class TestGet {
     Assert.assertEquals(1, qualifiers.size());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testDynamicFilter() throws Exception {
     Configuration conf = HBaseConfiguration.create();
     String localPath = conf.get("hbase.local.dir")
diff --git a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestIncrement.java b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestIncrement.java
index 4b9f113..3730a0d 100644
--- a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestIncrement.java
+++ b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestIncrement.java
@@ -29,7 +29,7 @@ import org.junit.Test;
 import org.junit.experimental.categories.Category;
 @Category({ClientTests.class, SmallTests.class})
 public class TestIncrement {
-  @Test
+  @Test (timeout=180000)
   public void test() {
     final long expected = 13;
     Increment inc = new Increment(new byte [] {'r'});
diff --git a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestOperation.java b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestOperation.java
index 96c4190d..d4cc0cf 100644
--- a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestOperation.java
+++ b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestOperation.java
@@ -295,7 +295,7 @@ public class TestOperation {
    * parseable and that the details are present and not corrupted.
    * @throws IOException
    */
-  @Test
+  @Test (timeout=180000)
   public void testOperationJSON()
       throws IOException {
     // produce a Scan Operation
@@ -374,7 +374,7 @@ public class TestOperation {
         Bytes.toStringBinary(QUALIFIER), kvMap.get("qualifier"));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testPutCreationWithByteBuffer() {
     Put p = new Put(ROW);
     List<Cell> c = p.get(FAMILY, QUALIFIER);
@@ -419,7 +419,7 @@ public class TestOperation {
     Assert.assertEquals(0, KeyValue.COMPARATOR.compare(c.get(0), new KeyValue(c.get(0))));
   }
 
-  @Test
+  @Test (timeout=180000)
   @SuppressWarnings("rawtypes")
   public void testOperationSubClassMethodsAreBuilderStyle() {
     /* All Operation subclasses should have a builder style setup where setXXX/addXXX methods
diff --git a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestPutDotHas.java b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestPutDotHas.java
index c269e62..df46c3a 100644
--- a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestPutDotHas.java
+++ b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestPutDotHas.java
@@ -44,25 +44,25 @@ public class TestPutDotHas {
     put.add(FAMILY_01, QUALIFIER_01, TS, VALUE_01);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testHasIgnoreValueIgnoreTS() {
     Assert.assertTrue(put.has(FAMILY_01, QUALIFIER_01));
     Assert.assertFalse(put.has(QUALIFIER_01, FAMILY_01));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testHasIgnoreValue() {
     Assert.assertTrue(put.has(FAMILY_01, QUALIFIER_01, TS));
     Assert.assertFalse(put.has(FAMILY_01, QUALIFIER_01, TS + 1));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testHasIgnoreTS() {
     Assert.assertTrue(put.has(FAMILY_01, QUALIFIER_01, VALUE_01));
     Assert.assertFalse(put.has(FAMILY_01, VALUE_01, QUALIFIER_01));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testHas() {
     Assert.assertTrue(put.has(FAMILY_01, QUALIFIER_01, TS, VALUE_01));
     // Bad TS
diff --git a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestScan.java b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestScan.java
index 129914f..d793780 100644
--- a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestScan.java
+++ b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestScan.java
@@ -38,7 +38,7 @@ import org.junit.experimental.categories.Category;
 // TODO: cover more test cases
 @Category({ClientTests.class, SmallTests.class})
 public class TestScan {
-  @Test
+  @Test (timeout=180000)
   public void testAttributesSerialization() throws IOException {
     Scan scan = new Scan();
     scan.setAttribute("attribute1", Bytes.toBytes("value1"));
@@ -56,7 +56,7 @@ public class TestScan {
     Assert.assertEquals(3, scan2.getAttributesMap().size());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testScanAttributes() {
     Scan scan = new Scan();
     Assert.assertTrue(scan.getAttributesMap().isEmpty());
@@ -103,7 +103,7 @@ public class TestScan {
     Assert.assertNull(scan.getAttributesMap().get("attribute1"));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testNullQualifier() {
     Scan scan = new Scan();
     byte[] family = Bytes.toBytes("family");
@@ -112,7 +112,7 @@ public class TestScan {
     Assert.assertEquals(1, qualifiers.size());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSetAuthorizations() {
     Scan scan = new Scan();
     try {
diff --git a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestSnapshotFromAdmin.java b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestSnapshotFromAdmin.java
index 78d718e..0210652 100644
--- a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestSnapshotFromAdmin.java
+++ b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestSnapshotFromAdmin.java
@@ -117,7 +117,7 @@ public class TestSnapshotFromAdmin {
    * the wire
    * @throws Exception on failure
    */
-  @Test
+  @Test (timeout=180000)
   public void testValidateSnapshotName() throws Exception {
     ConnectionManager.HConnectionImplementation mockConnection = Mockito
         .mock(ConnectionManager.HConnectionImplementation.class);
diff --git a/hbase-client/src/test/java/org/apache/hadoop/hbase/filter/TestLongComparator.java b/hbase-client/src/test/java/org/apache/hadoop/hbase/filter/TestLongComparator.java
index b003d5c..e685279 100644
--- a/hbase-client/src/test/java/org/apache/hadoop/hbase/filter/TestLongComparator.java
+++ b/hbase-client/src/test/java/org/apache/hadoop/hbase/filter/TestLongComparator.java
@@ -25,7 +25,7 @@ public class TestLongComparator {
   private long values[] = { Long.MIN_VALUE, -10000000000L, -1000000L, 0L, 1000000L, 10000000000L,
       Long.MAX_VALUE };
 
-  @Test
+  @Test (timeout=60000)
   public void testSimple() {
     for (int i = 1; i < values.length ; i++) {
       for (int j = 0; j < i; j++) {
diff --git a/hbase-client/src/test/java/org/apache/hadoop/hbase/ipc/TestIPCUtil.java b/hbase-client/src/test/java/org/apache/hadoop/hbase/ipc/TestIPCUtil.java
index 3eab225..8267c06 100644
--- a/hbase-client/src/test/java/org/apache/hadoop/hbase/ipc/TestIPCUtil.java
+++ b/hbase-client/src/test/java/org/apache/hadoop/hbase/ipc/TestIPCUtil.java
@@ -59,7 +59,7 @@ public class TestIPCUtil {
     this.util = new IPCUtil(new Configuration());
   }
   
-  @Test
+  @Test (timeout=180000)
   public void testBuildCellBlock() throws IOException {
     doBuildCellBlockUndoCellBlock(this.util, new KeyValueCodec(), null);
     doBuildCellBlockUndoCellBlock(this.util, new KeyValueCodec(), new DefaultCodec());
diff --git a/hbase-client/src/test/java/org/apache/hadoop/hbase/ipc/TestPayloadCarryingRpcController.java b/hbase-client/src/test/java/org/apache/hadoop/hbase/ipc/TestPayloadCarryingRpcController.java
index e6d6f43..6a65a61 100644
--- a/hbase-client/src/test/java/org/apache/hadoop/hbase/ipc/TestPayloadCarryingRpcController.java
+++ b/hbase-client/src/test/java/org/apache/hadoop/hbase/ipc/TestPayloadCarryingRpcController.java
@@ -37,7 +37,7 @@ import org.junit.experimental.categories.Category;
 
 @Category({ClientTests.class, SmallTests.class})
 public class TestPayloadCarryingRpcController {
-  @Test
+  @Test (timeout=180000)
   public void testListOfCellScannerables() throws IOException {
     List<CellScannable> cells = new ArrayList<CellScannable>();
     final int count = 10;
diff --git a/hbase-client/src/test/java/org/apache/hadoop/hbase/security/TestEncryptionUtil.java b/hbase-client/src/test/java/org/apache/hadoop/hbase/security/TestEncryptionUtil.java
index b0e3464..8519ddd 100644
--- a/hbase-client/src/test/java/org/apache/hadoop/hbase/security/TestEncryptionUtil.java
+++ b/hbase-client/src/test/java/org/apache/hadoop/hbase/security/TestEncryptionUtil.java
@@ -40,7 +40,7 @@ import org.junit.experimental.categories.Category;
 @Category({ClientTests.class, SmallTests.class})
 public class TestEncryptionUtil {
 
-  @Test
+  @Test (timeout=180000)
   public void testKeyWrapping() throws Exception {
     // set up the key provider for testing to resolve a key for our test subject
     Configuration conf = new Configuration(); // we don't need HBaseConfiguration for this
@@ -75,7 +75,7 @@ public class TestEncryptionUtil {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testWALKeyWrapping() throws Exception {
     // set up the key provider for testing to resolve a key for our test subject
     Configuration conf = new Configuration(); // we don't need HBaseConfiguration for this
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/TestCellComparator.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/TestCellComparator.java
index 007f826..f15e89f 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/TestCellComparator.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/TestCellComparator.java
@@ -43,7 +43,7 @@ public class TestCellComparator {
 
   byte[] val = Bytes.toBytes("val");
 
-  @Test
+  @Test (timeout=180000)
   public void testCompareCells() {
     KeyValue kv1 = new KeyValue(row1, fam1, qual1, val);
     KeyValue kv2 = new KeyValue(row2, fam1, qual1, val);
@@ -78,7 +78,7 @@ public class TestCellComparator {
     assertTrue((CellComparator.equals(kv1, kv2)));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testGetShortMidpoint() {
     KeyValue.KVComparator comparator = new KeyValue.KVComparator();
 
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/TestCellUtil.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/TestCellUtil.java
index fea517f..468db69 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/TestCellUtil.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/TestCellUtil.java
@@ -228,7 +228,7 @@ public class TestCellUtil {
    * Was overflowing if 100k or so lists of cellscanners to return.
    * @throws IOException
    */
-  @Test
+  @Test (timeout=180000)
   public void testCreateCellScannerOverflow() throws IOException {
     consume(doCreateCellScanner(1, 1), 1 * 1);
     consume(doCreateCellScanner(3, 0), 3 * 0);
@@ -281,7 +281,7 @@ public class TestCellUtil {
     Assert.assertEquals(expected, count);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testOverlappingKeys() {
     byte[] empty = HConstants.EMPTY_BYTE_ARRAY;
     byte[] a = Bytes.toBytes("a");
@@ -329,7 +329,7 @@ public class TestCellUtil {
     Assert.assertFalse(CellUtil.overlappingKeys(empty, a, b, c));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testFindCommonPrefixInFlatKey() {
     // The whole key matching case
     KeyValue kv1 = new KeyValue("r1".getBytes(), "f1".getBytes(), "q1".getBytes(), null);
@@ -376,7 +376,7 @@ public class TestCellUtil {
   /**
    * Assert CellUtil makes Cell toStrings same way we do KeyValue toStrings.
    */
-  @Test
+  @Test (timeout=180000)
   public void testToString() {
     byte [] row = Bytes.toBytes("row");
     long ts = 123l;
@@ -398,7 +398,7 @@ public class TestCellUtil {
     
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testToString1() {
     String row = "test.row";
     String family = "test.family";
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/TestClassFinder.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/TestClassFinder.java
index 0b83d05..0be55e8 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/TestClassFinder.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/TestClassFinder.java
@@ -87,7 +87,7 @@ public class TestClassFinder {
     testUtil.cleanupTestDir(TestClassFinder.class.getSimpleName());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testClassFinderCanFindClassesInJars() throws Exception {
     long counter = testCounter.incrementAndGet();
     FileAndPath c1 = compileTestClass(counter, "", "c1");
@@ -102,7 +102,7 @@ public class TestClassFinder {
     assertEquals(3, allClasses.size());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testClassFinderHandlesConflicts() throws Exception {
     long counter = testCounter.incrementAndGet();
     FileAndPath c1 = compileTestClass(counter, "", "c1");
@@ -116,7 +116,7 @@ public class TestClassFinder {
     assertEquals(2, allClasses.size());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testClassFinderHandlesNestedPackages() throws Exception {
     final String NESTED = ".nested";
     final String CLASSNAME1 = name.getMethodName() + "1";
@@ -138,7 +138,7 @@ public class TestClassFinder {
     assertTrue(nestedClasses.contains(nestedClass2));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testClassFinderFiltersByNameInJar() throws Exception {
     final long counter = testCounter.incrementAndGet();
     final String classNamePrefix = name.getMethodName();
@@ -158,7 +158,7 @@ public class TestClassFinder {
     assertTrue(incClasses.contains(incClass));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testClassFinderFiltersByClassInJar() throws Exception {
     final long counter = testCounter.incrementAndGet();
     final String classNamePrefix = name.getMethodName();
@@ -187,7 +187,7 @@ public class TestClassFinder {
     return packageAndLoadJar(c1, c2, c3);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testClassFinderFiltersByPathInJar() throws Exception {
     final String CLASSNAME = name.getMethodName();
     long counter = testCounter.incrementAndGet();
@@ -217,7 +217,7 @@ public class TestClassFinder {
     assertTrue(incClasses.contains(incClass));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testClassFinderCanFindClassesInDirs() throws Exception {
     // Make some classes for us to find.  Class naming and packaging is kinda cryptic.
     // TODO: Fix.
@@ -240,7 +240,7 @@ public class TestClassFinder {
     return false;
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testClassFinderFiltersByNameInDirs() throws Exception {
     // Make some classes for us to find.  Class naming and packaging is kinda cryptic.
     // TODO: Fix.
@@ -265,7 +265,7 @@ public class TestClassFinder {
     assertEquals(allClasses.size() - 1, notAllClasses.size());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testClassFinderFiltersByClassInDirs() throws Exception {
     // Make some classes for us to find.  Class naming and packaging is kinda cryptic.
     // TODO: Fix.
@@ -290,7 +290,7 @@ public class TestClassFinder {
     assertEquals(allClasses.size() - 1, notAllClasses.size());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testClassFinderFiltersByPathInDirs() throws Exception {
     final String hardcodedThisSubdir = "hbase-common";
     final ClassFinder.ResourcePathFilter notExcJarFilter =
@@ -306,7 +306,7 @@ public class TestClassFinder {
     assertFalse(notAllClasses.contains(this.getClass()));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testClassFinderDefaultsToOwnPackage() throws Exception {
     // Correct handling of nested packages is tested elsewhere, so here we just assume
     // pkgClasses is the correct answer that we don't have to check.
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/TestCompoundConfiguration.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/TestCompoundConfiguration.java
index 57409b6..50110cf 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/TestCompoundConfiguration.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/TestCompoundConfiguration.java
@@ -45,7 +45,7 @@ public class TestCompoundConfiguration extends TestCase {
     baseConfSize = baseConf.size();
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testBasicFunctionality() throws ClassNotFoundException {
     CompoundConfiguration compoundConf = new CompoundConfiguration()
         .add(baseConf); 
@@ -64,7 +64,7 @@ public class TestCompoundConfiguration extends TestCase {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testPut() {
     CompoundConfiguration compoundConf = new CompoundConfiguration()
       .add(baseConf);
@@ -87,7 +87,7 @@ public class TestCompoundConfiguration extends TestCase {
     assertEquals("fromParent", compoundConf.get("setInParent"));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testWithConfig() {
     Configuration conf = new Configuration();
     conf.set("B", "2b");
@@ -119,7 +119,7 @@ public class TestCompoundConfiguration extends TestCase {
     return new Bytes(Bytes.toBytes(s));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testWithIbwMap() {
     Map<Bytes, Bytes> map =
       new HashMap<Bytes, Bytes>();
@@ -160,7 +160,7 @@ public class TestCompoundConfiguration extends TestCase {
     assertEquals("4", conf2.get("D")); // map overrides
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testWithStringMap() {
     Map<String, String> map = new HashMap<String, String>();
     map.put("B", "2b");
@@ -197,7 +197,7 @@ public class TestCompoundConfiguration extends TestCase {
     assertEquals("4", conf2.get("D")); // map overrides
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testLaterConfigsOverrideEarlier() {
     Map<String, String> map1 = new HashMap<String, String>();
     map1.put("A", "2");
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/TestHBaseConfiguration.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/TestHBaseConfiguration.java
index 99e4a33..722886d 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/TestHBaseConfiguration.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/TestHBaseConfiguration.java
@@ -39,7 +39,7 @@ public class TestHBaseConfiguration {
 
   private static final Log LOG = LogFactory.getLog(TestHBaseConfiguration.class);
 
-  @Test
+  @Test (timeout=180000)
   public void testGetIntDeprecated() {
     int VAL = 1, VAL2 = 2;
     String NAME = "foo";
@@ -64,7 +64,7 @@ public class TestHBaseConfiguration {
     assertEquals(VAL, HBaseConfiguration.getInt(conf, NAME, DEPRECATED_NAME, 0));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testGetPassword() throws Exception {
     Configuration conf = HBaseConfiguration.create();
     conf.set(ReflectiveCredentialProviderClient.CREDENTIAL_PROVIDER_PATH,
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/codec/TestCellCodec.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/codec/TestCellCodec.java
index 922de6f..f5a2a5d 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/codec/TestCellCodec.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/codec/TestCellCodec.java
@@ -42,7 +42,7 @@ import com.google.common.io.CountingOutputStream;
 @Category({MiscTests.class, SmallTests.class})
 public class TestCellCodec {
 
-  @Test
+  @Test (timeout=180000)
   public void testEmptyWorks() throws IOException {
     ByteArrayOutputStream baos = new ByteArrayOutputStream();
     CountingOutputStream cos = new CountingOutputStream(baos);
@@ -62,7 +62,7 @@ public class TestCellCodec {
     assertEquals(0, cis.getCount());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testOne() throws IOException {
     ByteArrayOutputStream baos = new ByteArrayOutputStream();
     CountingOutputStream cos = new CountingOutputStream(baos);
@@ -87,7 +87,7 @@ public class TestCellCodec {
     assertEquals(offset, cis.getCount());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testThree() throws IOException {
     ByteArrayOutputStream baos = new ByteArrayOutputStream();
     CountingOutputStream cos = new CountingOutputStream(baos);
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/codec/TestCellCodecWithTags.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/codec/TestCellCodecWithTags.java
index 30f2f00..bacea31 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/codec/TestCellCodecWithTags.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/codec/TestCellCodecWithTags.java
@@ -45,7 +45,7 @@ import com.google.common.io.CountingOutputStream;
 @Category({MiscTests.class, SmallTests.class})
 public class TestCellCodecWithTags {
 
-  @Test
+  @Test (timeout=180000)
   public void testCellWithTag() throws IOException {
     ByteArrayOutputStream baos = new ByteArrayOutputStream();
     CountingOutputStream cos = new CountingOutputStream(baos);
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/codec/TestKeyValueCodec.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/codec/TestKeyValueCodec.java
index e3366fe..c0b30c0 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/codec/TestKeyValueCodec.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/codec/TestKeyValueCodec.java
@@ -39,7 +39,7 @@ import com.google.common.io.CountingOutputStream;
 
 @Category({MiscTests.class, SmallTests.class})
 public class TestKeyValueCodec {
-  @Test
+  @Test (timeout=180000)
   public void testEmptyWorks() throws IOException {
     ByteArrayOutputStream baos = new ByteArrayOutputStream();
     CountingOutputStream cos = new CountingOutputStream(baos);
@@ -59,7 +59,7 @@ public class TestKeyValueCodec {
     assertEquals(0, cis.getCount());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testOne() throws IOException {
     ByteArrayOutputStream baos = new ByteArrayOutputStream();
     CountingOutputStream cos = new CountingOutputStream(baos);
@@ -85,7 +85,7 @@ public class TestKeyValueCodec {
     assertEquals(length, cis.getCount());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testThree() throws IOException {
     ByteArrayOutputStream baos = new ByteArrayOutputStream();
     CountingOutputStream cos = new CountingOutputStream(baos);
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/codec/TestKeyValueCodecWithTags.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/codec/TestKeyValueCodecWithTags.java
index 007647a..99ea661 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/codec/TestKeyValueCodecWithTags.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/codec/TestKeyValueCodecWithTags.java
@@ -45,7 +45,7 @@ import com.google.common.io.CountingOutputStream;
 @Category({MiscTests.class, SmallTests.class})
 public class TestKeyValueCodecWithTags {
 
-  @Test
+  @Test (timeout=180000)
   public void testKeyValueWithTag() throws IOException {
     ByteArrayOutputStream baos = new ByteArrayOutputStream();
     CountingOutputStream cos = new CountingOutputStream(baos);
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/io/TestByteBufferInputStream.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/io/TestByteBufferInputStream.java
index 30fb71e..0073836 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/io/TestByteBufferInputStream.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/io/TestByteBufferInputStream.java
@@ -33,7 +33,7 @@ import org.junit.experimental.categories.Category;
 @Category({ IOTests.class, SmallTests.class })
 public class TestByteBufferInputStream {
 
-  @Test
+  @Test (timeout=180000)
   public void testReads() throws Exception {
     ByteArrayOutputStream bos = new ByteArrayOutputStream(100);
     DataOutputStream dos = new DataOutputStream(bos);
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/io/TestTagCompressionContext.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/io/TestTagCompressionContext.java
index 841c468..83d4147 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/io/TestTagCompressionContext.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/io/TestTagCompressionContext.java
@@ -43,7 +43,7 @@ public class TestTagCompressionContext {
   private static final byte[] Q = Bytes.toBytes("q");
   private static final byte[] V = Bytes.toBytes("v");
 
-  @Test
+  @Test (timeout=180000)
   public void testCompressUncompressTags1() throws Exception {
     ByteArrayOutputStream baos = new ByteArrayOutputStream();
     TagCompressionContext context = new TagCompressionContext(LRUDictionary.class, Byte.MAX_VALUE);
@@ -69,7 +69,7 @@ public class TestTagCompressionContext {
         tagsLength2));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testCompressUncompressTags2() throws Exception {
     ByteArrayOutputStream baos = new ByteArrayOutputStream();
     TagCompressionContext context = new TagCompressionContext(LRUDictionary.class, Byte.MAX_VALUE);
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/TestCipherProvider.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/TestCipherProvider.java
index dbf7fc5..7e86bd8 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/TestCipherProvider.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/TestCipherProvider.java
@@ -123,7 +123,7 @@ public class TestCipherProvider {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testCustomProvider() {
     Configuration conf = HBaseConfiguration.create();
     conf.set(HConstants.CRYPTO_CIPHERPROVIDER_CONF_KEY, MyCipherProvider.class.getName());
@@ -137,7 +137,7 @@ public class TestCipherProvider {
     assertEquals(a.getKeyLength(), 0);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testDefaultProvider() {
     Configuration conf = HBaseConfiguration.create();
     CipherProvider provider = Encryption.getCipherProvider(conf);
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/TestEncryption.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/TestEncryption.java
index 0d38356..e7a4297 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/TestEncryption.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/TestEncryption.java
@@ -41,7 +41,7 @@ public class TestEncryption {
 
   private static final Log LOG = LogFactory.getLog(TestEncryption.class);
 
-  @Test
+  @Test (timeout=180000)
   public void testSmallBlocks() throws Exception {
     byte[] key = new byte[16];
     Bytes.random(key);
@@ -52,7 +52,7 @@ public class TestEncryption {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testLargeBlocks() throws Exception {
     byte[] key = new byte[16];
     Bytes.random(key);
@@ -63,7 +63,7 @@ public class TestEncryption {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testOddSizedBlocks() throws Exception {
     byte[] key = new byte[16];
     Bytes.random(key);
@@ -74,7 +74,7 @@ public class TestEncryption {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testTypicalHFileBlocks() throws Exception {
     byte[] key = new byte[16];
     Bytes.random(key);
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/TestKeyProvider.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/TestKeyProvider.java
index dab03f2..147d9b1 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/TestKeyProvider.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/TestKeyProvider.java
@@ -34,7 +34,7 @@ import org.junit.experimental.categories.Category;
 @Category({MiscTests.class, SmallTests.class})
 public class TestKeyProvider {
 
-  @Test
+  @Test (timeout=180000)
   public void testTestProvider() {
     Configuration conf = HBaseConfiguration.create();
     conf.set(HConstants.CRYPTO_KEYPROVIDER_CONF_KEY, KeyProviderForTesting.class.getName());
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/aes/TestAES.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/aes/TestAES.java
index ea8879b..a4f8530 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/aes/TestAES.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/io/crypto/aes/TestAES.java
@@ -51,7 +51,7 @@ public class TestAES {
 
   // Validation for AES in CTR mode with a 128 bit key
   // From NIST Special Publication 800-38A
-  @Test
+  @Test (timeout=180000)
   public void testAESAlgorithm() throws Exception {
     Configuration conf = HBaseConfiguration.create();
     Cipher aes = Encryption.getCipher(conf, "AES");
@@ -81,7 +81,7 @@ public class TestAES {
     assertTrue("Failed #4", Bytes.equals(b, Bytes.fromHex("1e031dda2fbe03d1792170a0f3009cee")));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testAlternateRNG() throws Exception {
     Security.addProvider(new TestProvider());
 
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/io/util/TestLRUDictionary.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/io/util/TestLRUDictionary.java
index 9569ba8..ca50c20 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/io/util/TestLRUDictionary.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/io/util/TestLRUDictionary.java
@@ -47,7 +47,7 @@ public class TestLRUDictionary {
     testee.init(Short.MAX_VALUE);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void TestContainsNothing() {
     assertTrue(isDictionaryEmpty(testee));
   }
@@ -55,7 +55,7 @@ public class TestLRUDictionary {
   /**
    * Assert can't add empty array.
    */
-  @Test
+  @Test (timeout=180000)
   public void testPassingEmptyArrayToFindEntry() {
     assertEquals(Dictionary.NOT_IN_DICTIONARY,
       testee.findEntry(HConstants.EMPTY_BYTE_ARRAY, 0, 0));
@@ -63,7 +63,7 @@ public class TestLRUDictionary {
       testee.addEntry(HConstants.EMPTY_BYTE_ARRAY, 0, 0));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testPassingSameArrayToAddEntry() {
     // Add random predefined byte array, in this case a random byte array from
     // HConstants.  Assert that when we add, we get new index.  Thats how it
@@ -74,7 +74,7 @@ public class TestLRUDictionary {
     assertFalse(index == testee.addEntry(HConstants.CATALOG_FAMILY, 0, len));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testBasic() {
     Random rand = new Random();
     byte[] testBytes = new byte[10];
@@ -111,7 +111,7 @@ public class TestLRUDictionary {
     assertTrue(isDictionaryEmpty(testee));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void TestLRUPolicy(){
     //start by filling the dictionary up with byte arrays
     for (int i = 0; i < Short.MAX_VALUE; i++) {
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestFixedLengthWrapper.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestFixedLengthWrapper.java
index b259429..176113f 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestFixedLengthWrapper.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestFixedLengthWrapper.java
@@ -44,7 +44,7 @@ public class TestFixedLengthWrapper {
    */
   static final int[] limits = { 9, 12, 15 };
 
-  @Test
+  @Test (timeout=180000)
   public void testReadWrite() {
     for (int limit : limits) {
       PositionedByteRange buff = new SimplePositionedMutableByteRange(limit);
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestOrderedBlob.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestOrderedBlob.java
index c796fea..d1fc3be 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestOrderedBlob.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestOrderedBlob.java
@@ -36,7 +36,7 @@ public class TestOrderedBlob {
     Bytes.toBytes("7777777"), Bytes.toBytes("88888888"), Bytes.toBytes("999999999"),
   };
 
-  @Test
+  @Test (timeout=180000)
   public void testEncodedLength() {
     PositionedByteRange buff = new SimplePositionedMutableByteRange(20);
     for (DataType<byte[]> type : new OrderedBlob[] { OrderedBlob.ASCENDING, OrderedBlob.DESCENDING }) {
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestOrderedBlobVar.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestOrderedBlobVar.java
index d9c40e5..08aea82 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestOrderedBlobVar.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestOrderedBlobVar.java
@@ -36,7 +36,7 @@ public class TestOrderedBlobVar {
     Bytes.toBytes("7777777"), Bytes.toBytes("88888888"), Bytes.toBytes("999999999"),
   };
 
-  @Test
+  @Test (timeout=180000)
   public void testEncodedLength() {
     PositionedByteRange buff = new SimplePositionedMutableByteRange(20);
     for (DataType<byte[]> type :
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestOrderedString.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestOrderedString.java
index 6e9e9d0..285ec95 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestOrderedString.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestOrderedString.java
@@ -33,7 +33,7 @@ public class TestOrderedString {
       new String[] { null, "", "1", "22", "333", "4444", "55555", "666666",
     "7777777", "88888888", "999999999" };
 
-  @Test
+  @Test (timeout=180000)
   public void testEncodedLength() {
     PositionedByteRange buff = new SimplePositionedMutableByteRange(20);
     for (DataType<String> type : new OrderedString[] { OrderedString.ASCENDING, OrderedString.DESCENDING }) {
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestRawString.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestRawString.java
index 90f7e21..42e9c1f 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestRawString.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestRawString.java
@@ -36,7 +36,7 @@ public class TestRawString {
     "", "1", "22", "333", "4444", "55555", "666666", "7777777", "88888888", "999999999",
   };
 
-  @Test
+  @Test (timeout=180000)
   public void testReadWrite() {
     for (Order ord : new Order[] { Order.ASCENDING, Order.DESCENDING }) {
       RawString type =
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestStruct.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestStruct.java
index 8dc239b..91a46e3 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestStruct.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestStruct.java
@@ -342,7 +342,7 @@ public class TestStruct {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   @SuppressWarnings("unchecked")
   public void testOrderPreservation() throws Exception {
     Object[] vals = new Object[constructorArgs.length];
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestStructNullExtension.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestStructNullExtension.java
index e87438d..b65a916 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestStructNullExtension.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestStructNullExtension.java
@@ -49,7 +49,7 @@ public class TestStructNullExtension {
   /**
    * Positive cases for null extension.
    */
-  @Test
+  @Test (timeout=180000)
   public void testNullableNullExtension() {
     // the following field members are used because they're all nullable
     StructBuilder builder = new StructBuilder()
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestTerminatedWrapper.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestTerminatedWrapper.java
index e36a141..db22dd4 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestTerminatedWrapper.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestTerminatedWrapper.java
@@ -63,7 +63,7 @@ public class TestTerminatedWrapper {
     type.encode(buff, Bytes.toBytes("hello foobar!"));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testReadWriteSkippable() {
     PositionedByteRange buff = new SimplePositionedMutableByteRange(14);
     for (OrderedString t : new OrderedString[] {
@@ -82,7 +82,7 @@ public class TestTerminatedWrapper {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testReadWriteNonSkippable() {
     PositionedByteRange buff = new SimplePositionedMutableByteRange(12);
     for (Order ord : new Order[] { Order.ASCENDING, Order.DESCENDING }) {
@@ -99,7 +99,7 @@ public class TestTerminatedWrapper {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSkipSkippable() {
     PositionedByteRange buff = new SimplePositionedMutableByteRange(14);
     for (OrderedString t : new OrderedString[] {
@@ -119,7 +119,7 @@ public class TestTerminatedWrapper {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSkipNonSkippable() {
     PositionedByteRange buff = new SimplePositionedMutableByteRange(12);
     for (Order ord : new Order[] { Order.ASCENDING, Order.DESCENDING }) {
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestUnion2.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestUnion2.java
index 932be95..4fda067 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestUnion2.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/types/TestUnion2.java
@@ -106,7 +106,7 @@ public class TestUnion2 {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testEncodeDecode() {
     Integer intVal = Integer.valueOf(10);
     String strVal = "hello";
@@ -122,7 +122,7 @@ public class TestUnion2 {
     assertTrue(0 == strVal.compareTo(type.decodeB(buff)));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSkip() {
     Integer intVal = Integer.valueOf(10);
     String strVal = "hello";
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestByteRangeWithKVSerialization.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestByteRangeWithKVSerialization.java
index a6b7cc5..73eb07e 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestByteRangeWithKVSerialization.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestByteRangeWithKVSerialization.java
@@ -57,7 +57,7 @@ public class TestByteRangeWithKVSerialization {
     return kv;
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testWritingAndReadingCells() throws Exception {
     final byte[] FAMILY = Bytes.toBytes("f1");
     final byte[] QUALIFIER = Bytes.toBytes("q1");
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestConcatenatedLists.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestConcatenatedLists.java
index fd4baf5..790d9f6 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestConcatenatedLists.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestConcatenatedLists.java
@@ -36,7 +36,7 @@ import org.junit.experimental.categories.Category;
 
 @Category({MiscTests.class, SmallTests.class})
 public class TestConcatenatedLists {
-  @Test
+  @Test (timeout=180000)
   public void testUnsupportedOps() {
     // If adding support, add tests.
     ConcatenatedLists<Long> c = new ConcatenatedLists<Long>();
@@ -80,26 +80,26 @@ public class TestConcatenatedLists {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testEmpty() {
     verify(new ConcatenatedLists<Long>(), -1);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testOneOne() {
     ConcatenatedLists<Long> c = new ConcatenatedLists<Long>();
     c.addSublist(Arrays.asList(0L));
     verify(c, 0);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testOneMany() {
     ConcatenatedLists<Long> c = new ConcatenatedLists<Long>();
     c.addSublist(Arrays.asList(0L, 1L, 2L));
     verify(c, 2);
   }
 
-  @Test
+  @Test (timeout=180000)
   @SuppressWarnings("unchecked")
   public void testManyOne() {
     ConcatenatedLists<Long> c = new ConcatenatedLists<Long>();
@@ -108,7 +108,7 @@ public class TestConcatenatedLists {
     verify(c, 2);
   }
 
-  @Test
+  @Test (timeout=180000)
   @SuppressWarnings("unchecked")
   public void testManyMany() {
     ConcatenatedLists<Long> c = new ConcatenatedLists<Long>();
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestCoprocessorClassLoader.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestCoprocessorClassLoader.java
index daba459..83dd723 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestCoprocessorClassLoader.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestCoprocessorClassLoader.java
@@ -48,7 +48,7 @@ public class TestCoprocessorClassLoader {
     TEST_UTIL.getDataTestDir(); // prepare data test dir and hbase local dir
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testCleanupOldJars() throws Exception {
     String className = "TestCleanupOldJars";
     String folder = TEST_UTIL.getDataTestDir().toString();
@@ -68,12 +68,12 @@ public class TestCoprocessorClassLoader {
     assertFalse("tmp jar file should be removed", tmpJarFile.exists());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testLibJarName() throws Exception {
     checkingLibJarName("TestLibJarName.jar", "/lib/");
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRelativeLibJarName() throws Exception {
     checkingLibJarName("TestRelativeLibJarName.jar", "lib/");
   }
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestCounter.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestCounter.java
index 1c25ee3..59f1a7a 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestCounter.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestCounter.java
@@ -33,7 +33,7 @@ public class TestCounter {
     void execute();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testIncrement() throws Exception {
     for(int threadCount : THREAD_COUNTS) {
       final Counter counter = new Counter();
@@ -49,7 +49,7 @@ public class TestCounter {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testIncrementAndGet() throws Exception {
     for(int threadCount: THREAD_COUNTS) {
       final Counter counter = new Counter();
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestDrainBarrier.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestDrainBarrier.java
index 4542cbd..9d9c1ee1 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestDrainBarrier.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestDrainBarrier.java
@@ -30,7 +30,7 @@ import org.junit.experimental.categories.Category;
 @Category({MiscTests.class, SmallTests.class})
 public class TestDrainBarrier {
 
-  @Test
+  @Test (timeout=180000)
   public void testBeginEndStopWork() throws Exception {
     DrainBarrier barrier = new DrainBarrier();
     assertTrue(barrier.beginOp());
@@ -41,7 +41,7 @@ public class TestDrainBarrier {
     assertFalse(barrier.beginOp());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testUnmatchedEndAssert() throws Exception {
     DrainBarrier barrier = new DrainBarrier();
     try {
@@ -61,7 +61,7 @@ public class TestDrainBarrier {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testStopWithoutOpsDoesntBlock() throws Exception {
     DrainBarrier barrier = new DrainBarrier();
     barrier.stopAndDrainOpsOnce();
@@ -72,7 +72,7 @@ public class TestDrainBarrier {
     barrier.stopAndDrainOpsOnce();
   }
 
-  @Test
+  @Test (timeout=180000)
   /** This test tests blocking and can have false positives in very bad timing cases. */
   public void testStopIsBlockedByOps() throws Exception {
     final DrainBarrier barrier = new DrainBarrier();
@@ -102,7 +102,7 @@ public class TestDrainBarrier {
     assertFalse(stoppingThread.isAlive());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testMultipleStopOnceAssert() throws Exception {
     DrainBarrier barrier = new DrainBarrier();
     barrier.stopAndDrainOpsOnce();
@@ -113,7 +113,7 @@ public class TestDrainBarrier {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testMultipleSloppyStopsHaveNoEffect() throws Exception {
     DrainBarrier barrier = new DrainBarrier();
     barrier.stopAndDrainOps();
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestDynamicClassLoader.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestDynamicClassLoader.java
index 9269f2f..4caa0e6 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestDynamicClassLoader.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestDynamicClassLoader.java
@@ -46,7 +46,7 @@ public class TestDynamicClassLoader {
     conf.set("hbase.dynamic.jars.dir", TEST_UTIL.getDataTestDir().toString());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testLoadClassFromLocalPath() throws Exception {
     ClassLoader parent = TestDynamicClassLoader.class.getClassLoader();
     DynamicClassLoader classLoader = new DynamicClassLoader(conf, parent);
@@ -71,7 +71,7 @@ public class TestDynamicClassLoader {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testLoadClassFromAnotherPath() throws Exception {
     ClassLoader parent = TestDynamicClassLoader.class.getClassLoader();
     DynamicClassLoader classLoader = new DynamicClassLoader(conf, parent);
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestEnvironmentEdgeManager.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestEnvironmentEdgeManager.java
index 3c7a8dd..de42b99 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestEnvironmentEdgeManager.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestEnvironmentEdgeManager.java
@@ -34,7 +34,7 @@ import org.junit.experimental.categories.Category;
 @Category({MiscTests.class, MediumTests.class})
 public class TestEnvironmentEdgeManager {
 
-  @Test
+  @Test (timeout=60000)
   public void testManageSingleton() {
     EnvironmentEdgeManager.reset();
     EnvironmentEdge edge = EnvironmentEdgeManager.getDelegate();
@@ -53,7 +53,7 @@ public class TestEnvironmentEdgeManager {
     assertTrue(nullResult instanceof DefaultEnvironmentEdge);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCurrentTimeInMillis() {
     EnvironmentEdge mock = mock(EnvironmentEdge.class);
     EnvironmentEdgeManager.injectEdge(mock);
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestFastLongHistogram.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestFastLongHistogram.java
index f5848f3..2b48153 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestFastLongHistogram.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestFastLongHistogram.java
@@ -53,13 +53,13 @@ public class TestFastLongHistogram {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testUniform() {
     FastLongHistogram hist = new FastLongHistogram(100, 0, 50);
     doTestUniform(hist);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testAdaptionOfChange() {
     // assumes the uniform distribution
     FastLongHistogram hist = new FastLongHistogram(100, 0, 100);
@@ -88,7 +88,7 @@ public class TestFastLongHistogram {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSameValues() {
     FastLongHistogram hist = new FastLongHistogram(100);
 
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestKeyLocker.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestKeyLocker.java
index 9bb8a04..24b1ed1 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestKeyLocker.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestKeyLocker.java
@@ -28,7 +28,7 @@ import org.junit.experimental.categories.Category;
 
 @Category({MiscTests.class, SmallTests.class})
 public class TestKeyLocker {
-  @Test
+  @Test (timeout=180000)
   public void testLocker(){
     KeyLocker<String> locker = new KeyLocker();
     ReentrantLock lock1 = locker.acquireLock("l1");
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestLoadTestKVGenerator.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestLoadTestKVGenerator.java
index 120f2b6..ca0e21f 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestLoadTestKVGenerator.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestLoadTestKVGenerator.java
@@ -38,7 +38,7 @@ public class TestLoadTestKVGenerator {
   private Random rand = new Random(28937293L);
   private LoadTestKVGenerator gen = new LoadTestKVGenerator(MIN_LEN, MAX_LEN);
 
-  @Test
+  @Test (timeout=180000)
   public void testValueLength() {
     for (int i = 0; i < 1000; ++i) {
       byte[] v = gen.generateRandomSizeValue(Integer.toString(i).getBytes(),
@@ -48,7 +48,7 @@ public class TestLoadTestKVGenerator {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testVerification() {
     for (int i = 0; i < 1000; ++i) {
       for (int qualIndex = 0; qualIndex < 20; ++qualIndex) {
@@ -62,7 +62,7 @@ public class TestLoadTestKVGenerator {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testCorrectAndUniqueKeys() {
     Set<String> keys = new HashSet<String>();
     for (int i = 0; i < 1000; ++i) {
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestOrder.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestOrder.java
index 8029e44..5c69a0f 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestOrder.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestOrder.java
@@ -34,7 +34,7 @@ public class TestOrder {
 
   byte[][] VALS = { Bytes.toBytes("foo"), Bytes.toBytes("bar"), Bytes.toBytes("baz") };
 
-  @Test
+  @Test (timeout=180000)
   public void testApplyAscending() {
     byte[][] vals = new byte[VALS.length][];
     byte[][] ordered = new byte[VALS.length][];
@@ -56,7 +56,7 @@ public class TestOrder {
     assertArrayEquals(VALS[0], rangeApply);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testApplyDescending() {
     byte[][] vals = new byte[VALS.length][];
     byte[][] ordered = new byte[VALS.length][];
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestOrderedBytes.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestOrderedBytes.java
index 7e7c3aa..3aa64c9 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestOrderedBytes.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestOrderedBytes.java
@@ -76,7 +76,7 @@ public class TestOrderedBytes {
   /**
    * Expected lengths of equivalent values should match
    */
-  @Test
+  @Test (timeout=180000)
   public void testVerifyTestIntegrity() {
     for (int i = 0; i < I_VALS.length; i++) {
       for (int d = 0; d < D_VALS.length; d++) {
@@ -108,7 +108,7 @@ public class TestOrderedBytes {
    * 18446744073709551615 = ffffffffffffffffff<br /></code>
    * </p>
    */
-  @Test
+  @Test (timeout=180000)
   public void testVaruint64Boundaries() {
     long vals[] =
         { 239L, 240L, 2286L, 2287L, 67822L, 67823L, 16777214L, 16777215L, 4294967294L, 4294967295L,
@@ -153,7 +153,7 @@ public class TestOrderedBytes {
    * Test integer encoding. Example input values come from reference wiki
    * page.
    */
-  @Test
+  @Test (timeout=180000)
   public void testNumericInt() {
     /*
      * assert encoded values match decoded values. encode into target buffer
@@ -220,7 +220,7 @@ public class TestOrderedBytes {
   /**
    * Test real encoding. Example input values come from reference wiki page.
    */
-  @Test
+  @Test (timeout=180000)
   public void testNumericReal() {
     /*
      * assert encoded values match decoded values. encode into target buffer
@@ -287,7 +287,7 @@ public class TestOrderedBytes {
   /**
    * Fill gaps in Numeric encoding testing.
    */
-  @Test
+  @Test (timeout=180000)
   public void testNumericOther() {
     /*
      * assert encoded values match decoded values. encode into target buffer
@@ -331,7 +331,7 @@ public class TestOrderedBytes {
   /**
    * Verify Real and Int encodings are compatible.
    */
-  @Test
+  @Test (timeout=180000)
   public void testNumericIntRealCompatibility() {
     for (Order ord : new Order[] { Order.ASCENDING, Order.DESCENDING }) {
       for (int i = 0; i < I_VALS.length; i++) {
@@ -362,7 +362,7 @@ public class TestOrderedBytes {
   /**
    * Test int8 encoding.
    */
-  @Test
+  @Test (timeout=180000)
   public void testInt8() {
     Byte[] vals =
       { Byte.MIN_VALUE, Byte.MIN_VALUE / 2, 0, Byte.MAX_VALUE / 2, Byte.MAX_VALUE };
@@ -430,7 +430,7 @@ public class TestOrderedBytes {
   /**
    * Test int16 encoding.
    */
-  @Test
+  @Test (timeout=180000)
   public void testInt16() {
     Short[] vals =
       { Short.MIN_VALUE, Short.MIN_VALUE / 2, 0, Short.MAX_VALUE / 2, Short.MAX_VALUE };
@@ -498,7 +498,7 @@ public class TestOrderedBytes {
   /**
    * Test int32 encoding.
    */
-  @Test
+  @Test (timeout=180000)
   public void testInt32() {
     Integer[] vals =
       { Integer.MIN_VALUE, Integer.MIN_VALUE / 2, 0, Integer.MAX_VALUE / 2, Integer.MAX_VALUE };
@@ -566,7 +566,7 @@ public class TestOrderedBytes {
   /**
    * Test int64 encoding.
    */
-  @Test
+  @Test (timeout=180000)
   public void testInt64() {
     Long[] vals = { Long.MIN_VALUE, Long.MIN_VALUE / 2, 0L, Long.MAX_VALUE / 2, Long.MAX_VALUE };
 
@@ -633,7 +633,7 @@ public class TestOrderedBytes {
   /**
    * Test float32 encoding.
    */
-  @Test
+  @Test (timeout=180000)
   public void testFloat32() {
     Float[] vals =
       { Float.MIN_VALUE, Float.MIN_VALUE + 1.0f, 0.0f, Float.MAX_VALUE / 2.0f, Float.MAX_VALUE };
@@ -703,7 +703,7 @@ public class TestOrderedBytes {
   /**
    * Test float64 encoding.
    */
-  @Test
+  @Test (timeout=180000)
   public void testFloat64() {
     Double[] vals =
       { Double.MIN_VALUE, Double.MIN_VALUE + 1.0, 0.0, Double.MAX_VALUE / 2.0, Double.MAX_VALUE };
@@ -773,7 +773,7 @@ public class TestOrderedBytes {
   /**
    * Test string encoding.
    */
-  @Test
+  @Test (timeout=180000)
   public void testString() {
     String[] vals = { "foo", "baaaar", "bazz" };
     int expectedLengths[] = { 5, 8, 6 };
@@ -850,7 +850,7 @@ public class TestOrderedBytes {
    * Test length estimation algorithms for BlobVar encoding. Does not cover
    * 0-length input case properly.
    */
-  @Test
+  @Test (timeout=180000)
   public void testBlobVarLencodedLength() {
     int[][] values = {
         /* decoded length, encoded length
@@ -869,7 +869,7 @@ public class TestOrderedBytes {
   /**
    * Test BlobVar encoding.
    */
-  @Test
+  @Test (timeout=180000)
   public void testBlobVar() {
     byte[][] vals =
         { "".getBytes(), "foo".getBytes(), "foobarbazbub".getBytes(),
@@ -956,7 +956,7 @@ public class TestOrderedBytes {
   /**
    * Test BlobCopy encoding.
    */
-  @Test
+  @Test (timeout=180000)
   public void testBlobCopy() {
     byte[][] vals =
       { "".getBytes(), "foo".getBytes(), "foobarbazbub".getBytes(),
@@ -1059,7 +1059,7 @@ public class TestOrderedBytes {
   /**
    * Test generic skip logic
    */
-  @Test
+  @Test (timeout=180000)
   public void testSkip() {
     BigDecimal longMax = BigDecimal.valueOf(Long.MAX_VALUE);
     double negInf = Double.NEGATIVE_INFINITY;
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestShowProperties.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestShowProperties.java
index 2f16ee8..f3a4ac2 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestShowProperties.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestShowProperties.java
@@ -36,7 +36,7 @@ import org.junit.experimental.categories.Category;
 public class TestShowProperties {
   private static final Log LOG = LogFactory.getLog(TestShowProperties.class);
 
-  @Test
+  @Test (timeout=180000)
   public void testShowProperty() {
     Properties properties = System.getProperties();
     for (java.util.Map.Entry<Object, Object> prop : properties.entrySet()) {
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestSimpleMutableByteRange.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestSimpleMutableByteRange.java
index 88d4829..82e4ab6 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestSimpleMutableByteRange.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestSimpleMutableByteRange.java
@@ -26,7 +26,7 @@ import org.junit.experimental.categories.Category;
 @Category({MiscTests.class, SmallTests.class})
 public class TestSimpleMutableByteRange {
 
-  @Test
+  @Test (timeout=180000)
   public void testEmpty(){
     Assert.assertTrue(SimpleMutableByteRange.isEmpty(null));
     ByteRange r = new SimpleMutableByteRange();
@@ -41,7 +41,7 @@ public class TestSimpleMutableByteRange {
     Assert.assertEquals(0, r.hashCode());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testBasics() {
     ByteRange r = new SimpleMutableByteRange(new byte[] { 1, 3, 2 });
     Assert.assertFalse(SimpleMutableByteRange.isEmpty(r));
@@ -70,7 +70,7 @@ public class TestSimpleMutableByteRange {
     Assert.assertTrue(Bytes.equals(new byte[]{1, 3}, r.deepCopyToNewArray()));
   }
   
-  @Test
+  @Test (timeout=180000)
   public void testPutandGetPrimitiveTypes() throws Exception {
     ByteRange r = new SimpleMutableByteRange(100);
     int offset = 0;
diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestSimplePositionedMutableByteRange.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestSimplePositionedMutableByteRange.java
index ecc8c60..c8b8a2b 100644
--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestSimplePositionedMutableByteRange.java
+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/util/TestSimplePositionedMutableByteRange.java
@@ -27,7 +27,7 @@ import org.junit.experimental.categories.Category;
 
 @Category({MiscTests.class, SmallTests.class})
 public class TestSimplePositionedMutableByteRange {
-  @Test
+  @Test (timeout=180000)
   public void testPosition() {
     PositionedByteRange r = new SimplePositionedMutableByteRange(new byte[5], 1, 3);
 
@@ -69,7 +69,7 @@ public class TestSimplePositionedMutableByteRange {
     r.setPosition(3);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testPutAndGetPrimitiveTypes() throws Exception {
     PositionedByteRange pbr = new SimplePositionedMutableByteRange(100);
     int i1 = 18, i2 = 2;
@@ -95,7 +95,7 @@ public class TestSimplePositionedMutableByteRange {
     Assert.assertEquals(Long.MIN_VALUE, pbr.getVLong());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testPutGetAPIsCompareWithBBAPIs() throws Exception {
     // confirm that the long/int/short writing is same as BBs
     PositionedByteRange pbr = new SimplePositionedMutableByteRange(100);
diff --git a/hbase-examples/src/test/java/org/apache/hadoop/hbase/coprocessor/example/TestBulkDeleteProtocol.java b/hbase-examples/src/test/java/org/apache/hadoop/hbase/coprocessor/example/TestBulkDeleteProtocol.java
index 511bf46..fd81484 100644
--- a/hbase-examples/src/test/java/org/apache/hadoop/hbase/coprocessor/example/TestBulkDeleteProtocol.java
+++ b/hbase-examples/src/test/java/org/apache/hadoop/hbase/coprocessor/example/TestBulkDeleteProtocol.java
@@ -77,7 +77,7 @@ public class TestBulkDeleteProtocol {
     TEST_UTIL.shutdownMiniCluster();
   }
 
-  // @Ignore @Test
+  // @Ignore @Test (timeout=60000)
   public void testBulkDeleteEndpoint() throws Throwable {
     TableName tableName = TableName.valueOf("testBulkDeleteEndpoint");
     Table ht = createTable(tableName);
@@ -99,7 +99,7 @@ public class TestBulkDeleteProtocol {
     ht.close();
   }
 
-  // @Ignore @Test
+  // @Ignore @Test (timeout=60000)
   public void testBulkDeleteEndpointWhenRowBatchSizeLessThanRowsToDeleteFromARegion()
       throws Throwable {
     TableName tableName = TableName
@@ -154,7 +154,7 @@ public class TestBulkDeleteProtocol {
     return noOfDeletedRows;
   }
 
-  // @Ignore @Test
+  // @Ignore @Test (timeout=60000)
   public void testBulkDeleteWithConditionBasedDelete() throws Throwable {
     TableName tableName = TableName.valueOf("testBulkDeleteWithConditionBasedDelete");
     Table ht = createTable(tableName);
@@ -184,7 +184,7 @@ public class TestBulkDeleteProtocol {
     ht.close();
   }
 
-  // @Ignore @Test
+  // @Ignore @Test (timeout=60000)
   public void testBulkDeleteColumn() throws Throwable {
     TableName tableName = TableName.valueOf("testBulkDeleteColumn");
     Table ht = createTable(tableName);
@@ -213,7 +213,7 @@ public class TestBulkDeleteProtocol {
     ht.close();
   }
 
-  // @Ignore @Test
+  // @Ignore @Test (timeout=60000)
   public void testBulkDeleteFamily() throws Throwable {
     TableName tableName = TableName.valueOf("testBulkDeleteFamily");
     HTableDescriptor htd = new HTableDescriptor(tableName);
@@ -244,7 +244,7 @@ public class TestBulkDeleteProtocol {
     ht.close();
   }
 
-  // @Ignore @Test
+  // @Ignore @Test (timeout=60000)
   public void testBulkDeleteColumnVersion() throws Throwable {
     TableName tableName = TableName.valueOf("testBulkDeleteColumnVersion");
     Table ht = createTable(tableName);
@@ -292,7 +292,7 @@ public class TestBulkDeleteProtocol {
     ht.close();
   }
 
-  // @Ignore @Test
+  // @Ignore @Test (timeout=60000)
   public void testBulkDeleteColumnVersionBasedOnTS() throws Throwable {
     TableName tableName = TableName.valueOf("testBulkDeleteColumnVersionBasedOnTS");
     Table ht = createTable(tableName);
@@ -339,7 +339,7 @@ public class TestBulkDeleteProtocol {
     ht.close();
   }
 
-  // @Ignore @Test
+  // @Ignore @Test (timeout=60000)
   public void testBulkDeleteWithNumberOfVersions() throws Throwable {
     TableName tableName = TableName.valueOf("testBulkDeleteWithNumberOfVersions");
     Table ht = createTable(tableName);
diff --git a/hbase-examples/src/test/java/org/apache/hadoop/hbase/coprocessor/example/TestRowCountEndpoint.java b/hbase-examples/src/test/java/org/apache/hadoop/hbase/coprocessor/example/TestRowCountEndpoint.java
index 481cb91..b693fdb 100644
--- a/hbase-examples/src/test/java/org/apache/hadoop/hbase/coprocessor/example/TestRowCountEndpoint.java
+++ b/hbase-examples/src/test/java/org/apache/hadoop/hbase/coprocessor/example/TestRowCountEndpoint.java
@@ -69,7 +69,7 @@ public class TestRowCountEndpoint {
     TEST_UTIL.shutdownMiniCluster();
   }
 
-  // @Ignore @Test
+  // @Ignore @Test (timeout=60000)
   public void testEndpoint() throws Throwable {
     Table table = TEST_UTIL.getConnection().getTable(TEST_TABLE);
 
diff --git a/hbase-examples/src/test/java/org/apache/hadoop/hbase/coprocessor/example/TestZooKeeperScanPolicyObserver.java b/hbase-examples/src/test/java/org/apache/hadoop/hbase/coprocessor/example/TestZooKeeperScanPolicyObserver.java
index db10c5a..8407685 100644
--- a/hbase-examples/src/test/java/org/apache/hadoop/hbase/coprocessor/example/TestZooKeeperScanPolicyObserver.java
+++ b/hbase-examples/src/test/java/org/apache/hadoop/hbase/coprocessor/example/TestZooKeeperScanPolicyObserver.java
@@ -66,7 +66,7 @@ public class TestZooKeeperScanPolicyObserver {
     TEST_UTIL.shutdownMiniCluster();
   }
 
-  // @Ignore @Test
+  // @Ignore @Test (timeout=60000)
   public void testScanPolicyObserver() throws Exception {
     TableName tableName =
         TableName.valueOf("testScanPolicyObserver");
diff --git a/hbase-examples/src/test/java/org/apache/hadoop/hbase/mapreduce/TestMapReduceExamples.java b/hbase-examples/src/test/java/org/apache/hadoop/hbase/mapreduce/TestMapReduceExamples.java
index 1f10cb9..3da7d21 100644
--- a/hbase-examples/src/test/java/org/apache/hadoop/hbase/mapreduce/TestMapReduceExamples.java
+++ b/hbase-examples/src/test/java/org/apache/hadoop/hbase/mapreduce/TestMapReduceExamples.java
@@ -53,7 +53,7 @@ public class TestMapReduceExamples {
    */
 
   @SuppressWarnings("unchecked")
-  @Test
+  @Test (timeout=60000)
   public void testSampleUploader() throws Exception {
 
     Configuration configuration = new Configuration();
@@ -84,7 +84,7 @@ public class TestMapReduceExamples {
   /**
    * Test main method of SampleUploader.
    */
-  @Test
+  @Test (timeout=60000)
   public void testMainSampleUploader() throws Exception {
     PrintStream oldPrintStream = System.err;
     SecurityManager SECURITY_MANAGER = System.getSecurityManager();
@@ -116,7 +116,7 @@ public class TestMapReduceExamples {
    * Test IndexBuilder from examples
    */
   @SuppressWarnings("unchecked")
-  @Test
+  @Test (timeout=60000)
   public void testIndexBuilder() throws Exception {
     Configuration configuration = new Configuration();
     String[] args = { "tableName", "columnFamily", "column1", "column2" };
@@ -151,7 +151,7 @@ public class TestMapReduceExamples {
   /**
    * Test main method of IndexBuilder
    */
-  @Test
+  @Test (timeout=60000)
   public void testMainIndexBuilder() throws Exception {
     PrintStream oldPrintStream = System.err;
     SecurityManager SECURITY_MANAGER = System.getSecurityManager();
diff --git a/hbase-examples/src/test/java/org/apache/hadoop/hbase/types/TestPBCell.java b/hbase-examples/src/test/java/org/apache/hadoop/hbase/types/TestPBCell.java
index a548b8a..d53fb75 100644
--- a/hbase-examples/src/test/java/org/apache/hadoop/hbase/types/TestPBCell.java
+++ b/hbase-examples/src/test/java/org/apache/hadoop/hbase/types/TestPBCell.java
@@ -41,7 +41,7 @@ public class TestPBCell {
   /**
    * Basic test to verify utility methods in {@link PBType} and delegation to protobuf works.
    */
-  @Test
+  @Test (timeout=180000)
   public void testRoundTrip() {
     final Cell cell = new KeyValue(Bytes.toBytes("row"), Bytes.toBytes("fam"),
       Bytes.toBytes("qual"), Bytes.toBytes("val"));
diff --git a/hbase-hadoop-compat/src/test/java/org/apache/hadoop/hbase/TestCompatibilitySingletonFactory.java b/hbase-hadoop-compat/src/test/java/org/apache/hadoop/hbase/TestCompatibilitySingletonFactory.java
index db5a1a3..a34e5ec 100644
--- a/hbase-hadoop-compat/src/test/java/org/apache/hadoop/hbase/TestCompatibilitySingletonFactory.java
+++ b/hbase-hadoop-compat/src/test/java/org/apache/hadoop/hbase/TestCompatibilitySingletonFactory.java
@@ -48,7 +48,7 @@ public class TestCompatibilitySingletonFactory {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGetInstance() throws Exception {
     List<TestCompatibilitySingletonFactoryCallable> callables =
         new ArrayList<TestCompatibilitySingletonFactoryCallable>(ITERATIONS);
diff --git a/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/master/TestMetricsMasterSourceImpl.java b/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/master/TestMetricsMasterSourceImpl.java
index 0a784eb..0f510d6 100644
--- a/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/master/TestMetricsMasterSourceImpl.java
+++ b/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/master/TestMetricsMasterSourceImpl.java
@@ -29,7 +29,7 @@ import static org.junit.Assert.assertTrue;
  */
 public class TestMetricsMasterSourceImpl {
 
-  @Test
+  @Test (timeout=60000)
   public void testGetInstance() throws Exception {
     MetricsMasterSourceFactory metricsMasterSourceFactory = CompatibilitySingletonFactory
         .getInstance(MetricsMasterSourceFactory.class);
diff --git a/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/metrics/TestBaseSourceImpl.java b/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/metrics/TestBaseSourceImpl.java
index 3c9d792..a449056 100644
--- a/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/metrics/TestBaseSourceImpl.java
+++ b/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/metrics/TestBaseSourceImpl.java
@@ -38,7 +38,7 @@ public class TestBaseSourceImpl {
     bmsi = new BaseSourceImpl("TestName", "test description", "testcontext", "TestContext");
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSetGauge() throws Exception {
     bmsi.setGauge("testset", 100);
     assertEquals(100, ((MutableGaugeLong) bmsi.metricsRegistry.get("testset")).value());
@@ -47,7 +47,7 @@ public class TestBaseSourceImpl {
 
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testIncGauge() throws Exception {
     bmsi.incGauge("testincgauge", 100);
     assertEquals(100, ((MutableGaugeLong) bmsi.metricsRegistry.get("testincgauge")).value());
@@ -56,7 +56,7 @@ public class TestBaseSourceImpl {
 
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testDecGauge() throws Exception {
     bmsi.decGauge("testdec", 100);
     assertEquals(-100, ((MutableGaugeLong) bmsi.metricsRegistry.get("testdec")).value());
@@ -65,7 +65,7 @@ public class TestBaseSourceImpl {
 
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testIncCounters() throws Exception {
     bmsi.incCounters("testinccounter", 100);
     assertEquals(100, ((MutableCounterLong) bmsi.metricsRegistry.get("testinccounter")).value());
@@ -74,7 +74,7 @@ public class TestBaseSourceImpl {
 
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testRemoveMetric() throws Exception {
     bmsi.setGauge("testrmgauge", 100);
     bmsi.removeMetric("testrmgauge");
diff --git a/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/regionserver/TestMetricsRegionServerSourceImpl.java b/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/regionserver/TestMetricsRegionServerSourceImpl.java
index e6e16c7..8e4c6af 100644
--- a/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/regionserver/TestMetricsRegionServerSourceImpl.java
+++ b/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/regionserver/TestMetricsRegionServerSourceImpl.java
@@ -29,7 +29,7 @@ import static org.junit.Assert.assertTrue;
  */
 public class TestMetricsRegionServerSourceImpl {
 
-  @Test
+  @Test (timeout=60000)
   public void testGetInstance() throws Exception {
     MetricsRegionServerSourceFactory metricsRegionServerSourceFactory =
         CompatibilitySingletonFactory.getInstance(MetricsRegionServerSourceFactory.class);
diff --git a/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/regionserver/TestMetricsRegionSourceImpl.java b/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/regionserver/TestMetricsRegionSourceImpl.java
index 4be8905..008d534 100644
--- a/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/regionserver/TestMetricsRegionSourceImpl.java
+++ b/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/regionserver/TestMetricsRegionSourceImpl.java
@@ -30,7 +30,7 @@ import org.junit.Test;
 
 public class TestMetricsRegionSourceImpl {
 
-  @Test
+  @Test (timeout=60000)
   public void testCompareToHashCodeEquals() throws Exception {
     MetricsRegionServerSourceFactory fact = CompatibilitySingletonFactory.getInstance(MetricsRegionServerSourceFactory.class);
 
diff --git a/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestMetricsWALSourceImpl.java b/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestMetricsWALSourceImpl.java
index 088a8cf..4aec2b2 100644
--- a/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestMetricsWALSourceImpl.java
+++ b/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestMetricsWALSourceImpl.java
@@ -25,7 +25,7 @@ import static org.junit.Assert.assertTrue;
 
 public class TestMetricsWALSourceImpl {
 
-  @Test
+  @Test (timeout=60000)
   public void testGetInstance() throws Exception {
     MetricsWALSource walSource =
         CompatibilitySingletonFactory.getInstance(MetricsWALSource.class);
diff --git a/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestMetricsReplicationSourceFactoryImpl.java b/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestMetricsReplicationSourceFactoryImpl.java
index d370b17..0f75f15 100644
--- a/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestMetricsReplicationSourceFactoryImpl.java
+++ b/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestMetricsReplicationSourceFactoryImpl.java
@@ -25,7 +25,7 @@ import static org.junit.Assert.*;
 public class TestMetricsReplicationSourceFactoryImpl {
 
 
-  @Test
+  @Test (timeout=60000)
   public void testGetInstance() throws Exception {
     MetricsReplicationSourceFactory rms = CompatibilitySingletonFactory
         .getInstance(MetricsReplicationSourceFactory.class);
diff --git a/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestMetricsReplicationSourceImpl.java b/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestMetricsReplicationSourceImpl.java
index bd7f3dd..503164b 100644
--- a/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestMetricsReplicationSourceImpl.java
+++ b/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestMetricsReplicationSourceImpl.java
@@ -28,7 +28,7 @@ import static org.junit.Assert.assertTrue;
 /** Test for MetricsReplicationSourceImpl */
 public class TestMetricsReplicationSourceImpl {
 
-  @Test
+  @Test (timeout=60000)
   public void testGetInstance() throws Exception {
     MetricsReplicationSource rms = CompatibilitySingletonFactory
         .getInstance(MetricsReplicationSource.class);
diff --git a/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/rest/TestMetricsRESTSourceImpl.java b/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/rest/TestMetricsRESTSourceImpl.java
index 5f4e70b..a59da3a 100644
--- a/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/rest/TestMetricsRESTSourceImpl.java
+++ b/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/rest/TestMetricsRESTSourceImpl.java
@@ -31,7 +31,7 @@ import static org.junit.Assert.assertTrue;
  */
 public class TestMetricsRESTSourceImpl {
 
-  @Test
+  @Test (timeout=60000)
   public void ensureCompatRegistered() throws Exception {
     assertNotNull(CompatibilitySingletonFactory.getInstance(MetricsRESTSource.class));
     assertTrue(CompatibilitySingletonFactory.getInstance(MetricsRESTSource.class) instanceof MetricsRESTSourceImpl);
diff --git a/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/thrift/TestMetricsThriftServerSourceFactoryImpl.java b/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/thrift/TestMetricsThriftServerSourceFactoryImpl.java
index c9eda58..1c4fa04 100644
--- a/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/thrift/TestMetricsThriftServerSourceFactoryImpl.java
+++ b/hbase-hadoop2-compat/src/test/java/org/apache/hadoop/hbase/thrift/TestMetricsThriftServerSourceFactoryImpl.java
@@ -32,13 +32,13 @@ import static org.junit.Assert.assertTrue;
  */
 public class TestMetricsThriftServerSourceFactoryImpl {
 
-  @Test
+  @Test (timeout=60000)
   public void testCompatabilityRegistered() throws Exception {
     assertNotNull(CompatibilitySingletonFactory.getInstance(MetricsThriftServerSourceFactory.class));
     assertTrue(CompatibilitySingletonFactory.getInstance(MetricsThriftServerSourceFactory.class) instanceof MetricsThriftServerSourceFactoryImpl);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCreateThriftOneSource() throws Exception {
     //Make sure that the factory gives back a singleton.
     assertSame(new MetricsThriftServerSourceFactoryImpl().createThriftOneSource(),
@@ -46,7 +46,7 @@ public class TestMetricsThriftServerSourceFactoryImpl {
 
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCreateThriftTwoSource() throws Exception {
     //Make sure that the factory gives back a singleton.
     assertSame(new MetricsThriftServerSourceFactoryImpl().createThriftTwoSource(),
diff --git a/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/keyvalue/TestKeyValueTool.java b/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/keyvalue/TestKeyValueTool.java
index 9e27942..e49ff31 100644
--- a/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/keyvalue/TestKeyValueTool.java
+++ b/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/keyvalue/TestKeyValueTool.java
@@ -52,7 +52,7 @@ public class TestKeyValueTool {
     this.rows = testRows;
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRoundTripToBytes() {
     if(rows instanceof TestRowDataTrivialWithTags || rows instanceof TestRowDataRandomKeyValuesWithTags) {
       return;
diff --git a/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/blockmeta/TestBlockMeta.java b/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/blockmeta/TestBlockMeta.java
index 6bf14bf..4e95e86 100644
--- a/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/blockmeta/TestBlockMeta.java
+++ b/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/blockmeta/TestBlockMeta.java
@@ -77,7 +77,7 @@ public class TestBlockMeta {
     return m;
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testStreamSerialization() throws IOException {
     PrefixTreeBlockMeta original = createSample();
     ByteArrayOutputStream os = new ByteArrayOutputStream(10000);
diff --git a/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/builder/TestTokenizer.java b/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/builder/TestTokenizer.java
index 77cc5d3..53a0897 100644
--- a/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/builder/TestTokenizer.java
+++ b/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/builder/TestTokenizer.java
@@ -57,14 +57,14 @@ public class TestTokenizer {
     this.roundTripped = builder.getArrays();
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testReaderRoundTrip() {
     Assert.assertEquals(inputs.size(), roundTripped.size());
     Assert.assertTrue(Bytes.isSorted(roundTripped));
     Assert.assertTrue(Bytes.equals(inputs, roundTripped));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSearching() {
     for (byte[] input : inputs) {
       TokenizerRowSearchResult resultHolder = new TokenizerRowSearchResult();
diff --git a/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/builder/TestTreeDepth.java b/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/builder/TestTreeDepth.java
index 87fcf07..fe481d2 100644
--- a/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/builder/TestTreeDepth.java
+++ b/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/builder/TestTreeDepth.java
@@ -35,43 +35,43 @@ import com.google.common.collect.Lists;
 @Category({MiscTests.class, SmallTests.class})
 public class TestTreeDepth {
 
-  @Test
+  @Test (timeout=180000)
   public void testSingleNode() {
     List<String> inputs = Lists.newArrayList("a");
     testInternal(inputs, 1);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSimpleBranch() {
     List<String> inputs = Lists.newArrayList("a", "aa", "ab");
     testInternal(inputs, 2);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testEmptyRoot() {
     List<String> inputs = Lists.newArrayList("a", "b");
     testInternal(inputs, 2);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRootAsNub() {
     List<String> inputs = Lists.newArrayList("a", "aa");
     testInternal(inputs, 2);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRootAsNubPlusNub() {
     List<String> inputs = Lists.newArrayList("a", "aa", "aaa");
     testInternal(inputs, 3);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testEmptyRootPlusNub() {
     List<String> inputs = Lists.newArrayList("a", "aa", "b");
     testInternal(inputs, 3);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSplitDistantAncestor() {
     List<String> inputs = Lists.newArrayList("a", "ac", "acd", "b");
     testInternal(inputs, 4);
diff --git a/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/column/TestColumnBuilder.java b/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/column/TestColumnBuilder.java
index c33a953..ab133f0 100644
--- a/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/column/TestColumnBuilder.java
+++ b/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/column/TestColumnBuilder.java
@@ -82,7 +82,7 @@ public class TestColumnBuilder {
 
   /************* methods ********************************/
 
-  @Test
+  @Test (timeout=180000)
   public void testReaderRoundTrip() throws IOException {
     for (int i = 0; i < sortedUniqueColumns.size(); ++i) {
       ByteRange column = sortedUniqueColumns.get(i);
diff --git a/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/row/TestPrefixTreeSearcher.java b/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/row/TestPrefixTreeSearcher.java
index 98513da..164bdd7 100644
--- a/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/row/TestPrefixTreeSearcher.java
+++ b/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/row/TestPrefixTreeSearcher.java
@@ -70,7 +70,7 @@ public class TestPrefixTreeSearcher {
     this.block = ByteBuffer.wrap(outputBytes);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testScanForwards() throws IOException {
     CellSearcher searcher = null;
     try {
@@ -94,7 +94,7 @@ public class TestPrefixTreeSearcher {
   }
 
 
-  @Test
+  @Test (timeout=180000)
   public void testScanBackwards() throws IOException {
     CellSearcher searcher = null;
     try {
@@ -115,7 +115,7 @@ public class TestPrefixTreeSearcher {
   }
 
 
-  @Test
+  @Test (timeout=180000)
   public void testRandomSeekHits() throws IOException {
     CellSearcher searcher = null;
     try {
@@ -131,7 +131,7 @@ public class TestPrefixTreeSearcher {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRandomSeekMisses() throws IOException {
     CellSearcher searcher = null;
     List<Integer> rowStartIndexes = rows.getRowStartIndexes();
@@ -188,7 +188,7 @@ public class TestPrefixTreeSearcher {
   }
 
 
-  @Test
+  @Test (timeout=180000)
   public void testRandomSeekIndividualAssertions() throws IOException {
     CellSearcher searcher = null;
     try {
@@ -199,7 +199,7 @@ public class TestPrefixTreeSearcher {
     }
   }
   
-  @Test
+  @Test (timeout=180000)
   public void testSeekWithPrefix() throws IOException {
     if (!(rows instanceof TestRowDataSearchWithPrefix)) {
       return;
diff --git a/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/row/TestRowEncoder.java b/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/row/TestRowEncoder.java
index ec11551..1204c73 100644
--- a/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/row/TestRowEncoder.java
+++ b/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/row/TestRowEncoder.java
@@ -102,13 +102,13 @@ public class TestRowEncoder {
     searcher.initOnBlock(blockMetaReader, outputBytes, includeMemstoreTS);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testEncoderOutput() throws IOException {
     Assert.assertEquals(totalBytes, outputBytes.length);
     Assert.assertEquals(blockMetaWriter, blockMetaReader);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testForwardScanner() {
     int counter = -1;
     while (searcher.advance()) {
@@ -125,7 +125,7 @@ public class TestRowEncoder {
   /**
    * probably not needed since testReverseScannerWithJitter() below is more thorough
    */
-  @Test
+  @Test (timeout=180000)
   public void testReverseScanner() {
     searcher.positionAfterLastCell();
     int counter = -1;
@@ -144,7 +144,7 @@ public class TestRowEncoder {
    * Exercise the nubCellsRemain variable by calling next+previous.  NubCellsRemain is basically
    * a special fan index.
    */
-  @Test
+  @Test (timeout=180000)
   public void testReverseScannerWithJitter() {
     searcher.positionAfterLastCell();
     int counter = -1;
@@ -169,7 +169,7 @@ public class TestRowEncoder {
     Assert.assertEquals(rows.getInputs().size(), counter + 1);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testIndividualBlockMetaAssertions() {
     rows.individualBlockMetaAssertions(blockMetaReader);
   }
diff --git a/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/timestamp/TestTimestampEncoder.java b/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/timestamp/TestTimestampEncoder.java
index 65cbcc9..3baa51b 100644
--- a/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/timestamp/TestTimestampEncoder.java
+++ b/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/codec/prefixtree/timestamp/TestTimestampEncoder.java
@@ -65,12 +65,12 @@ public class TestTimestampEncoder {
     decoder.initOnBlock(blockMeta, bytes);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testCompressorMinimum() {
     Assert.assertEquals(timestamps.getMinimum(), encoder.getMin());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testCompressorRoundTrip() {
     long[] outputs = encoder.getSortedUniqueTimestamps();
     for (int i = 0; i < timestamps.getOutputs().size(); ++i) {
@@ -80,12 +80,12 @@ public class TestTimestampEncoder {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testReaderMinimum() {
     Assert.assertEquals(timestamps.getMinimum(), decoder.getLong(0));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testReaderRoundTrip() {
     for (int i = 0; i < timestamps.getOutputs().size(); ++i) {
       long input = timestamps.getOutputs().get(i);
diff --git a/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/util/bytes/TestByteRange.java b/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/util/bytes/TestByteRange.java
index 028d604..dd39806 100644
--- a/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/util/bytes/TestByteRange.java
+++ b/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/util/bytes/TestByteRange.java
@@ -30,7 +30,7 @@ import org.junit.experimental.categories.Category;
 @Category({MiscTests.class, SmallTests.class})
 public class TestByteRange {
 
-  @Test
+  @Test (timeout=180000)
   public void testConstructor() {
     ByteRange b = new SimpleMutableByteRange(new byte[] { 0, 1, 2 });
     Assert.assertEquals(3, b.getLength());
diff --git a/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/util/vint/TestFIntTool.java b/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/util/vint/TestFIntTool.java
index 4d12335..8453aaf 100644
--- a/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/util/vint/TestFIntTool.java
+++ b/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/util/vint/TestFIntTool.java
@@ -31,7 +31,7 @@ import org.junit.experimental.categories.Category;
 
 @Category({MiscTests.class, SmallTests.class})
 public class TestFIntTool {
-  @Test
+  @Test (timeout=180000)
   public void testLeadingZeros() {
     Assert.assertEquals(64, Long.numberOfLeadingZeros(0));
     Assert.assertEquals(63, Long.numberOfLeadingZeros(1));
@@ -41,7 +41,7 @@ public class TestFIntTool {
     Assert.assertEquals(1, Long.numberOfLeadingZeros(Long.MAX_VALUE - 1));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testMaxValueForNumBytes() {
     Assert.assertEquals(255, UFIntTool.maxValueForNumBytes(1));
     Assert.assertEquals(65535, UFIntTool.maxValueForNumBytes(2));
@@ -49,7 +49,7 @@ public class TestFIntTool {
     Assert.assertEquals(0xffffffffffffffL, UFIntTool.maxValueForNumBytes(7));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testNumBytes() {
     Assert.assertEquals(1, UFIntTool.numBytes(0));
     Assert.assertEquals(1, UFIntTool.numBytes(1));
@@ -64,7 +64,7 @@ public class TestFIntTool {
     Assert.assertEquals(8, UFIntTool.numBytes(Long.MAX_VALUE - 1));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testGetBytes() {
     Assert.assertArrayEquals(new byte[] { 0 }, UFIntTool.getBytes(1, 0));
     Assert.assertArrayEquals(new byte[] { 1 }, UFIntTool.getBytes(1, 1));
@@ -79,7 +79,7 @@ public class TestFIntTool {
       UFIntTool.getBytes(8, Long.MAX_VALUE));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testFromBytes() {
     Assert.assertEquals(0, UFIntTool.fromBytes(new byte[] { 0 }));
     Assert.assertEquals(1, UFIntTool.fromBytes(new byte[] { 1 }));
@@ -93,7 +93,7 @@ public class TestFIntTool {
       UFIntTool.fromBytes(new byte[] { 127, -1, -1, -1, -1, -1, -1, -1 }));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRoundTrips() {
     long[] values = new long[] { 0, 1, 2, 255, 256, 31123, 65535, 65536, 65537, 0xfffffeL,
         0xffffffL, 0x1000000L, 0x1000001L, Integer.MAX_VALUE - 1, Integer.MAX_VALUE,
@@ -103,7 +103,7 @@ public class TestFIntTool {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testWriteBytes() throws IOException {// copied from testGetBytes
     Assert.assertArrayEquals(new byte[] { 0 }, bytesViaOutputStream(1, 0));
     Assert.assertArrayEquals(new byte[] { 1 }, bytesViaOutputStream(1, 1));
diff --git a/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/util/vint/TestVIntTool.java b/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/util/vint/TestVIntTool.java
index b9cb372..7f51268 100644
--- a/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/util/vint/TestVIntTool.java
+++ b/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/util/vint/TestVIntTool.java
@@ -32,7 +32,7 @@ import org.junit.experimental.categories.Category;
 @Category({MiscTests.class, SmallTests.class})
 public class TestVIntTool {
 
-  @Test
+  @Test (timeout=180000)
   public void testNumBytes() {
     Assert.assertEquals(1, UVIntTool.numBytes(0));
     Assert.assertEquals(1, UVIntTool.numBytes(1));
@@ -44,7 +44,7 @@ public class TestVIntTool {
     Assert.assertEquals(5, UVIntTool.numBytes(Integer.MAX_VALUE));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testWriteBytes() throws IOException {
     Assert.assertArrayEquals(new byte[] { 0 }, bytesViaOutputStream(0));
     Assert.assertArrayEquals(new byte[] { 1 }, bytesViaOutputStream(1));
@@ -61,7 +61,7 @@ public class TestVIntTool {
     return os.toByteArray();
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testToBytes() {
     Assert.assertArrayEquals(new byte[] { 0 }, UVIntTool.getBytes(0));
     Assert.assertArrayEquals(new byte[] { 1 }, UVIntTool.getBytes(1));
@@ -72,12 +72,12 @@ public class TestVIntTool {
     Assert.assertArrayEquals(UVIntTool.MAX_VALUE_BYTES, UVIntTool.getBytes(Integer.MAX_VALUE));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testFromBytes() {
     Assert.assertEquals(Integer.MAX_VALUE, UVIntTool.getInt(UVIntTool.MAX_VALUE_BYTES));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRoundTrips() {
     Random random = new Random();
     for (int i = 0; i < 10000; ++i) {
@@ -88,7 +88,7 @@ public class TestVIntTool {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testInputStreams() throws IOException {
     ByteArrayInputStream is;
     is = new ByteArrayInputStream(new byte[] { 0 });
diff --git a/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/util/vint/TestVLongTool.java b/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/util/vint/TestVLongTool.java
index ed637f6..cf7b514 100644
--- a/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/util/vint/TestVLongTool.java
+++ b/hbase-prefix-tree/src/test/java/org/apache/hadoop/hbase/util/vint/TestVLongTool.java
@@ -32,7 +32,7 @@ import org.junit.experimental.categories.Category;
 @Category({MiscTests.class, SmallTests.class})
 public class TestVLongTool {
 
-  @Test
+  @Test (timeout=180000)
   public void testNumBytes() {
     Assert.assertEquals(1, UVLongTool.numBytes(0));
     Assert.assertEquals(1, UVLongTool.numBytes(1));
@@ -44,7 +44,7 @@ public class TestVLongTool {
     Assert.assertEquals(9, UVLongTool.numBytes(Long.MAX_VALUE));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testToBytes() {
     Assert.assertArrayEquals(new byte[] { 0 }, UVLongTool.getBytes(0));
     Assert.assertArrayEquals(new byte[] { 1 }, UVLongTool.getBytes(1));
@@ -55,12 +55,12 @@ public class TestVLongTool {
     Assert.assertArrayEquals(UVLongTool.MAX_VALUE_BYTES, UVLongTool.getBytes(Long.MAX_VALUE));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testFromBytes() {
     Assert.assertEquals(Long.MAX_VALUE, UVLongTool.getLong(UVLongTool.MAX_VALUE_BYTES));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testFromBytesOffset() {
     Assert.assertEquals(Long.MAX_VALUE, UVLongTool.getLong(UVLongTool.MAX_VALUE_BYTES, 0));
 
@@ -82,7 +82,7 @@ public class TestVLongTool {
     Assert.assertEquals(ms, shiftedRoundTrip);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRoundTrips() {
     Random random = new Random();
     for (int i = 0; i < 10000; ++i) {
@@ -96,7 +96,7 @@ public class TestVLongTool {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testInputStreams() throws IOException {
     ByteArrayInputStream is;
     is = new ByteArrayInputStream(new byte[] { 0 });
diff --git a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestDeleteRow.java b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestDeleteRow.java
index 516ce9e..37598e3 100644
--- a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestDeleteRow.java
+++ b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestDeleteRow.java
@@ -30,7 +30,7 @@ import org.junit.experimental.categories.Category;
 @Category({RestTests.class, MediumTests.class})
 public class TestDeleteRow extends RowResourceBase {
 
-  @Test
+  @Test (timeout=60000)
   public void testDeleteNonExistentColumn() throws Exception {
     Response response = putValueJson(TABLE, ROW_1, COLUMN_1, VALUE_1);
     assertEquals(response.getCode(), 200);
@@ -56,7 +56,7 @@ public class TestDeleteRow extends RowResourceBase {
     assertEquals(200, getValueJson(TABLE, ROW_1, COLUMN_1).getCode());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testDeleteXML() throws IOException, JAXBException {
     Response response = putValueXML(TABLE, ROW_1, COLUMN_1, VALUE_1);
     assertEquals(response.getCode(), 200);
diff --git a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestGZIPResponseWrapper.java b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestGZIPResponseWrapper.java
index 18beb24..41a7c43 100644
--- a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestGZIPResponseWrapper.java
+++ b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestGZIPResponseWrapper.java
@@ -46,7 +46,7 @@ public class TestGZIPResponseWrapper {
   /**
    * wrapper should set all headers except "content-length"
    */
-  @Test
+  @Test (timeout=180000)
   public void testHeader() throws IOException {
     wrapper.setStatus(200);
     verify(response).setStatus(200);
@@ -72,7 +72,7 @@ public class TestGZIPResponseWrapper {
     verify(response).flushBuffer();
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testResetBuffer() throws IOException {
     when(response.isCommitted()).thenReturn(false);
     ServletOutputStream out = mock(ServletOutputStream.class);
@@ -89,7 +89,7 @@ public class TestGZIPResponseWrapper {
     assertNotNull(wrapper.getWriter());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testReset() throws IOException {
     when(response.isCommitted()).thenReturn(false);
     ServletOutputStream out = mock(ServletOutputStream.class);
@@ -106,7 +106,7 @@ public class TestGZIPResponseWrapper {
     assertEquals(out.getClass(), servletOutput.getClass());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSendError() throws IOException {
     wrapper.sendError(404);
     verify(response).sendError(404);
diff --git a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestGetAndPutResource.java b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestGetAndPutResource.java
index a5326af..3fd61b3 100644
--- a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestGetAndPutResource.java
+++ b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestGetAndPutResource.java
@@ -49,7 +49,7 @@ public class TestGetAndPutResource extends RowResourceBase {
   private static final MetricsAssertHelper METRICS_ASSERT =
       CompatibilityFactory.getInstance(MetricsAssertHelper.class);
 
-  @Test
+  @Test (timeout=60000)
   public void testForbidden() throws IOException, JAXBException {
     conf.set("hbase.rest.readonly", "true");
 
@@ -84,7 +84,7 @@ public class TestGetAndPutResource extends RowResourceBase {
     assertEquals(response.getCode(), 200);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSingleCellGetPutXML() throws IOException, JAXBException {
     Response response = getValueXML(TABLE, ROW_1, COLUMN_1);
     assertEquals(response.getCode(), 404);
@@ -105,7 +105,7 @@ public class TestGetAndPutResource extends RowResourceBase {
     assertEquals(response.getCode(), 200);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSingleCellGetPutPB() throws IOException, JAXBException {
     Response response = getValuePB(TABLE, ROW_1, COLUMN_1);
     assertEquals(response.getCode(), 404);
@@ -128,7 +128,7 @@ public class TestGetAndPutResource extends RowResourceBase {
     assertEquals(response.getCode(), 200);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSingleCellGetPutBinary() throws IOException {
     final String path = "/" + TABLE + "/" + ROW_3 + "/" + COLUMN_1;
     final byte[] body = Bytes.toBytes(VALUE_3);
@@ -153,7 +153,7 @@ public class TestGetAndPutResource extends RowResourceBase {
     assertEquals(response.getCode(), 200);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSingleCellGetJSON() throws IOException, JAXBException {
     final String path = "/" + TABLE + "/" + ROW_4 + "/" + COLUMN_1;
     Response response = client.put(path, Constants.MIMETYPE_BINARY,
@@ -167,7 +167,7 @@ public class TestGetAndPutResource extends RowResourceBase {
     assertEquals(response.getCode(), 200);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testLatestCellGetJSON() throws IOException, JAXBException {
     final String path = "/" + TABLE + "/" + ROW_4 + "/" + COLUMN_1;
     CellSetModel cellSetModel = new CellSetModel();
@@ -197,7 +197,7 @@ public class TestGetAndPutResource extends RowResourceBase {
     assertEquals(response.getCode(), 200);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testURLEncodedKey() throws IOException, JAXBException {
     String urlKey = "http://example.com/foo";
     StringBuilder path = new StringBuilder();
@@ -214,7 +214,7 @@ public class TestGetAndPutResource extends RowResourceBase {
     checkValueXML(path.toString(), TABLE, urlKey, COLUMN_1, VALUE_1);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testNoSuchCF() throws IOException, JAXBException {
     final String goodPath = "/" + TABLE + "/" + ROW_1 + "/" + CFA+":";
     final String badPath = "/" + TABLE + "/" + ROW_1 + "/" + "BAD";
@@ -229,7 +229,7 @@ public class TestGetAndPutResource extends RowResourceBase {
       200);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMultiCellGetPutXML() throws IOException, JAXBException {
     String path = "/" + TABLE + "/fakerow";  // deliberate nonexistent row
 
@@ -268,7 +268,7 @@ public class TestGetAndPutResource extends RowResourceBase {
     assertEquals(response.getCode(), 200);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMultiCellGetPutPB() throws IOException {
     String path = "/" + TABLE + "/fakerow";  // deliberate nonexistent row
 
@@ -305,7 +305,7 @@ public class TestGetAndPutResource extends RowResourceBase {
     assertEquals(response.getCode(), 200);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testStartEndRowGetPutXML() throws IOException, JAXBException {
     String[] rows = { ROW_1, ROW_2, ROW_3 };
     String[] values = { VALUE_1, VALUE_2, VALUE_3 };
@@ -333,7 +333,7 @@ public class TestGetAndPutResource extends RowResourceBase {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testInvalidCheckParam() throws IOException, JAXBException {
     CellSetModel cellSetModel = new CellSetModel();
     RowModel rowModel = new RowModel(ROW_1);
@@ -350,7 +350,7 @@ public class TestGetAndPutResource extends RowResourceBase {
     assertEquals(response.getCode(), 400);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testInvalidColumnPut() throws IOException, JAXBException {
     String dummyColumn = "doesnot:exist";
     CellSetModel cellSetModel = new CellSetModel();
@@ -368,7 +368,7 @@ public class TestGetAndPutResource extends RowResourceBase {
     assertEquals(response.getCode(), 404);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMultiCellGetJson() throws IOException, JAXBException {
     String path = "/" + TABLE + "/fakerow";  // deliberate nonexistent row
 
@@ -407,7 +407,7 @@ public class TestGetAndPutResource extends RowResourceBase {
     assertEquals(response.getCode(), 200);
   }
   
-  @Test
+  @Test (timeout=60000)
   public void testMetrics() throws IOException, JAXBException {
     final String path = "/" + TABLE + "/" + ROW_4 + "/" + COLUMN_1;
     Response response = client.put(path, Constants.MIMETYPE_BINARY,
@@ -434,7 +434,7 @@ public class TestGetAndPutResource extends RowResourceBase {
       RESTServlet.getInstance(conf, userProvider).getMetrics().getSource());
   }
   
-  @Test
+  @Test (timeout=60000)
   public void testMultiColumnGetXML() throws Exception {
     String path = "/" + TABLE + "/fakerow";
     CellSetModel cellSetModel = new CellSetModel();
@@ -482,7 +482,7 @@ public class TestGetAndPutResource extends RowResourceBase {
     return contains;
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSuffixGlobbingXMLWithNewScanner() throws IOException, JAXBException {
     String path = "/" + TABLE + "/fakerow";  // deliberate nonexistent row
 
@@ -528,7 +528,7 @@ public class TestGetAndPutResource extends RowResourceBase {
     assertEquals(response.getCode(), 200);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSuffixGlobbingXML() throws IOException, JAXBException {
     String path = "/" + TABLE + "/fakerow";  // deliberate nonexistent row
 
diff --git a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestGzipFilter.java b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestGzipFilter.java
index 42d355d..b38a71e 100644
--- a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestGzipFilter.java
+++ b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestGzipFilter.java
@@ -82,7 +82,7 @@ public class TestGzipFilter {
     TEST_UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGzipFilter() throws Exception {
     String path = "/" + TABLE + "/" + ROW_1 + "/" + COLUMN_1;
 
@@ -125,7 +125,7 @@ public class TestGzipFilter {
     testScannerResultCodes();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testErrorNotGzipped() throws Exception {
     Header[] headers = new Header[2];
     headers[0] = new Header("Accept", Constants.MIMETYPE_BINARY);
diff --git a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestMultiRowResource.java b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestMultiRowResource.java
index c7da65a..ba3fe69 100644
--- a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestMultiRowResource.java
+++ b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestMultiRowResource.java
@@ -99,7 +99,7 @@ public class TestMultiRowResource {
   }
 
 
-  @Test
+  @Test (timeout=60000)
   public void testMultiCellGetJSON() throws IOException, JAXBException {
     String row_5_url = "/" + TABLE + "/" + ROW_1 + "/" + COLUMN_1;
     String row_6_url = "/" + TABLE + "/" + ROW_2 + "/" + COLUMN_2;
@@ -126,7 +126,7 @@ public class TestMultiRowResource {
 
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMultiCellGetXML() throws IOException, JAXBException {
     String row_5_url = "/" + TABLE + "/" + ROW_1 + "/" + COLUMN_1;
     String row_6_url = "/" + TABLE + "/" + ROW_2 + "/" + COLUMN_2;
@@ -153,7 +153,7 @@ public class TestMultiRowResource {
 
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMultiCellGetJSONNotFound() throws IOException, JAXBException {
     String row_5_url = "/" + TABLE + "/" + ROW_1 + "/" + COLUMN_1;
 
diff --git a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestResourceFilter.java b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestResourceFilter.java
index 11d465f..2074028 100644
--- a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestResourceFilter.java
+++ b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestResourceFilter.java
@@ -53,7 +53,7 @@ public class TestResourceFilter {
     TEST_UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testFilter() throws Exception {
     String path = "/status/cluster";
     Response response = client.get(path);
diff --git a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestScannerResource.java b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestScannerResource.java
index 4f4f698..aa71130 100644
--- a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestScannerResource.java
+++ b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestScannerResource.java
@@ -193,7 +193,7 @@ public class TestScannerResource {
     TEST_UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSimpleScannerXML() throws IOException, JAXBException {
     final int BATCH_SIZE = 5;
     // new scanner
@@ -240,7 +240,7 @@ public class TestScannerResource {
     assertEquals(response.getCode(), 200);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSimpleScannerPB() throws IOException {
     final int BATCH_SIZE = 10;
     // new scanner
@@ -284,7 +284,7 @@ public class TestScannerResource {
     assertEquals(response.getCode(), 200);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSimpleScannerBinary() throws IOException {
     // new scanner
     ScannerModel model = new ScannerModel();
@@ -340,7 +340,7 @@ public class TestScannerResource {
     assertEquals(response.getCode(), 200);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testFullTableScan() throws IOException {
     ScannerModel model = new ScannerModel();
     model.addColumn(Bytes.toBytes(COLUMN_1));
@@ -351,7 +351,7 @@ public class TestScannerResource {
     assertEquals(fullTableScan(model), expectedRows2);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testTableDoesNotExist() throws IOException, JAXBException {
     ScannerModel model = new ScannerModel();
     StringWriter writer = new StringWriter();
diff --git a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestScannersWithFilters.java b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestScannersWithFilters.java
index 3acddc1..c1fd158 100644
--- a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestScannersWithFilters.java
+++ b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestScannersWithFilters.java
@@ -343,7 +343,7 @@ public class TestScannersWithFilters {
       " rows", expectedRows, j);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testNoFilter() throws Exception {
     // No filter
     long expectedRows = numRows;
@@ -359,7 +359,7 @@ public class TestScannersWithFilters {
     verifyScan(s, expectedRows, expectedKeys/2);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testPrefixFilter() throws Exception {
     // Grab rows from group one (half of total)
     long expectedRows = numRows / 2;
@@ -369,7 +369,7 @@ public class TestScannersWithFilters {
     verifyScan(s, expectedRows, expectedKeys);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testPageFilter() throws Exception {
     // KVs in first 6 rows
     KeyValue [] expectedKVs = {
@@ -454,7 +454,7 @@ public class TestScannersWithFilters {
     verifyScanFull(s, Arrays.copyOf(expectedKVs, 6));    
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testInclusiveStopFilter() throws Exception {
     // Grab rows from group one
     
@@ -487,7 +487,7 @@ public class TestScannersWithFilters {
     verifyScan(s, expectedRows, expectedKeys);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testQualifierFilter() throws Exception {
     // Match two keys (one from each family) in half the rows
     long expectedRows = numRows / 2;
@@ -643,7 +643,7 @@ public class TestScannersWithFilters {
     verifyScanFull(s, kvs);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testRowFilter() throws Exception {
     // Match a single row, all keys
     long expectedRows = 1;
@@ -787,7 +787,7 @@ public class TestScannersWithFilters {
     verifyScanFull(s, kvs);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testValueFilter() throws Exception {
     // Match group one rows
     long expectedRows = numRows / 2;
@@ -910,7 +910,7 @@ public class TestScannersWithFilters {
     verifyScanFull(s, kvs);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSkipFilter() throws Exception {
     // Test for qualifier regex: "testQualifierOne-2"
     // Should only get rows from second group, and all keys
@@ -945,7 +945,7 @@ public class TestScannersWithFilters {
     verifyScanFull(s, kvs);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testFilterList() throws Exception {
     // Test getting a single row, single key using Row, Qualifier, and Value 
     // regular expression and substring filters
@@ -981,7 +981,7 @@ public class TestScannersWithFilters {
     verifyScanNoEarlyOut(s, numRows, colsPerRow);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testFirstKeyOnlyFilter() throws Exception {
     Scan s = new Scan();
     s.setFilter(new FirstKeyOnlyFilter());
diff --git a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestScannersWithLabels.java b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestScannersWithLabels.java
index 41c036d..54c79cc 100644
--- a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestScannersWithLabels.java
+++ b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestScannersWithLabels.java
@@ -183,7 +183,7 @@ public class TestScannersWithLabels {
       throw new IOException(t);
     }
   }
-  @Test
+  @Test (timeout=60000)
   public void testSimpleScannerXMLWithLabelsThatReceivesNoData() throws IOException, JAXBException {
     final int BATCH_SIZE = 5;
     // new scanner
@@ -208,7 +208,7 @@ public class TestScannersWithLabels {
     assertEquals(Constants.MIMETYPE_XML, response.getHeader("content-type"));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSimpleScannerXMLWithLabelsThatReceivesData() throws IOException, JAXBException {
     // new scanner
     ScannerModel model = new ScannerModel();
diff --git a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestSchemaResource.java b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestSchemaResource.java
index 17bb733..13a0e95 100644
--- a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestSchemaResource.java
+++ b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestSchemaResource.java
@@ -90,7 +90,7 @@ public class TestSchemaResource {
       .unmarshal(new ByteArrayInputStream(content));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testTableCreateAndDeleteXML() throws IOException, JAXBException {
     String schemaPath = "/" + TABLE1 + "/schema";
     TableSchemaModel model;
@@ -137,7 +137,7 @@ public class TestSchemaResource {
     assertFalse(admin.tableExists(TableName.valueOf(TABLE1)));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testTableCreateAndDeletePB() throws IOException, JAXBException {
     String schemaPath = "/" + TABLE2 + "/schema";
     TableSchemaModel model;
diff --git a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestStatusResource.java b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestStatusResource.java
index 5fdc631..a560819 100644
--- a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestStatusResource.java
+++ b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestStatusResource.java
@@ -105,7 +105,7 @@ public class TestStatusResource {
     TEST_UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGetClusterStatusXML() throws IOException, JAXBException {
     Response response = client.get("/status/cluster", Constants.MIMETYPE_XML);
     assertEquals(response.getCode(), 200);
@@ -116,7 +116,7 @@ public class TestStatusResource {
     validate(model);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGetClusterStatusPB() throws IOException {
     Response response = client.get("/status/cluster", Constants.MIMETYPE_PROTOBUF);
     assertEquals(response.getCode(), 200);
diff --git a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestTableResource.java b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestTableResource.java
index b0b8fef..27dd3e3 100644
--- a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestTableResource.java
+++ b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestTableResource.java
@@ -196,14 +196,14 @@ public class TestTableResource {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testTableListText() throws IOException {
     Response response = client.get("/", Constants.MIMETYPE_TEXT);
     assertEquals(response.getCode(), 200);
     assertEquals(Constants.MIMETYPE_TEXT, response.getHeader("content-type"));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testTableListXML() throws IOException, JAXBException {
     Response response = client.get("/", Constants.MIMETYPE_XML);
     assertEquals(response.getCode(), 200);
@@ -214,14 +214,14 @@ public class TestTableResource {
     checkTableList(model);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testTableListJSON() throws IOException {
     Response response = client.get("/", Constants.MIMETYPE_JSON);
     assertEquals(response.getCode(), 200);
     assertEquals(Constants.MIMETYPE_JSON, response.getHeader("content-type"));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testTableListPB() throws IOException, JAXBException {
     Response response = client.get("/", Constants.MIMETYPE_PROTOBUF);
     assertEquals(response.getCode(), 200);
@@ -237,14 +237,14 @@ public class TestTableResource {
     checkTableList(model);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testTableInfoText() throws IOException {
     Response response = client.get("/" + TABLE + "/regions", Constants.MIMETYPE_TEXT);
     assertEquals(response.getCode(), 200);
     assertEquals(Constants.MIMETYPE_TEXT, response.getHeader("content-type"));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testTableInfoXML() throws IOException, JAXBException {
     Response response = client.get("/" + TABLE + "/regions",  Constants.MIMETYPE_XML);
     assertEquals(response.getCode(), 200);
@@ -255,14 +255,14 @@ public class TestTableResource {
     checkTableInfo(model);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testTableInfoJSON() throws IOException {
     Response response = client.get("/" + TABLE + "/regions", Constants.MIMETYPE_JSON);
     assertEquals(response.getCode(), 200);
     assertEquals(Constants.MIMETYPE_JSON, response.getHeader("content-type"));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testTableInfoPB() throws IOException, JAXBException {
     Response response = client.get("/" + TABLE + "/regions", Constants.MIMETYPE_PROTOBUF);
     assertEquals(response.getCode(), 200);
diff --git a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestTableScan.java b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestTableScan.java
index 789e9e1..6b6fa94 100644
--- a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestTableScan.java
+++ b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestTableScan.java
@@ -116,7 +116,7 @@ public class TestTableScan {
     TEST_UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSimpleScannerXML() throws IOException, JAXBException, XMLStreamException {
     // Test scanning particular columns
     StringBuilder builder = new StringBuilder();
@@ -192,7 +192,7 @@ public class TestTableScan {
     checkRowsNotNull(model);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSimpleScannerJson() throws IOException, JAXBException {
     // Test scanning particular columns with limit.
     StringBuilder builder = new StringBuilder();
@@ -252,7 +252,7 @@ public class TestTableScan {
    * An example to scan using listener in unmarshaller for XML.
    * @throws Exception the exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testScanUsingListenerUnmarshallerXML() throws Exception {
     StringBuilder builder = new StringBuilder();
     builder.append("/*");
@@ -302,7 +302,7 @@ public class TestTableScan {
 
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testStreamingJSON() throws Exception {
     // Test scanning particular columns with limit.
     StringBuilder builder = new StringBuilder();
@@ -374,7 +374,7 @@ public class TestTableScan {
     assertEquals(24, count);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSimpleScannerProtobuf() throws Exception {
     StringBuilder builder = new StringBuilder();
     builder.append("/*");
@@ -447,7 +447,7 @@ public class TestTableScan {
     return rowCount;
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testScanningUnknownColumnJson() throws IOException, JAXBException {
     // Test scanning particular columns with limit.
     StringBuilder builder = new StringBuilder();
@@ -465,7 +465,7 @@ public class TestTableScan {
     assertEquals(0, count);
   }
   
-  @Test
+  @Test (timeout=60000)
   public void testSimpleFilter() throws IOException, JAXBException {
     StringBuilder builder = new StringBuilder();
     builder = new StringBuilder();
@@ -489,7 +489,7 @@ public class TestTableScan {
     assertEquals("aab", new String(model.getRows().get(0).getCells().get(0).getValue()));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCompoundFilter() throws IOException, JAXBException {
     StringBuilder builder = new StringBuilder();
     builder = new StringBuilder();
@@ -508,7 +508,7 @@ public class TestTableScan {
     assertEquals("abc", new String(model.getRows().get(0).getCells().get(0).getValue()));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCustomFilter() throws IOException, JAXBException {
     StringBuilder builder = new StringBuilder();
     builder = new StringBuilder();
@@ -528,7 +528,7 @@ public class TestTableScan {
     assertEquals("abc", new String(model.getRows().get(0).getCells().get(0).getValue()));
   }
   
-  @Test
+  @Test (timeout=60000)
   public void testNegativeCustomFilter() throws IOException, JAXBException {
     StringBuilder builder = new StringBuilder();
     builder = new StringBuilder();
diff --git a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestVersionResource.java b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestVersionResource.java
index 34973c2..f8489ae 100644
--- a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestVersionResource.java
+++ b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/TestVersionResource.java
@@ -93,7 +93,7 @@ public class TestVersionResource {
       .getImplementationVersion());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGetStargateVersionText() throws IOException {
     Response response = client.get("/version", Constants.MIMETYPE_TEXT);
     assertTrue(response.getCode() == 200);
@@ -111,7 +111,7 @@ public class TestVersionResource {
       .getImplementationVersion()));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGetStargateVersionXML() throws IOException, JAXBException {
     Response response = client.get("/version", Constants.MIMETYPE_XML);
     assertTrue(response.getCode() == 200);
@@ -123,14 +123,14 @@ public class TestVersionResource {
     LOG.info("success retrieving Stargate version as XML");
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGetStargateVersionJSON() throws IOException {
     Response response = client.get("/version", Constants.MIMETYPE_JSON);
     assertTrue(response.getCode() == 200);
     assertEquals(Constants.MIMETYPE_JSON, response.getHeader("content-type"));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGetStargateVersionPB() throws IOException {
     Response response = client.get("/version", Constants.MIMETYPE_PROTOBUF);
     assertTrue(response.getCode() == 200);
@@ -146,14 +146,14 @@ public class TestVersionResource {
     validate(model);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGetStorageClusterVersionText() throws IOException {
     Response response = client.get("/version/cluster", Constants.MIMETYPE_TEXT);
     assertTrue(response.getCode() == 200);
     assertEquals(Constants.MIMETYPE_TEXT, response.getHeader("content-type"));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGetStorageClusterVersionXML() throws IOException,
       JAXBException {
     Response response = client.get("/version/cluster",Constants.MIMETYPE_XML);
@@ -168,7 +168,7 @@ public class TestVersionResource {
     LOG.info("success retrieving storage cluster version as XML");
   }
 
-  @Test
+  @Test (timeout=60000)
   public void doTestGetStorageClusterVersionJSON() throws IOException {
     Response response = client.get("/version/cluster", Constants.MIMETYPE_JSON);
     assertTrue(response.getCode() == 200);
diff --git a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/client/TestRemoteAdminRetries.java b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/client/TestRemoteAdminRetries.java
index 7c888e0..a905484 100644
--- a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/client/TestRemoteAdminRetries.java
+++ b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/client/TestRemoteAdminRetries.java
@@ -70,7 +70,7 @@ public class TestRemoteAdminRetries {
     remoteAdmin = new RemoteAdmin(client, TEST_UTIL.getConfiguration(), "MyTable");
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testFailingGetRestVersion() throws Exception  {
     testTimedOutGetCall(new CallExecutor() {
       @Override
@@ -80,7 +80,7 @@ public class TestRemoteAdminRetries {
     });
   }
   
-  @Test
+  @Test (timeout=180000)
   public void testFailingGetClusterStatus() throws Exception  {
     testTimedOutGetCall(new CallExecutor() {
       @Override
@@ -90,7 +90,7 @@ public class TestRemoteAdminRetries {
     });
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testFailingGetClusterVersion() throws Exception {
     testTimedOutGetCall(new CallExecutor() {
       @Override
@@ -100,7 +100,7 @@ public class TestRemoteAdminRetries {
     });
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testFailingGetTableAvailable() throws Exception {
     testTimedOutCall(new CallExecutor() {
       @Override
@@ -110,7 +110,7 @@ public class TestRemoteAdminRetries {
     });
   }
 
-  @Test
+  @Test (timeout=180000)
   @SuppressWarnings("deprecation")
   public void testFailingCreateTable() throws Exception {
     testTimedOutCall(new CallExecutor() {
@@ -122,7 +122,7 @@ public class TestRemoteAdminRetries {
     verify(client, times(RETRIES)).put(anyString(), anyString(), any(byte[].class));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testFailingDeleteTable() throws Exception {
     testTimedOutCall(new CallExecutor() {
       @Override
@@ -133,7 +133,7 @@ public class TestRemoteAdminRetries {
     verify(client, times(RETRIES)).delete(anyString());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testFailingGetTableList() throws Exception {
     testTimedOutGetCall(new CallExecutor() {
       @Override
diff --git a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/client/TestRemoteHTableRetries.java b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/client/TestRemoteHTableRetries.java
index 5b18a6a..b7deb6d 100644
--- a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/client/TestRemoteHTableRetries.java
+++ b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/client/TestRemoteHTableRetries.java
@@ -88,7 +88,7 @@ public class TestRemoteHTableRetries {
     remoteTable.close();
   }
   
-  @Test
+  @Test (timeout=180000)
   public void testDelete() throws Exception {
     testTimedOutCall(new CallExecutor() {
       @Override
@@ -100,7 +100,7 @@ public class TestRemoteHTableRetries {
     verify(client, times(RETRIES)).delete(anyString());
   }
   
-  @Test
+  @Test (timeout=180000)
   public void testGet() throws Exception {
     testTimedOutGetCall(new CallExecutor() {
       @Override
@@ -110,7 +110,7 @@ public class TestRemoteHTableRetries {
     });
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSingleRowPut() throws Exception {
     testTimedOutCall(new CallExecutor() {
       @Override
@@ -121,7 +121,7 @@ public class TestRemoteHTableRetries {
     verify(client, times(RETRIES)).put(anyString(), anyString(), any(byte[].class));
   }
   
-  @Test
+  @Test (timeout=180000)
   public void testMultiRowPut() throws Exception {
     testTimedOutCall(new CallExecutor() {
       @Override
@@ -134,7 +134,7 @@ public class TestRemoteHTableRetries {
     verify(client, times(RETRIES)).put(anyString(), anyString(), any(byte[].class));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testGetScanner() throws Exception {
     testTimedOutCall(new CallExecutor() {
       @Override
@@ -145,7 +145,7 @@ public class TestRemoteHTableRetries {
     verify(client, times(RETRIES)).post(anyString(), anyString(), any(byte[].class));
   }
   
-  @Test
+  @Test (timeout=180000)
   public void testCheckAndPut() throws Exception {
     testTimedOutCall(new CallExecutor() {
       @Override
@@ -158,7 +158,7 @@ public class TestRemoteHTableRetries {
     verify(client, times(RETRIES)).put(anyString(), anyString(), any(byte[].class));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testCheckAndDelete() throws Exception {
     testTimedOutCall(new CallExecutor() {
       @Override
diff --git a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/client/TestRemoteTable.java b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/client/TestRemoteTable.java
index 297162b..0ea5f3e 100644
--- a/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/client/TestRemoteTable.java
+++ b/hbase-rest/src/test/java/org/apache/hadoop/hbase/rest/client/TestRemoteTable.java
@@ -125,7 +125,7 @@ public class TestRemoteTable {
     TEST_UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGetTableDescriptor() throws IOException {
     Table table = null;
     try {
@@ -137,7 +137,7 @@ public class TestRemoteTable {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGet() throws IOException {
     Get get = new Get(ROW_1);
     Result result = remoteTable.get(get);
@@ -240,7 +240,7 @@ public class TestRemoteTable {
     assertEquals(2, count);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMultiGet() throws Exception {
     ArrayList<Get> gets = new ArrayList<Get>();
     gets.add(new Get(ROW_1));
@@ -279,7 +279,7 @@ public class TestRemoteTable {
     assertEquals(2, results.length);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testPut() throws IOException {
     Put put = new Put(ROW_3);
     put.add(COLUMN_1, QUALIFIER_1, VALUE_1);
@@ -324,7 +324,7 @@ public class TestRemoteTable {
     assertTrue(Bytes.equals(Bytes.toBytes("TestRemoteTable"), remoteTable.getTableName()));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testDelete() throws IOException {
     Put put = new Put(ROW_3);
     put.add(COLUMN_1, QUALIFIER_1, VALUE_1);
@@ -386,7 +386,7 @@ public class TestRemoteTable {
   /**
    * Test RemoteHTable.Scanner 
    */
-  @Test
+  @Test (timeout=60000)
   public void testScanner() throws IOException {
     List<Put> puts = new ArrayList<Put>();
     Put put = new Put(ROW_1);
@@ -448,7 +448,7 @@ public class TestRemoteTable {
 
   }
   
-  @Test
+  @Test (timeout=60000)
   public void testCheckAndDelete() throws IOException {
     Get get = new Get(ROW_1);
     Result result = remoteTable.get(get);
@@ -477,7 +477,7 @@ public class TestRemoteTable {
   /**
    * Test RemoteHable.Scanner.iterator method  
    */
-  @Test
+  @Test (timeout=60000)
   public void testIteratorScaner() throws IOException {
     List<Put> puts = new ArrayList<Put>();
     Put put = new Put(ROW_1);
@@ -508,7 +508,7 @@ public class TestRemoteTable {
   /**
    * Test a some methods of class Response.
    */
-  @Test
+  @Test (timeout=60000)
   public void testResponse(){
     Response response = new Response(200);
     assertEquals(200, response.getCode());
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestAcidGuarantees.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestAcidGuarantees.java
index 5659f6b..0d53835 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestAcidGuarantees.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestAcidGuarantees.java
@@ -337,7 +337,7 @@ public class TestAcidGuarantees implements Tool {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGetAtomicity() throws Exception {
     util.startMiniCluster(1);
     try {
@@ -347,7 +347,7 @@ public class TestAcidGuarantees implements Tool {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testScanAtomicity() throws Exception {
     util.startMiniCluster(1);
     try {
@@ -357,7 +357,7 @@ public class TestAcidGuarantees implements Tool {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMixedAtomicity() throws Exception {
     util.startMiniCluster(1);
     try {
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestCheckTestClasses.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestCheckTestClasses.java
index 06b98f7..9e4fe09 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestCheckTestClasses.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestCheckTestClasses.java
@@ -37,7 +37,7 @@ public class TestCheckTestClasses {
    * Throws an assertion if we find a test class without category (small/medium/large/integration).
    * List all the test classes without category in the assertion message.
    */
-  @Test
+  @Test (timeout=180000)
   public void checkClasses() throws Exception {
     List<Class<?>> badClasses = new java.util.ArrayList<Class<?>>();
     ClassTestFinder classFinder = new ClassTestFinder();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestClusterBootOrder.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestClusterBootOrder.java
index 4097efb..f2f6474 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestClusterBootOrder.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestClusterBootOrder.java
@@ -99,7 +99,7 @@ public class TestClusterBootOrder {
    * Tests launching the cluster by first starting regionserver, and then the master
    * to ensure that it does not matter which is started first.
    */
-  @Test
+  @Test (timeout=60000)
   public void testBootRegionServerFirst() throws Exception {
     startRegionServer();
     startMaster();
@@ -110,7 +110,7 @@ public class TestClusterBootOrder {
    * Tests launching the cluster by first starting master, and then the regionserver
    * to ensure that it does not matter which is started first.
    */
-  @Test
+  @Test (timeout=60000)
   public void testBootMasterFirst() throws Exception {
     startMaster();
     startRegionServer();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestFSTableDescriptorForceCreation.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestFSTableDescriptorForceCreation.java
index 07b9cbd..e8a5e11 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestFSTableDescriptorForceCreation.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestFSTableDescriptorForceCreation.java
@@ -35,7 +35,7 @@ import org.junit.experimental.categories.Category;
 public class TestFSTableDescriptorForceCreation {
   private static final HBaseTestingUtility UTIL = new HBaseTestingUtility();
 
-  @Test
+  @Test (timeout=180000)
   public void testShouldCreateNewTableDescriptorIfForcefulCreationIsFalse()
       throws IOException {
     final String name = "newTable2";
@@ -47,7 +47,7 @@ public class TestFSTableDescriptorForceCreation {
     assertTrue("Should create new table descriptor", fstd.createTableDescriptor(htd, false));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testShouldNotCreateTheSameTableDescriptorIfForcefulCreationIsFalse()
       throws IOException {
     final String name = "testAlreadyExists";
@@ -60,7 +60,7 @@ public class TestFSTableDescriptorForceCreation {
     assertFalse("Should not create new table descriptor", fstd.createTableDescriptor(htd, false));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testShouldAllowForcefulCreationOfAlreadyExistingTableDescriptor()
       throws Exception {
     final String name = "createNewTableNew2";
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestGlobalMemStoreSize.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestGlobalMemStoreSize.java
index d8178f0..871ada5 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestGlobalMemStoreSize.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestGlobalMemStoreSize.java
@@ -61,7 +61,7 @@ public class TestGlobalMemStoreSize {
    * region's mem store size
    * @throws Exception 
    */
-  @Test
+  @Test (timeout=60000)
   public void testGlobalMemStore() throws Exception {
     // Start the cluster
     LOG.info("Starting cluster");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestHBaseTestingUtility.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestHBaseTestingUtility.java
index f3e3dc2..f72e481 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestHBaseTestingUtility.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestHBaseTestingUtility.java
@@ -128,7 +128,7 @@ public class TestHBaseTestingUtility {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMiniClusterBindToWildcard() throws Exception {
     HBaseTestingUtility hbt = new HBaseTestingUtility();
     hbt.getConfiguration().set("hbase.regionserver.ipc.address", "0.0.0.0");
@@ -140,7 +140,7 @@ public class TestHBaseTestingUtility {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMiniClusterWithSSLOn() throws Exception {
     final String BASEDIR = System.getProperty("test.build.dir",
         "target/test-dir") + "/" + TestHBaseTestingUtility.class.getSimpleName();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestHColumnDescriptorDefaultVersions.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestHColumnDescriptorDefaultVersions.java
index 4fa945a..8fe3779 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestHColumnDescriptorDefaultVersions.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestHColumnDescriptorDefaultVersions.java
@@ -72,7 +72,7 @@ public class TestHColumnDescriptorDefaultVersions {
     TEST_UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCreateTableWithDefault() throws IOException {
     Admin admin = TEST_UTIL.getHBaseAdmin();
     // Create a table with one family
@@ -89,7 +89,7 @@ public class TestHColumnDescriptorDefaultVersions {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCreateTableWithDefaultFromConf() throws Exception {
     TEST_UTIL.shutdownMiniCluster();
     TEST_UTIL.getConfiguration().setInt("hbase.column.max.version", 3);
@@ -111,7 +111,7 @@ public class TestHColumnDescriptorDefaultVersions {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCreateTableWithSetVersion() throws Exception {
     TEST_UTIL.shutdownMiniCluster();
     TEST_UTIL.getConfiguration().setInt("hbase.column.max.version", 3);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestHDFSBlocksDistribution.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestHDFSBlocksDistribution.java
index 2329fc2..8efa841 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestHDFSBlocksDistribution.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestHDFSBlocksDistribution.java
@@ -30,7 +30,7 @@ import static junit.framework.Assert.assertEquals;
 
 @Category({MiscTests.class, SmallTests.class})
 public class TestHDFSBlocksDistribution {
-  @Test
+  @Test (timeout=180000)
   public void testAddHostsAndBlockWeight() throws Exception {
     HDFSBlocksDistribution distribution = new HDFSBlocksDistribution();
     distribution.addHostsAndBlockWeight(null, 100);
@@ -57,7 +57,7 @@ public class TestHDFSBlocksDistribution {
 
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testAdd() throws Exception {
     HDFSBlocksDistribution distribution = new HDFSBlocksDistribution();
     distribution.add(new MockHDFSBlocksDistribution());
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestHRegionLocation.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestHRegionLocation.java
index 2ad5f9a..fe39722 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestHRegionLocation.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestHRegionLocation.java
@@ -35,7 +35,7 @@ public class TestHRegionLocation {
    * port -- even if they are carrying different regions.  Verify that is indeed
    * the case.
    */
-  @Test
+  @Test (timeout=180000)
   public void testHashAndEqualsCode() {
     ServerName hsa1 = ServerName.valueOf("localhost", 1234, -1L);
     HRegionLocation hrl1 = new HRegionLocation(HRegionInfo.FIRST_META_REGIONINFO, hsa1);
@@ -56,14 +56,14 @@ public class TestHRegionLocation {
     assertTrue(hrl4.equals(hrl5));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testToString() {
     ServerName hsa1 = ServerName.valueOf("localhost", 1234, -1L);
     HRegionLocation hrl1 = new HRegionLocation(HRegionInfo.FIRST_META_REGIONINFO, hsa1);
     System.out.println(hrl1.toString());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testCompareTo() {
     ServerName hsa1 = ServerName.valueOf("localhost", 1234, -1L);
     HRegionLocation hsl1 =
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestIOFencing.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestIOFencing.java
index f44eb7b..776de12 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestIOFencing.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestIOFencing.java
@@ -222,7 +222,7 @@ public class TestIOFencing {
    * a new regionserver altogether.  This fakes the double assignment case where region in one
    * location changes the files out from underneath a region being served elsewhere.
    */
-  @Test
+  @Test (timeout=60000)
   public void testFencingAroundCompaction() throws Exception {
     doTest(BlockCompactionsInPrepRegion.class, false);
     doTest(BlockCompactionsInPrepRegion.class, true);
@@ -234,7 +234,7 @@ public class TestIOFencing {
    * a new regionserver altogether.  This fakes the double assignment case where region in one
    * location changes the files out from underneath a region being served elsewhere.
    */
-  @Test
+  @Test (timeout=60000)
   public void testFencingAroundCompactionAfterWALSync() throws Exception {
     doTest(BlockCompactionsInCompletionRegion.class, false);
     doTest(BlockCompactionsInCompletionRegion.class, true);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestIPv6NIOServerSocketChannel.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestIPv6NIOServerSocketChannel.java
index 6b5ad98..18e74b9 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestIPv6NIOServerSocketChannel.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestIPv6NIOServerSocketChannel.java
@@ -105,7 +105,7 @@ public class TestIPv6NIOServerSocketChannel {
    * Checks whether we are effected by the JDK issue on windows, and if so
    * ensures that we are running with preferIPv4Stack=true.
    */
-  @Test
+  @Test (timeout=180000)
   public void testServerSocket() throws IOException {
     byte[] addr = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1 };
     InetAddress inetAddr = InetAddress.getByAddress(addr);
@@ -143,7 +143,7 @@ public class TestIPv6NIOServerSocketChannel {
    * Tests whether every InetAddress we obtain by resolving can open a
    * ServerSocketChannel.
    */
-  @Test
+  @Test (timeout=180000)
   public void testServerSocketFromLocalhostResolution() throws IOException {
     InetAddress[] addrs = InetAddress.getAllByName("localhost");
     for (InetAddress addr : addrs) {
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestInfoServers.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestInfoServers.java
index a72b151..ed15e2f 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestInfoServers.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestInfoServers.java
@@ -64,7 +64,7 @@ public class TestInfoServers {
   /**
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testInfoServersRedirect() throws Exception {
     // give the cluster time to start up
     UTIL.getConnection().getTable(TableName.META_TABLE_NAME).close();
@@ -84,7 +84,7 @@ public class TestInfoServers {
    * TestMasterStatusServlet, but those are true unit tests
    * whereas this uses a cluster.
    */
-  @Test
+  @Test (timeout=60000)
   public void testInfoServersStatusPages() throws Exception {
     // give the cluster time to start up
     UTIL.getConnection().getTable(TableName.META_TABLE_NAME).close();
@@ -97,7 +97,7 @@ public class TestInfoServers {
         "/rs-status"), "meta");
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMasterServerReadOnly() throws Exception {
     TableName tableName = TableName.valueOf("testMasterServerReadOnly");
     byte[] cf = Bytes.toBytes("d");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestJMXListener.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestJMXListener.java
index ed141a6..ef1b392 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestJMXListener.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestJMXListener.java
@@ -62,7 +62,7 @@ public class TestJMXListener {
     UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testStart() throws Exception {
     JMXConnector connector = JMXConnectorFactory.connect(
       JMXListener.buildJMXServiceURL(connectorPort,connectorPort));
@@ -78,7 +78,7 @@ public class TestJMXListener {
   //shutdown hbase only. then try connect, IOException expected
   @Rule
   public ExpectedException expectedEx = ExpectedException.none();
-  @Test
+  @Test (timeout=60000)
   public void testStop() throws Exception {
     MiniHBaseCluster cluster = UTIL.getHBaseCluster();
     LOG.info("shutdown hbase cluster...");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestLocalHBaseCluster.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestLocalHBaseCluster.java
index bbf4f32..bf23320 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestLocalHBaseCluster.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestLocalHBaseCluster.java
@@ -41,7 +41,7 @@ public class TestLocalHBaseCluster {
    * HBaseTestingUtility facilities for creating a LocalHBaseCluster with
    * custom master and regionserver classes.
    */
-  @Test
+  @Test (timeout=60000)
   public void testLocalHBaseCluster() throws Exception {
     TEST_UTIL.startMiniCluster(1, 1, null, MyHMaster.class, MyHRegionServer.class);
     // Can we cast back to our master class?
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestMetaTableAccessor.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestMetaTableAccessor.java
index eefb974..751a1bd 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestMetaTableAccessor.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestMetaTableAccessor.java
@@ -291,7 +291,7 @@ public class TestMetaTableAccessor {
       pair.getFirst().getEncodedName());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testParseReplicaIdFromServerColumn() {
     String column1 = HConstants.SERVER_QUALIFIER_STR;
     assertEquals(0, MetaTableAccessor.parseReplicaIdFromServerColumn(Bytes.toBytes(column1)));
@@ -307,7 +307,7 @@ public class TestMetaTableAccessor {
     assertEquals(-1, MetaTableAccessor.parseReplicaIdFromServerColumn(Bytes.toBytes(column6)));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMetaReaderGetColumnMethods() {
     Assert.assertArrayEquals(HConstants.SERVER_QUALIFIER, MetaTableAccessor.getServerColumn(0));
     Assert.assertArrayEquals(Bytes.toBytes(HConstants.SERVER_QUALIFIER_STR
@@ -327,7 +327,7 @@ public class TestMetaTableAccessor {
       MetaTableAccessor.getSeqNumColumn(42));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMetaLocationsForRegionReplicas() throws IOException {
     ServerName serverName0 = ServerName.valueOf("foo", 60010, random.nextLong());
     ServerName serverName1 = ServerName.valueOf("bar", 60010, random.nextLong());
@@ -404,7 +404,7 @@ public class TestMetaTableAccessor {
     assertEquals(0, startCodeCell.getValueLength());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMetaLocationForRegionReplicasIsAddedAtTableCreation() throws IOException {
     long regionId = System.currentTimeMillis();
     HRegionInfo primary = new HRegionInfo(TableName.valueOf("table_foo"),
@@ -422,7 +422,7 @@ public class TestMetaTableAccessor {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMetaLocationForRegionReplicasIsAddedAtRegionSplit() throws IOException {
     long regionId = System.currentTimeMillis();
     ServerName serverName0 = ServerName.valueOf("foo", 60010, random.nextLong());
@@ -450,7 +450,7 @@ public class TestMetaTableAccessor {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMetaLocationForRegionReplicasIsAddedAtRegionMerge() throws IOException {
     long regionId = System.currentTimeMillis();
     ServerName serverName0 = ServerName.valueOf("foo", 60010, random.nextLong());
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestMetaTableAccessorNoCluster.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestMetaTableAccessorNoCluster.java
index f70a0d7..8272930 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestMetaTableAccessorNoCluster.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestMetaTableAccessorNoCluster.java
@@ -83,7 +83,7 @@ public class TestMetaTableAccessorNoCluster {
     UTIL.shutdownMiniZKCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGetHRegionInfo() throws IOException {
     assertNull(HRegionInfo.getHRegionInfo(new Result()));
 
@@ -119,7 +119,7 @@ public class TestMetaTableAccessorNoCluster {
    * @throws IOException
    * @throws InterruptedException
    */
-  @Test
+  @Test (timeout=60000)
   public void testRideOverServerNotRunning()
       throws IOException, InterruptedException, ServiceException {
     // Need a zk watcher.
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestMetaTableLocator.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestMetaTableLocator.java
index 9943749..09f9c93 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestMetaTableLocator.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestMetaTableLocator.java
@@ -205,7 +205,7 @@ public class TestMetaTableLocator {
    * @throws KeeperException
    * @throws ServiceException
    */
-  @Test
+  @Test (timeout=60000)
   public void testGetMetaServerConnectionFails()
   throws IOException, InterruptedException, KeeperException, ServiceException {
     testVerifyMetaRegionLocationWithException(new ConnectException("Connection refused"));
@@ -225,7 +225,7 @@ public class TestMetaTableLocator {
    * @throws KeeperException
    * @throws ServiceException
    */
-  @Test
+  @Test (timeout=60000)
   public void testVerifyMetaRegionServerNotRunning()
   throws IOException, InterruptedException, KeeperException, ServiceException {
     testVerifyMetaRegionLocationWithException(new ServerNotRunningYetException("mock"));
@@ -238,7 +238,7 @@ public class TestMetaTableLocator {
    * @throws KeeperException
    * @throws ServiceException
    */
-  @Test
+  @Test (timeout=60000)
   public void testVerifyMetaRegionLocationFails()
   throws IOException, InterruptedException, KeeperException, ServiceException {
     ClusterConnection connection = Mockito.mock(ClusterConnection.class);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestMultiVersions.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestMultiVersions.java
index 278973e..adddf6a 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestMultiVersions.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestMultiVersions.java
@@ -87,7 +87,7 @@ public class TestMultiVersions {
    * up cluster running more than a single test per spin up.  Keep old tests'
    * crazyness.
    */
-  @Test
+  @Test (timeout=60000)
   public void testTimestamps() throws Exception {
     HTableDescriptor desc = new HTableDescriptor(TableName.valueOf("testTimestamps"));
     HColumnDescriptor hcd = new HColumnDescriptor(TimestampTestBase.FAMILY_NAME);
@@ -121,7 +121,7 @@ public class TestMultiVersions {
    * up cluster running more than a single test per spin up.  Keep old tests'
    * crazyness.
    */
-  @Test
+  @Test (timeout=60000)
   public void testGetRowVersions() throws Exception {
     final String tableName = "testGetRowVersions";
     final byte [] contents = Bytes.toBytes("contents");
@@ -187,7 +187,7 @@ public class TestMultiVersions {
    * <p>Tests five cases of scans and timestamps.
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testScanMultipleVersions() throws Exception {
     final TableName tableName = TableName.valueOf("testScanMultipleVersions");
     final HTableDescriptor desc = new HTableDescriptor(tableName);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestNamespace.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestNamespace.java
index f47a8e0..d37bcac 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestNamespace.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestNamespace.java
@@ -99,7 +99,7 @@ public class TestNamespace {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void verifyReservedNS() throws IOException {
     //verify existence of reserved namespaces
     NamespaceDescriptor ns =
@@ -150,7 +150,7 @@ public class TestNamespace {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testDeleteReservedNS() throws Exception {
     boolean exceptionCaught = false;
     try {
@@ -172,7 +172,7 @@ public class TestNamespace {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void createRemoveTest() throws Exception {
     String testName = "createRemoveTest";
     String nsName = prefix+"_"+testName;
@@ -195,7 +195,7 @@ public class TestNamespace {
     assertNull(zkNamespaceManager.get(nsName));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void createDoubleTest() throws IOException, InterruptedException {
     String testName = "createDoubleTest";
     String nsName = prefix+"_"+testName;
@@ -218,7 +218,7 @@ public class TestNamespace {
     assertEquals(1, admin.listTables().length);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void createTableTest() throws IOException, InterruptedException {
     String testName = "createTableTest";
     String nsName = prefix+"_"+testName;
@@ -266,7 +266,7 @@ public class TestNamespace {
     admin.deleteNamespace(nsName);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void createTableInDefaultNamespace() throws Exception {
     HTableDescriptor desc = new HTableDescriptor(TableName.valueOf("default_table"));
     HColumnDescriptor colDesc = new HColumnDescriptor("cf1");
@@ -277,7 +277,7 @@ public class TestNamespace {
     admin.deleteTable(desc.getTableName());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void createTableInSystemNamespace() throws Exception {
     TableName tableName = TableName.valueOf("hbase:createTableInSystemNamespace");
     HTableDescriptor desc = new HTableDescriptor(tableName);
@@ -290,7 +290,7 @@ public class TestNamespace {
     admin.deleteTable(desc.getTableName());
   }
 
-  @Ignore @Test
+  @Ignore @Test (timeout=60000)
   public void testNamespaceJanitor() throws Exception {
     FileSystem fs = TEST_UTIL.getTestFileSystem();
 
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestPerformanceEvaluation.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestPerformanceEvaluation.java
index e35fc08..1f80b44 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestPerformanceEvaluation.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestPerformanceEvaluation.java
@@ -48,7 +48,7 @@ import com.yammer.metrics.stats.UniformSample;
 public class TestPerformanceEvaluation {
   private static final HBaseTestingUtility HTU = new HBaseTestingUtility();
 
-  @Test
+  @Test (timeout=180000)
   public void testSerialization()
   throws JsonGenerationException, JsonMappingException, IOException {
     PerformanceEvaluation.TestOptions options = new PerformanceEvaluation.TestOptions();
@@ -65,7 +65,7 @@ public class TestPerformanceEvaluation {
    * Exercise the mr spec writing.  Simple assertions to make sure it is basically working.
    * @throws IOException
    */
-  @Ignore @Test
+  @Ignore @Test (timeout=180000)
   public void testWriteInputFile() throws IOException {
     TestOptions opts = new PerformanceEvaluation.TestOptions();
     final int clients = 10;
@@ -93,7 +93,7 @@ public class TestPerformanceEvaluation {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSizeCalculation() {
     TestOptions opts = new PerformanceEvaluation.TestOptions();
     opts = PerformanceEvaluation.calculateRowsAndSize(opts);
@@ -115,7 +115,7 @@ public class TestPerformanceEvaluation {
     assertEquals(defaultPerClientRunRows * 2, opts.getPerClientRunRows());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testZipfian()
   throws NoSuchMethodException, SecurityException, InstantiationException, IllegalAccessException,
       IllegalArgumentException, InvocationTargetException {
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestSerialization.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestSerialization.java
index c29a460..988ee70 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestSerialization.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestSerialization.java
@@ -121,7 +121,7 @@ public class TestSerialization {
 
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSplitLogTask() throws DeserializationException {
     SplitLogTask slt = new SplitLogTask.Unassigned(ServerName.valueOf("mgr,1,1"), 
       RecoveryMode.LOG_REPLAY);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestServerLoad.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestServerLoad.java
index 5c56e9a..c313db9 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestServerLoad.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestServerLoad.java
@@ -34,7 +34,7 @@ import com.google.protobuf.ByteString;
 @Category({MiscTests.class, SmallTests.class})
 public class TestServerLoad {
 
-  @Test
+  @Test (timeout=180000)
   public void testRegionLoadAggregation() {
     ServerLoad sl = new ServerLoad(createServerLoadProto());
     assertEquals(13, sl.getStores());
@@ -47,7 +47,7 @@ public class TestServerLoad {
     
   }
  
-  @Test
+  @Test (timeout=180000)
   public void testToString() {
     ServerLoad sl = new ServerLoad(createServerLoadProto());
     String slToString = sl.toString();
@@ -59,7 +59,7 @@ public class TestServerLoad {
     assertTrue(slToString.contains("coprocessors=[]"));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRegionLoadWrapAroundAggregation() {
 	  ServerLoad sl = new ServerLoad(createServerLoadProto());
 	  long totalCount = ((long)Integer.MAX_VALUE)*2;
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestServerName.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestServerName.java
index e5125c6..d1201f6 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestServerName.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestServerName.java
@@ -33,7 +33,7 @@ import org.junit.experimental.categories.Category;
 
 @Category({MiscTests.class, SmallTests.class})
 public class TestServerName {
-  @Test
+  @Test (timeout=180000)
   public void testGetHostNameMinusDomain() {
     assertEquals("2607:f0d0:1002:51::4",
       ServerName.getHostNameMinusDomain("2607:f0d0:1002:51::4"));
@@ -47,7 +47,7 @@ public class TestServerName {
     assertEquals("asf000.sp2.ygridcore.net,1,1", sn.toString());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testShortString() {
     ServerName sn = ServerName.valueOf("asf000.sp2.ygridcore.net", 1, 1);
     assertEquals("asf000:1", sn.toShortString());
@@ -57,7 +57,7 @@ public class TestServerName {
     assertEquals("1.1.1.1:1", sn.toShortString());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRegexPatterns() {
     assertTrue(Pattern.matches(Addressing.VALID_PORT_REGEX, "123"));
     assertFalse(Pattern.matches(Addressing.VALID_PORT_REGEX, ""));
@@ -81,7 +81,7 @@ public class TestServerName {
     assertEquals(expecting, ServerName.parseVersionedServerName(bytes).toString());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testServerName() {
     ServerName sn = ServerName.valueOf("www.example.org", 1234, 5678);
     ServerName sn2 = ServerName.valueOf("www.example.org", 1234, 5678);
@@ -99,7 +99,7 @@ public class TestServerName {
       ServerName.SERVERNAME_SEPARATOR + "5678");
   }
 
-  @Test
+  @Test (timeout=180000)
   public void getServerStartcodeFromServerName() {
     ServerName sn = ServerName.valueOf("www.example.org", 1234, 5678);
     assertEquals(5678,
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestTableDescriptor.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestTableDescriptor.java
index 89029b9..d138e9f 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestTableDescriptor.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestTableDescriptor.java
@@ -39,7 +39,7 @@ import static org.junit.Assert.assertEquals;
 public class TestTableDescriptor {
   final static Log LOG = LogFactory.getLog(TestTableDescriptor.class);
 
-  @Test
+  @Test (timeout=180000)
   public void testPb() throws DeserializationException, IOException {
     HTableDescriptor htd = new HTableDescriptor(TableName.META_TABLE_NAME);
     final int v = 123;
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestZooKeeper.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestZooKeeper.java
index 30ad325..cecd873 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestZooKeeper.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestZooKeeper.java
@@ -141,7 +141,7 @@ public class TestZooKeeper {
    * @throws InterruptedException
    */
   // fails frequently, disabled for now, see HBASE-6406
-  //@Test
+  //@Test (timeout=60000)
   public void testClientSessionExpired() throws Exception {
     Configuration c = new Configuration(TEST_UTIL.getConfiguration());
 
@@ -269,7 +269,7 @@ public class TestZooKeeper {
     table.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMultipleZK()
   throws IOException, NoSuchMethodException, InvocationTargetException, IllegalAccessException {
     Table localMeta = TEST_UTIL.getConnection().getTable(TableName.META_TABLE_NAME);
@@ -300,7 +300,7 @@ public class TestZooKeeper {
    * Create a znode with data
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testCreateWithParents() throws Exception {
     ZooKeeperWatcher zkw =
         new ZooKeeperWatcher(new Configuration(TEST_UTIL.getConfiguration()),
@@ -322,7 +322,7 @@ public class TestZooKeeper {
    * delete it recursively, then delete the last znode
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testZNodeDeletes() throws Exception {
     ZooKeeperWatcher zkw = new ZooKeeperWatcher(
       new Configuration(TEST_UTIL.getConfiguration()),
@@ -345,7 +345,7 @@ public class TestZooKeeper {
     assertNull(ZKUtil.getDataNoWatch(zkw, "/l1/l2", null));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testClusterKey() throws Exception {
     testKey("server", "2181", "hbase");
     testKey("server1,server2,server3", "2181", "hbase");
@@ -379,7 +379,7 @@ public class TestZooKeeper {
    * @throws KeeperException Any of the zookeeper connections had a
    * KeeperException
    */
-  @Test
+  @Test (timeout=60000)
   public void testCreateSilentIsReallySilent() throws InterruptedException,
       KeeperException, IOException {
     Configuration c = TEST_UTIL.getConfiguration();
@@ -471,7 +471,7 @@ public class TestZooKeeper {
    * Test should not fail with NPE when getChildDataAndWatchForNewChildren
    * invoked with wrongNode
    */
-  @Test
+  @Test (timeout=60000)
   @SuppressWarnings("deprecation")
   public void testGetChildDataAndWatchForNewChildrenShouldNotThrowNPE()
       throws Exception {
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/backup/TestHFileArchiving.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/backup/TestHFileArchiving.java
index 903ce0e..3fad91c 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/backup/TestHFileArchiving.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/backup/TestHFileArchiving.java
@@ -113,7 +113,7 @@ public class TestHFileArchiving {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testRemovesRegionDirOnArchive() throws Exception {
     TableName TABLE_NAME =
         TableName.valueOf("testRemovesRegionDirOnArchive");
@@ -173,7 +173,7 @@ public class TestHFileArchiving {
    * still has hidden files.
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testDeleteRegionWithNoStoreFiles() throws Exception {
     TableName TABLE_NAME =
         TableName.valueOf("testDeleteRegionWithNoStoreFiles");
@@ -222,7 +222,7 @@ public class TestHFileArchiving {
     UTIL.deleteTable(TABLE_NAME);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testArchiveOnTableDelete() throws Exception {
     TableName TABLE_NAME =
         TableName.valueOf("testArchiveOnTableDelete");
@@ -301,7 +301,7 @@ public class TestHFileArchiving {
    * Test that the store files are archived when a column family is removed.
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testArchiveOnTableFamilyDelete() throws Exception {
     TableName TABLE_NAME =
         TableName.valueOf("testArchiveOnTableFamilyDelete");
@@ -349,7 +349,7 @@ public class TestHFileArchiving {
   /**
    * Test HFileArchiver.resolveAndArchive() race condition HBASE-7643
    */
-  @Test
+  @Test (timeout=60000)
   public void testCleaningRace() throws Exception {
     final long TEST_TIME = 20 * 1000;
     final ChoreService choreService = new ChoreService("TEST_SERVER_NAME");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestAdmin1.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestAdmin1.java
index fd1eff7..42cc0bc 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestAdmin1.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestAdmin1.java
@@ -1152,7 +1152,7 @@ public class TestAdmin1 {
     table.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSplitAndMergeWithReplicaTable() throws Exception {
     // The test tries to directly split replica regions and directly merge replica regions. These
     // are not allowed. The test validates that. Then the test does a valid split/merge of allowed
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestCheckAndMutate.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestCheckAndMutate.java
index a8c4abd..0b130fa 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestCheckAndMutate.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestCheckAndMutate.java
@@ -50,7 +50,7 @@ public class TestCheckAndMutate {
     TEST_UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCheckAndMutate() throws Exception {
     final TableName tableName = TableName.valueOf("TestPutWithDelete");
     final byte[] rowKey = Bytes.toBytes("12345");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestClientOperationInterrupt.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestClientOperationInterrupt.java
index 072098e..1128417 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestClientOperationInterrupt.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestClientOperationInterrupt.java
@@ -90,7 +90,7 @@ public class TestClientOperationInterrupt {
   }
 
 
-  @Test
+  @Test (timeout=60000)
   public void testInterrupt50Percent() throws IOException, InterruptedException {
     final AtomicInteger noEx = new AtomicInteger(0);
     final AtomicInteger badEx = new AtomicInteger(0);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestClientScannerRPCTimeout.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestClientScannerRPCTimeout.java
index 65483c9..889cf9b 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestClientScannerRPCTimeout.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestClientScannerRPCTimeout.java
@@ -82,7 +82,7 @@ public class TestClientScannerRPCTimeout {
     TEST_UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testScannerNextRPCTimesout() throws Exception {
     final TableName TABLE_NAME = TableName.valueOf("testScannerNextRPCTimesout");
     Table ht = TEST_UTIL.createTable(TABLE_NAME, FAMILY);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestClientTimeouts.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestClientTimeouts.java
index d3986b2..b56d86e 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestClientTimeouts.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestClientTimeouts.java
@@ -84,7 +84,7 @@ public class TestClientTimeouts {
    * doesn't throw any unexpected exceptions.
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testAdminTimeout() throws Exception {
     Connection lastConnection = null;
     boolean lastFailed = false;
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestCloneSnapshotFromClient.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestCloneSnapshotFromClient.java
index 2cb2cfc..e329b18 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestCloneSnapshotFromClient.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestCloneSnapshotFromClient.java
@@ -152,7 +152,7 @@ public class TestCloneSnapshotFromClient {
     admin.cloneSnapshot(snapshotName1, clonedTableName);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCloneSnapshot() throws IOException, InterruptedException {
     TableName clonedTableName = TableName.valueOf("clonedtb-" + System.currentTimeMillis());
     testCloneSnapshot(clonedTableName, snapshotName0, snapshot0Rows);
@@ -174,7 +174,7 @@ public class TestCloneSnapshotFromClient {
     SnapshotTestingUtils.verifyReplicasCameOnline(tableName, admin, getNumReplicas());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCloneSnapshotCrossNamespace() throws IOException, InterruptedException {
     String nsName = "testCloneSnapshotCrossNamespace";
     admin.createNamespace(NamespaceDescriptor.create(nsName).build());
@@ -188,7 +188,7 @@ public class TestCloneSnapshotFromClient {
   /**
    * Verify that tables created from the snapshot are still alive after source table deletion.
    */
-  @Test
+  @Test (timeout=60000)
   public void testCloneLinksAfterDelete() throws IOException, InterruptedException {
     // Clone a table from the first snapshot
     TableName clonedTableName = TableName.valueOf("clonedtb1-" + System.currentTimeMillis());
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestConnectionUtils.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestConnectionUtils.java
index ac0a0bd..27804e1 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestConnectionUtils.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestConnectionUtils.java
@@ -32,7 +32,7 @@ import static org.junit.Assert.assertTrue;
 @Category({SmallTests.class, ClientTests.class})
 public class TestConnectionUtils {
 
-  @Test
+  @Test (timeout=180000)
   public void testRetryTimeJitter() {
     long[] retries = new long[200];
     long baseTime = 1000000;  //Larger number than reality to help test randomness.
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFastFail.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFastFail.java
index e2b915f..031d869 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFastFail.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFastFail.java
@@ -95,7 +95,7 @@ public class TestFastFail {
     // Nothing to do.
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testFastFail() throws IOException, InterruptedException {
     Admin admin = TEST_UTIL.getHBaseAdmin();
 
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java
index 67e33b2..9e85776 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java
@@ -166,7 +166,7 @@ public class TestFromClientSide {
   /**
    * Basic client side validation of HBASE-4536
    */
-   @Test
+   @Test (timeout=60000)
    public void testKeepDeletedCells() throws Exception {
      final TableName TABLENAME = TableName.valueOf("testKeepDeletesCells");
      final byte[] FAMILY = Bytes.toBytes("family");
@@ -233,7 +233,7 @@ public class TestFromClientSide {
     /**
     * Basic client side validation of HBASE-10118
     */
-   @Test
+   @Test (timeout=60000)
    public void testPurgeFutureDeletes() throws Exception {
      final TableName TABLENAME = TableName.valueOf("testPurgeFutureDeletes");
      final byte[] ROW = Bytes.toBytes("row");
@@ -290,7 +290,7 @@ public class TestFromClientSide {
     * @throws Exception
     */
    @Deprecated
-   @Test
+   @Test (timeout=60000)
    public void testSharedZooKeeper() throws Exception {
      Configuration newConfig = new Configuration(TEST_UTIL.getConfiguration());
      newConfig.set(HConstants.HBASE_CLIENT_INSTANCE_ID, "12345");
@@ -379,7 +379,7 @@ public class TestFromClientSide {
    * Verifies that getConfiguration returns the same Configuration object used
    * to create the HTable instance.
    */
-  @Test
+  @Test (timeout=60000)
   public void testGetConfiguration() throws Exception {
     TableName TABLE = TableName.valueOf("testGetConfiguration");
     byte[][] FAMILIES = new byte[][] { Bytes.toBytes("foo") };
@@ -394,7 +394,7 @@ public class TestFromClientSide {
    *
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testWeirdCacheBehaviour() throws Exception {
     TableName TABLE = TableName.valueOf("testWeirdCacheBehaviour");
     byte [][] FAMILIES = new byte[][] { Bytes.toBytes("trans-blob"),
@@ -526,7 +526,7 @@ public class TestFromClientSide {
    * @throws IOException
    * @throws InterruptedException
    */
-  @Test
+  @Test (timeout=60000)
   public void testFilterAcrossMultipleRegions()
   throws IOException, InterruptedException {
     TableName name = TableName.valueOf("testFilterAcrossMutlipleRegions");
@@ -670,7 +670,7 @@ public class TestFromClientSide {
     return regions;
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSuperSimple() throws Exception {
     byte [] TABLE = Bytes.toBytes("testSuperSimple");
     Table ht = TEST_UTIL.createTable(TABLE, FAMILY);
@@ -685,7 +685,7 @@ public class TestFromClientSide {
     scanner.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMaxKeyValueSize() throws Exception {
     byte [] TABLE = Bytes.toBytes("testMaxKeyValueSize");
     Configuration conf = TEST_UTIL.getConfiguration();
@@ -712,7 +712,7 @@ public class TestFromClientSide {
     conf.set(TableConfiguration.MAX_KEYVALUE_SIZE_KEY, oldMaxSize);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testFilters() throws Exception {
     byte [] TABLE = Bytes.toBytes("testFilters");
     Table ht = TEST_UTIL.createTable(TABLE, FAMILY);
@@ -748,7 +748,7 @@ public class TestFromClientSide {
     scanner.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testFilterWithLongCompartor() throws Exception {
     byte [] TABLE = Bytes.toBytes("testFilterWithLongCompartor");
     Table ht = TEST_UTIL.createTable(TABLE, FAMILY);
@@ -779,7 +779,7 @@ public class TestFromClientSide {
     scanner.close();
 }
 
-  @Test
+  @Test (timeout=60000)
   public void testKeyOnlyFilter() throws Exception {
     byte [] TABLE = Bytes.toBytes("testKeyOnlyFilter");
     Table ht = TEST_UTIL.createTable(TABLE, FAMILY);
@@ -816,7 +816,7 @@ public class TestFromClientSide {
   /**
    * Test simple table and non-existent row cases.
    */
-  @Test
+  @Test (timeout=60000)
   public void testSimpleMissing() throws Exception {
     byte [] TABLE = Bytes.toBytes("testSimpleMissing");
     Table ht = TEST_UTIL.createTable(TABLE, FAMILY);
@@ -927,7 +927,7 @@ public class TestFromClientSide {
    * Test basic puts, gets, scans, and deletes for a single row
    * in a multiple family table.
    */
-  @Test
+  @Test (timeout=60000)
   public void testSingleRowMultipleFamily() throws Exception {
     byte [] TABLE = Bytes.toBytes("testSingleRowMultipleFamily");
     byte [][] ROWS = makeN(ROW, 3);
@@ -1228,7 +1228,7 @@ public class TestFromClientSide {
 
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testNull() throws Exception {
     byte [] TABLE = Bytes.toBytes("testNull");
 
@@ -1336,7 +1336,7 @@ public class TestFromClientSide {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testVersions() throws Exception {
     byte [] TABLE = Bytes.toBytes("testVersions");
 
@@ -1550,7 +1550,7 @@ public class TestFromClientSide {
 
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testVersionLimits() throws Exception {
     byte [] TABLE = Bytes.toBytes("testVersionLimits");
     byte [][] FAMILIES = makeNAscii(FAMILY, 3);
@@ -1744,7 +1744,7 @@ public class TestFromClientSide {
 
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testDeleteFamilyVersion() throws Exception {
     HBaseAdmin admin = TEST_UTIL.getHBaseAdmin();
     byte [] TABLE = Bytes.toBytes("testDeleteFamilyVersion");
@@ -1783,7 +1783,7 @@ public class TestFromClientSide {
     admin.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testDeleteFamilyVersionWithOtherDeletes() throws Exception {
     byte [] TABLE = Bytes.toBytes("testDeleteFamilyVersionWithOtherDeletes");
 
@@ -1898,7 +1898,7 @@ public class TestFromClientSide {
     admin.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testDeletes() throws Exception {
     byte [] TABLE = Bytes.toBytes("testDeletes");
 
@@ -2205,7 +2205,7 @@ public class TestFromClientSide {
    *
    * Tests one hundred families, one million columns, one million versions
    */
-  @Ignore @Test
+  @Ignore @Test (timeout=60000)
   public void testMillions() throws Exception {
 
     // 100 families
@@ -2216,7 +2216,7 @@ public class TestFromClientSide {
 
   }
 
-  @Ignore @Test
+  @Ignore @Test (timeout=60000)
   public void testMultipleRegionsAndBatchPuts() throws Exception {
     // Two family table
 
@@ -2245,7 +2245,7 @@ public class TestFromClientSide {
 
   }
 
-  @Ignore @Test
+  @Ignore @Test (timeout=60000)
   public void testMultipleRowMultipleFamily() throws Exception {
 
   }
@@ -2264,7 +2264,7 @@ public class TestFromClientSide {
    *    To test at scale, up numColsPerRow to the millions
    *    (have not gotten that to work running as junit though)
    */
-  @Test
+  @Test (timeout=60000)
   public void testJiraTest867() throws Exception {
     int numRows = 10;
     int numColsPerRow = 2000;
@@ -2350,7 +2350,7 @@ public class TestFromClientSide {
    *    get with timestamp will return a value if there is a version with an
    *    earlier timestamp
    */
-  @Test
+  @Test (timeout=60000)
   public void testJiraTest861() throws Exception {
 
     byte [] TABLE = Bytes.toBytes("testJiraTest861");
@@ -2414,7 +2414,7 @@ public class TestFromClientSide {
    *    Add a HTable get/obtainScanner method that retrieves all versions of a
    *    particular column and row between two timestamps
    */
-  @Test
+  @Test (timeout=60000)
   public void testJiraTest33() throws Exception {
 
     byte [] TABLE = Bytes.toBytes("testJiraTest33");
@@ -2463,7 +2463,7 @@ public class TestFromClientSide {
    * HBASE-1014
    *    commit(BatchUpdate) method should return timestamp
    */
-  @Test
+  @Test (timeout=60000)
   public void testJiraTest1014() throws Exception {
 
     byte [] TABLE = Bytes.toBytes("testJiraTest1014");
@@ -2488,7 +2488,7 @@ public class TestFromClientSide {
    * HBASE-1182
    *    Scan for columns > some timestamp
    */
-  @Test
+  @Test (timeout=60000)
   public void testJiraTest1182() throws Exception {
 
     byte [] TABLE = Bytes.toBytes("testJiraTest1182");
@@ -2532,7 +2532,7 @@ public class TestFromClientSide {
    * HBASE-52
    *    Add a means of scanning over all versions
    */
-  @Test
+  @Test (timeout=60000)
   public void testJiraTest52() throws Exception {
     byte [] TABLE = Bytes.toBytes("testJiraTest52");
     byte [][] VALUES = makeNAscii(VALUE, 7);
@@ -3362,7 +3362,7 @@ public class TestFromClientSide {
     return Bytes.equals(left, right);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testDuplicateVersions() throws Exception {
     byte [] TABLE = Bytes.toBytes("testDuplicateVersions");
 
@@ -3576,7 +3576,7 @@ public class TestFromClientSide {
         0, 9);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testUpdates() throws Exception {
 
     byte [] TABLE = Bytes.toBytes("testUpdates");
@@ -3626,7 +3626,7 @@ public class TestFromClientSide {
     assertEquals("DDD", Bytes.toString(navigableMap.get(2L)));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testUpdatesWithMajorCompaction() throws Exception {
 
     TableName TABLE = TableName.valueOf("testUpdatesWithMajorCompaction");
@@ -3687,7 +3687,7 @@ public class TestFromClientSide {
     assertEquals("DDD", Bytes.toString(navigableMap.get(2L)));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMajorCompactionBetweenTwoUpdates() throws Exception {
 
     String tableName = "testMajorCompactionBetweenTwoUpdates";
@@ -3755,7 +3755,7 @@ public class TestFromClientSide {
     assertEquals("DDD", Bytes.toString(navigableMap.get(2L)));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGet_EmptyTable() throws IOException {
     Table table = TEST_UTIL.createTable(TableName.valueOf("testGet_EmptyTable"), FAMILY);
     Get get = new Get(ROW);
@@ -3764,7 +3764,7 @@ public class TestFromClientSide {
     assertTrue(r.isEmpty());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGet_NullQualifier() throws IOException {
     Table table = TEST_UTIL.createTable(TableName.valueOf("testGet_NullQualifier"), FAMILY);
     Put put = new Put(ROW);
@@ -3787,7 +3787,7 @@ public class TestFromClientSide {
     assertEquals(2, r.size());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGet_NonExistentRow() throws IOException {
     Table table = TEST_UTIL.createTable(TableName.valueOf("testGet_NonExistentRow"), FAMILY);
     Put put = new Put(ROW);
@@ -3809,7 +3809,7 @@ public class TestFromClientSide {
     LOG.info("Row missing as it should be");
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testPut() throws IOException {
     final byte [] CONTENTS_FAMILY = Bytes.toBytes("contents");
     final byte [] SMALL_FAMILY = Bytes.toBytes("smallfam");
@@ -3849,7 +3849,7 @@ public class TestFromClientSide {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testPutNoCF() throws IOException {
     final byte[] BAD_FAM = Bytes.toBytes("BAD_CF");
     final byte[] VAL = Bytes.toBytes(100);
@@ -3868,7 +3868,7 @@ public class TestFromClientSide {
 
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testRowsPut() throws IOException {
     final byte[] CONTENTS_FAMILY = Bytes.toBytes("contents");
     final byte[] SMALL_FAMILY = Bytes.toBytes("smallfam");
@@ -3895,7 +3895,7 @@ public class TestFromClientSide {
     assertEquals(NB_BATCH_ROWS, nbRows);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testRowsPutBufferedOneFlush() throws IOException {
     final byte [] CONTENTS_FAMILY = Bytes.toBytes("contents");
     final byte [] SMALL_FAMILY = Bytes.toBytes("smallfam");
@@ -3937,7 +3937,7 @@ public class TestFromClientSide {
     table.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testRowsPutBufferedManyManyFlushes() throws IOException {
     final byte[] CONTENTS_FAMILY = Bytes.toBytes("contents");
     final byte[] SMALL_FAMILY = Bytes.toBytes("smallfam");
@@ -3966,7 +3966,7 @@ public class TestFromClientSide {
     assertEquals(NB_BATCH_ROWS * 10, nbRows);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testAddKeyValue() throws IOException {
     final byte[] CONTENTS_FAMILY = Bytes.toBytes("contents");
     final byte[] value = Bytes.toBytes("abcd");
@@ -4000,7 +4000,7 @@ public class TestFromClientSide {
    * test for HBASE-737
    * @throws IOException
    */
-  @Test
+  @Test (timeout=60000)
   public void testHBase737 () throws IOException {
     final byte [] FAM1 = Bytes.toBytes("fam1");
     final byte [] FAM2 = Bytes.toBytes("fam2");
@@ -4091,7 +4091,7 @@ public class TestFromClientSide {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testListTables() throws IOException, InterruptedException {
     TableName t1 = TableName.valueOf("testListTables1");
     TableName t2 = TableName.valueOf("testListTables2");
@@ -4137,7 +4137,7 @@ public class TestFromClientSide {
    *
    * @throws IOException
    */
-  @Test
+  @Test (timeout=60000)
   public void testUnmanagedHConnection() throws IOException {
     final TableName tableName = TableName.valueOf("testUnmanagedHConnection");
     HTable t = createUnmangedHConnectionHTable(tableName);
@@ -4153,7 +4153,7 @@ public class TestFromClientSide {
    *
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testUnmanagedHConnectionReconnect() throws Exception {
     final TableName tableName = TableName.valueOf("testUnmanagedHConnectionReconnect");
     HTable t = createUnmangedHConnectionHTable(tableName);
@@ -4180,7 +4180,7 @@ public class TestFromClientSide {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMiscHTableStuff() throws IOException {
     final TableName tableAname = TableName.valueOf("testMiscHTableStuffA");
     final TableName tableBname = TableName.valueOf("testMiscHTableStuffB");
@@ -4257,7 +4257,7 @@ public class TestFromClientSide {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGetClosestRowBefore() throws IOException, InterruptedException {
     final TableName tableAname = TableName.valueOf("testGetClosestRowBefore");
     final byte[] firstRow = Bytes.toBytes("row111");
@@ -4356,7 +4356,7 @@ public class TestFromClientSide {
    * For HBASE-2156
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testScanVariableReuse() throws Exception {
     Scan scan = new Scan();
     scan.addFamily(FAMILY);
@@ -4371,7 +4371,7 @@ public class TestFromClientSide {
     assertTrue(scan.getFamilyMap().containsKey(FAMILY));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMultiRowMutation() throws Exception {
     LOG.info("Starting testMultiRowMutation");
     final TableName TABLENAME = TableName.valueOf("testMultiRowMutation");
@@ -4402,7 +4402,7 @@ public class TestFromClientSide {
     assertEquals(0, Bytes.compareTo(VALUE, r.getValue(FAMILY, QUALIFIER)));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testRowMutation() throws Exception {
     LOG.info("Starting testRowMutation");
     final TableName TABLENAME = TableName.valueOf("testRowMutation");
@@ -4434,7 +4434,7 @@ public class TestFromClientSide {
     assertNull(r.getValue(FAMILY, QUALIFIERS[0]));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testAppend() throws Exception {
     LOG.info("Starting testAppend");
     final TableName TABLENAME = TableName.valueOf("testAppend");
@@ -4463,7 +4463,7 @@ public class TestFromClientSide {
         r.getColumnLatestCell(FAMILY, QUALIFIERS[2]).getTimestamp());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testIncrementWithDeletes() throws Exception {
     LOG.info("Starting testIncrementWithDeletes");
     final TableName TABLENAME =
@@ -4485,7 +4485,7 @@ public class TestFromClientSide {
     assertEquals(5, Bytes.toLong(r.getValue(FAMILY, COLUMN)));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testIncrementingInvalidValue() throws Exception {
     LOG.info("Starting testIncrementingInvalidValue");
     final TableName TABLENAME = TableName.valueOf("testIncrementingInvalidValue");
@@ -4511,7 +4511,7 @@ public class TestFromClientSide {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testIncrementInvalidArguments() throws Exception {
     LOG.info("Starting testIncrementInvalidArguments");
     final TableName TABLENAME = TableName.valueOf("testIncrementInvalidArguments");
@@ -4566,7 +4566,7 @@ public class TestFromClientSide {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testIncrementOutOfOrder() throws Exception {
     LOG.info("Starting testIncrementOutOfOrder");
     final TableName TABLENAME = TableName.valueOf("testIncrementOutOfOrder");
@@ -4606,7 +4606,7 @@ public class TestFromClientSide {
     assertIncrementKey(kvs[2], ROW, FAMILY, QUALIFIERS[2], 2);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testIncrementOnSameColumn() throws Exception {
     LOG.info("Starting testIncrementOnSameColumn");
     final byte[] TABLENAME = Bytes.toBytes("testIncrementOnSameColumn");
@@ -4649,7 +4649,7 @@ public class TestFromClientSide {
     ht.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testIncrement() throws Exception {
     LOG.info("Starting testIncrement");
     final TableName TABLENAME = TableName.valueOf("testIncrement");
@@ -4721,7 +4721,7 @@ public class TestFromClientSide {
   }
 
 
-  @Test
+  @Test (timeout=60000)
   public void testClientPoolRoundRobin() throws IOException {
     final TableName tableName = TableName.valueOf("testClientPoolRoundRobin");
 
@@ -4757,7 +4757,7 @@ public class TestFromClientSide {
     }
   }
 
-  @Ignore ("Flakey: HBASE-8989") @Test
+  @Ignore ("Flakey: HBASE-8989") @Test (timeout=60000)
   public void testClientPoolThreadLocal() throws IOException {
     final TableName tableName = TableName.valueOf("testClientPoolThreadLocal");
 
@@ -4840,7 +4840,7 @@ public class TestFromClientSide {
     assertNull(error.get());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCheckAndPut() throws IOException {
     final byte [] anotherrow = Bytes.toBytes("anotherrow");
     final byte [] value2 = Bytes.toBytes("abcd");
@@ -4879,7 +4879,7 @@ public class TestFromClientSide {
 
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCheckAndPutWithCompareOp() throws IOException {
     final byte [] value1 = Bytes.toBytes("aaaa");
     final byte [] value2 = Bytes.toBytes("bbbb");
@@ -4944,7 +4944,7 @@ public class TestFromClientSide {
     assertEquals(ok, true);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCheckAndDeleteWithCompareOp() throws IOException {
     final byte [] value1 = Bytes.toBytes("aaaa");
     final byte [] value2 = Bytes.toBytes("bbbb");
@@ -5022,7 +5022,7 @@ public class TestFromClientSide {
   * Test ScanMetrics
   * @throws Exception
   */
-  @Test
+  @Test (timeout=60000)
   @SuppressWarnings ("unused")
   public void testScanMetrics() throws Exception {
     TableName TABLENAME = TableName.valueOf("testScanMetrics");
@@ -5128,7 +5128,7 @@ public class TestFromClientSide {
    *
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testCacheOnWriteEvictOnClose() throws Exception {
     TableName tableName = TableName.valueOf("testCOWEOCfromClient");
     byte [] data = Bytes.toBytes("data");
@@ -5237,7 +5237,7 @@ public class TestFromClientSide {
     assertEquals(count, store.getStorefilesCount());
   }
 
-  @Test
+  @Test (timeout=60000)
   /**
    * Tests the non cached version of getRegionLocator by moving a region.
    */
@@ -5283,7 +5283,7 @@ public class TestFromClientSide {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   /**
    * Tests getRegionsInRange by creating some regions over which a range of
    * keys spans; then changing the key range.
@@ -5344,7 +5344,7 @@ public class TestFromClientSide {
     assertEquals(1, regionsList.size());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testJira6912() throws Exception {
     TableName TABLE = TableName.valueOf("testJira6912");
     Table foo = TEST_UTIL.createTable(TABLE, new byte[][] {FAMILY}, 10);
@@ -5370,7 +5370,7 @@ public class TestFromClientSide {
     assertEquals(1, bar.length);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testScan_NullQualifier() throws IOException {
     Table table = TEST_UTIL.createTable(TableName.valueOf("testScan_NullQualifier"), FAMILY);
     Put put = new Put(ROW);
@@ -5399,7 +5399,7 @@ public class TestFromClientSide {
     assertEquals(2, bar[0].size());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testNegativeTimestamp() throws IOException {
     Table table = TEST_UTIL.createTable(TableName.valueOf("testNegativeTimestamp"), FAMILY);
 
@@ -5458,7 +5458,7 @@ public class TestFromClientSide {
     table.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testIllegalTableDescriptor() throws Exception {
     HTableDescriptor htd = new HTableDescriptor(TableName.valueOf("testIllegalTableDescriptor"));
     HColumnDescriptor hcd = new HColumnDescriptor(FAMILY);
@@ -5543,7 +5543,7 @@ public class TestFromClientSide {
     assertFalse(admin.tableExists(htd.getTableName()));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testRawScanRespectsVersions() throws Exception {
     TableName TABLE = TableName.valueOf("testRawScan");
     Table table = TEST_UTIL.createTable(TABLE, FAMILY);
@@ -5613,7 +5613,7 @@ public class TestFromClientSide {
     TEST_UTIL.deleteTable(TABLE);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSmallScan() throws Exception {
     // Test Initialization.
     TableName TABLE = TableName.valueOf("testSmallScan");
@@ -5650,7 +5650,7 @@ public class TestFromClientSide {
 
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSuperSimpleWithReverseScan() throws Exception {
     TableName TABLE = TableName.valueOf("testSuperSimpleWithReverseScan");
     Table ht = TEST_UTIL.createTable(TABLE, FAMILY);
@@ -5695,7 +5695,7 @@ public class TestFromClientSide {
     ht.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testFiltersWithReverseScan() throws Exception {
     TableName TABLE = TableName.valueOf("testFiltersWithReverseScan");
     Table ht = TEST_UTIL.createTable(TABLE, FAMILY);
@@ -5735,7 +5735,7 @@ public class TestFromClientSide {
     ht.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testKeyOnlyFilterWithReverseScan() throws Exception {
     TableName TABLE = TableName.valueOf("testKeyOnlyFilterWithReverseScan");
     Table ht = TEST_UTIL.createTable(TABLE, FAMILY);
@@ -5776,7 +5776,7 @@ public class TestFromClientSide {
   /**
    * Test simple table and non-existent row cases.
    */
-  @Test
+  @Test (timeout=60000)
   public void testSimpleMissingWithReverseScan() throws Exception {
     TableName TABLE = TableName.valueOf("testSimpleMissingWithReverseScan");
     Table ht = TEST_UTIL.createTable(TABLE, FAMILY);
@@ -5841,7 +5841,7 @@ public class TestFromClientSide {
     ht.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testNullWithReverseScan() throws Exception {
     TableName TABLE = TableName.valueOf("testNullWithReverseScan");
     Table ht = TEST_UTIL.createTable(TABLE, FAMILY);
@@ -5878,7 +5878,7 @@ public class TestFromClientSide {
     ht.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testDeletesWithReverseScan() throws Exception {
     TableName TABLE = TableName.valueOf("testDeletesWithReverseScan");
     byte[][] ROWS = makeNAscii(ROW, 6);
@@ -6063,7 +6063,7 @@ public class TestFromClientSide {
   /**
    * Tests reversed scan under multi regions
    */
-  @Test
+  @Test (timeout=60000)
   public void testReversedScanUnderMultiRegions() throws Exception {
     // Test Initialization.
     TableName TABLE = TableName.valueOf("testReversedScanUnderMultiRegions");
@@ -6120,7 +6120,7 @@ public class TestFromClientSide {
   /**
    * Tests reversed scan under multi regions
    */
-  @Test
+  @Test (timeout=60000)
   public void testSmallReversedScanUnderMultiRegions() throws Exception {
     // Test Initialization.
     TableName TABLE = TableName.valueOf("testSmallReversedScanUnderMultiRegions");
@@ -6282,7 +6282,7 @@ public class TestFromClientSide {
     assertEquals(4, count); // 003 004 005 006
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGetStartEndKeysWithRegionReplicas() throws IOException {
     HTableDescriptor htd = new HTableDescriptor(TableName.valueOf("testGetStartEndKeys"));
     HColumnDescriptor fam = new HColumnDescriptor(FAMILY);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide3.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide3.java
index 680dcfb..0d7a8da 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide3.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide3.java
@@ -266,7 +266,7 @@ public class TestFromClientSide3 {
         "hbase.hstore.compaction.min"));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testHTableBatchWithEmptyPut() throws Exception {
     Table table = TEST_UTIL.createTable(
       Bytes.toBytes("testHTableBatchWithEmptyPut"), new byte[][] { FAMILY });
@@ -290,7 +290,7 @@ public class TestFromClientSide3 {
     }
   }
   
-  @Test
+  @Test (timeout=60000)
   public void testHTableExistsMethodSingleRegionSingleGet() throws Exception {
 
     // Test with a single region table.
@@ -332,7 +332,7 @@ public class TestFromClientSide3 {
     assertEquals(results[2], false);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testHTableExistsMethodMultipleRegionsSingleGet() throws Exception {
 
     Table table = TEST_UTIL.createTable(
@@ -352,7 +352,7 @@ public class TestFromClientSide3 {
     assertEquals(exist, true);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testHTableExistsMethodMultipleRegionsMultipleGets() throws Exception {
     HTable table = TEST_UTIL.createTable(
       TableName.valueOf("testHTableExistsMethodMultipleRegionsMultipleGets"), 
@@ -401,7 +401,7 @@ public class TestFromClientSide3 {
     assertEquals(results[2], false);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGetEmptyRow() throws Exception {
     //Create a table and put in 1 row
     Admin admin = TEST_UTIL.getHBaseAdmin();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSideNoCodec.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSideNoCodec.java
index f5807c2..b0d2d1e 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSideNoCodec.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSideNoCodec.java
@@ -59,7 +59,7 @@ public class TestFromClientSideNoCodec {
     TEST_UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testBasics() throws IOException {
     final byte [] t = Bytes.toBytes("testBasics");
     final byte [][] fs = new byte[][] {Bytes.toBytes("cf1"), Bytes.toBytes("cf2"),
@@ -93,7 +93,7 @@ public class TestFromClientSideNoCodec {
     assertTrue(count == 1);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testNoCodec() {
     Configuration c = new Configuration();
     c.set("hbase.client.default.rpc.codec", "");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHBaseAdminNoCluster.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHBaseAdminNoCluster.java
index fbca881..3f288db 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHBaseAdminNoCluster.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHBaseAdminNoCluster.java
@@ -67,7 +67,7 @@ public class TestHBaseAdminNoCluster {
    * @throws MasterNotRunningException
    * @throws ServiceException
    */
-  @Test
+  @Test (timeout=180000)
   public void testMasterMonitorCallableRetries()
   throws MasterNotRunningException, ZooKeeperConnectionException, IOException, ServiceException {
     Configuration configuration = HBaseConfiguration.create();
@@ -105,7 +105,7 @@ public class TestHBaseAdminNoCluster {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testMasterOperationsRetries() throws Exception {
 
     // Admin.listTables()
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHCM.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHCM.java
index 219496f..6e4b5aa 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHCM.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHCM.java
@@ -148,7 +148,7 @@ public class TestHCM {
     return HConnectionTestingUtility.getConnectionCount();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testClusterConnection() throws IOException {
     ThreadPoolExecutor otherPool = new ThreadPoolExecutor(1, 1,
         5, TimeUnit.SECONDS,
@@ -211,7 +211,7 @@ public class TestHCM {
    * Naive test to check that HConnection#getAdmin returns a properly constructed HBaseAdmin object
    * @throws IOException Unable to construct admin
    */
-  @Test
+  @Test (timeout=60000)
   public void testAdminFactory() throws IOException {
     Connection con1 = ConnectionFactory.createConnection(TEST_UTIL.getConfiguration());
     Admin admin = con1.getAdmin();
@@ -287,12 +287,12 @@ public class TestHCM {
    * Test that we can handle connection close: it will trigger a retry, but the calls will
    *  finish.
    */
-  @Test
+  @Test (timeout=60000)
   public void testConnectionCloseAllowsInterrupt() throws Exception {
     testConnectionClose(true);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testConnectionNotAllowsInterrupt() throws Exception {
     testConnectionClose(false);
   }
@@ -305,7 +305,7 @@ public class TestHCM {
    * succeeds. But the client won't wait that much, because 20 + 20 > 30, so the client
    * timeouted when the server answers.
    */
-  @Test
+  @Test (timeout=60000)
   public void testOperationTimeout() throws Exception {
     HTableDescriptor hdt = TEST_UTIL.createTableDescriptor("HCM-testOperationTimeout");
     hdt.addCoprocessor(SleepAndFailFirstTime.class.getName());
@@ -416,7 +416,7 @@ public class TestHCM {
   /**
    * Test that connection can become idle without breaking everything.
    */
-  @Test
+  @Test (timeout=60000)
   public void testConnectionIdle() throws Exception {
     TableName tableName = TableName.valueOf("HCM-testConnectionIdle");
     TEST_UTIL.createTable(tableName, FAM_NAM).close();
@@ -477,7 +477,7 @@ public class TestHCM {
    *  notification.
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testConnectionCut() throws Exception {
     if (!isJavaOk){
       // This test requires jdk 1.7+
@@ -570,7 +570,7 @@ public class TestHCM {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void abortingHConnectionRemovesItselfFromHCM() throws Exception {
     // Save off current HConnections
     Map<HConnectionKey, HConnectionImplementation> oldHBaseInstances =
@@ -597,7 +597,7 @@ public class TestHCM {
    * that we really delete it.
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testRegionCaching() throws Exception{
     TEST_UTIL.createMultiRegionTable(TABLE_NAME, FAM_NAM).close();
     Configuration conf =  new Configuration(TEST_UTIL.getConfiguration());
@@ -785,7 +785,7 @@ public class TestHCM {
    * Test that Connection or Pool are not closed when managed externally
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testConnectionManagement() throws Exception{
     Table table0 = TEST_UTIL.createTable(TABLE_NAME1, FAM_NAM);
     Connection conn = ConnectionFactory.createConnection(TEST_UTIL.getConfiguration());
@@ -852,7 +852,7 @@ public class TestHCM {
    * Make sure that {@link Configuration} instances that are essentially the
    * same map to the same {@link HConnection} instance.
    */
-  @Test
+  @Test (timeout=60000)
   public void testConnectionSameness() throws Exception {
     Connection previousConnection = null;
     for (int i = 0; i < 2; i++) {
@@ -884,7 +884,7 @@ public class TestHCM {
    * @deprecated Tests deprecated functionality.  Remove in 1.0.
    */
   @Deprecated
-  @Test
+  @Test (timeout=60000)
   public void testConnectionUniqueness() throws Exception {
     int zkmaxconnections = TEST_UTIL.getConfiguration().
       getInt(HConstants.ZOOKEEPER_MAX_CLIENT_CNXNS,
@@ -930,7 +930,7 @@ public class TestHCM {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testClosing() throws Exception {
     Configuration configuration =
       new Configuration(TEST_UTIL.getConfiguration());
@@ -970,7 +970,7 @@ public class TestHCM {
    * Trivial test to verify that nobody messes with
    * {@link HConnectionManager#createConnection(Configuration)}
    */
-  @Test
+  @Test (timeout=60000)
   public void testCreateConnection() throws Exception {
     Configuration configuration = TEST_UTIL.getConfiguration();
     Connection c1 = ConnectionFactory.createConnection(configuration);
@@ -1129,7 +1129,7 @@ public class TestHCM {
      }
   }
 
-  @Ignore ("Test presumes RETRY_BACKOFF will never change; it has") @Test
+  @Ignore ("Test presumes RETRY_BACKOFF will never change; it has") @Test (timeout=60000)
   public void testErrorBackoffTimeCalculation() throws Exception {
     // TODO: This test would seem to presume hardcoded RETRY_BACKOFF which it should not.
     final long ANY_PAUSE = 100;
@@ -1205,7 +1205,7 @@ public class TestHCM {
    * zk connections.
    * @throws Exception
    */
-  @Ignore ("Flakey test: See HBASE-8996")@Test
+  @Ignore ("Flakey test: See HBASE-8996")@Test (timeout=60000)
   public void testDeleteForZKConnLeak() throws Exception {
     TEST_UTIL.createTable(TABLE_NAME4, FAM_NAM);
     final Configuration config = HBaseConfiguration.create(TEST_UTIL.getConfiguration());
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHTableMultiplexer.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHTableMultiplexer.java
index 26fe485..bf98dbc 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHTableMultiplexer.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHTableMultiplexer.java
@@ -81,7 +81,7 @@ public class TestHTableMultiplexer {
       Bytes.toStringBinary(r.getValue(FAMILY, QUALIFIER)));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testHTableMultiplexer() throws Exception {
     TableName TABLE_1 = TableName.valueOf("testHTableMultiplexer_1");
     TableName TABLE_2 = TableName.valueOf("testHTableMultiplexer_2");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHTableMultiplexerFlushCache.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHTableMultiplexerFlushCache.java
index 2898369..d2429d2 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHTableMultiplexerFlushCache.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHTableMultiplexerFlushCache.java
@@ -81,7 +81,7 @@ public class TestHTableMultiplexerFlushCache {
       Bytes.toStringBinary(r.getValue(family, quality)));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testOnRegionChange() throws Exception {
     TableName TABLE = TableName.valueOf("testOnRegionChange");
     final int NUM_REGIONS = 10;
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestIntraRowPagination.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestIntraRowPagination.java
index 1f6dc98..648b7aa 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestIntraRowPagination.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestIntraRowPagination.java
@@ -47,7 +47,7 @@ public class TestIntraRowPagination {
    *
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   public void testScanLimitAndOffset() throws Exception {
     //byte [] TABLE = HTestConst.DEFAULT_TABLE_BYTES;
     byte [][] ROWS = HTestConst.makeNAscii(HTestConst.DEFAULT_ROW_BYTES, 2);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestMetaScanner.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestMetaScanner.java
index e195baf..9ed3a4b 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestMetaScanner.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestMetaScanner.java
@@ -65,7 +65,7 @@ public class TestMetaScanner {
     TEST_UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMetaScanner() throws Exception {
     LOG.info("Starting testMetaScanner");
 
@@ -110,7 +110,7 @@ public class TestMetaScanner {
     table.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testConcurrentMetaScannerAndCatalogJanitor() throws Throwable {
     /* TEST PLAN: start with only one region in a table. Have a splitter
      * thread  and metascanner threads that continously scan the meta table for regions.
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestMetaWithReplicas.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestMetaWithReplicas.java
index b83dc81..5e36214 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestMetaWithReplicas.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestMetaWithReplicas.java
@@ -104,13 +104,13 @@ public class TestMetaWithReplicas {
     TEST_UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMetaHTDReplicaCount() throws Exception {
     assertTrue(TEST_UTIL.getHBaseAdmin().getTableDescriptor(TableName.META_TABLE_NAME)
         .getRegionReplication() == 3);
   }
   
-  @Test
+  @Test (timeout=60000)
   public void testZookeeperNodesForReplicas() throws Exception {
     // Checks all the znodes exist when meta's replicas are enabled
     ZooKeeperWatcher zkw = TEST_UTIL.getZooKeeperWatcher();
@@ -133,7 +133,7 @@ public class TestMetaWithReplicas {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testShutdownHandling() throws Exception {
     // This test creates a table, flushes the meta (with 3 replicas), kills the
     // server holding the primary meta replica. Then it does a put/get into/from
@@ -223,7 +223,7 @@ public class TestMetaWithReplicas {
     assertTrue(Arrays.equals(r.getRow(), row));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMetaLookupThreadPoolCreated() throws Exception {
     byte[] TABLE = Bytes.toBytes("testMetaLookupThreadPoolCreated");
     byte[][] FAMILIES = new byte[][] { Bytes.toBytes("foo") };
@@ -240,7 +240,7 @@ public class TestMetaWithReplicas {
     assert(ex != null);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testChangingReplicaCount() throws Exception {
     // tests changing the replica count across master restarts
     // reduce the replica count from 3 to 2
@@ -309,13 +309,13 @@ public class TestMetaWithReplicas {
         + "(" + metaZnodes.toString() + ")";
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testHBaseFsckWithMetaReplicas() throws Exception {
     HBaseFsck hbck = HbckTestingUtil.doFsck(TEST_UTIL.getConfiguration(), false);
     HbckTestingUtil.assertNoErrors(hbck);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testHBaseFsckWithFewerMetaReplicas() throws Exception {
     ClusterConnection c = (ClusterConnection)ConnectionFactory.createConnection(
         TEST_UTIL.getConfiguration());
@@ -333,7 +333,7 @@ public class TestMetaWithReplicas {
     assertErrors(hbck, new ERROR_CODE[]{});
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testHBaseFsckWithFewerMetaReplicaZnodes() throws Exception {
     ClusterConnection c = (ClusterConnection)ConnectionFactory.createConnection(
         TEST_UTIL.getConfiguration());
@@ -353,7 +353,7 @@ public class TestMetaWithReplicas {
     assertErrors(hbck, new ERROR_CODE[]{});
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testAccessingUnknownTables() throws Exception {
     Configuration conf = new Configuration(TEST_UTIL.getConfiguration());
     conf.setBoolean(HConstants.USE_META_REPLICAS, true);
@@ -367,7 +367,7 @@ public class TestMetaWithReplicas {
     fail("Expected TableNotFoundException");
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMetaAddressChange() throws Exception {
     // checks that even when the meta's location changes, the various
     // caches update themselves. Uses the master operations to test
@@ -406,7 +406,7 @@ public class TestMetaWithReplicas {
     assertTrue(TEST_UTIL.getHBaseAdmin().isTableDisabled("randomTable5678"));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testShutdownOfReplicaHolder() throws Exception {
     // checks that the when the server holding meta replica is shut down, the meta replica
     // can be recovered
@@ -427,7 +427,7 @@ public class TestMetaWithReplicas {
     assertTrue(i != 3);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testHBaseFsckWithExcessMetaReplicas() throws Exception {
     HBaseFsck hbck = new HBaseFsck(TEST_UTIL.getConfiguration());
     // Create a meta replica (this will be the 4th one) and assign it
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestMultiParallel.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestMultiParallel.java
index abea699..e830268 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestMultiParallel.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestMultiParallel.java
@@ -205,7 +205,7 @@ public class TestMultiParallel {
     table.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testBadFam() throws Exception {
     LOG.info("test=testBadFam");
     Table table = UTIL.getConnection().getTable(TEST_TABLE);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestMultipleTimestamps.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestMultipleTimestamps.java
index abb919f..bd18758 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestMultipleTimestamps.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestMultipleTimestamps.java
@@ -80,7 +80,7 @@ public class TestMultipleTimestamps {
     // Nothing to do.
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testReseeksWithOneColumnMiltipleTimestamp() throws IOException {
     TableName TABLE =
         TableName.valueOf("testReseeksWithOne" +
@@ -121,7 +121,7 @@ public class TestMultipleTimestamps {
     ht.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testReseeksWithMultipleColumnOneTimestamp() throws IOException {
     LOG.info("testReseeksWithMultipleColumnOneTimestamp");
     TableName TABLE =
@@ -161,7 +161,7 @@ public class TestMultipleTimestamps {
     ht.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testReseeksWithMultipleColumnMultipleTimestamp() throws
   IOException {
     LOG.info("testReseeksWithMultipleColumnMultipleTimestamp");
@@ -216,7 +216,7 @@ public class TestMultipleTimestamps {
     ht.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testReseeksWithMultipleFiles() throws IOException {
     LOG.info("testReseeksWithMultipleFiles");
     TableName TABLE =
@@ -276,7 +276,7 @@ public class TestMultipleTimestamps {
     ht.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testWithVersionDeletes() throws Exception {
 
     // first test from memstore (without flushing).
@@ -319,7 +319,7 @@ public class TestMultipleTimestamps {
     ht.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testWithMultipleVersionDeletes() throws IOException {
     LOG.info("testWithMultipleVersionDeletes");
 
@@ -347,7 +347,7 @@ public class TestMultipleTimestamps {
     ht.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testWithColumnDeletes() throws IOException {
     TableName TABLE =
         TableName.valueOf("testWithColumnDeletes");
@@ -373,7 +373,7 @@ public class TestMultipleTimestamps {
     ht.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testWithFamilyDeletes() throws IOException {
     TableName TABLE =
         TableName.valueOf("testWithFamilyDeletes");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestPutDeleteEtcCellIteration.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestPutDeleteEtcCellIteration.java
index c46056d..c6868c5 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestPutDeleteEtcCellIteration.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestPutDeleteEtcCellIteration.java
@@ -43,7 +43,7 @@ public class TestPutDeleteEtcCellIteration {
   private static final long TIMESTAMP = System.currentTimeMillis();
   private static final int COUNT = 10;
 
-  @Test
+  @Test (timeout=180000)
   public void testPutIteration() throws IOException {
     Put p = new Put(ROW);
     for (int i = 0; i < COUNT; i++) {
@@ -78,7 +78,7 @@ public class TestPutDeleteEtcCellIteration {
     assertEquals(COUNT, index);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testDeleteIteration() throws IOException {
     Delete d = new Delete(ROW);
     for (int i = 0; i < COUNT; i++) {
@@ -94,7 +94,7 @@ public class TestPutDeleteEtcCellIteration {
     assertEquals(COUNT, index);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testAppendIteration() throws IOException {
     Append a = new Append(ROW);
     for (int i = 0; i < COUNT; i++) {
@@ -112,7 +112,7 @@ public class TestPutDeleteEtcCellIteration {
     assertEquals(COUNT, index);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testIncrementIteration() throws IOException {
     Increment increment = new Increment(ROW);
     for (int i = 0; i < COUNT; i++) {
@@ -132,7 +132,7 @@ public class TestPutDeleteEtcCellIteration {
     assertEquals(COUNT, index);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testResultIteration() throws IOException {
     Cell [] cells = new Cell[COUNT];
     for(int i = 0; i < COUNT; i++) {
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestPutWithDelete.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestPutWithDelete.java
index 0e819bb..b63a5be 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestPutWithDelete.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestPutWithDelete.java
@@ -49,7 +49,7 @@ public class TestPutWithDelete {
     TEST_UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testHbasePutDeleteCell() throws Exception {
     final TableName tableName = TableName.valueOf("TestPutWithDelete");
     final byte[] rowKey = Bytes.toBytes("12345");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestReplicasClient.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestReplicasClient.java
index efc8db2..35fcd3b 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestReplicasClient.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestReplicasClient.java
@@ -283,7 +283,7 @@ public class TestReplicasClient {
     TestRegionServerNoMaster.flushRegion(HTU, regionInfo);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testUseRegionWithoutReplica() throws Exception {
     byte[] b1 = "testUseRegionWithoutReplica".getBytes();
     openRegion(hriSecondary);
@@ -297,7 +297,7 @@ public class TestReplicasClient {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testLocations() throws Exception {
     byte[] b1 = "testLocations".getBytes();
     openRegion(hriSecondary);
@@ -322,7 +322,7 @@ public class TestReplicasClient {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGetNoResultNoStaleRegionWithReplica() throws Exception {
     byte[] b1 = "testGetNoResultNoStaleRegionWithReplica".getBytes();
     openRegion(hriSecondary);
@@ -338,7 +338,7 @@ public class TestReplicasClient {
   }
 
 
-  @Test
+  @Test (timeout=60000)
   public void testGetNoResultStaleRegionWithReplica() throws Exception {
     byte[] b1 = "testGetNoResultStaleRegionWithReplica".getBytes();
     openRegion(hriSecondary);
@@ -355,7 +355,7 @@ public class TestReplicasClient {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGetNoResultNotStaleSleepRegionWithReplica() throws Exception {
     byte[] b1 = "testGetNoResultNotStaleSleepRegionWithReplica".getBytes();
     openRegion(hriSecondary);
@@ -374,7 +374,7 @@ public class TestReplicasClient {
   }
 
 
-  @Test
+  @Test (timeout=60000)
   public void testFlushTable() throws Exception {
     openRegion(hriSecondary);
     try {
@@ -394,7 +394,7 @@ public class TestReplicasClient {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testFlushPrimary() throws Exception {
     openRegion(hriSecondary);
 
@@ -413,7 +413,7 @@ public class TestReplicasClient {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testFlushSecondary() throws Exception {
     openRegion(hriSecondary);
     try {
@@ -432,7 +432,7 @@ public class TestReplicasClient {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testUseRegionWithReplica() throws Exception {
     byte[] b1 = "testUseRegionWithReplica".getBytes();
     openRegion(hriSecondary);
@@ -525,7 +525,7 @@ public class TestReplicasClient {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCancelOfMultiGet() throws Exception {
     openRegion(hriSecondary);
     try {
@@ -590,25 +590,25 @@ public class TestReplicasClient {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testScanWithReplicas() throws Exception {
     //simple scan
     runMultipleScansOfOneType(false, false);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSmallScanWithReplicas() throws Exception {
     //small scan
     runMultipleScansOfOneType(false, true);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testReverseScanWithReplicas() throws Exception {
     //reverse scan
     runMultipleScansOfOneType(true, false);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCancelOfScan() throws Exception {
     openRegion(hriSecondary);
     int NUMROWS = 100;
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestRestoreSnapshotFromClient.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestRestoreSnapshotFromClient.java
index c5e6449..a881191 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestRestoreSnapshotFromClient.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestRestoreSnapshotFromClient.java
@@ -137,7 +137,7 @@ public class TestRestoreSnapshotFromClient {
     SnapshotTestingUtils.deleteArchiveDirectory(TEST_UTIL);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testRestoreSnapshot() throws IOException {
     SnapshotTestingUtils.verifyRowCount(TEST_UTIL, tableName, snapshot1Rows);
     admin.disableTable(tableName);
@@ -173,7 +173,7 @@ public class TestRestoreSnapshotFromClient {
     return 1;
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testRestoreSchemaChange() throws Exception {
     byte[] TEST_FAMILY2 = Bytes.toBytes("cf2");
 
@@ -227,7 +227,7 @@ public class TestRestoreSnapshotFromClient {
     table.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCloneSnapshotOfCloned() throws IOException, InterruptedException {
     TableName clonedTableName =
         TableName.valueOf("clonedtb-" + System.currentTimeMillis());
@@ -245,7 +245,7 @@ public class TestRestoreSnapshotFromClient {
     TEST_UTIL.deleteTable(clonedTableName);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCloneAndRestoreSnapshot() throws IOException, InterruptedException {
     TEST_UTIL.deleteTable(tableName);
     waitCleanerRun();
@@ -262,7 +262,7 @@ public class TestRestoreSnapshotFromClient {
     SnapshotTestingUtils.verifyReplicasCameOnline(tableName, admin, getNumReplicas());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCorruptedSnapshot() throws IOException, InterruptedException {
     SnapshotTestingUtils.corruptSnapshot(TEST_UTIL, Bytes.toString(snapshotName0));
     TableName cloneName = TableName.valueOf("corruptedClone-" + System.currentTimeMillis());
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestRpcControllerFactory.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestRpcControllerFactory.java
index dcf26f2..de529c1 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestRpcControllerFactory.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestRpcControllerFactory.java
@@ -118,7 +118,7 @@ public class TestRpcControllerFactory {
    * won't be sure to add them here. So we just can cover the major ones.
    * @throws Exception on failure
    */
-  @Test
+  @Test (timeout=60000)
   public void testCountController() throws Exception {
     Configuration conf = new Configuration(UTIL.getConfiguration());
     // setup our custom controller
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestScannersFromClientSide.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestScannersFromClientSide.java
index a6c1cfe..702cab0 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestScannersFromClientSide.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestScannersFromClientSide.java
@@ -100,7 +100,7 @@ public class TestScannersFromClientSide {
    *
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testScanBatch() throws Exception {
     TableName TABLE = TableName.valueOf("testScanBatch");
     byte [][] QUALIFIERS = HTestConst.makeNAscii(QUALIFIER, 8);
@@ -175,7 +175,7 @@ public class TestScannersFromClientSide {
    *
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testGetMaxResults() throws Exception {
     byte [] TABLE = Bytes.toBytes("testGetMaxResults");
     byte [][] FAMILIES = HTestConst.makeNAscii(FAMILY, 3);
@@ -295,7 +295,7 @@ public class TestScannersFromClientSide {
    *
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testScanMaxResults() throws Exception {
     byte [] TABLE = Bytes.toBytes("testScanLimit");
     byte [][] ROWS = HTestConst.makeNAscii(ROW, 2);
@@ -345,7 +345,7 @@ public class TestScannersFromClientSide {
    *
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testGetRowOffset() throws Exception {
     byte [] TABLE = Bytes.toBytes("testGetRowOffset");
     byte [][] FAMILIES = HTestConst.makeNAscii(FAMILY, 3);
@@ -441,7 +441,7 @@ public class TestScannersFromClientSide {
    *
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testScanOnReopenedRegion() throws Exception {
     TableName TABLE = TableName.valueOf("testScanOnReopenedRegion");
     byte [][] QUALIFIERS = HTestConst.makeNAscii(QUALIFIER, 2);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestTableSnapshotScanner.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestTableSnapshotScanner.java
index 0f0baff..ec94f6d 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestTableSnapshotScanner.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestTableSnapshotScanner.java
@@ -110,17 +110,17 @@ public class TestTableSnapshotScanner {
     table.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testWithSingleRegion() throws Exception {
     testScanner(UTIL, "testWithSingleRegion", 1, false);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testWithMultiRegion() throws Exception {
     testScanner(UTIL, "testWithMultiRegion", 10, false);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testWithOfflineHBaseMultiRegion() throws Exception {
     testScanner(UTIL, "testWithMultiRegion", 20, true);
   }
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestTimestampsFilter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestTimestampsFilter.java
index 4843715..6b0349f 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestTimestampsFilter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestTimestampsFilter.java
@@ -90,7 +90,7 @@ public class TestTimestampsFilter {
    *
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testTimestampsFilter() throws Exception {
     byte [] TABLE = Bytes.toBytes("testTimestampsFilter");
     byte [] FAMILY = Bytes.toBytes("event_log");
@@ -166,7 +166,7 @@ public class TestTimestampsFilter {
     ht.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMultiColumns() throws Exception {
     byte [] TABLE = Bytes.toBytes("testTimestampsFilterMultiColumns");
     byte [] FAMILY = Bytes.toBytes("event_log");
@@ -216,7 +216,7 @@ public class TestTimestampsFilter {
    *
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testWithVersionDeletes() throws Exception {
 
     // first test from memstore (without flushing).
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestUpdateConfiguration.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestUpdateConfiguration.java
index 73e493b..5333110 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestUpdateConfiguration.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestUpdateConfiguration.java
@@ -46,7 +46,7 @@ public class TestUpdateConfiguration {
     TEST_UTIL.startMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testOnlineConfigChange() throws IOException {
     LOG.debug("Starting the test");
     Admin admin = TEST_UTIL.getHBaseAdmin();
@@ -54,7 +54,7 @@ public class TestUpdateConfiguration {
     admin.updateConfiguration(server);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMasterOnlineConfigChange() throws IOException {
     LOG.debug("Starting the test");
     Path cnfPath = FileSystems.getDefault().getPath("target/test-classes/hbase-site.xml");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/replication/TestReplicationAdmin.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/replication/TestReplicationAdmin.java
index 4db646e..5872fb9 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/replication/TestReplicationAdmin.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/replication/TestReplicationAdmin.java
@@ -73,7 +73,7 @@ public class TestReplicationAdmin {
    * all interactions with ZK work
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testAddRemovePeer() throws Exception {
     // Add a valid peer
     admin.addPeer(ID_ONE, KEY_ONE);
@@ -110,7 +110,7 @@ public class TestReplicationAdmin {
    * basic checks that when we add a peer that it is enabled, and that we can disable
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testEnableDisable() throws Exception {
     admin.addPeer(ID_ONE, KEY_ONE);
     assertEquals(1, admin.getPeersCount());
@@ -126,7 +126,7 @@ public class TestReplicationAdmin {
     admin.removePeer(ID_ONE);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGetTableCfsStr() {
     // opposite of TestPerTableCFReplication#testParseTableCFsFromConfig()
 
@@ -157,7 +157,7 @@ public class TestReplicationAdmin {
     assertEquals("tab1;tab2:cf1;tab3:cf1,cf3", ReplicationAdmin.getTableCfsStr(tabCFsMap));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testAppendPeerTableCFs() throws Exception {
     // Add a valid peer
     admin.addPeer(ID_ONE, KEY_ONE);
@@ -175,7 +175,7 @@ public class TestReplicationAdmin {
     admin.removePeer(ID_ONE);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testRemovePeerTableCFs() throws Exception {
     // Add a valid peer
     admin.addPeer(ID_ONE, KEY_ONE);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/codec/TestCellMessageCodec.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/codec/TestCellMessageCodec.java
index b51de80..7338417 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/codec/TestCellMessageCodec.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/codec/TestCellMessageCodec.java
@@ -45,7 +45,7 @@ import com.google.common.io.CountingOutputStream;
 public class TestCellMessageCodec {
   public static final Log LOG = LogFactory.getLog(TestCellMessageCodec.class);
 
-  @Test
+  @Test (timeout=180000)
   public void testEmptyWorks() throws IOException {
     ByteArrayOutputStream baos = new ByteArrayOutputStream();
     CountingOutputStream cos = new CountingOutputStream(baos);
@@ -64,7 +64,7 @@ public class TestCellMessageCodec {
     assertEquals(0, cis.getCount());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testOne() throws IOException {
     ByteArrayOutputStream baos = new ByteArrayOutputStream();
     CountingOutputStream cos = new CountingOutputStream(baos);
@@ -86,7 +86,7 @@ public class TestCellMessageCodec {
     assertEquals(offset, cis.getCount());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testThree() throws IOException {
     ByteArrayOutputStream baos = new ByteArrayOutputStream();
     CountingOutputStream cos = new CountingOutputStream(baos);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/conf/TestConfigurationManager.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/conf/TestConfigurationManager.java
index fe56344..098ac4c 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/conf/TestConfigurationManager.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/conf/TestConfigurationManager.java
@@ -68,7 +68,7 @@ public class TestConfigurationManager {
    * Test if observers get notified by the <code>ConfigurationManager</code>
    * when the Configuration is reloaded.
    */
-  @Test
+  @Test (timeout=180000)
   public void testCheckIfObserversNotified() {
     Configuration conf = new Configuration();
     ConfigurationManager cm = new ConfigurationManager();
@@ -104,7 +104,7 @@ public class TestConfigurationManager {
   /**
    * Test if out-of-scope observers are deregistered on GC.
    */
-  @Test
+  @Test (timeout=180000)
   public void testDeregisterOnOutOfScope() {
     Configuration conf = new Configuration();
     ConfigurationManager cm = new ConfigurationManager();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/constraint/TestConstraint.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/constraint/TestConstraint.java
index 96da03a..d29f4c6 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/constraint/TestConstraint.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/constraint/TestConstraint.java
@@ -70,7 +70,7 @@ public class TestConstraint {
    * @throws Exception
    */
   @SuppressWarnings("unchecked")
-  @Test
+  @Test (timeout=60000)
   public void testConstraintPasses() throws Exception {
     // create the table
     // it would be nice if this was also a method on the util
@@ -139,7 +139,7 @@ public class TestConstraint {
    * @throws Throwable
    */
   @SuppressWarnings("unchecked")
-  @Test
+  @Test (timeout=60000)
   public void testDisableConstraint() throws Throwable {
     // create the table
     HTableDescriptor desc = new HTableDescriptor(tableName);
@@ -174,7 +174,7 @@ public class TestConstraint {
    * @throws Throwable
    */
   @SuppressWarnings("unchecked")
-  @Test
+  @Test (timeout=60000)
   public void testDisableConstraints() throws Throwable {
     // create the table
     HTableDescriptor desc = new HTableDescriptor(tableName);
@@ -206,7 +206,7 @@ public class TestConstraint {
    * Check to make sure a constraint is unloaded when it fails
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testIsUnloaded() throws Exception {
     // create the table
     HTableDescriptor desc = new HTableDescriptor(tableName);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/constraint/TestConstraints.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/constraint/TestConstraints.java
index afd55bb..65853ae 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/constraint/TestConstraints.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/constraint/TestConstraints.java
@@ -43,7 +43,7 @@ import org.junit.experimental.categories.Category;
 public class TestConstraints {
 
   @SuppressWarnings("unchecked")
-  @Test
+  @Test (timeout=180000)
   public void testSimpleReadWrite() throws Throwable {
     HTableDescriptor desc = new HTableDescriptor(TableName.valueOf("table"));
     Constraints.add(desc, WorksConstraint.class);
@@ -68,7 +68,7 @@ public class TestConstraints {
   }
 
   @SuppressWarnings("unchecked")
-  @Test
+  @Test (timeout=180000)
   public void testReadWriteWithConf() throws Throwable {
     HTableDescriptor desc = new HTableDescriptor(TableName.valueOf("table"));
     Constraints.add(
@@ -101,7 +101,7 @@ public class TestConstraints {
    * @throws Exception
    */
   @SuppressWarnings("unchecked")
-  @Test
+  @Test (timeout=180000)
   public void testEnableDisableRemove() throws Exception {
     HTableDescriptor desc = new HTableDescriptor(TableName.valueOf("table"));
     // check general enabling/disabling of constraints
@@ -137,7 +137,7 @@ public class TestConstraints {
    * @throws Exception
    */
   @SuppressWarnings("unchecked")
-  @Test
+  @Test (timeout=180000)
   public void testUpdateConstraint() throws Exception {
     HTableDescriptor desc = new HTableDescriptor(TableName.valueOf("table"));
     Constraints.add(desc, CheckConfigurationConstraint.class,
@@ -163,14 +163,14 @@ public class TestConstraints {
    * @throws Throwable
    *           on failure.
    */
-  @Test
+  @Test (timeout=180000)
   public void testRemoveUnsetConstraint() throws Throwable {
     HTableDescriptor desc = new HTableDescriptor(TableName.valueOf("table"));
     Constraints.remove(desc);
     Constraints.remove(desc, AlsoWorks.class);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testConfigurationPreserved() throws Throwable {
     Configuration conf = new Configuration();
     conf.setBoolean("_ENABLED", false);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestBatchCoprocessorEndpoint.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestBatchCoprocessorEndpoint.java
index a5ee4c1..ba86608 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestBatchCoprocessorEndpoint.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestBatchCoprocessorEndpoint.java
@@ -108,7 +108,7 @@ public class TestBatchCoprocessorEndpoint {
     util.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testAggregationNullResponse() throws Throwable {
     Table table = util.getConnection().getTable(TEST_TABLE);
     ColumnAggregationWithNullResponseProtos.SumRequest.Builder builder =
@@ -161,7 +161,7 @@ public class TestBatchCoprocessorEndpoint {
         builder.build(), start, end, ColumnAggregationProtos.SumResponse.getDefaultInstance());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testAggregationWithReturnValue() throws Throwable {
     Table table = util.getConnection().getTable(TEST_TABLE);
     Map<byte[], SumResponse> results = sum(table, TEST_FAMILY, TEST_QUALIFIER, ROWS[0],
@@ -197,7 +197,7 @@ public class TestBatchCoprocessorEndpoint {
     table.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testAggregation() throws Throwable {
     Table table = util.getConnection().getTable(TEST_TABLE);
     Map<byte[], SumResponse> results = sum(table, TEST_FAMILY, TEST_QUALIFIER,
@@ -230,7 +230,7 @@ public class TestBatchCoprocessorEndpoint {
     table.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testAggregationWithErrors() throws Throwable {
     Table table = util.getConnection().getTable(TEST_TABLE);
     final Map<byte[], ColumnAggregationWithErrorsProtos.SumResponse> results =
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestBigDecimalColumnInterpreter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestBigDecimalColumnInterpreter.java
index ac75660..4d42cfc 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestBigDecimalColumnInterpreter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestBigDecimalColumnInterpreter.java
@@ -684,7 +684,7 @@ public class TestBigDecimalColumnInterpreter {
     // null column family, and max will be set to 0
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testStdWithInvalidRange() {
     AggregationClient aClient = new AggregationClient(conf);
     Scan scan = new Scan();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestClassLoading.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestClassLoading.java
index 140c3b9..8f8d79e 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestClassLoading.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestClassLoading.java
@@ -111,7 +111,7 @@ public class TestClassLoading {
       TEST_UTIL.getDataTestDir().toString(), className, code);
   }
 
-  @Test
+  @Test (timeout=60000)
   // HBASE-3516: Test CP Class loading from HDFS
   public void testClassLoadingFromHDFS() throws Exception {
     FileSystem fs = cluster.getFileSystem();
@@ -218,7 +218,7 @@ public class TestClassLoading {
     return new Path(file.toURI()).toString();
   }
 
-  @Test
+  @Test (timeout=60000)
   // HBASE-3516: Test CP Class loading from local file system
   public void testClassLoadingFromLocalFS() throws Exception {
     File jarFile = buildCoprocessorJar(cpName3);
@@ -244,7 +244,7 @@ public class TestClassLoading {
     assertTrue("Class " + cpName3 + " was missing on a region", found);
   }
 
-  @Test
+  @Test (timeout=60000)
   // HBASE-6308: Test CP classloader is the CoprocessorClassLoader
   public void testPrivateClassLoader() throws Exception {
     File jarFile = buildCoprocessorJar(cpName4);
@@ -275,7 +275,7 @@ public class TestClassLoading {
     assertTrue("Class " + cpName4 + " was missing on a region", found);
   }
 
-  @Test
+  @Test (timeout=60000)
   // HBase-3810: Registering a Coprocessor at HTableDescriptor should be
   // less strict
   public void testHBase3810() throws Exception {
@@ -370,12 +370,12 @@ public class TestClassLoading {
     assertFalse("Configuration key 'k4' wasn't configured", found6_k4);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testClassLoadingFromLibDirInJar() throws Exception {
     loadingClassFromLibDirInJar("/lib/");
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testClassLoadingFromRelativeLibDirInJar() throws Exception {
     loadingClassFromLibDirInJar("lib/");
   }
@@ -447,7 +447,7 @@ public class TestClassLoading {
     assertTrue("Configuration key 'k3' was missing on a region", found2_k3);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testRegionServerCoprocessorsReported() throws Exception {
     // This was a test for HBASE-4070.
     // We are removing coprocessors from region load in HBASE-5258.
@@ -518,7 +518,7 @@ public class TestClassLoading {
     assertTrue(success);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMasterCoprocessorsReported() {
     // HBASE 4070: Improve region server metrics to report loaded coprocessors
     // to master: verify that the master is reporting the correct set of
@@ -531,7 +531,7 @@ public class TestClassLoading {
     assertEquals(loadedMasterCoprocessorsVerify, loadedMasterCoprocessors);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testFindCoprocessors() {
     // HBASE 12277: 
     CoprocessorHost masterCpHost =
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorConfiguration.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorConfiguration.java
index fb2f20c..5e9a8e2 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorConfiguration.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorConfiguration.java
@@ -94,7 +94,7 @@ public class TestCoprocessorConfiguration {
     public void stop(CoprocessorEnvironment env) throws IOException { }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRegionCoprocessorHostDefaults() throws Exception {
     Configuration conf = new Configuration(CONF);
     HRegion region = mock(HRegion.class);
@@ -113,7 +113,7 @@ public class TestCoprocessorConfiguration {
       CoprocessorHost.DEFAULT_USER_COPROCESSORS_ENABLED);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRegionServerCoprocessorHostDefaults() throws Exception {
     Configuration conf = new Configuration(CONF);
     RegionServerServices rsServices = mock(RegionServerServices.class);
@@ -124,7 +124,7 @@ public class TestCoprocessorConfiguration {
       CoprocessorHost.DEFAULT_COPROCESSORS_ENABLED);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testMasterCoprocessorHostDefaults() throws Exception {
     Configuration conf = new Configuration(CONF);
     MasterServices masterServices = mock(MasterServices.class);
@@ -135,7 +135,7 @@ public class TestCoprocessorConfiguration {
       CoprocessorHost.DEFAULT_COPROCESSORS_ENABLED);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRegionCoprocessorHostAllDisabled() throws Exception {
     Configuration conf = new Configuration(CONF);
     conf.setBoolean(CoprocessorHost.COPROCESSORS_ENABLED_CONF_KEY, false);
@@ -152,7 +152,7 @@ public class TestCoprocessorConfiguration {
       tableCoprocessorLoaded.get());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRegionCoprocessorHostTableLoadingDisabled() throws Exception {
     Configuration conf = new Configuration(CONF);
     conf.setBoolean(CoprocessorHost.COPROCESSORS_ENABLED_CONF_KEY, true); // if defaults change
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorEndpoint.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorEndpoint.java
index a3e0c91..7ba145a 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorEndpoint.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorEndpoint.java
@@ -136,7 +136,7 @@ public class TestCoprocessorEndpoint {
       });
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testAggregation() throws Throwable {
     Table table = util.getConnection().getTable(TEST_TABLE);
     Map<byte[], Long> results = sum(table, TEST_FAMILY, TEST_QUALIFIER,
@@ -170,7 +170,7 @@ public class TestCoprocessorEndpoint {
     table.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCoprocessorService() throws Throwable {
     HTable table = (HTable) util.getConnection().getTable(TEST_TABLE);
     NavigableMap<HRegionInfo,ServerName> regions = table.getRegionLocations();
@@ -244,7 +244,7 @@ public class TestCoprocessorEndpoint {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCoprocessorServiceNullResponse() throws Throwable {
     HTable table = (HTable) util.getConnection().getTable(TEST_TABLE);
     NavigableMap<HRegionInfo,ServerName> regions = table.getRegionLocations();
@@ -282,7 +282,7 @@ public class TestCoprocessorEndpoint {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMasterCoprocessorService() throws Throwable {
     Admin admin = util.getHBaseAdmin();
     final TestProtos.EchoRequestProto request =
@@ -292,7 +292,7 @@ public class TestCoprocessorEndpoint {
     assertEquals("hello", service.echo(null, request).getMessage());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCoprocessorError() throws Exception {
     Configuration configuration = new Configuration(util.getConfiguration());
     // Make it not retry forever
@@ -313,7 +313,7 @@ public class TestCoprocessorEndpoint {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMasterCoprocessorError() throws Throwable {
     Admin admin = util.getHBaseAdmin();
     TestRpcServiceProtos.TestProtobufRpcProto.BlockingInterface service =
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorInterface.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorInterface.java
index ce76e8a..14aaf03 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorInterface.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorInterface.java
@@ -274,7 +274,7 @@ public class TestCoprocessorInterface {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSharedData() throws IOException {
     TableName tableName = TableName.valueOf(name.getMethodName());
     byte [][] families = { fam1, fam2, fam3 };
@@ -353,7 +353,7 @@ public class TestCoprocessorInterface {
     HBaseTestingUtility.closeRegionAndWAL(region);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testCoprocessorInterface() throws IOException {
     TableName tableName = TableName.valueOf(name.getMethodName());
     byte [][] families = { fam1, fam2, fam3 };
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorStop.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorStop.java
index 2ef13f7..16f2d6c 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorStop.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorStop.java
@@ -104,7 +104,7 @@ public class TestCoprocessorStop {
     UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testStopped() throws Exception {
     //shutdown hbase only. then check flag file.
     MiniHBaseCluster cluster = UTIL.getHBaseCluster();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorTableEndpoint.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorTableEndpoint.java
index 7695361..ffb6fb5 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorTableEndpoint.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorTableEndpoint.java
@@ -67,7 +67,7 @@ public class TestCoprocessorTableEndpoint {
     TEST_UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCoprocessorTableEndpoint() throws Throwable {    
     final TableName tableName = TableName.valueOf("testCoprocessorTableEndpoint");
 
@@ -79,7 +79,7 @@ public class TestCoprocessorTableEndpoint {
     verifyTable(tableName);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testDynamicCoprocessorTableEndpoint() throws Throwable {    
     final TableName tableName = TableName.valueOf("testDynamicCoprocessorTableEndpoint");
 
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestDoubleColumnInterpreter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestDoubleColumnInterpreter.java
index baea95d..da32755 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestDoubleColumnInterpreter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestDoubleColumnInterpreter.java
@@ -682,7 +682,7 @@ public class TestDoubleColumnInterpreter {
     // null column family, and max will be set to 0
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testStdWithInvalidRange() {
     AggregationClient aClient = new AggregationClient(conf);
     Scan scan = new Scan();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestHTableWrapper.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestHTableWrapper.java
index 317707a..bbc7355 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestHTableWrapper.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestHTableWrapper.java
@@ -127,7 +127,7 @@ public class TestHTableWrapper {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testHTableInterfaceMethods() throws Exception {
     Configuration conf = util.getConfiguration();
     MasterCoprocessorHost cpHost = util.getMiniHBaseCluster().getMaster().getMasterCoprocessorHost();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestMasterObserver.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestMasterObserver.java
index 094555e..1951931 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestMasterObserver.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestMasterObserver.java
@@ -1179,7 +1179,7 @@ public class TestMasterObserver {
     UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testStarted() throws Exception {
     MiniHBaseCluster cluster = UTIL.getHBaseCluster();
 
@@ -1199,7 +1199,7 @@ public class TestMasterObserver {
         cp.wasStartMasterCalled());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testTableOperations() throws Exception {
     MiniHBaseCluster cluster = UTIL.getHBaseCluster();
 
@@ -1365,7 +1365,7 @@ public class TestMasterObserver {
         cp.wasDeleteTableHandlerCalled());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSnapshotOperations() throws Exception {
     MiniHBaseCluster cluster = UTIL.getHBaseCluster();
     HMaster master = cluster.getMaster();
@@ -1426,7 +1426,7 @@ public class TestMasterObserver {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testNamespaceOperations() throws Exception {
     MiniHBaseCluster cluster = UTIL.getHBaseCluster();
     String testNamespace = "observed_ns";
@@ -1513,7 +1513,7 @@ public class TestMasterObserver {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testRegionTransitionOperations() throws Exception {
     MiniHBaseCluster cluster = UTIL.getHBaseCluster();
 
@@ -1615,7 +1615,7 @@ public class TestMasterObserver {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testTableDescriptorsEnumeration() throws Exception {
     MiniHBaseCluster cluster = UTIL.getHBaseCluster();
 
@@ -1633,7 +1633,7 @@ public class TestMasterObserver {
       cp.wasGetTableDescriptorsCalled());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testTableNamesEnumeration() throws Exception {
     MiniHBaseCluster cluster = UTIL.getHBaseCluster();
 
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestOpenTableInCoprocessor.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestOpenTableInCoprocessor.java
index 4c3594b..d887b23 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestOpenTableInCoprocessor.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestOpenTableInCoprocessor.java
@@ -135,12 +135,12 @@ public class TestOpenTableInCoprocessor {
     UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCoprocessorCanCreateConnectionToRemoteTable() throws Throwable {
     runCoprocessorConnectionToRemoteTable(SendToOtherTableCoprocessor.class, completed);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCoprocessorCanCreateConnectionToRemoteTableWithCustomPool() throws Throwable {
     runCoprocessorConnectionToRemoteTable(CustomThreadPoolCoprocessor.class, completedWithPool);
   }
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionObserverBypass.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionObserverBypass.java
index a02758dac..fe70be8 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionObserverBypass.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionObserverBypass.java
@@ -91,7 +91,7 @@ public class TestRegionObserverBypass {
    * do a single put that is bypassed by a RegionObserver
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testSimple() throws Exception {
     Table t = util.getConnection().getTable(tableName);
     Put p = new Put(row1);
@@ -106,7 +106,7 @@ public class TestRegionObserverBypass {
    * Test various multiput operations.
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testMulti() throws Exception {
     //ensure that server time increments every time we do an operation, otherwise
     //previous deletes will eclipse successive puts having the same timestamp
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionObserverScannerOpenHook.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionObserverScannerOpenHook.java
index 6c7552a..e56f81a 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionObserverScannerOpenHook.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionObserverScannerOpenHook.java
@@ -162,7 +162,7 @@ public class TestRegionObserverScannerOpenHook {
     return r;
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testRegionObserverScanTimeStacking() throws Exception {
     byte[] ROW = Bytes.toBytes("testRow");
     byte[] TABLE = Bytes.toBytes(getClass().getName());
@@ -187,7 +187,7 @@ public class TestRegionObserverScannerOpenHook {
     HBaseTestingUtility.closeRegionAndWAL(region);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testRegionObserverFlushTimeStacking() throws Exception {
     byte[] ROW = Bytes.toBytes("testRow");
     byte[] TABLE = Bytes.toBytes(getClass().getName());
@@ -245,7 +245,7 @@ public class TestRegionObserverScannerOpenHook {
    * the usual compaction mechanism on the region, rather than going through the backdoor to the
    * region
    */
-  @Test
+  @Test (timeout=60000)
   public void testRegionObserverCompactionTimeStacking() throws Exception {
     // setup a mini cluster so we can do a real compaction on a region
     Configuration conf = UTIL.getConfiguration();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionServerCoprocessorEndpoint.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionServerCoprocessorEndpoint.java
index 7ae6787..a221deb 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionServerCoprocessorEndpoint.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionServerCoprocessorEndpoint.java
@@ -65,7 +65,7 @@ public class TestRegionServerCoprocessorEndpoint {
     TEST_UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testEndpoint() throws Exception {
     final ServerName serverName = TEST_UTIL.getHBaseCluster().getRegionServer(0).getServerName();
     final ServerRpcController controller = new ServerRpcController();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionServerObserver.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionServerObserver.java
index 2e6eabc..eb5fbd6 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionServerObserver.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRegionServerObserver.java
@@ -60,7 +60,7 @@ public class TestRegionServerObserver {
    * Test verifies the hooks in regions merge.
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testCoprocessorHooksInRegionsMerge() throws Exception {
     final int NUM_MASTERS = 1;
     final int NUM_RS = 1;
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRowProcessorEndpoint.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRowProcessorEndpoint.java
index 2136c3c..b5b958a 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRowProcessorEndpoint.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRowProcessorEndpoint.java
@@ -151,7 +151,7 @@ public class TestRowProcessorEndpoint {
     row2Size = put.size();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testDoubleScan() throws Throwable {
     prepareTestData();
 
@@ -173,7 +173,7 @@ public class TestRowProcessorEndpoint {
     assertEquals(expected, result);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testReadModifyWrite() throws Throwable {
     prepareTestData();
     failures.set(0);
@@ -234,7 +234,7 @@ public class TestRowProcessorEndpoint {
     doneSignal.await();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMultipleRows() throws Throwable {
     prepareTestData();
     failures.set(0);
@@ -270,7 +270,7 @@ public class TestRowProcessorEndpoint {
     service.process(null, request);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testTimeout() throws Throwable {
     prepareTestData();
     CoprocessorRpcChannel channel = table.coprocessorService(ROW);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestWALObserver.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestWALObserver.java
index cdcdeed..b404ec9 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestWALObserver.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestWALObserver.java
@@ -161,7 +161,7 @@ public class TestWALObserver {
    * WALEdit written to WAL, and ignore, modify, and add KeyValue's for the
    * WALEdit.
    */
-  @Test
+  @Test (timeout=60000)
   public void testWALObserverWriteToWAL() throws Exception {
     final WAL log = wals.getWAL(UNSPECIFIED_REGION);
     verifyWritesSeen(log, getCoprocessor(log, SampleRegionWALObserver.class), false);
@@ -172,7 +172,7 @@ public class TestWALObserver {
    * WALEdit written to WAL, and ignore, modify, and add KeyValue's for the
    * WALEdit.
    */
-  @Test
+  @Test (timeout=60000)
   public void testLegacyWALObserverWriteToWAL() throws Exception {
     final WAL log = wals.getWAL(UNSPECIFIED_REGION);
     verifyWritesSeen(log, getCoprocessor(log, SampleRegionWALObserver.Legacy.class), true);
@@ -266,7 +266,7 @@ public class TestWALObserver {
     assertEquals(seesLegacy, cp.isPostWALWriteDeprecatedCalled());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testNonLegacyWALKeysDoNotExplode() throws Exception {
     TableName tableName = TableName.valueOf(TEST_TABLE);
     final HTableDescriptor htd = createBasic3FamilyHTD(Bytes
@@ -344,7 +344,7 @@ public class TestWALObserver {
   /**
    * Coprocessors shouldn't get notice of empty waledits.
    */
-  @Test
+  @Test (timeout=60000)
   public void testEmptyWALEditAreNotSeen() throws Exception {
     final HRegionInfo hri = createBasic3FamilyHRegionInfo(Bytes.toString(TEST_TABLE));
     final HTableDescriptor htd = createBasic3FamilyHTD(Bytes.toString(TEST_TABLE));
@@ -374,7 +374,7 @@ public class TestWALObserver {
   /**
    * Test WAL replay behavior with WALObserver.
    */
-  @Test
+  @Test (timeout=60000)
   public void testWALCoprocessorReplay() throws Exception {
     // WAL replay is handled at HRegion::replayRecoveredEdits(), which is
     // ultimately called by HRegion::initialize()
@@ -446,7 +446,7 @@ public class TestWALObserver {
    * TestHLog, but the purpose of that one is to see whether the loaded CP will
    * impact existing WAL tests or not.
    */
-  @Test
+  @Test (timeout=60000)
   public void testWALObserverLoaded() throws Exception {
     WAL log = wals.getWAL(UNSPECIFIED_REGION);
     assertNotNull(getCoprocessor(log, SampleRegionWALObserver.class));
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/errorhandling/TestForeignExceptionDispatcher.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/errorhandling/TestForeignExceptionDispatcher.java
index 229b170..25e8a01 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/errorhandling/TestForeignExceptionDispatcher.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/errorhandling/TestForeignExceptionDispatcher.java
@@ -46,7 +46,7 @@ public class TestForeignExceptionDispatcher {
    * Tests that a dispatcher only dispatches only the first exception, and does not propagate
    * subsequent exceptions.
    */
-  @Test
+  @Test (timeout=180000)
   public void testErrorPropagation() {
     ForeignExceptionListener listener1 = Mockito.mock(ForeignExceptionListener.class);
     ForeignExceptionListener listener2 = Mockito.mock(ForeignExceptionListener.class);
@@ -78,7 +78,7 @@ public class TestForeignExceptionDispatcher {
     Mockito.verify(listener2, Mockito.never()).receive(EXTEXN2);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSingleDispatcherWithTimer() {
     ForeignExceptionListener listener1 = Mockito.mock(ForeignExceptionListener.class);
     ForeignExceptionListener listener2 = Mockito.mock(ForeignExceptionListener.class);
@@ -103,7 +103,7 @@ public class TestForeignExceptionDispatcher {
   /**
    * Test that the dispatcher can receive an error via the timer mechanism.
    */
-  @Test
+  @Test (timeout=180000)
   public void testAttemptTimer() {
     ForeignExceptionListener listener1 = Mockito.mock(ForeignExceptionListener.class);
     ForeignExceptionListener listener2 = Mockito.mock(ForeignExceptionListener.class);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/errorhandling/TestForeignExceptionSerialization.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/errorhandling/TestForeignExceptionSerialization.java
index f893555..2628660 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/errorhandling/TestForeignExceptionSerialization.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/errorhandling/TestForeignExceptionSerialization.java
@@ -40,7 +40,7 @@ public class TestForeignExceptionSerialization {
    * Verify that we get back similar stack trace information before an after serialization.
    * @throws InvalidProtocolBufferException
    */
-  @Test
+  @Test (timeout=180000)
   public void testSimpleException() throws InvalidProtocolBufferException {
     String data = "some bytes";
     ForeignException in = new ForeignException("SRC", new IllegalArgumentException(data));
@@ -63,7 +63,7 @@ public class TestForeignExceptionSerialization {
    * serialization and deserialization
    * @throws InvalidProtocolBufferException
    */
-  @Test
+  @Test (timeout=180000)
   public void testRemoteFromLocal() throws InvalidProtocolBufferException {
     String errorMsg = "some message";
     Exception generic = new Exception(errorMsg);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/errorhandling/TestTimeoutExceptionInjector.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/errorhandling/TestTimeoutExceptionInjector.java
index 49f6164..930e8d3 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/errorhandling/TestTimeoutExceptionInjector.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/errorhandling/TestTimeoutExceptionInjector.java
@@ -51,7 +51,7 @@ public class TestTimeoutExceptionInjector {
   /**
    * Test that a manually triggered exception with data fires with the data in receiveError.
    */
-  @Test
+  @Test (timeout=180000)
   public void testTimerPassesOnErrorInfo() {
     final long time = 1000000;
     ForeignExceptionListener listener = Mockito.mock(ForeignExceptionListener.class);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/executor/TestExecutorService.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/executor/TestExecutorService.java
index 0561ac4..70310b1 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/executor/TestExecutorService.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/executor/TestExecutorService.java
@@ -43,7 +43,7 @@ import static org.mockito.Mockito.*;
 public class TestExecutorService {
   private static final Log LOG = LogFactory.getLog(TestExecutorService.class);
 
-  @Test
+  @Test (timeout=180000)
   public void testExecutorService() throws Exception {
     int maxThreads = 5;
     int maxTries = 10;
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestBitComparator.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestBitComparator.java
index 21414f0..8419c52 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestBitComparator.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestBitComparator.java
@@ -42,7 +42,7 @@ public class TestBitComparator {
   private final int Equal = 0;
   private final int NotEqual = 1;
 
-  @Test
+  @Test (timeout=180000)
   public void testANDOperation() {
     testOperation(zeros, ones, BitComparator.BitwiseOp.AND, NotEqual);
     testOperation(data1, ones, BitComparator.BitwiseOp.AND, Equal);
@@ -52,7 +52,7 @@ public class TestBitComparator {
     testOperation(ones, data3, BitComparator.BitwiseOp.AND, NotEqual);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testOROperation() {
     testOperation(ones, zeros, BitComparator.BitwiseOp.OR, Equal);
     testOperation(zeros, zeros, BitComparator.BitwiseOp.OR, NotEqual);
@@ -61,7 +61,7 @@ public class TestBitComparator {
     testOperation(ones, data3, BitComparator.BitwiseOp.OR, NotEqual);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testXOROperation() {
     testOperation(ones, zeros, BitComparator.BitwiseOp.XOR, Equal);
     testOperation(zeros, zeros, BitComparator.BitwiseOp.XOR, NotEqual);
@@ -75,20 +75,20 @@ public class TestBitComparator {
     assertEquals(comparator.compareTo(data), expected);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testANDOperationWithOffset() {
     testOperationWithOffset(data1_2, ones, BitComparator.BitwiseOp.AND, Equal);
     testOperationWithOffset(data1_2, data0, BitComparator.BitwiseOp.AND, NotEqual);
     testOperationWithOffset(data2_2, data1, BitComparator.BitwiseOp.AND, NotEqual);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testOROperationWithOffset() {
     testOperationWithOffset(data1_2, zeros, BitComparator.BitwiseOp.OR, Equal);
     testOperationWithOffset(data2_2, data1, BitComparator.BitwiseOp.OR, Equal);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testXOROperationWithOffset() {
     testOperationWithOffset(data2_2, data1, BitComparator.BitwiseOp.XOR, Equal);
   }
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestColumnPaginationFilter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestColumnPaginationFilter.java
index 4d0329b..f910195 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestColumnPaginationFilter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestColumnPaginationFilter.java
@@ -84,7 +84,7 @@ public class TestColumnPaginationFilter
      * Tests serialization
      * @throws Exception
      */
-    @Test
+    @Test (timeout=180000)
     public void testSerialization() throws Exception {
       Filter newFilter = serializationTest(columnPaginationFilter);
       basicFilterTests((ColumnPaginationFilter)newFilter);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestColumnPrefixFilter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestColumnPrefixFilter.java
index 2e51c82..7beb505 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestColumnPrefixFilter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestColumnPrefixFilter.java
@@ -45,7 +45,7 @@ public class TestColumnPrefixFilter {
   private final static HBaseTestingUtility TEST_UTIL = new
       HBaseTestingUtility();
 
-  @Test
+  @Test (timeout=180000)
   public void testColumnPrefixFilter() throws IOException {
     String family = "Family";
     HTableDescriptor htd = new HTableDescriptor(TableName.valueOf("TestColumnPrefixFilter"));
@@ -107,7 +107,7 @@ public class TestColumnPrefixFilter {
     HBaseTestingUtility.closeRegionAndWAL(region);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testColumnPrefixFilterWithFilterList() throws IOException {
     String family = "Family";
     HTableDescriptor htd = new HTableDescriptor(TableName.valueOf("TestColumnPrefixFilter"));
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestColumnRangeFilter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestColumnRangeFilter.java
index 1c81adf..3aac57b 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestColumnRangeFilter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestColumnRangeFilter.java
@@ -156,7 +156,7 @@ public class TestColumnRangeFilter {
     // Nothing to do.
   }
 
-  @Test
+  @Test (timeout=60000)
   public void TestColumnRangeFilterClient() throws Exception {
     String family = "Family";
     String table = "TestColumnRangeFilterClient";
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestComparatorSerialization.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestComparatorSerialization.java
index 223416f..c812844 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestComparatorSerialization.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestComparatorSerialization.java
@@ -34,14 +34,14 @@ import org.junit.experimental.categories.Category;
 @Category({FilterTests.class, SmallTests.class})
 public class TestComparatorSerialization {
 
-  @Test
+  @Test (timeout=180000)
   public void testBinaryComparator() throws Exception {
     BinaryComparator binaryComparator = new BinaryComparator(Bytes.toBytes("binaryComparator"));
     assertTrue(binaryComparator.areSerializedFieldsEqual(
       ProtobufUtil.toComparator(ProtobufUtil.toComparator(binaryComparator))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testBinaryPrefixComparator() throws Exception {
     BinaryPrefixComparator binaryPrefixComparator =
       new BinaryPrefixComparator(Bytes.toBytes("binaryPrefixComparator"));
@@ -49,7 +49,7 @@ public class TestComparatorSerialization {
       ProtobufUtil.toComparator(ProtobufUtil.toComparator(binaryPrefixComparator))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testBitComparator() throws Exception {
     BitComparator bitComparator =
       new BitComparator(Bytes.toBytes("bitComparator"), BitComparator.BitwiseOp.XOR);
@@ -57,14 +57,14 @@ public class TestComparatorSerialization {
       ProtobufUtil.toComparator(ProtobufUtil.toComparator(bitComparator))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testNullComparator() throws Exception {
     NullComparator nullComparator = new NullComparator();
     assertTrue(nullComparator.areSerializedFieldsEqual(
       ProtobufUtil.toComparator(ProtobufUtil.toComparator(nullComparator))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRegexStringComparator() throws Exception {
     // test without specifying flags
     RegexStringComparator regexStringComparator = new RegexStringComparator(".+-2");
@@ -79,7 +79,7 @@ public class TestComparatorSerialization {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSubstringComparator() throws Exception {
     SubstringComparator substringComparator = new SubstringComparator("substr");
     assertTrue(substringComparator.areSerializedFieldsEqual(
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestDependentColumnFilter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestDependentColumnFilter.java
index 40a4c43..b2f60f9 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestDependentColumnFilter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestDependentColumnFilter.java
@@ -166,7 +166,7 @@ public class TestDependentColumnFilter {
   /**
    * Test scans using a DependentColumnFilter
    */
-  @Test
+  @Test (timeout=180000)
   public void testScans() throws Exception {
     Filter filter = new DependentColumnFilter(FAMILIES[0], QUALIFIER);
 
@@ -222,7 +222,7 @@ public class TestDependentColumnFilter {
    *
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   public void testFilterDropping() throws Exception {
     Filter filter = new DependentColumnFilter(FAMILIES[0], QUALIFIER);
     List<Cell> accepted = new ArrayList<Cell>();
@@ -253,7 +253,7 @@ public class TestDependentColumnFilter {
   /**
    * Test for HBASE-8794. Avoid NullPointerException in DependentColumnFilter.toString().
    */
-  @Test
+  @Test (timeout=180000)
   public void testToStringWithNullComparator() {
     // Test constructor that implicitly sets a null comparator
     Filter filter = new DependentColumnFilter(FAMILIES[0], QUALIFIER);
@@ -268,7 +268,7 @@ public class TestDependentColumnFilter {
       filter.toString().contains("null"));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testToStringWithNonNullComparator() {
     Filter filter =
         new DependentColumnFilter(FAMILIES[0], QUALIFIER, true, CompareOp.EQUAL,
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilter.java
index 61321dd..7958b01 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilter.java
@@ -220,7 +220,7 @@ public class TestFilter {
     HBaseTestingUtility.closeRegionAndWAL(region);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRegionScannerReseek() throws Exception {
     // create new rows and column family to show how reseek works..
     for (byte[] ROW : ROWS_THREE) {
@@ -287,7 +287,7 @@ public class TestFilter {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testNoFilter() throws Exception {
     // No filter
     long expectedRows = this.numRows;
@@ -303,7 +303,7 @@ public class TestFilter {
     verifyScan(s, expectedRows, expectedKeys/2);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testPrefixFilter() throws Exception {
     // Grab rows from group one (half of total)
     long expectedRows = this.numRows / 2;
@@ -323,7 +323,7 @@ public class TestFilter {
     verifyScan(s, expectedRows, expectedKeys);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testPageFilter() throws Exception {
 
     // KVs in first 6 rows
@@ -553,7 +553,7 @@ public class TestFilter {
    *
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   public void testWhileMatchFilterWithFilterRow() throws Exception {
     final int pageSize = 4;
 
@@ -611,7 +611,7 @@ public class TestFilter {
    * 
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   public void tes94FilterRowCompatibility() throws Exception {
     Scan s = new Scan();
     OldTestFilter filter = new OldTestFilter();
@@ -632,7 +632,7 @@ public class TestFilter {
    *
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   public void testWhileMatchFilterWithFilterRowKey() throws Exception {
     Scan s = new Scan();
     String prefix = "testRowOne";
@@ -660,7 +660,7 @@ public class TestFilter {
    *
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   public void testWhileMatchFilterWithFilterKeyValue() throws Exception {
     Scan s = new Scan();
     WhileMatchFilter filter = new WhileMatchFilter(
@@ -679,7 +679,7 @@ public class TestFilter {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testInclusiveStopFilter() throws IOException {
 
     // Grab rows from group one
@@ -714,7 +714,7 @@ public class TestFilter {
 
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testQualifierFilter() throws IOException {
 
     // Match two keys (one from each family) in half the rows
@@ -872,7 +872,7 @@ public class TestFilter {
 
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testFamilyFilter() throws IOException {
 
       // Match family, only half of columns returned.
@@ -1007,7 +1007,7 @@ public class TestFilter {
     }
 
 
-  @Test
+  @Test (timeout=180000)
   public void testRowFilter() throws IOException {
 
     // Match a single row, all keys
@@ -1154,7 +1154,7 @@ public class TestFilter {
 
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testValueFilter() throws IOException {
 
     // Match group one rows
@@ -1278,7 +1278,7 @@ public class TestFilter {
     verifyScanFull(s, kvs);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSkipFilter() throws IOException {
 
     // Test for qualifier regex: "testQualifierOne-2"
@@ -1316,7 +1316,7 @@ public class TestFilter {
 
   // TODO: This is important... need many more tests for ordering, etc
   // There are limited tests elsewhere but we need HRegion level ones here
-  @Test
+  @Test (timeout=180000)
   public void testFilterList() throws IOException {
 
     // Test getting a single row, single key using Row, Qualifier, and Value
@@ -1349,7 +1349,7 @@ public class TestFilter {
 
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testFirstKeyOnlyFilter() throws IOException {
     Scan s = new Scan();
     s.setFilter(new FirstKeyOnlyFilter());
@@ -1365,7 +1365,7 @@ public class TestFilter {
     verifyScanFull(s, kvs);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testFilterListWithSingleColumnValueFilter() throws IOException {
     // Test for HBASE-3191
 
@@ -1443,7 +1443,7 @@ public class TestFilter {
   }
 
   // HBASE-9747
-  @Test
+  @Test (timeout=180000)
   public void testFilterListWithPrefixFilter() throws IOException {
     byte[] family = Bytes.toBytes("f1");
     byte[] qualifier = Bytes.toBytes("q1");
@@ -1490,7 +1490,7 @@ public class TestFilter {
     wal.close();
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSingleColumnValueFilter() throws IOException {
 
     // From HBASE-1821
@@ -1812,7 +1812,7 @@ public class TestFilter {
     this.verifyScanFull(s, expectedKVs3);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testColumnPaginationFilter() throws Exception {
       // Test that the filter skips multiple column versions.
       Put p = new Put(ROWS_ONE[0]);
@@ -1910,7 +1910,7 @@ public class TestFilter {
       this.verifyScanFull(s, expectedKVs4);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testKeyOnlyFilter() throws Exception {
 
     // KVs in first 6 rows
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterList.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterList.java
index 759435b..7ae19d8 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterList.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterList.java
@@ -57,7 +57,7 @@ public class TestFilterList {
   static byte[] BAD_BYTES = Bytes.toBytes("def");
 
 
-  @Test
+  @Test (timeout=180000)
   public void testAddFilter() throws Exception {
     Filter filter1 = new FirstKeyOnlyFilter();
     Filter filter2 = new FirstKeyOnlyFilter();
@@ -81,7 +81,7 @@ public class TestFilterList {
    * Test "must pass one"
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   public void testMPONE() throws Exception {
     mpOneTest(getFilterMPONE());
   }
@@ -147,7 +147,7 @@ public class TestFilterList {
    * Test "must pass all"
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   public void testMPALL() throws Exception {
     mpAllTest(getMPALLFilter());
   }
@@ -195,7 +195,7 @@ public class TestFilterList {
    * Test list ordering
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   public void testOrdering() throws Exception {
     orderingTest(getOrderingFilter());
   }
@@ -328,7 +328,7 @@ public class TestFilterList {
    * Test serialization
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   public void testSerialization() throws Exception {
     List<Filter> filters = new ArrayList<Filter>();
     filters.add(new PageFilter(MAX_PAGES));
@@ -404,7 +404,7 @@ public class TestFilterList {
   /**
    * Test pass-thru of hints.
    */
-  @Test
+  @Test (timeout=180000)
   public void testHintPassThru() throws Exception {
 
     final KeyValue minKeyValue = new KeyValue(Bytes.toBytes(0L), null, null);
@@ -516,7 +516,7 @@ public class TestFilterList {
    * transform() only applies after a filterKeyValue() whose return-code includes the KeyValue.
    * Lazy evaluation of AND
    */
-  @Test
+  @Test (timeout=180000)
   public void testTransformMPO() throws Exception {
     // Apply the following filter:
     //     (family=fam AND qualifier=qual1 AND KeyOnlyFilter)
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterSerialization.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterSerialization.java
index 0a8b4bf..cf3b68b 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterSerialization.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterSerialization.java
@@ -39,21 +39,21 @@ import org.junit.experimental.categories.Category;
 @Category({FilterTests.class, SmallTests.class})
 public class TestFilterSerialization {
 
-  @Test
+  @Test (timeout=180000)
   public void testColumnCountGetFilter() throws Exception {
     ColumnCountGetFilter columnCountGetFilter = new ColumnCountGetFilter(1);
     assertTrue(columnCountGetFilter.areSerializedFieldsEqual(
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(columnCountGetFilter))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testColumnPaginationFilter() throws Exception {
     ColumnPaginationFilter columnPaginationFilter = new ColumnPaginationFilter(1,7);
     assertTrue(columnPaginationFilter.areSerializedFieldsEqual(
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(columnPaginationFilter))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testColumnPrefixFilter() throws Exception {
     // empty string
     ColumnPrefixFilter columnPrefixFilter = new ColumnPrefixFilter(Bytes.toBytes(""));
@@ -66,7 +66,7 @@ public class TestFilterSerialization {
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(columnPrefixFilter))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testColumnRangeFilter() throws Exception {
     // null columns
     ColumnRangeFilter columnRangeFilter = new ColumnRangeFilter(null, true, null, false);
@@ -79,7 +79,7 @@ public class TestFilterSerialization {
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(columnRangeFilter))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testDependentColumnFilter() throws Exception {
     // null column qualifier/family
     DependentColumnFilter dependentColumnFilter = new DependentColumnFilter(null, null);
@@ -94,7 +94,7 @@ public class TestFilterSerialization {
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(dependentColumnFilter))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testFamilyFilter() throws Exception {
     FamilyFilter familyFilter = new FamilyFilter(CompareFilter.CompareOp.EQUAL,
       new BinaryPrefixComparator(Bytes.toBytes("testValueOne")));
@@ -102,7 +102,7 @@ public class TestFilterSerialization {
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(familyFilter))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testFilterList() throws Exception {
     // empty filter list
     FilterList filterList = new FilterList(new LinkedList<Filter>());
@@ -118,7 +118,7 @@ public class TestFilterSerialization {
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(filterList))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testFilterWrapper() throws Exception {
     FilterWrapper filterWrapper =
       new FilterWrapper(
@@ -127,7 +127,7 @@ public class TestFilterSerialization {
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(filterWrapper))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testFirstKeyValueMatchingQualifiersFilter() throws Exception {
     // empty qualifiers set
     TreeSet<byte []> set = new TreeSet<byte []>(Bytes.BYTES_COMPARATOR);
@@ -145,14 +145,14 @@ public class TestFilterSerialization {
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(firstKeyValueMatchingQualifiersFilter))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testFirstKeyOnlyFilter() throws Exception {
     FirstKeyOnlyFilter firstKeyOnlyFilter = new FirstKeyOnlyFilter();
     assertTrue(firstKeyOnlyFilter.areSerializedFieldsEqual(
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(firstKeyOnlyFilter))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testFuzzyRowFilter() throws Exception {
     LinkedList<Pair<byte[], byte[]>> fuzzyList = new LinkedList<Pair<byte[], byte[]>>();
     fuzzyList.add(new Pair<byte[], byte[]>(Bytes.toBytes("999"),new byte[] {0, 0, 1}));
@@ -162,7 +162,7 @@ public class TestFilterSerialization {
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(fuzzyRowFilter))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testInclusiveStopFilter() throws Exception {
     // InclusveStopFilter with null stopRowKey
     InclusiveStopFilter inclusiveStopFilter = new InclusiveStopFilter(null);
@@ -175,7 +175,7 @@ public class TestFilterSerialization {
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(inclusiveStopFilter))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testKeyOnlyFilter() throws Exception {
     // KeyOnlyFilter with lenAsVal
     KeyOnlyFilter keyOnlyFilter = new KeyOnlyFilter(true);
@@ -188,7 +188,7 @@ public class TestFilterSerialization {
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(keyOnlyFilter))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testMultipleColumnPrefixFilter() throws Exception {
     // empty array
     byte [][] prefixes = null;
@@ -206,14 +206,14 @@ public class TestFilterSerialization {
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(multipleColumnPrefixFilter))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testPageFilter() throws Exception {
     PageFilter pageFilter = new PageFilter(6);
     assertTrue(pageFilter.areSerializedFieldsEqual(
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(pageFilter))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testPrefixFilter() throws Exception {
     // null prefix
     PrefixFilter prefixFilter = new PrefixFilter(null);
@@ -226,7 +226,7 @@ public class TestFilterSerialization {
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(prefixFilter))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testQualifierFilter() throws Exception {
     QualifierFilter qualifierFilter = new QualifierFilter(CompareFilter.CompareOp.EQUAL,
       new NullComparator());
@@ -234,14 +234,14 @@ public class TestFilterSerialization {
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(qualifierFilter))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRandomRowFilter() throws Exception {
     RandomRowFilter randomRowFilter = new RandomRowFilter((float)0.1);
     assertTrue(randomRowFilter.areSerializedFieldsEqual(
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(randomRowFilter))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRowFilter() throws Exception {
     RowFilter rowFilter = new RowFilter(CompareFilter.CompareOp.EQUAL,
       new SubstringComparator("testRowFilter"));
@@ -249,7 +249,7 @@ public class TestFilterSerialization {
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(rowFilter))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSingleColumnValueExcludeFilter() throws Exception {
     // null family/column SingleColumnValueExcludeFilter
     SingleColumnValueExcludeFilter singleColumnValueExcludeFilter =
@@ -266,7 +266,7 @@ public class TestFilterSerialization {
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(singleColumnValueExcludeFilter))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSingleColumnValueFilter() throws Exception {
     // null family/column SingleColumnValueFilter
     SingleColumnValueFilter singleColumnValueFilter =
@@ -283,14 +283,14 @@ public class TestFilterSerialization {
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(singleColumnValueFilter))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSkipFilter() throws Exception {
     SkipFilter skipFilter = new SkipFilter(new PageFilter(6));
     assertTrue(skipFilter.areSerializedFieldsEqual(
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(skipFilter))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testTimestampsFilter() throws Exception {
     // Empty timestamp list
     TimestampsFilter timestampsFilter = new TimestampsFilter(new LinkedList<Long>());
@@ -306,7 +306,7 @@ public class TestFilterSerialization {
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(timestampsFilter))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testValueFilter() throws Exception {
     ValueFilter valueFilter = new ValueFilter(CompareFilter.CompareOp.NO_OP,
       new BinaryComparator(Bytes.toBytes("testValueOne")));
@@ -314,7 +314,7 @@ public class TestFilterSerialization {
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(valueFilter))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testWhileMatchFilter() throws Exception {
     WhileMatchFilter whileMatchFilter =
       new WhileMatchFilter(
@@ -323,7 +323,7 @@ public class TestFilterSerialization {
       ProtobufUtil.toFilter(ProtobufUtil.toFilter(whileMatchFilter))));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testMultiRowRangeFilter() throws Exception {
     List<RowRange> ranges = new ArrayList<RowRange>();
     ranges.add(new RowRange(Bytes.toBytes(30), true, Bytes.toBytes(40), false));
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterWithScanLimits.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterWithScanLimits.java
index 78a4d1f..850287c 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterWithScanLimits.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterWithScanLimits.java
@@ -54,7 +54,7 @@ public class TestFilterWithScanLimits extends FilterTestingCluster {
   private static final TableName tableName = TableName.valueOf("scanWithLimit");
   private static final String columnFamily = "f1";
 
-  @Test
+  @Test (timeout=60000)
   public void testScanWithLimit() {
     int kv_number = 0;
     try {
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterWrapper.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterWrapper.java
index 8ce0b76..0d92278 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterWrapper.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFilterWrapper.java
@@ -70,7 +70,7 @@ public class TestFilterWrapper {
   private static TableName name = TableName.valueOf("test");
   private static Connection connection;
 
-  @Test
+  @Test (timeout=60000)
   public void testFilterWrapper() {
     int kv_number = 0;
     int row_number = 0;
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFuzzyRowAndColumnRangeFilter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFuzzyRowAndColumnRangeFilter.java
index 565c7db..142dbd7 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFuzzyRowAndColumnRangeFilter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFuzzyRowAndColumnRangeFilter.java
@@ -86,7 +86,7 @@ public class TestFuzzyRowAndColumnRangeFilter {
     // Nothing to do.
   }
 
-  @Test
+  @Test (timeout=60000)
   public void Test() throws Exception {
     String cf = "f";
     String table = "TestFuzzyAndColumnRangeFilterClient";
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFuzzyRowFilter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFuzzyRowFilter.java
index 3ec1351..0396deb 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFuzzyRowFilter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestFuzzyRowFilter.java
@@ -26,7 +26,7 @@ import org.junit.experimental.categories.Category;
 
 @Category({FilterTests.class, SmallTests.class})
 public class TestFuzzyRowFilter {
-  @Test
+  @Test (timeout=180000)
   public void testSatisfiesForward() {
     Assert.assertEquals(FuzzyRowFilter.SatisfiesCode.NEXT_EXISTS,
             FuzzyRowFilter.satisfies(false,
@@ -95,7 +95,7 @@ public class TestFuzzyRowFilter {
                                      new byte[]{1, 0, 0}));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSatisfiesReverse() {
     Assert.assertEquals(FuzzyRowFilter.SatisfiesCode.NO_NEXT,
       FuzzyRowFilter.satisfies(true,
@@ -164,7 +164,7 @@ public class TestFuzzyRowFilter {
         new byte[]{1, 0, 0}));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testGetNextForFuzzyRuleForward() {
     assertNext(false,
             new byte[]{0, 1, 2}, // fuzzy row
@@ -275,7 +275,7 @@ public class TestFuzzyRowFilter {
             new byte[]{0, 0, 1, 0}));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testGetNextForFuzzyRuleReverse() {
     assertNext(true,
       new byte[]{0, 1, 2}, // fuzzy row
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestInclusiveStopFilter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestInclusiveStopFilter.java
index e527ca8..4248463 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestInclusiveStopFilter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestInclusiveStopFilter.java
@@ -48,7 +48,7 @@ public class TestInclusiveStopFilter {
    * Tests identification of the stop row
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   public void testStopRowIdentification() throws Exception {
     stopRowTests(mainFilter);
   }
@@ -57,7 +57,7 @@ public class TestInclusiveStopFilter {
    * Tests serialization
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   public void testSerialization() throws Exception {
     // Decompose mainFilter to bytes.
     byte[] buffer = mainFilter.toByteArray();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestInvocationRecordFilter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestInvocationRecordFilter.java
index 5454480d..ee05bfc 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestInvocationRecordFilter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestInvocationRecordFilter.java
@@ -81,7 +81,7 @@ public class TestInvocationRecordFilter {
     this.region.flushcache();
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testFilterInvocation() throws Exception {
     List<Integer> selectQualifiers = new ArrayList<Integer>();
     List<Integer> expectedQualifiers = new ArrayList<Integer>();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestMultiRowRangeFilter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestMultiRowRangeFilter.java
index c2d25de..6113a60 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestMultiRowRangeFilter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestMultiRowRangeFilter.java
@@ -68,7 +68,7 @@ public class TestMultiRowRangeFilter {
     TEST_UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMergeAndSortWithEmptyStartRow() throws IOException {
     List<RowRange> ranges = new ArrayList<RowRange>();
     ranges.add(new RowRange(Bytes.toBytes(""), true, Bytes.toBytes(20), false));
@@ -79,7 +79,7 @@ public class TestMultiRowRangeFilter {
     assertRangesEqual(expectedRanges, actualRanges);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMergeAndSortWithEmptyStopRow() throws IOException {
     List<RowRange> ranges = new ArrayList<RowRange>();
     ranges.add(new RowRange(Bytes.toBytes(10), true, Bytes.toBytes(20), false));
@@ -91,7 +91,7 @@ public class TestMultiRowRangeFilter {
     assertRangesEqual(expectedRanges, actualRanges);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMergeAndSortWithEmptyStartRowAndStopRow() throws IOException {
     List<RowRange> ranges = new ArrayList<RowRange>();
     ranges.add(new RowRange(Bytes.toBytes(10), true, Bytes.toBytes(20), false));
@@ -119,7 +119,7 @@ public class TestMultiRowRangeFilter {
     new MultiRowRangeFilter(ranges);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMergeAndSortWithoutOverlap() throws IOException {
     List<RowRange> ranges = new ArrayList<RowRange>();
     ranges.add(new RowRange(Bytes.toBytes(10), true, Bytes.toBytes(20), false));
@@ -133,7 +133,7 @@ public class TestMultiRowRangeFilter {
     assertRangesEqual(expectedRanges, actualRanges);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMergeAndSortWithOverlap() throws IOException {
     List<RowRange> ranges = new ArrayList<RowRange>();
     ranges.add(new RowRange(Bytes.toBytes(10), true, Bytes.toBytes(20), false));
@@ -150,7 +150,7 @@ public class TestMultiRowRangeFilter {
     assertRangesEqual(expectedRanges, actualRanges);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMergeAndSortWithStartRowInclusive() throws IOException {
     List<RowRange> ranges = new ArrayList<RowRange>();
     ranges.add(new RowRange(Bytes.toBytes(10), true, Bytes.toBytes(20), false));
@@ -161,7 +161,7 @@ public class TestMultiRowRangeFilter {
     assertRangesEqual(expectedRanges, actualRanges);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMergeAndSortWithRowExclusive() throws IOException {
     List<RowRange> ranges = new ArrayList<RowRange>();
     ranges.add(new RowRange(Bytes.toBytes(10), true, Bytes.toBytes(20), false));
@@ -173,7 +173,7 @@ public class TestMultiRowRangeFilter {
     assertRangesEqual(expectedRanges, actualRanges);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMergeAndSortWithRowInclusive() throws IOException {
     List<RowRange> ranges = new ArrayList<RowRange>();
     ranges.add(new RowRange(Bytes.toBytes(10), true, Bytes.toBytes(20), true));
@@ -196,7 +196,7 @@ public class TestMultiRowRangeFilter {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMultiRowRangeFilterWithRangeOverlap() throws IOException {
     tableName = Bytes.toBytes("testMultiRowRangeFilterWithRangeOverlap");
     HTable ht = TEST_UTIL.createTable(tableName, family, Integer.MAX_VALUE);
@@ -224,7 +224,7 @@ public class TestMultiRowRangeFilter {
     ht.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMultiRowRangeFilterWithoutRangeOverlap() throws IOException {
     tableName = Bytes.toBytes("testMultiRowRangeFilterWithoutRangeOverlap");
     HTable ht = TEST_UTIL.createTable(tableName, family, Integer.MAX_VALUE);
@@ -251,7 +251,7 @@ public class TestMultiRowRangeFilter {
     ht.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMultiRowRangeFilterWithEmptyStartRow() throws IOException {
     tableName = Bytes.toBytes("testMultiRowRangeFilterWithEmptyStartRow");
     HTable ht = TEST_UTIL.createTable(tableName, family, Integer.MAX_VALUE);
@@ -273,7 +273,7 @@ public class TestMultiRowRangeFilter {
     ht.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMultiRowRangeFilterWithEmptyStopRow() throws IOException {
     tableName = Bytes.toBytes("testMultiRowRangeFilterWithEmptyStopRow");
     HTable ht = TEST_UTIL.createTable(tableName, family, Integer.MAX_VALUE);
@@ -294,7 +294,7 @@ public class TestMultiRowRangeFilter {
     ht.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMultiRowRangeFilterWithInclusive() throws IOException {
     tableName = Bytes.toBytes("testMultiRowRangeFilterWithInclusive");
     HTable ht = TEST_UTIL.createTable(tableName, family, Integer.MAX_VALUE);
@@ -322,7 +322,7 @@ public class TestMultiRowRangeFilter {
     ht.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMultiRowRangeFilterWithExclusive() throws IOException {
     tableName = Bytes.toBytes("testMultiRowRangeFilterWithExclusive");
     HTable ht = TEST_UTIL.createTable(tableName, family, Integer.MAX_VALUE);
@@ -348,7 +348,7 @@ public class TestMultiRowRangeFilter {
     ht.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMultiRowRangeWithFilterListAndOperator() throws IOException {
     tableName = Bytes.toBytes("TestMultiRowRangeFilterWithFilterListAndOperator");
     HTable ht = TEST_UTIL.createTable(tableName, family, Integer.MAX_VALUE);
@@ -383,7 +383,7 @@ public class TestMultiRowRangeFilter {
     ht.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMultiRowRangeWithFilterListOrOperator() throws IOException {
     tableName = Bytes.toBytes("TestMultiRowRangeFilterWithFilterListOrOperator");
     HTable ht = TEST_UTIL.createTable(tableName, family, Integer.MAX_VALUE);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestMultipleColumnPrefixFilter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestMultipleColumnPrefixFilter.java
index d2997af..814e853 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestMultipleColumnPrefixFilter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestMultipleColumnPrefixFilter.java
@@ -45,7 +45,7 @@ public class TestMultipleColumnPrefixFilter {
   private final static HBaseTestingUtility TEST_UTIL = new
       HBaseTestingUtility();
 
-  @Test
+  @Test (timeout=180000)
   public void testMultipleColumnPrefixFilter() throws IOException {
     String family = "Family";
     HTableDescriptor htd = new HTableDescriptor(TableName.valueOf("TestMultipleColumnPrefixFilter"));
@@ -108,7 +108,7 @@ public class TestMultipleColumnPrefixFilter {
     HBaseTestingUtility.closeRegionAndWAL(region);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testMultipleColumnPrefixFilterWithManyFamilies() throws IOException {
     String family1 = "Family1";
     String family2 = "Family2";
@@ -180,7 +180,7 @@ public class TestMultipleColumnPrefixFilter {
     HBaseTestingUtility.closeRegionAndWAL(region);
   }
   
-  @Test
+  @Test (timeout=180000)
   public void testMultipleColumnPrefixFilterWithColumnPrefixFilter() throws IOException {
     String family = "Family";
     HTableDescriptor htd = new HTableDescriptor(TableName.valueOf("TestMultipleColumnPrefixFilter"));
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestNullComparator.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestNullComparator.java
index 2f13da1..406d83a 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestNullComparator.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestNullComparator.java
@@ -25,7 +25,7 @@ import org.junit.experimental.categories.Category;
 @Category({FilterTests.class, SmallTests.class})
 public class TestNullComparator {
 
-  @Test
+  @Test (timeout=180000)
   public void testNullValue()
   {
     // given
@@ -41,7 +41,7 @@ public class TestNullComparator {
     Assert.assertEquals(0, comp2);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testNonNullValue() {
     // given
     byte[] value = new byte[] { 0, 1, 2, 3, 4, 5 };
@@ -56,7 +56,7 @@ public class TestNullComparator {
     Assert.assertEquals(1, comp2);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testEmptyValue() {
     // given
     byte[] value = new byte[] { 0 };
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestPageFilter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestPageFilter.java
index 139bf6f..775c9a1 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestPageFilter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestPageFilter.java
@@ -40,7 +40,7 @@ public class TestPageFilter {
    * test page size filter
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   public void testPageSize() throws Exception {
     Filter f = new PageFilter(ROW_LIMIT);
     pageSizeTests(f);
@@ -50,7 +50,7 @@ public class TestPageFilter {
    * Test filter serialization
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   public void testSerialization() throws Exception {
     Filter f = new PageFilter(ROW_LIMIT);
     // Decompose mainFilter to bytes.
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestParseFilter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestParseFilter.java
index 4b2df33..50c08ff 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestParseFilter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestParseFilter.java
@@ -53,7 +53,7 @@ public class TestParseFilter {
     // Nothing to do.
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testKeyOnlyFilter() throws IOException {
     String filterString = "KeyOnlyFilter()";
     doTestFilter(filterString, KeyOnlyFilter.class);
@@ -68,7 +68,7 @@ public class TestParseFilter {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testFirstKeyOnlyFilter() throws IOException {
     String filterString = " FirstKeyOnlyFilter( ) ";
     doTestFilter(filterString, FirstKeyOnlyFilter.class);
@@ -83,7 +83,7 @@ public class TestParseFilter {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testPrefixFilter() throws IOException {
     String filterString = " PrefixFilter('row' ) ";
     PrefixFilter prefixFilter = doTestFilter(filterString, PrefixFilter.class);
@@ -100,7 +100,7 @@ public class TestParseFilter {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testColumnPrefixFilter() throws IOException {
     String filterString = " ColumnPrefixFilter('qualifier' ) ";
     ColumnPrefixFilter columnPrefixFilter =
@@ -109,7 +109,7 @@ public class TestParseFilter {
     assertEquals(new String(columnPrefix), "qualifier");
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testMultipleColumnPrefixFilter() throws IOException {
     String filterString = " MultipleColumnPrefixFilter('qualifier1', 'qualifier2' ) ";
     MultipleColumnPrefixFilter multipleColumnPrefixFilter =
@@ -119,7 +119,7 @@ public class TestParseFilter {
     assertEquals(new String(prefixes[1]), "qualifier2");
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testColumnCountGetFilter() throws IOException {
     String filterString = " ColumnCountGetFilter(4)";
     ColumnCountGetFilter columnCountGetFilter =
@@ -144,7 +144,7 @@ public class TestParseFilter {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testPageFilter() throws IOException {
     String filterString = " PageFilter(4)";
     PageFilter pageFilter =
@@ -161,7 +161,7 @@ public class TestParseFilter {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testColumnPaginationFilter() throws IOException {
     String filterString = "ColumnPaginationFilter(4, 6)";
     ColumnPaginationFilter columnPaginationFilter =
@@ -196,7 +196,7 @@ public class TestParseFilter {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testInclusiveStopFilter() throws IOException {
     String filterString = "InclusiveStopFilter ('row 3')";
     InclusiveStopFilter inclusiveStopFilter =
@@ -206,7 +206,7 @@ public class TestParseFilter {
   }
 
 
-  @Test
+  @Test (timeout=180000)
   public void testTimestampsFilter() throws IOException {
     String filterString = "TimestampsFilter(9223372036854775806, 6)";
     TimestampsFilter timestampsFilter =
@@ -237,7 +237,7 @@ public class TestParseFilter {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRowFilter() throws IOException {
     String filterString = "RowFilter ( =,   'binary:regionse')";
     RowFilter rowFilter =
@@ -248,7 +248,7 @@ public class TestParseFilter {
     assertEquals("regionse", new String(binaryComparator.getValue()));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testFamilyFilter() throws IOException {
     String filterString = "FamilyFilter(>=, 'binaryprefix:pre')";
     FamilyFilter familyFilter =
@@ -260,7 +260,7 @@ public class TestParseFilter {
     assertEquals("pre", new String(binaryPrefixComparator.getValue()));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testQualifierFilter() throws IOException {
     String filterString = "QualifierFilter(=, 'regexstring:pre*')";
     QualifierFilter qualifierFilter =
@@ -272,7 +272,7 @@ public class TestParseFilter {
     assertEquals("pre*", new String(regexStringComparator.getValue()));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testValueFilter() throws IOException {
     String filterString = "ValueFilter(!=, 'substring:pre')";
     ValueFilter valueFilter =
@@ -284,7 +284,7 @@ public class TestParseFilter {
     assertEquals("pre", new String(substringComparator.getValue()));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testColumnRangeFilter() throws IOException {
     String filterString = "ColumnRangeFilter('abc', true, 'xyz', false)";
     ColumnRangeFilter columnRangeFilter =
@@ -295,7 +295,7 @@ public class TestParseFilter {
     assertFalse(columnRangeFilter.isMaxColumnInclusive());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testDependentColumnFilter() throws IOException {
     String filterString = "DependentColumnFilter('family', 'qualifier', true, =, 'binary:abc')";
     DependentColumnFilter dependentColumnFilter =
@@ -309,7 +309,7 @@ public class TestParseFilter {
     assertEquals("abc", new String(binaryComparator.getValue()));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSingleColumnValueFilter() throws IOException {
     String filterString = "SingleColumnValueFilter " +
       "('family', 'qualifier', >=, 'binary:a', true, false)";
@@ -338,7 +338,7 @@ public class TestParseFilter {
     assertTrue(singleColumnValueFilter.getLatestVersionOnly());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSingleColumnValueExcludeFilter() throws IOException {
     String filterString =
       "SingleColumnValueExcludeFilter ('family', 'qualifier', <, 'binaryprefix:a')";
@@ -367,7 +367,7 @@ public class TestParseFilter {
     assertFalse(singleColumnValueExcludeFilter.getLatestVersionOnly());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSkipFilter() throws IOException {
     String filterString = "SKIP ValueFilter( =,  'binary:0')";
     SkipFilter skipFilter =
@@ -381,7 +381,7 @@ public class TestParseFilter {
     assertEquals("0", new String(binaryComparator.getValue()));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testWhileFilter() throws IOException {
     String filterString = " WHILE   RowFilter ( !=, 'binary:row1')";
     WhileMatchFilter whileMatchFilter =
@@ -395,7 +395,7 @@ public class TestParseFilter {
     assertEquals("row1", new String(binaryComparator.getValue()));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testCompoundFilter1() throws IOException {
     String filterString = " (PrefixFilter ('realtime')AND  FirstKeyOnlyFilter())";
     FilterList filterList =
@@ -410,7 +410,7 @@ public class TestParseFilter {
     FirstKeyOnlyFilter firstKeyOnlyFilter = (FirstKeyOnlyFilter) filters.get(1);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testCompoundFilter2() throws IOException {
     String filterString = "(PrefixFilter('realtime') AND QualifierFilter (>=, 'binary:e'))" +
       "OR FamilyFilter (=, 'binary:qualifier') ";
@@ -445,7 +445,7 @@ public class TestParseFilter {
     assertEquals("e", new String(binaryComparator.getValue()));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testCompoundFilter3() throws IOException {
     String filterString = " ColumnPrefixFilter ('realtime')AND  " +
       "FirstKeyOnlyFilter() OR SKIP FamilyFilter(=, 'substring:hihi')";
@@ -479,7 +479,7 @@ public class TestParseFilter {
     assertEquals("hihi", new String(substringComparator.getValue()));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testCompoundFilter4() throws IOException {
     String filterString = " ColumnPrefixFilter ('realtime') OR " +
       "FirstKeyOnlyFilter() OR SKIP FamilyFilter(=, 'substring:hihi')";
@@ -508,7 +508,7 @@ public class TestParseFilter {
     assertEquals("hihi", new String(substringComparator.getValue()));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testIncorrectCompareOperator() throws IOException {
     String filterString = "RowFilter ('>>' , 'binary:region')";
     try {
@@ -519,7 +519,7 @@ public class TestParseFilter {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testIncorrectComparatorType () throws IOException {
     String  filterString = "RowFilter ('>=' , 'binaryoperator:region')";
     try {
@@ -547,7 +547,7 @@ public class TestParseFilter {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testPrecedence1() throws IOException {
     String filterString = " (PrefixFilter ('realtime')AND  FirstKeyOnlyFilter()" +
       " OR KeyOnlyFilter())";
@@ -570,7 +570,7 @@ public class TestParseFilter {
     assertEquals(new String(prefix), "realtime");
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testPrecedence2() throws IOException {
     String filterString = " PrefixFilter ('realtime')AND  SKIP FirstKeyOnlyFilter()" +
       "OR KeyOnlyFilter()";
@@ -595,7 +595,7 @@ public class TestParseFilter {
     assertTrue(skipFilter.getFilter() instanceof FirstKeyOnlyFilter);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testUnescapedQuote1 () throws IOException {
     String filterString = "InclusiveStopFilter ('row''3')";
     InclusiveStopFilter inclusiveStopFilter =
@@ -604,7 +604,7 @@ public class TestParseFilter {
     assertEquals(new String(stopRowKey), "row'3");
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testUnescapedQuote2 () throws IOException {
     String filterString = "InclusiveStopFilter ('row''3''')";
     InclusiveStopFilter inclusiveStopFilter =
@@ -613,7 +613,7 @@ public class TestParseFilter {
     assertEquals(new String(stopRowKey), "row'3'");
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testUnescapedQuote3 () throws IOException {
     String filterString = " InclusiveStopFilter ('''')";
     InclusiveStopFilter inclusiveStopFilter =
@@ -622,7 +622,7 @@ public class TestParseFilter {
     assertEquals(new String(stopRowKey), "'");
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testIncorrectFilterString () throws IOException {
     String filterString = "()";
     byte [] filterStringAsByteArray = Bytes.toBytes(filterString);
@@ -634,14 +634,14 @@ public class TestParseFilter {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testCorrectFilterString () throws IOException {
     String filterString = "(FirstKeyOnlyFilter())";
     FirstKeyOnlyFilter firstKeyOnlyFilter =
       doTestFilter(filterString, FirstKeyOnlyFilter.class);
   }
   
-  @Test
+  @Test (timeout=180000)
   public void testRegisterFilter() {
     ParseFilter.registerFilter("MyFilter", "some.class");
     
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestPrefixFilter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestPrefixFilter.java
index 02a55ba..ef7be60 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestPrefixFilter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestPrefixFilter.java
@@ -41,17 +41,17 @@ public class TestPrefixFilter {
     this.mainFilter = new PrefixFilter(Bytes.toBytes(HOST_PREFIX));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testPrefixOnRow() throws Exception {
     prefixRowTests(mainFilter);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testPrefixOnRowInsideWhileMatchRow() throws Exception {
     prefixRowTests(new WhileMatchFilter(this.mainFilter), true);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSerialization() throws Exception {
     // Decompose mainFilter to bytes.
     byte[] buffer = mainFilter.toByteArray();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestRandomRowFilter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestRandomRowFilter.java
index 8effca5..371b864 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestRandomRowFilter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestRandomRowFilter.java
@@ -42,7 +42,7 @@ public class TestRandomRowFilter {
    * 
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   public void testBasics() throws Exception {
     int included = 0;
     int max = 1000000;
@@ -65,7 +65,7 @@ public class TestRandomRowFilter {
    * 
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   public void testSerialization() throws Exception {
     RandomRowFilter newFilter = serializationTest(quarterChanceFilter);
     // use epsilon float comparison
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestRegexComparator.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestRegexComparator.java
index 9dbe432..5c74d5b 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestRegexComparator.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestRegexComparator.java
@@ -32,7 +32,7 @@ import org.junit.experimental.categories.Category;
 @Category({FilterTests.class, SmallTests.class})
 public class TestRegexComparator {
 
-  @Test
+  @Test (timeout=180000)
   public void testSerialization() throws Exception {
     // Default engine is the Java engine
     RegexStringComparator a = new RegexStringComparator("a|b");
@@ -47,7 +47,7 @@ public class TestRegexComparator {
     assertTrue(b.getEngine() instanceof RegexStringComparator.JoniRegexEngine);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testJavaEngine() throws Exception {
     for (TestCase t: TEST_CASES) {
       boolean result = new RegexStringComparator(t.regex, t.flags, EngineType.JAVA)
@@ -57,7 +57,7 @@ public class TestRegexComparator {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testJoniEngine() throws Exception {
     for (TestCase t: TEST_CASES) {
       boolean result = new RegexStringComparator(t.regex, t.flags, EngineType.JONI)
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestScanRowPrefix.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestScanRowPrefix.java
index 3be10ec..786b135 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestScanRowPrefix.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestScanRowPrefix.java
@@ -47,7 +47,7 @@ public class TestScanRowPrefix extends FilterTestingCluster {
   private static final Log LOG = LogFactory
       .getLog(TestScanRowPrefix.class);
 
-  @Test
+  @Test (timeout=60000)
   public void testPrefixScanning() throws IOException {
     TableName tableName = TableName.valueOf("prefixScanning");
     createTable(tableName,"F");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestSingleColumnValueExcludeFilter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestSingleColumnValueExcludeFilter.java
index 7aa298c..3918637 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestSingleColumnValueExcludeFilter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestSingleColumnValueExcludeFilter.java
@@ -51,7 +51,7 @@ public class TestSingleColumnValueExcludeFilter {
    * Test the overridden functionality of filterKeyValue(KeyValue)
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   public void testFilterKeyValue() throws Exception {
     Filter filter = new SingleColumnValueExcludeFilter(COLUMN_FAMILY, COLUMN_QUALIFIER,
         CompareOp.EQUAL, VAL_1);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestSingleColumnValueFilter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestSingleColumnValueFilter.java
index b4e364d..199acb7 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestSingleColumnValueFilter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestSingleColumnValueFilter.java
@@ -96,7 +96,7 @@ public class TestSingleColumnValueFilter {
         new RegexStringComparator(pattern.pattern(), pattern.flags()));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testLongComparator() throws IOException {
     Filter filter = new SingleColumnValueFilter(COLUMN_FAMILY,
         COLUMN_QUALIFIER, CompareOp.GREATER, new LongComparator(100L));
@@ -201,7 +201,7 @@ public class TestSingleColumnValueFilter {
    * Tests identification of the stop row
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   public void testStop() throws Exception {
     basicFilterTests((SingleColumnValueFilter) basicFilter);
     nullFilterTests(nullFilter);
@@ -214,7 +214,7 @@ public class TestSingleColumnValueFilter {
    * Tests serialization
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   public void testSerialization() throws Exception {
     Filter newFilter = serializationTest(basicFilter);
     basicFilterTests((SingleColumnValueFilter)newFilter);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/fs/TestBlockReorder.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/fs/TestBlockReorder.java
index 613d1ea..4ce8a24 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/fs/TestBlockReorder.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/fs/TestBlockReorder.java
@@ -111,7 +111,7 @@ public class TestBlockReorder {
   /**
    * Test that we're can add a hook, and that this hook works when we try to read the file in HDFS.
    */
-  @Test
+  @Test (timeout=60000)
   public void testBlockLocationReorder() throws Exception {
     Path p = new Path("hello");
 
@@ -414,7 +414,7 @@ public class TestBlockReorder {
   /**
    * Test that the reorder algo works as we expect.
    */
-  @Test
+  @Test (timeout=60000)
   public void testBlockLocation() throws Exception {
     // We need to start HBase to get  HConstants.HBASE_DIR set in conf
     htu.startMiniZKCluster();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestGlobalFilter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestGlobalFilter.java
index b06dea1..f3db361 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestGlobalFilter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestGlobalFilter.java
@@ -105,7 +105,7 @@ public class TestGlobalFilter extends HttpServerFunctionalTest {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testServletFilter() throws Exception {
     Configuration conf = new Configuration();
     
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestHtmlQuoting.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestHtmlQuoting.java
index 82fbe04..dcbf480 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestHtmlQuoting.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestHtmlQuoting.java
@@ -69,7 +69,7 @@ public class TestHtmlQuoting {
   }
   
 
-  @Test
+  @Test (timeout=180000)
   public void testRequestQuoting() throws Exception {
     HttpServletRequest mockReq = Mockito.mock(HttpServletRequest.class);
     HttpServer.QuotingInputFilter.RequestQuoter quoter =
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestHttpRequestLog.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestHttpRequestLog.java
index 8fea254..bdb54a1 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestHttpRequestLog.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestHttpRequestLog.java
@@ -32,13 +32,13 @@ import static org.junit.Assert.assertNull;
 @Category({MiscTests.class, SmallTests.class})
 public class TestHttpRequestLog {
 
-  @Test
+  @Test (timeout=180000)
   public void testAppenderUndefined() {
     RequestLog requestLog = HttpRequestLog.getRequestLog("test");
     assertNull("RequestLog should be null", requestLog);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testAppenderDefined() {
     HttpRequestLogAppender requestLogAppender = new HttpRequestLogAppender();
     requestLogAppender.setName("testrequestlog");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestHttpRequestLogAppender.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestHttpRequestLogAppender.java
index a17b9e9..40845c1 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestHttpRequestLogAppender.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestHttpRequestLogAppender.java
@@ -27,7 +27,7 @@ import static org.junit.Assert.assertEquals;
 @Category({MiscTests.class, SmallTests.class})
 public class TestHttpRequestLogAppender {
 
-  @Test
+  @Test (timeout=180000)
   public void testParameterPropagation() {
 
     HttpRequestLogAppender requestLogAppender = new HttpRequestLogAppender();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestHttpServer.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestHttpServer.java
index ffb924c..f4d0277 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestHttpServer.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestHttpServer.java
@@ -236,7 +236,7 @@ public class TestHttpServer extends HttpServerFunctionalTest {
     assertEquals(HttpURLConnection.HTTP_OK, conn.getResponseCode());
   }
 
-  @Test
+  @Test (timeout=180000)
   @Ignore
   public void testContentTypes() throws Exception {
     // Static CSS files should have text/css
@@ -359,7 +359,7 @@ public class TestHttpServer extends HttpServerFunctionalTest {
    * enabled.
    * @throws Exception 
    */
-  @Test
+  @Test (timeout=180000)
   @Ignore
   public void testDisabledAuthorizationOfDefaultServlets() throws Exception {
 
@@ -396,7 +396,7 @@ public class TestHttpServer extends HttpServerFunctionalTest {
    * 
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   @Ignore
   public void testAuthorizationOfDefaultServlets() throws Exception {
     Configuration conf = new Configuration();
@@ -437,7 +437,7 @@ public class TestHttpServer extends HttpServerFunctionalTest {
     myServer.stop();
   }
   
-  @Test
+  @Test (timeout=180000)
   public void testRequestQuoterWithNull() throws Exception {
     HttpServletRequest request = Mockito.mock(HttpServletRequest.class);
     Mockito.doReturn(null).when(request).getParameterValues("dummy");
@@ -447,7 +447,7 @@ public class TestHttpServer extends HttpServerFunctionalTest {
         + "when there are no values for the parameter", null, parameterValues);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRequestQuoterWithNotNull() throws Exception {
     HttpServletRequest request = Mockito.mock(HttpServletRequest.class);
     String[] values = new String[] { "abc", "def" };
@@ -473,7 +473,7 @@ public class TestHttpServer extends HttpServerFunctionalTest {
     LOG.info("END testJersey()");
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testHasAdministratorAccess() throws Exception {
     Configuration conf = new Configuration();
     conf.setBoolean(CommonConfigurationKeys.HADOOP_SECURITY_AUTHORIZATION, false);
@@ -514,7 +514,7 @@ public class TestHttpServer extends HttpServerFunctionalTest {
 
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRequiresAuthorizationAccess() throws Exception {
     Configuration conf = new Configuration();
     ServletContext context = Mockito.mock(ServletContext.class);
@@ -588,7 +588,7 @@ public class TestHttpServer extends HttpServerFunctionalTest {
     return server;
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testNoCacheHeader() throws Exception {
     URL url = new URL(baseUrl, "/echo?a=b&c=d");
     HttpURLConnection conn = (HttpURLConnection) url.openConnection();
@@ -603,7 +603,7 @@ public class TestHttpServer extends HttpServerFunctionalTest {
   /**
    * HTTPServer.Builder should proceed if a external connector is available.
    */
-  @Test
+  @Test (timeout=180000)
   public void testHttpServerBuilderWithExternalConnector() throws Exception {
     Connector c = mock(Connector.class);
     doReturn("localhost").when(c).getHost();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestHttpServerLifecycle.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestHttpServerLifecycle.java
index 2fb51ea..43e3c37 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestHttpServerLifecycle.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestHttpServerLifecycle.java
@@ -61,7 +61,7 @@ public class TestHttpServerLifecycle extends HttpServerFunctionalTest {
    *
    * @throws Throwable on failure
    */
-  @Test
+  @Test (timeout=180000)
   public void testStartedServerIsAlive() throws Throwable {
     HttpServer server = null;
     server = createTestServer();
@@ -114,7 +114,7 @@ public class TestHttpServerLifecycle extends HttpServerFunctionalTest {
    * @throws Throwable
    *           on failure
    */
-  @Test
+  @Test (timeout=180000)
   public void testWepAppContextAfterServerStop() throws Throwable {
     HttpServer server = null;
     String key = "test.attribute.key";
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestHttpServerWebapps.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestHttpServerWebapps.java
index db394a8..6f051c8 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestHttpServerWebapps.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestHttpServerWebapps.java
@@ -37,7 +37,7 @@ public class TestHttpServerWebapps extends HttpServerFunctionalTest {
    * Test that the test server is loadable on the classpath
    * @throws Throwable if something went wrong
    */
-  @Test
+  @Test (timeout=180000)
   public void testValidServerResource() throws Throwable {
     HttpServer server = null;
     try {
@@ -51,7 +51,7 @@ public class TestHttpServerWebapps extends HttpServerFunctionalTest {
    * Test that an invalid webapp triggers an exception
    * @throws Throwable if something went wrong
    */
-  @Test
+  @Test (timeout=180000)
   public void testMissingServerResource() throws Throwable {
     try {
       HttpServer server = createServer("NoSuchWebapp");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestPathFilter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestPathFilter.java
index 5854ea2..7804be5 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestPathFilter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestPathFilter.java
@@ -106,7 +106,7 @@ public class TestPathFilter extends HttpServerFunctionalTest {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testPathSpecFilters() throws Exception {
     Configuration conf = new Configuration();
     
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestSSLHttpServer.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestSSLHttpServer.java
index 1b79aff..7996ed1 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestSSLHttpServer.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestSSLHttpServer.java
@@ -103,7 +103,7 @@ public class TestSSLHttpServer extends HttpServerFunctionalTest {
     clientSslFactory.destroy();
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testEcho() throws Exception {
     assertEquals("a:b\nc:d\n", readOut(new URL(baseUrl, "/echo?a=b&c=d")));
     assertEquals("a:b\nc&lt;:d\ne:&gt;\n", readOut(new URL(baseUrl,
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestServletFilter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestServletFilter.java
index f9857e4..7350027 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestServletFilter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/http/TestServletFilter.java
@@ -105,7 +105,7 @@ public class TestServletFilter extends HttpServerFunctionalTest {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   @Ignore
   //From stack
   // Its a 'foreign' test, one that came in from hadoop when we copy/pasted http
@@ -172,7 +172,7 @@ public class TestServletFilter extends HttpServerFunctionalTest {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testServletFilterWhenInitThrowsException() throws Exception {
     Configuration conf = new Configuration();
     // start a http server with ErrorFilter
@@ -191,7 +191,7 @@ public class TestServletFilter extends HttpServerFunctionalTest {
    * Similar to the above test case, except that it uses a different API to add the
    * filter. Regression test for HADOOP-8786.
    */
-  @Test
+  @Test (timeout=180000)
   public void testContextSpecificServletFilterWhenInitThrowsException()
       throws Exception {
     Configuration conf = new Configuration();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/http/conf/TestConfServlet.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/http/conf/TestConfServlet.java
index 0385355..2b00795 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/http/conf/TestConfServlet.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/http/conf/TestConfServlet.java
@@ -53,7 +53,7 @@ public class TestConfServlet extends TestCase {
     return testConf;
   }
 
-  @Test
+  @Test (timeout=180000)
   @SuppressWarnings("unchecked")
   public void testWriteJson() throws Exception {
     StringWriter sw = new StringWriter();
@@ -76,7 +76,7 @@ public class TestConfServlet extends TestCase {
     assertTrue(foundSetting);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testWriteXml() throws Exception {
     StringWriter sw = new StringWriter();
     ConfServlet.writeResponse(getTestConf(), sw, "xml");
@@ -102,7 +102,7 @@ public class TestConfServlet extends TestCase {
     assertTrue(foundSetting);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testBadFormat() throws Exception {
     StringWriter sw = new StringWriter();
     try {
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/http/lib/TestStaticUserWebFilter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/http/lib/TestStaticUserWebFilter.java
index 81bcbd5..de4b3b5 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/http/lib/TestStaticUserWebFilter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/http/lib/TestStaticUserWebFilter.java
@@ -46,7 +46,7 @@ public class TestStaticUserWebFilter {
     return mock;
   }
   
-  @Test
+  @Test (timeout=180000)
   public void testFilter() throws Exception {
     FilterConfig config = mockConfig("myuser");
     StaticUserFilter suf = new StaticUserFilter();
@@ -69,14 +69,14 @@ public class TestStaticUserWebFilter {
     suf.destroy();
   }
   
-  @Test
+  @Test (timeout=180000)
   public void testOldStyleConfiguration() {
     Configuration conf = new Configuration();
     conf.set("dfs.web.ugi", "joe,group1,group2");
     assertEquals("joe", StaticUserWebFilter.getUsernameFromConf(conf));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testConfiguration() {
     Configuration conf = new Configuration();
     conf.set(CommonConfigurationKeys.HADOOP_HTTP_STATIC_USER, "dr.stack");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestFileLink.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestFileLink.java
index 777b3cd..db9ed23 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestFileLink.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestFileLink.java
@@ -50,7 +50,7 @@ public class TestFileLink {
    * Test, on HDFS, that the FileLink is still readable
    * even when the current file gets renamed.
    */
-  @Test
+  @Test (timeout=60000)
   public void testHDFSLinkReadDuringRename() throws Exception {
     HBaseTestingUtility testUtil = new HBaseTestingUtility();
     Configuration conf = testUtil.getConfiguration();
@@ -73,7 +73,7 @@ public class TestFileLink {
    * Test, on a local filesystem, that the FileLink is still readable
    * even when the current file gets renamed.
    */
-  @Test
+  @Test (timeout=60000)
   public void testLocalLinkReadDuringRename() throws IOException {
     HBaseTestingUtility testUtil = new HBaseTestingUtility();
     FileSystem fs = testUtil.getTestFileSystem();
@@ -145,7 +145,7 @@ public class TestFileLink {
    * a query to the namenode is performed, using the filename,
    * and the deleted file doesn't exists anymore (FileNotFoundException).
    */
-  @Test
+  @Test (timeout=60000)
   public void testHDFSLinkReadDuringDelete() throws Exception {
     HBaseTestingUtility testUtil = new HBaseTestingUtility();
     Configuration conf = testUtil.getConfiguration();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHFileLink.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHFileLink.java
index f2b26c1..c843ed5 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHFileLink.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHFileLink.java
@@ -42,7 +42,7 @@ import static org.junit.Assert.assertTrue;
 @Category({IOTests.class, SmallTests.class})
 public class TestHFileLink {
 
-  @Test
+  @Test (timeout=180000)
   public void testValidLinkNames() {
     String validLinkNames[] = {"foo=fefefe-0123456", "ns=foo=abababa-fefefefe"};
 
@@ -82,7 +82,7 @@ public class TestHFileLink {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testBackReference() {
     Path rootDir = new Path("/root");
     Path archiveDir = new Path(rootDir, ".archive");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHalfStoreFileReader.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHalfStoreFileReader.java
index 18595a8..bb08ecb 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHalfStoreFileReader.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHalfStoreFileReader.java
@@ -77,7 +77,7 @@ public class TestHalfStoreFileReader {
    *
    * @throws IOException
    */
-  @Test
+  @Test (timeout=180000)
   public void testHalfScanAndReseek() throws IOException {
     String root_dir = TEST_UTIL.getDataTestDir().toString();
     Path p = new Path(root_dir, "test");
@@ -143,7 +143,7 @@ public class TestHalfStoreFileReader {
 
 
   // Tests the scanner on an HFile that is backed by HalfStoreFiles
-  @Test
+  @Test (timeout=180000)
   public void testHalfScanner() throws IOException {
       String root_dir = TEST_UTIL.getDataTestDir().toString();
       Path p = new Path(root_dir, "test");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHeapSize.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHeapSize.java
index d6423e8..1efa623 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHeapSize.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestHeapSize.java
@@ -86,7 +86,7 @@ public class TestHeapSize  {
   /**
    * Test our hard-coded sizing of native java objects
    */
-  @Test
+  @Test (timeout=180000)
   public void testNativeSizes() throws IOException {
     Class<?> cl;
     long expected;
@@ -253,7 +253,7 @@ public class TestHeapSize  {
    * TestHFile since it is a non public class
    * @throws IOException
    */
-  @Test
+  @Test (timeout=180000)
   public void testSizes() throws IOException {
     Class<?> cl;
     long expected;
@@ -357,7 +357,7 @@ public class TestHeapSize  {
     // any of these classes are modified without updating overhead sizes.
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testMutations(){
     Class<?> cl;
     long expected;
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestReference.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestReference.java
index 80295ff..7f33420 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestReference.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/TestReference.java
@@ -40,7 +40,7 @@ public class TestReference {
    * Exercises the code path that parses Writables.
    * @throws IOException
    */
-  @Test
+  @Test (timeout=180000)
   public void testParsingWritableReference() throws IOException {
     // Read a Reference written w/ 0.94 out of the test data dir.
     final String datafile = System.getProperty("project.build.testSourceDirectory", "src/test") +
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestBufferedDataBlockEncoder.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestBufferedDataBlockEncoder.java
index 9330cea..f2a6956 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestBufferedDataBlockEncoder.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestBufferedDataBlockEncoder.java
@@ -26,7 +26,7 @@ import org.junit.experimental.categories.Category;
 @Category({IOTests.class, MediumTests.class})
 public class TestBufferedDataBlockEncoder {
 
-  @Test
+  @Test (timeout=60000)
   public void testEnsureSpaceForKey() {
     BufferedDataBlockEncoder.SeekerState state =
         new BufferedDataBlockEncoder.SeekerState();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestChangingEncoding.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestChangingEncoding.java
index 918e0f1..78efa0d 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestChangingEncoding.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestChangingEncoding.java
@@ -238,7 +238,7 @@ public class TestChangingEncoding {
     LOG.debug("Compaction queue size reached 0, continuing");
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCrazyRandomChanges() throws Exception {
     prepareTest("RandomChanges");
     Random rand = new Random(2934298742974297L);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestDataBlockEncoders.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestDataBlockEncoders.java
index cabb67f..417d1e7 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestDataBlockEncoders.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestDataBlockEncoders.java
@@ -102,7 +102,7 @@ public class TestDataBlockEncoders {
    * @throws IOException
    *           On test failure.
    */
-  @Test
+  @Test (timeout=60000)
   public void testEmptyKeyValues() throws IOException {
     List<KeyValue> kvList = new ArrayList<KeyValue>();
     byte[] row = new byte[0];
@@ -129,7 +129,7 @@ public class TestDataBlockEncoders {
    * @throws IOException
    *           On test failure.
    */
-  @Test
+  @Test (timeout=60000)
   public void testNegativeTimestamps() throws IOException {
     List<KeyValue> kvList = new ArrayList<KeyValue>();
     byte[] row = new byte[0];
@@ -156,7 +156,7 @@ public class TestDataBlockEncoders {
    * pseudorandom sample.
    * @throws IOException On test failure.
    */
-  @Test
+  @Test (timeout=60000)
   public void testExecutionOnSample() throws IOException {
     List<KeyValue> kvList = generator.generateTestKeyValues(NUMBER_OF_KV, includesTags);
     testEncodersOnDataset(kvList, includesMemstoreTS, includesTags);
@@ -165,7 +165,7 @@ public class TestDataBlockEncoders {
   /**
    * Test seeking while file is encoded.
    */
-  @Test
+  @Test (timeout=60000)
   public void testSeekingOnSample() throws IOException {
     List<KeyValue> sampleKv = generator.generateTestKeyValues(NUMBER_OF_KV, includesTags);
 
@@ -234,7 +234,7 @@ public class TestDataBlockEncoders {
     return ByteBuffer.wrap(encodedData);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testNextOnSample() throws IOException {
     List<KeyValue> sampleKv = generator.generateTestKeyValues(NUMBER_OF_KV, includesTags);
 
@@ -288,7 +288,7 @@ public class TestDataBlockEncoders {
    * Test whether the decompression of first key is implemented correctly.
    * @throws IOException
    */
-  @Test
+  @Test (timeout=60000)
   public void testFirstKeyInBlockOnSample() throws IOException {
     List<KeyValue> sampleKv = generator.generateTestKeyValues(NUMBER_OF_KV, includesTags);
 
@@ -379,7 +379,7 @@ public class TestDataBlockEncoders {
     }
   }
   
-  @Test
+  @Test (timeout=60000)
   public void testZeroByte() throws IOException {
     List<KeyValue> kvList = new ArrayList<KeyValue>();
     byte[] row = Bytes.toBytes("abcd");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestEncodedSeekers.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestEncodedSeekers.java
index e087457..ad6e54b 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestEncodedSeekers.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestEncodedSeekers.java
@@ -97,7 +97,7 @@ public class TestEncodedSeekers {
     this.compressTags = compressTags;
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testEncodedSeeker() throws IOException {
     System.err.println("Testing encoded seekers for encoding : " + encoding + ", includeTags : "
         + includeTags + ", compressTags : " + compressTags);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestPrefixTree.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestPrefixTree.java
index 80a50b0..54e8173 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestPrefixTree.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestPrefixTree.java
@@ -83,7 +83,7 @@ public class TestPrefixTree {
     testUtil.cleanupTestDir();
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testHBASE11728() throws Exception {
     Put put = new Put(Bytes.toBytes("a-b-0-0"));
     put.add(fam, qual1, Bytes.toBytes("c1-value"));
@@ -173,7 +173,7 @@ public class TestPrefixTree {
     scanner.close();
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testHBASE12817() throws IOException {
     for (int i = 0; i < 100; i++) {
       region.put(new Put(Bytes.toBytes("obj" + (2900 + i))).add(fam, qual1, Bytes.toBytes(i)));
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestPrefixTreeEncoding.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestPrefixTreeEncoding.java
index ee664bd..450ac95 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestPrefixTreeEncoding.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestPrefixTreeEncoding.java
@@ -94,7 +94,7 @@ public class TestPrefixTreeEncoding {
     formatRowNum = false;
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSeekBeforeWithFixedData() throws Exception {
     formatRowNum = true;
     PrefixTreeCodec encoder = new PrefixTreeCodec();
@@ -142,7 +142,7 @@ public class TestPrefixTreeEncoding {
     assertArrayEquals(getRowKey(batchId, NUM_ROWS_PER_BATCH - 1), seeker.getKeyValue().getRow());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testScanWithRandomData() throws Exception {
     PrefixTreeCodec encoder = new PrefixTreeCodec();
     ByteArrayOutputStream baosInMemory = new ByteArrayOutputStream();
@@ -180,7 +180,7 @@ public class TestPrefixTreeEncoding {
     } while (seeker.next());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSeekWithRandomData() throws Exception {
     PrefixTreeCodec encoder = new PrefixTreeCodec();
     ByteArrayOutputStream baosInMemory = new ByteArrayOutputStream();
@@ -203,7 +203,7 @@ public class TestPrefixTreeEncoding {
     verifySeeking(seeker, readBuffer, batchId);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSeekWithFixedData() throws Exception {
     PrefixTreeCodec encoder = new PrefixTreeCodec();
     int batchId = numBatchesWritten++;
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestSeekToBlockWithEncoders.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestSeekToBlockWithEncoders.java
index c053449..0bdad18 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestSeekToBlockWithEncoders.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/encoding/TestSeekToBlockWithEncoders.java
@@ -42,7 +42,7 @@ public class TestSeekToBlockWithEncoders {
   /**
    * Test seeking while file is encoded.
    */
-  @Test
+  @Test (timeout=180000)
   public void testSeekToBlockWithNonMatchingSeekKey() throws IOException {
     List<KeyValue> sampleKv = new ArrayList<KeyValue>();
     KeyValue kv1 = new KeyValue(Bytes.toBytes("aaa"), Bytes.toBytes("f1"), Bytes.toBytes("q1"),
@@ -68,7 +68,7 @@ public class TestSeekToBlockWithEncoders {
   /**
    * Test seeking while file is encoded.
    */
-  @Test
+  @Test (timeout=180000)
   public void testSeekingToBlockWithBiggerNonLength1() throws IOException {
     List<KeyValue> sampleKv = new ArrayList<KeyValue>();
     KeyValue kv1 = new KeyValue(Bytes.toBytes("aaa"), Bytes.toBytes("f1"), Bytes.toBytes("q1"),
@@ -94,7 +94,7 @@ public class TestSeekToBlockWithEncoders {
   /**
    * Test seeking while file is encoded.
    */
-  @Test
+  @Test (timeout=180000)
   public void testSeekingToBlockToANotAvailableKey() throws IOException {
     List<KeyValue> sampleKv = new ArrayList<KeyValue>();
     KeyValue kv1 = new KeyValue(Bytes.toBytes("aaa"), Bytes.toBytes("f1"), Bytes.toBytes("q1"),
@@ -120,7 +120,7 @@ public class TestSeekToBlockWithEncoders {
   /**
    * Test seeking while file is encoded.
    */
-  @Test
+  @Test (timeout=180000)
   public void testSeekToBlockWithDecreasingCommonPrefix() throws IOException {
     List<KeyValue> sampleKv = new ArrayList<KeyValue>();
     KeyValue kv1 = new KeyValue(Bytes.toBytes("row10aaa"), Bytes.toBytes("f1"),
@@ -140,7 +140,7 @@ public class TestSeekToBlockWithEncoders {
     seekToTheKey(kv3, sampleKv, toSeek);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSeekToBlockWithDiffQualifer() throws IOException {
     List<KeyValue> sampleKv = new ArrayList<KeyValue>();
     KeyValue kv1 = new KeyValue(Bytes.toBytes("aaa"), Bytes.toBytes("f1"), Bytes.toBytes("q1"),
@@ -160,7 +160,7 @@ public class TestSeekToBlockWithEncoders {
     seekToTheKey(kv5, sampleKv, toSeek);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSeekToBlockWithDiffQualiferOnSameRow() throws IOException {
     List<KeyValue> sampleKv = new ArrayList<KeyValue>();
     KeyValue kv1 = new KeyValue(Bytes.toBytes("aaa"), Bytes.toBytes("f1"), Bytes.toBytes("q1"),
@@ -183,7 +183,7 @@ public class TestSeekToBlockWithEncoders {
     seekToTheKey(kv6, sampleKv, toSeek);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSeekToBlockWithDiffQualiferOnSameRow1() throws IOException {
     List<KeyValue> sampleKv = new ArrayList<KeyValue>();
     KeyValue kv1 = new KeyValue(Bytes.toBytes("aaa"), Bytes.toBytes("f1"), Bytes.toBytes("q1"),
@@ -206,7 +206,7 @@ public class TestSeekToBlockWithEncoders {
     seekToTheKey(kv5, sampleKv, toSeek);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSeekToBlockWithDiffQualiferOnSameRowButDescendingInSize() throws IOException {
     List<KeyValue> sampleKv = new ArrayList<KeyValue>();
     KeyValue kv1 = new KeyValue(Bytes.toBytes("aaa"), Bytes.toBytes("f1"), Bytes.toBytes("qual1"),
@@ -229,7 +229,7 @@ public class TestSeekToBlockWithEncoders {
     seekToTheKey(kv6, sampleKv, toSeek);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSeekToBlockWithDiffFamilyAndQualifer() throws IOException {
     List<KeyValue> sampleKv = new ArrayList<KeyValue>();
     KeyValue kv1 = new KeyValue(Bytes.toBytes("aaa"), Bytes.toBytes("fam1"), Bytes.toBytes("q1"),
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestBlockCacheReporting.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestBlockCacheReporting.java
index 4080249..6313b3a 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestBlockCacheReporting.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestBlockCacheReporting.java
@@ -76,7 +76,7 @@ public class TestBlockCacheReporting {
     bc.getStats().getEvictedCount();
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testBucketCache() throws JsonGenerationException, JsonMappingException, IOException {
     this.conf.set(HConstants.BUCKET_CACHE_IOENGINE_KEY, "offheap");
     this.conf.setInt(HConstants.BUCKET_CACHE_SIZE_KEY, 100);
@@ -94,7 +94,7 @@ public class TestBlockCacheReporting {
     LOG.info(BlockCacheUtil.toJSON(cbsbf));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testLruBlockCache() throws JsonGenerationException, JsonMappingException, IOException {
     CacheConfig cc = new CacheConfig(this.conf);
     assertTrue(cc.isBlockCacheEnabled());
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheConfig.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheConfig.java
index c5fcc3c..0c4d327 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheConfig.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheConfig.java
@@ -203,7 +203,7 @@ public class TestCacheConfig {
     return cc.getBlockCache().getBlockCount();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCacheConfigDefaultLRUBlockCache() {
     CacheConfig cc = new CacheConfig(this.conf);
     assertTrue(cc.isBlockCacheEnabled());
@@ -215,19 +215,19 @@ public class TestCacheConfig {
   /**
    * Assert that the caches are deployed with CombinedBlockCache and of the appropriate sizes.
    */
-  @Test
+  @Test (timeout=60000)
   public void testOffHeapBucketCacheConfig() {
     this.conf.set(HConstants.BUCKET_CACHE_IOENGINE_KEY, "offheap");
     doBucketCacheConfigTest();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testOnHeapBucketCacheConfig() {
     this.conf.set(HConstants.BUCKET_CACHE_IOENGINE_KEY, "heap");
     doBucketCacheConfigTest();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testFileBucketCacheConfig() throws IOException {
     HBaseTestingUtility htu = new HBaseTestingUtility(this.conf);
     try {
@@ -318,7 +318,7 @@ public class TestCacheConfig {
    * Test the cacheDataInL1 flag.  When set, data blocks should be cached in the l1 tier, up in
    * LruBlockCache when using CombinedBlockCcahe.
    */
-  @Test
+  @Test (timeout=60000)
   public void testCacheDataInL1() {
     this.conf.set(HConstants.BUCKET_CACHE_IOENGINE_KEY, "offheap");
     this.conf.setInt(HConstants.BUCKET_CACHE_SIZE_KEY, 100);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java
index 7ec7e08..a1dcff7 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestCacheOnWrite.java
@@ -481,13 +481,13 @@ public class TestCacheOnWrite {
     region.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testStoreFileCacheOnWrite() throws IOException {
     testStoreFileCacheOnWriteInternals(false);
     testStoreFileCacheOnWriteInternals(true);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testNotCachingDataBlocksDuringCompaction() throws IOException, InterruptedException {
     testNotCachingDataBlocksDuringCompactionInternals(false);
     testNotCachingDataBlocksDuringCompactionInternals(true);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java
index 80266af..4ac2cee 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestChecksum.java
@@ -72,7 +72,7 @@ public class TestChecksum {
    * Introduce checksum failures and check that we can still read
    * the data
    */
-  @Test
+  @Test (timeout=180000)
   public void testChecksumCorruption() throws IOException {
     testChecksumCorruptionInternals(false);
     testChecksumCorruptionInternals(true);
@@ -180,7 +180,7 @@ public class TestChecksum {
   /** 
    * Test different values of bytesPerChecksum
    */
-  @Test
+  @Test (timeout=180000)
   public void testChecksumChunks() throws IOException {
     testChecksumInternals(false);
     testChecksumInternals(true);
@@ -259,7 +259,7 @@ public class TestChecksum {
   /** 
    * Test to ensure that these is at least one valid checksum implementation
    */
-  @Test
+  @Test (timeout=180000)
   public void testChecksumAlgorithm() throws IOException {
     ChecksumType type = ChecksumType.CRC32;
     assertEquals(ChecksumType.nameToType(type.getName()), type);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java
index 1b6731a..8fbab19 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestFixedFileTrailer.java
@@ -87,7 +87,7 @@ public class TestFixedFileTrailer {
     fs = FileSystem.get(util.getConfiguration());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testTrailer() throws IOException {
     FixedFileTrailer t = new FixedFileTrailer(version, 
         HFileReaderV2.PBUF_TRAILER_MINOR_VERSION);
@@ -168,7 +168,7 @@ public class TestFixedFileTrailer {
     assertEquals(trailerStr, t4.toString());
   }
   
-  @Test
+  @Test (timeout=180000)
   public void testTrailerForV2NonPBCompatibility() throws Exception {
     if (version == 2) {
       FixedFileTrailer t = new FixedFileTrailer(version,
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestForceCacheImportantBlocks.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestForceCacheImportantBlocks.java
index 2af3a6e..ba45b70 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestForceCacheImportantBlocks.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestForceCacheImportantBlocks.java
@@ -102,7 +102,7 @@ public class TestForceCacheImportantBlocks {
     HFile.dataBlockReadCnt.set(0);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCacheBlocks() throws IOException {
     // Set index block size to be the same as normal block size.
     TEST_UTIL.getConfiguration().setInt(HFileBlockIndex.MAX_CHUNK_SIZE_KEY, BLOCK_SIZE);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFile.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFile.java
index 3855629..3bd7072 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFile.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFile.java
@@ -86,7 +86,7 @@ public class TestHFile extends HBaseTestCase {
    * Test all features work reasonably when hfile is empty of entries.
    * @throws IOException
    */
-  @Test
+  @Test (timeout=180000)
   public void testEmptyHFile() throws IOException {
     if (cacheConf == null) cacheConf = new CacheConfig(conf);
     Path f = new Path(ROOT_DIR, getName());
@@ -103,7 +103,7 @@ public class TestHFile extends HBaseTestCase {
   /**
    * Create 0-length hfile and show that it fails
    */
-  @Test
+  @Test (timeout=180000)
   public void testCorrupt0LengthHFile() throws IOException {
     if (cacheConf == null) cacheConf = new CacheConfig(conf);
     Path f = new Path(ROOT_DIR, getName());
@@ -137,7 +137,7 @@ public class TestHFile extends HBaseTestCase {
   /**
    * Create a truncated hfile and verify that exception thrown.
    */
-  @Test
+  @Test (timeout=180000)
   public void testCorruptTruncatedHFile() throws IOException {
     if (cacheConf == null) cacheConf = new CacheConfig(conf);
     Path f = new Path(ROOT_DIR, getName());
@@ -287,13 +287,13 @@ public class TestHFile extends HBaseTestCase {
     fs.delete(ncTFile, true);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testTFileFeatures() throws IOException {
     testTFilefeaturesInternals(false);
     testTFilefeaturesInternals(true);
   }
 
-  @Test
+  @Test (timeout=180000)
   protected void testTFilefeaturesInternals(boolean useTags) throws IOException {
     basicWithSomeCodec("none", useTags);
     basicWithSomeCodec("gz", useTags);
@@ -361,13 +361,13 @@ public class TestHFile extends HBaseTestCase {
   }
 
   // test meta blocks for tfiles
-  @Test
+  @Test (timeout=180000)
   public void testMetaBlocks() throws Exception {
     metablocks("none");
     metablocks("gz");
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testNullMetaBlocks() throws Exception {
     if (cacheConf == null) cacheConf = new CacheConfig(conf);
     for (Compression.Algorithm compressAlgo : 
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java
index eb1f1bb..91f706e 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlock.java
@@ -232,7 +232,7 @@ public class TestHFileBlock {
     return Bytes.toStringBinary(testV2Block);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testNoCompression() throws IOException {
     CacheConfig cacheConf = Mockito.mock(CacheConfig.class);
     Mockito.when(cacheConf.isBlockCacheEnabled()).thenReturn(false);
@@ -244,7 +244,7 @@ public class TestHFileBlock {
     assertTrue(block.isUnpacked());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGzipCompression() throws IOException {
     final String correctTestBlockStr =
         "DATABLK*\\x00\\x00\\x00>\\x00\\x00\\x0F\\xA0\\xFF\\xFF\\xFF\\xFF"
@@ -273,7 +273,7 @@ public class TestHFileBlock {
       testBlockStr.substring(0, correctGzipBlockLength - 4));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testReaderV2() throws IOException {
     testReaderV2Internals();
   }
@@ -353,7 +353,7 @@ public class TestHFileBlock {
    * Test encoding/decoding data blocks.
    * @throws IOException a bug or a problem with temporary files.
    */
-  @Test
+  @Test (timeout=60000)
   public void testDataBlockEncoding() throws IOException {
     testInternals();
   }
@@ -511,7 +511,7 @@ public class TestHFileBlock {
         numBytes) + (numBytes < maxBytes ? "..." : "");
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testPreviousOffset() throws IOException {
     testPreviousOffsetInternals();
   }
@@ -703,7 +703,7 @@ public class TestHFileBlock {
 
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testConcurrentReading() throws Exception {
     testConcurrentReadingInternals();
   }
@@ -812,7 +812,7 @@ public class TestHFileBlock {
     return totalSize;
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testBlockHeapSize() {
     testBlockHeapSizeInternals();
   }
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java
index fc44f3c..673bc3c 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockCompatibility.java
@@ -137,13 +137,13 @@ public class TestHFileBlockCompatibility {
     return Bytes.toStringBinary(testV2Block);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testNoCompression() throws IOException {
     assertEquals(4000, createTestV2Block(NONE).getBlockForCaching().
         getUncompressedSizeWithoutHeader());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testGzipCompression() throws IOException {
     final String correctTestBlockStr =
         "DATABLK*\\x00\\x00\\x00:\\x00\\x00\\x0F\\xA0\\xFF\\xFF\\xFF\\xFF"
@@ -166,7 +166,7 @@ public class TestHFileBlockCompatibility {
     assertEquals(correctTestBlockStr, returnedStr);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testReaderV2() throws IOException {
     if(includesTag) {
       TEST_UTIL.getConfiguration().setInt("hfile.format.version", 3);
@@ -238,7 +238,7 @@ public class TestHFileBlockCompatibility {
    * Test encoding/decoding data blocks.
    * @throws IOException a bug or a problem with temporary files.
    */
-  @Test
+  @Test (timeout=180000)
   public void testDataBlockEncoding() throws IOException {
     if(includesTag) {
       TEST_UTIL.getConfiguration().setInt("hfile.format.version", 3);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java
index 939c019..2387abc 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileBlockIndex.java
@@ -120,7 +120,7 @@ public class TestHFileBlockIndex {
     fs = HFileSystem.get(conf);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testBlockIndex() throws IOException {
     testBlockIndexInternals(false);
     clear();
@@ -318,7 +318,7 @@ public class TestHFileBlockIndex {
     return i * i * 37 + i * 19 + 13;
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSecondaryIndexBinarySearch() throws IOException {
     int numTotalKeys = 99;
     assertTrue(numTotalKeys % 2 == 1); // Ensure no one made this even.
@@ -445,7 +445,7 @@ public class TestHFileBlockIndex {
 
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testBlockIndexChunk() throws IOException {
     BlockIndexChunk c = new BlockIndexChunk();
     ByteArrayOutputStream baos = new ByteArrayOutputStream();
@@ -482,7 +482,7 @@ public class TestHFileBlockIndex {
   }
 
   /** Checks if the HeapSize calculator is within reason */
-  @Test
+  @Test (timeout=60000)
   public void testHeapSizeForBlockIndex() throws IOException {
     Class<HFileBlockIndex.BlockIndexReader> cl =
         HFileBlockIndex.BlockIndexReader.class;
@@ -510,7 +510,7 @@ public class TestHFileBlockIndex {
    *
    * @throws IOException
    */
-  @Test
+  @Test (timeout=60000)
   public void testHFileWriterAndReader() throws IOException {
     Path hfilePath = new Path(TEST_UTIL.getDataTestDir(),
         "hfile_for_block_index");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java
index 3cdc92b..079d31c 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileDataBlockEncoder.java
@@ -68,7 +68,7 @@ public class TestHFileDataBlockEncoder {
    * Test putting and taking out blocks into cache with different
    * encoding options.
    */
-  @Test
+  @Test (timeout=180000)
   public void testEncodingWithCache() throws IOException {
     testEncodingWithCacheInternals(false);
     testEncodingWithCacheInternals(true);
@@ -102,7 +102,7 @@ public class TestHFileDataBlockEncoder {
   }
 
   /** Test for HBASE-5746. */
-  @Test
+  @Test (timeout=180000)
   public void testHeaderSizeInCacheWithoutChecksum() throws Exception {
     testHeaderSizeInCacheWithoutChecksumInternals(false);
     testHeaderSizeInCacheWithoutChecksumInternals(true);
@@ -135,7 +135,7 @@ public class TestHFileDataBlockEncoder {
    * Test encoding.
    * @throws IOException
    */
-  @Test
+  @Test (timeout=180000)
   public void testEncoding() throws IOException {
     testEncodingInternals(false);
     testEncodingInternals(true);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileInlineToRootChunkConversion.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileInlineToRootChunkConversion.java
index c0683f8..539bd4e 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileInlineToRootChunkConversion.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileInlineToRootChunkConversion.java
@@ -46,7 +46,7 @@ public class TestHFileInlineToRootChunkConversion {
   private final HBaseTestingUtility testUtil = new HBaseTestingUtility();
   private final Configuration conf = testUtil.getConfiguration();
   
-  @Test
+  @Test (timeout=180000)
   public void testWriteHFile() throws Exception {
     Path hfPath = new Path(testUtil.getDataTestDir(),
         TestHFileInlineToRootChunkConversion.class.getSimpleName() + ".hfile");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java
index 42e918a..f48aaf0 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV2.java
@@ -75,7 +75,7 @@ public class TestHFileWriterV2 {
     fs = FileSystem.get(conf);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testHFileFormatV2() throws IOException {
     Path hfilePath = new Path(TEST_UTIL.getDataTestDir(), "testHFileFormatV2");
     final Compression.Algorithm compressAlgo = Compression.Algorithm.GZ;
@@ -83,7 +83,7 @@ public class TestHFileWriterV2 {
     writeDataAndReadFromHFile(hfilePath, compressAlgo, entryCount, false);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testMidKeyInHFile() throws IOException{
     Path hfilePath = new Path(TEST_UTIL.getDataTestDir(),
     "testMidKeyInHFile");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV3.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV3.java
index f96e8ef..a0141b7 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV3.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileWriterV3.java
@@ -89,7 +89,7 @@ public class TestHFileWriterV3 {
     fs = FileSystem.get(conf);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testHFileFormatV3() throws IOException {
     testHFileFormatV3Internals(useTags);
   }
@@ -101,7 +101,7 @@ public class TestHFileWriterV3 {
     writeDataAndReadFromHFile(hfilePath, compressAlgo, entryCount, false, useTags);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testMidKeyInHFile() throws IOException{
     testMidKeyInHFileInternals(useTags);
   }
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestLazyDataBlockDecompression.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestLazyDataBlockDecompression.java
index 2fd3684..b1118e8 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestLazyDataBlockDecompression.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestLazyDataBlockDecompression.java
@@ -134,7 +134,7 @@ public class TestLazyDataBlockDecompression {
     LOG.info("read " + Iterables.toString(blocks));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testCompressionIncreasesEffectiveBlockCacheSize() throws Exception {
     // enough room for 2 uncompressed block
     int maxSize = (int) (HConstants.DEFAULT_BLOCKSIZE * 2.1);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestLruBlockCache.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestLruBlockCache.java
index ec60bcd..f54c44b 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestLruBlockCache.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestLruBlockCache.java
@@ -43,7 +43,7 @@ import org.junit.experimental.categories.Category;
 public class TestLruBlockCache {
 
 
-  @Test
+  @Test (timeout=180000)
   public void testBackgroundEvictionThread() throws Exception {
     long maxSize = 100000;
     int numBlocks = 9;
@@ -93,7 +93,7 @@ public class TestLruBlockCache {
     System.out.println("Background Evictions run: " + evictionCount);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testCacheSimple() throws Exception {
 
     long maxSize = 1000000;
@@ -152,7 +152,7 @@ public class TestLruBlockCache {
     t.join();
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testCacheEvictionSimple() throws Exception {
 
     long maxSize = 100000;
@@ -192,7 +192,7 @@ public class TestLruBlockCache {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testCacheEvictionTwoPriorities() throws Exception {
 
     long maxSize = 100000;
@@ -251,7 +251,7 @@ public class TestLruBlockCache {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testCacheEvictionThreePriorities() throws Exception {
 
     long maxSize = 100000;
@@ -372,7 +372,7 @@ public class TestLruBlockCache {
     assertEquals(null, cache.getBlock(memoryBlocks[3].cacheKey, true, false, true));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testCacheEvictionInMemoryForceMode() throws Exception {
     long maxSize = 100000;
     long blockSize = calculateBlockSize(maxSize, 10);
@@ -476,7 +476,7 @@ public class TestLruBlockCache {
   }
 
   // test scan resistance
-  @Test
+  @Test (timeout=180000)
   public void testScanResistance() throws Exception {
 
     long maxSize = 100000;
@@ -540,7 +540,7 @@ public class TestLruBlockCache {
   }
 
   // test setMaxSize
-  @Test
+  @Test (timeout=180000)
   public void testResizeBlockCache() throws Exception {
 
     long maxSize = 300000;
@@ -603,7 +603,7 @@ public class TestLruBlockCache {
   }
 
   // test metricsPastNPeriods
-  @Test
+  @Test (timeout=180000)
   public void testPastNPeriodsMetrics() throws Exception {
    double delta = 0.01;
 
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestLruCachedBlock.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestLruCachedBlock.java
index 141c95b..0f4489a 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestLruCachedBlock.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestLruCachedBlock.java
@@ -47,7 +47,7 @@ public class TestLruCachedBlock {
     blockNotEqual = new LruCachedBlock(cacheKey, cacheable, 1);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testEquality() {
     assertEquals(block.hashCode(), blockEqual.hashCode());
     assertNotEquals(block.hashCode(), blockNotEqual.hashCode());
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestReseekTo.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestReseekTo.java
index 3a0fdf7..5b6a1be 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestReseekTo.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestReseekTo.java
@@ -44,7 +44,7 @@ public class TestReseekTo {
 
   private final static HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility();
 
-  @Test
+  @Test (timeout=180000)
   public void testReseekTo() throws Exception {
     testReseekToInternals(TagUsage.NO_TAG);
     testReseekToInternals(TagUsage.ONLY_TAG);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestScannerSelectionUsingKeyRange.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestScannerSelectionUsingKeyRange.java
index e8f6c1b..6538ea1 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestScannerSelectionUsingKeyRange.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestScannerSelectionUsingKeyRange.java
@@ -90,7 +90,7 @@ public class TestScannerSelectionUsingKeyRange {
     TEST_UTIL.cleanupTestDir();
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testScannerSelection() throws IOException {
     Configuration conf = TEST_UTIL.getConfiguration();
     conf.setInt("hbase.hstore.compactionThreshold", 10000);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestScannerSelectionUsingTTL.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestScannerSelectionUsingTTL.java
index 1c426e4..73ec171 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestScannerSelectionUsingTTL.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestScannerSelectionUsingTTL.java
@@ -95,7 +95,7 @@ public class TestScannerSelectionUsingTTL {
     this.explicitCompaction = explicitCompaction;
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testScannerSelection() throws IOException {
     Configuration conf = TEST_UTIL.getConfiguration();
     conf.setBoolean("hbase.store.delete.expired.storefile", false);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestSeekTo.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestSeekTo.java
index b9a126f..4d62ba4 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestSeekTo.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestSeekTo.java
@@ -98,7 +98,7 @@ public class TestSeekTo extends HBaseTestCase {
     return ncTFile;
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSeekBefore() throws Exception {
     testSeekBeforeInternals(TagUsage.NO_TAG);
     testSeekBeforeInternals(TagUsage.ONLY_TAG);
@@ -140,7 +140,7 @@ public class TestSeekTo extends HBaseTestCase {
     reader.close();
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSeekBeforeWithReSeekTo() throws Exception {
     testSeekBeforeWithReSeekToInternals(TagUsage.NO_TAG);
     testSeekBeforeWithReSeekToInternals(TagUsage.ONLY_TAG);
@@ -230,7 +230,7 @@ public class TestSeekTo extends HBaseTestCase {
     assertEquals("k", toRowStr(scanner.getKeyValue()));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSeekTo() throws Exception {
     testSeekToInternals(TagUsage.NO_TAG);
     testSeekToInternals(TagUsage.ONLY_TAG);
@@ -260,7 +260,7 @@ public class TestSeekTo extends HBaseTestCase {
     reader.close();
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testBlockContainingKey() throws Exception {
     testBlockContainingKeyInternals(TagUsage.NO_TAG);
     testBlockContainingKeyInternals(TagUsage.ONLY_TAG);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/bucket/TestBucketCache.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/bucket/TestBucketCache.java
index d29be01..22e446d 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/bucket/TestBucketCache.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/bucket/TestBucketCache.java
@@ -129,7 +129,7 @@ public class TestBucketCache {
     return a.get(RAND.nextInt(a.size()));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testBucketAllocator() throws BucketAllocatorException {
     BucketAllocator mAllocator = cache.getAllocator();
     /*
@@ -167,17 +167,17 @@ public class TestBucketCache {
     assertEquals(0, mAllocator.getUsedSize());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testCacheSimple() throws Exception {
     CacheTestUtils.testCacheSimple(cache, BLOCK_SIZE, NUM_QUERIES);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testCacheMultiThreadedSingleKey() throws Exception {
     CacheTestUtils.hammerSingleKey(cache, BLOCK_SIZE, NUM_THREADS, NUM_QUERIES);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testHeapSizeChanges() throws Exception {
     cache.stopWriterThreads();
     CacheTestUtils.testHeapSizeChanges(cache, BLOCK_SIZE);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/bucket/TestBucketWriterThread.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/bucket/TestBucketWriterThread.java
index 4d3f550..ba68d78 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/bucket/TestBucketWriterThread.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/bucket/TestBucketWriterThread.java
@@ -116,7 +116,7 @@ public class TestBucketWriterThread {
    * Manually run the WriterThread.
    * @throws InterruptedException
    */
-  @Test
+  @Test (timeout=180000)
   public void testTooBigEntry() throws InterruptedException {
     Cacheable tooBigCacheable = Mockito.mock(Cacheable.class);
     Mockito.when(tooBigCacheable.getSerializedLength()).thenReturn(Integer.MAX_VALUE);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/bucket/TestByteBufferIOEngine.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/bucket/TestByteBufferIOEngine.java
index 511f942..2efc15f 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/bucket/TestByteBufferIOEngine.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/bucket/TestByteBufferIOEngine.java
@@ -33,7 +33,7 @@ import org.junit.experimental.categories.Category;
 @Category({IOTests.class, SmallTests.class})
 public class TestByteBufferIOEngine {
 
-  @Test
+  @Test (timeout=180000)
   public void testByteBufferIOEngine() throws Exception {
     int capacity = 32 * 1024 * 1024; // 32 MB
     int testNum = 100;
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/bucket/TestFileIOEngine.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/bucket/TestFileIOEngine.java
index 8306114..bede0c0 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/bucket/TestFileIOEngine.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/bucket/TestFileIOEngine.java
@@ -34,7 +34,7 @@ import org.junit.experimental.categories.Category;
  */
 @Category({IOTests.class, SmallTests.class})
 public class TestFileIOEngine {
-  @Test
+  @Test (timeout=180000)
   public void testFileIOEngine() throws IOException {
     int size = 2 * 1024 * 1024; // 2 MB
     String filePath = "testFileIOEngine";
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestAsyncIPC.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestAsyncIPC.java
index 768871c..9adf10c 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestAsyncIPC.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestAsyncIPC.java
@@ -151,7 +151,7 @@ public class TestAsyncIPC extends AbstractTestIPC {
         });
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testAsyncConnectionSetup() throws Exception {
     TestRpcServer rpcServer = new TestRpcServer();
     AsyncRpcClient client = createRpcClient(CONF);
@@ -187,7 +187,7 @@ public class TestAsyncIPC extends AbstractTestIPC {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRTEDuringAsyncConnectionSetup() throws Exception {
     TestRpcServer rpcServer = new TestRpcServer();
     AsyncRpcClient client = createRpcClientRTEDuringConnectionSetup(CONF);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestBufferChain.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestBufferChain.java
index e8f6464..4b9176a 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestBufferChain.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestBufferChain.java
@@ -57,14 +57,14 @@ public class TestBufferChain {
     tmpFile.delete();
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testGetBackBytesWePutIn() {
     ByteBuffer[] bufs = wrapArrays(HELLO_WORLD_CHUNKS);
     BufferChain chain = new BufferChain(bufs);
     assertTrue(Bytes.equals(Bytes.toBytes("hello world"), chain.getBytes()));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testChainChunkBiggerThanWholeArray() throws IOException {
     ByteBuffer[] bufs = wrapArrays(HELLO_WORLD_CHUNKS);
     BufferChain chain = new BufferChain(bufs);
@@ -72,7 +72,7 @@ public class TestBufferChain {
     assertNoRemaining(bufs);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testChainChunkBiggerThanSomeArrays() throws IOException {
     ByteBuffer[] bufs = wrapArrays(HELLO_WORLD_CHUNKS);
     BufferChain chain = new BufferChain(bufs);
@@ -80,7 +80,7 @@ public class TestBufferChain {
     assertNoRemaining(bufs);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testLimitOffset() throws IOException {
     ByteBuffer[] bufs = new ByteBuffer[] {
         stringBuf("XXXhelloYYY", 3, 5),
@@ -91,7 +91,7 @@ public class TestBufferChain {
     assertNoRemaining(bufs);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testWithSpy() throws IOException {
     ByteBuffer[] bufs = new ByteBuffer[] {
         stringBuf("XXXhelloYYY", 3, 5),
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestCallRunner.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestCallRunner.java
index be16529..50454f1 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestCallRunner.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestCallRunner.java
@@ -29,7 +29,7 @@ public class TestCallRunner {
   /**
    * Does nothing but exercise a {@link CallRunner} outside of {@link RpcServer} context.
    */
-  @Test
+  @Test (timeout=180000)
   public void testSimpleCall() {
     RpcServerInterface mockRpcServer = Mockito.mock(RpcServerInterface.class);
     Mockito.when(mockRpcServer.isStarted()).thenReturn(true);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestDelayedRpc.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestDelayedRpc.java
index 961001f..578faca 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestDelayedRpc.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestDelayedRpc.java
@@ -282,7 +282,7 @@ public class TestDelayedRpc {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testEndDelayThrowing() throws IOException {
     Configuration conf = HBaseConfiguration.create();
     InetSocketAddress isa = new InetSocketAddress("localhost", 0);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestGlobalEventLoopGroup.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestGlobalEventLoopGroup.java
index 60dbd1b..64f1c43 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestGlobalEventLoopGroup.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestGlobalEventLoopGroup.java
@@ -33,7 +33,7 @@ import org.junit.experimental.categories.Category;
 @Category({ RPCTests.class, SmallTests.class })
 public class TestGlobalEventLoopGroup {
 
-  @Test
+  @Test (timeout=180000)
   public void test() {
     Configuration conf = HBaseConfiguration.create();
     conf.setBoolean(AsyncRpcClient.USE_GLOBAL_EVENT_LOOP_GROUP, true);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestHBaseClient.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestHBaseClient.java
index 26488cf..36a9abe 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestHBaseClient.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestHBaseClient.java
@@ -32,7 +32,7 @@ import java.net.InetSocketAddress;
 @Category({RPCTests.class, MediumTests.class})   // Can't be small, we're playing with the EnvironmentEdge
 public class TestHBaseClient {
 
-  @Test
+  @Test (timeout=60000)
   public void testFailedServer(){
     ManualEnvironmentEdge ee = new ManualEnvironmentEdge();
     EnvironmentEdgeManager.injectEdge(  ee );
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestProtoBufRpc.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestProtoBufRpc.java
index cee459f..9aa8406 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestProtoBufRpc.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestProtoBufRpc.java
@@ -110,7 +110,7 @@ public class TestProtoBufRpc {
     server.stop();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testProtoBufRpc() throws Exception {
     RpcClient rpcClient = RpcClientFactory.createClient(conf, HConstants.CLUSTER_ID_DEFAULT);
     try {
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestRpcHandlerException.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestRpcHandlerException.java
index 298f086..6edefcb 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestRpcHandlerException.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestRpcHandlerException.java
@@ -166,7 +166,7 @@ public class TestRpcHandlerException {
    * caught errors exceeds the threshold. Client will hang when RS aborts.
    */
   @Ignore
-  @Test
+  @Test (timeout=180000)
   public void testRpcScheduler() throws IOException, InterruptedException {
     PriorityFunction qosFunction = mock(PriorityFunction.class);
     Abortable abortable = new AbortServer();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestRpcMetrics.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestRpcMetrics.java
index 443ec78..e923819 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestRpcMetrics.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestRpcMetrics.java
@@ -33,7 +33,7 @@ import static org.junit.Assert.*;
 public class TestRpcMetrics {
   public MetricsAssertHelper HELPER = CompatibilityFactory.getInstance(MetricsAssertHelper.class);
 
-  @Test
+  @Test (timeout=180000)
   public void testFactory() {
     MetricsHBaseServer masterMetrics = new MetricsHBaseServer("HMaster", new MetricsHBaseServerWrapperStub());
     MetricsHBaseServerSource masterSource = masterMetrics.getMetricsSource();
@@ -56,7 +56,7 @@ public class TestRpcMetrics {
    * This test makes sure that the numbers from a MetricsHBaseServerWrapper are correctly exported
    * to hadoop metrics 2 system.
    */
-  @Test
+  @Test (timeout=180000)
   public void testWrapperSource() {
     MetricsHBaseServer mrpc = new MetricsHBaseServer("HMaster", new MetricsHBaseServerWrapperStub());
     MetricsHBaseServerSource serverSource = mrpc.getMetricsSource();
@@ -71,7 +71,7 @@ public class TestRpcMetrics {
   /**
    * Test to make sure that all the actively called method on MetricsHBaseServer work.
    */
-  @Test
+  @Test (timeout=180000)
   public void testSourceMethods() {
     MetricsHBaseServer mrpc = new MetricsHBaseServer("HMaster", new MetricsHBaseServerWrapperStub());
     MetricsHBaseServerSource serverSource = mrpc.getMetricsSource();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestSimpleRpcScheduler.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestSimpleRpcScheduler.java
index 11ac43f..119a550 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestSimpleRpcScheduler.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestSimpleRpcScheduler.java
@@ -75,7 +75,7 @@ public class TestSimpleRpcScheduler {
     conf = HBaseConfiguration.create();
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testBasic() throws IOException, InterruptedException {
     PriorityFunction qosFunction = mock(PriorityFunction.class);
     RpcScheduler scheduler = new SimpleRpcScheduler(
@@ -88,7 +88,7 @@ public class TestSimpleRpcScheduler {
     scheduler.stop();
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testHandlerIsolation() throws IOException, InterruptedException {
     CallRunner generalTask = createMockTask();
     CallRunner priorityTask = createMockTask();
@@ -146,7 +146,7 @@ public class TestSimpleRpcScheduler {
     return task;
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testRpcScheduler() throws Exception {
     testRpcScheduler(SimpleRpcScheduler.CALL_QUEUE_TYPE_DEADLINE_CONF_VALUE);
     testRpcScheduler(SimpleRpcScheduler.CALL_QUEUE_TYPE_FIFO_CONF_VALUE);
@@ -227,7 +227,7 @@ public class TestSimpleRpcScheduler {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testScanQueues() throws Exception {
     Configuration schedConf = HBaseConfiguration.create();
     schedConf.setFloat(SimpleRpcScheduler.CALL_QUEUE_HANDLER_FACTOR_CONF_KEY, 1.0f);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestDriver.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestDriver.java
index ab6a86d..c4d731a 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestDriver.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestDriver.java
@@ -31,7 +31,7 @@ import static org.mockito.Mockito.verify;
 @Category({MapReduceTests.class, SmallTests.class})
 public class TestDriver {
 
-  @Test
+  @Test (timeout=180000)
   public void testDriverMainMethod() throws Throwable {
     ProgramDriver programDriverMock = mock(ProgramDriver.class);
     Driver.setProgramDriver(programDriverMock);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestGroupingTableMap.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestGroupingTableMap.java
index 90ed73b..c19b6ef 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestGroupingTableMap.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestGroupingTableMap.java
@@ -52,7 +52,7 @@ import com.google.common.collect.ImmutableList;
 @Category({MapReduceTests.class, SmallTests.class})
 public class TestGroupingTableMap {
 
-  @Test
+  @Test (timeout=180000)
   @SuppressWarnings({ "deprecation", "unchecked" })
   public void shouldNotCallCollectonSinceFindUniqueKeyValueMoreThanOnes()
       throws Exception {
@@ -83,7 +83,7 @@ public class TestGroupingTableMap {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   @SuppressWarnings({ "deprecation", "unchecked" })
   public void shouldCreateNewKeyAlthoughExtraKey() throws Exception {
     GroupingTableMap gTableMap = null;
@@ -115,7 +115,7 @@ public class TestGroupingTableMap {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   @SuppressWarnings({ "deprecation" })
   public void shouldCreateNewKey() throws Exception {
     GroupingTableMap gTableMap = null;  
@@ -164,7 +164,7 @@ public class TestGroupingTableMap {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   @SuppressWarnings({ "deprecation" })
   public void shouldReturnNullFromCreateGroupKey() throws Exception {
     GroupingTableMap gTableMap = null;
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestIdentityTableMap.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestIdentityTableMap.java
index 3fad1fe..19f1286 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestIdentityTableMap.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestIdentityTableMap.java
@@ -37,7 +37,7 @@ import org.mockito.Mockito;
 @Category({MapReduceTests.class, SmallTests.class})
 public class TestIdentityTableMap {
 
-  @Test
+  @Test (timeout=180000)
   @SuppressWarnings({ "deprecation", "unchecked" })
   public void shouldCollectPredefinedTimes() throws IOException {
     int recordNumber = 999;
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestRowCounter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestRowCounter.java
index 6c7e445..24f1b25 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestRowCounter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestRowCounter.java
@@ -48,7 +48,7 @@ import com.google.common.base.Joiner;
 @Category({MapReduceTests.class, SmallTests.class})
 public class TestRowCounter {
 
-  @Test
+  @Test (timeout=180000)
   @SuppressWarnings("deprecation")
   public void shouldPrintUsage() throws Exception {
     String expectedOutput = "rowcounter <outputdir> <tablename> <column1> [<column2>...]";
@@ -62,7 +62,7 @@ public class TestRowCounter {
     assertTrue(result.startsWith(expectedOutput));
   }
 
-  @Test
+  @Test (timeout=180000)
   @SuppressWarnings("deprecation")
   public void shouldExitAndPrintUsageSinceParameterNumberLessThanThree()
       throws Exception {
@@ -78,7 +78,7 @@ public class TestRowCounter {
     assertTrue(result.startsWith(line));
   }
 
-  @Test
+  @Test (timeout=180000)
   @SuppressWarnings({ "deprecation", "unchecked" })
   public void shouldRegInReportEveryIncomingRow() throws IOException {
     int iterationNumber = 999;
@@ -92,7 +92,7 @@ public class TestRowCounter {
         any(Enum.class), anyInt());
   }
 
-  @Test
+  @Test (timeout=180000)
   @SuppressWarnings({ "deprecation" })
   public void shouldCreateAndRunSubmittableJob() throws Exception {
     RowCounter rCounter = new RowCounter();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestSplitTable.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestSplitTable.java
index 216041d..cbb21d3 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestSplitTable.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestSplitTable.java
@@ -33,7 +33,7 @@ import org.junit.experimental.categories.Category;
 @Category({MapReduceTests.class, SmallTests.class})
 public class TestSplitTable {
 
-  @Test
+  @Test (timeout=180000)
   @SuppressWarnings("deprecation")
   public void testSplitTableCompareTo() {
     TableSplit aTableSplit = new TableSplit(Bytes.toBytes("tableA"),
@@ -61,7 +61,7 @@ public class TestSplitTable {
     assertTrue(cTableSplit.compareTo(aTableSplit) > 0);
   }
 
-  @Test
+  @Test (timeout=180000)
   @SuppressWarnings("deprecation")
   public void testSplitTableEquals() {
     byte[] tableA = Bytes.toBytes("tableA");
@@ -92,7 +92,7 @@ public class TestSplitTable {
     assertEquals(tablesplit, same);
   }
 
-  @Test
+  @Test (timeout=180000)
   @SuppressWarnings("deprecation")
   public void testToString() {
     TableSplit split =
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestTableInputFormat.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestTableInputFormat.java
index d7dd8ec..1042de0 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestTableInputFormat.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestTableInputFormat.java
@@ -265,7 +265,7 @@ public class TestTableInputFormat {
    * 
    * @throws IOException
    */
-  @Test
+  @Test (timeout=60000)
   public void testTableRecordReader() throws IOException {
     Table table = createTable("table1".getBytes());
     runTestMapred(table);
@@ -276,7 +276,7 @@ public class TestTableInputFormat {
    * 
    * @throws IOException
    */
-  @Test
+  @Test (timeout=60000)
   public void testTableRecordReaderScannerFail() throws IOException {
     Table htable = createIOEScannerTable("table2".getBytes(), 1);
     runTestMapred(htable);
@@ -299,7 +299,7 @@ public class TestTableInputFormat {
    * 
    * @throws org.apache.hadoop.hbase.DoNotRetryIOException
    */
-  @Test
+  @Test (timeout=60000)
   public void testTableRecordReaderScannerTimeout() throws IOException {
     Table htable = createDNRIOEScannerTable("table4".getBytes(), 1);
     runTestMapred(htable);
@@ -320,7 +320,7 @@ public class TestTableInputFormat {
   /**
    * Verify the example we present in javadocs on TableInputFormatBase
    */
-  @Test
+  @Test (timeout=60000)
   public void testExtensionOfTableInputFormatBase() throws IOException {
     LOG.info("testing use of an InputFormat taht extends InputFormatBase");
     final Table table = createTable(Bytes.toBytes("exampleTable"),
@@ -328,7 +328,7 @@ public class TestTableInputFormat {
     testInputFormat(ExampleTIF.class);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testDeprecatedExtensionOfTableInputFormatBase() throws IOException {
     LOG.info("testing use of an InputFormat taht extends InputFormatBase, "
         + "as it was given in 0.98.");
@@ -337,7 +337,7 @@ public class TestTableInputFormat {
     testInputFormat(ExampleDeprecatedTIF.class);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testJobConfigurableExtensionOfTableInputFormatBase() throws IOException {
     LOG.info("testing use of an InputFormat taht extends InputFormatBase, "
         + "using JobConfigurable.");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestTableMapReduceUtil.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestTableMapReduceUtil.java
index 628bb96..8b733c7 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestTableMapReduceUtil.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestTableMapReduceUtil.java
@@ -135,7 +135,7 @@ public class TestTableMapReduceUtil {
    * Check what the given number of reduce tasks for the given job configuration
    * does not exceed the number of regions for the given table.
    */
-  @Test
+  @Test (timeout=60000)
   public void shouldNumberOfReduceTaskNotExceedNumberOfRegionsForGivenTable()
       throws IOException {
     Assert.assertNotNull(presidentsTable);
@@ -153,7 +153,7 @@ public class TestTableMapReduceUtil {
     assertEquals(1, jobConf.getNumReduceTasks());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void shouldNumberOfMapTaskNotExceedNumberOfRegionsForGivenTable()
       throws IOException {
     Configuration cfg = UTIL.getConfiguration();
@@ -168,7 +168,7 @@ public class TestTableMapReduceUtil {
     assertEquals(1, jobConf.getNumMapTasks());
   }
 
-  @Test
+  @Test (timeout=60000)
   @SuppressWarnings("deprecation")
   public void shoudBeValidMapReduceEvaluation() throws Exception {
     Configuration cfg = UTIL.getConfiguration();
@@ -189,7 +189,7 @@ public class TestTableMapReduceUtil {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   @SuppressWarnings("deprecation")
   public void shoudBeValidMapReduceWithPartitionerEvaluation()
       throws IOException {
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestTableSnapshotInputFormat.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestTableSnapshotInputFormat.java
index eabedec..1fd63cc 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestTableSnapshotInputFormat.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapred/TestTableSnapshotInputFormat.java
@@ -95,7 +95,7 @@ public class TestTableSnapshotInputFormat extends TableSnapshotInputFormatTestBa
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testInitTableSnapshotMapperJobConfig() throws Exception {
     setupCluster();
     TableName tableName = TableName.valueOf("testInitTableSnapshotMapperJobConfig");
@@ -129,19 +129,19 @@ public class TestTableSnapshotInputFormat extends TableSnapshotInputFormatTestBa
   // TODO: mapred does not support limiting input range by startrow, endrow.
   // Thus the following tests must override parameterverification.
 
-  @Test
+  @Test (timeout=60000)
   @Override
   public void testWithMockedMapReduceMultiRegion() throws Exception {
     testWithMockedMapReduce(UTIL, "testWithMockedMapReduceMultiRegion", 10, 10);
   }
 
-  @Test
+  @Test (timeout=60000)
   @Override
   public void testWithMapReduceMultiRegion() throws Exception {
     testWithMapReduce(UTIL, "testWithMapReduceMultiRegion", 10, 10, false);
   }
 
-  @Test
+  @Test (timeout=60000)
   @Override
   // run the MR job while HBase is offline
   public void testWithMapReduceAndOfflineHBaseMultiRegion() throws Exception {
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestCellCounter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestCellCounter.java
index 22bc330..5c3ac29 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestCellCounter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestCellCounter.java
@@ -321,7 +321,7 @@ public class TestCellCounter {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void TestCellCounterWithoutOutputDir() throws Exception {
     String[] args = new String[] { "tableName" };
     assertEquals("CellCounter should exit with -1 as output directory is not specified.", -1,
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestCopyTable.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestCopyTable.java
index 4b11abb..f72bf09 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestCopyTable.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestCopyTable.java
@@ -119,7 +119,7 @@ public class TestCopyTable {
    * Simple end-to-end test
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testCopyTable() throws Exception {
     doCopyTableTest(false);
   }
@@ -127,12 +127,12 @@ public class TestCopyTable {
   /**
    * Simple end-to-end test with bulkload.
    */
-  @Test
+  @Test (timeout=60000)
   public void testCopyTableWithBulkload() throws Exception {
     doCopyTableTest(true);
   }
   
-  @Test
+  @Test (timeout=60000)
   public void testStartStopRow() throws Exception {
     final TableName TABLENAME1 = TableName.valueOf("testStartStopRow1");
     final TableName TABLENAME2 = TableName.valueOf("testStartStopRow2");
@@ -186,7 +186,7 @@ public class TestCopyTable {
   /**
    * Test copy of table from sourceTable to targetTable all rows from family a
    */
-  @Test
+  @Test (timeout=60000)
   public void testRenameFamily() throws Exception {
     String sourceTable = "sourceTable";
     String targetTable = "targetTable";
@@ -229,7 +229,7 @@ public class TestCopyTable {
   /**
    * Test main method of CopyTable.
    */
-  @Test
+  @Test (timeout=60000)
   public void testMainMethod() throws Exception {
     String[] emptyArgs = { "-h" };
     PrintStream oldWriter = System.err;
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestGroupingTableMapper.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestGroupingTableMapper.java
index fc7b102..2050545 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestGroupingTableMapper.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestGroupingTableMapper.java
@@ -38,7 +38,7 @@ public class TestGroupingTableMapper {
   /**
    * Test GroupingTableMapper class
    */
-  @Test
+  @Test (timeout=180000)
   public void testGroupingTableMapper() throws Exception {
 
     GroupingTableMapper mapper = new GroupingTableMapper();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat.java
index ecea98e..fbb38fe 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat.java
@@ -179,7 +179,7 @@ public class TestHFileOutputFormat  {
    * passed a keyvalue whose timestamp is {@link HConstants#LATEST_TIMESTAMP}.
    * @see <a href="https://issues.apache.org/jira/browse/HBASE-2615">HBASE-2615</a>
    */
-  @Test
+  @Test (timeout=60000)
   public void test_LATEST_TIMESTAMP_isReplaced()
   throws Exception {
     Configuration conf = new Configuration(this.util.getConfiguration());
@@ -229,7 +229,7 @@ public class TestHFileOutputFormat  {
    * Test that {@link HFileOutputFormat} creates an HFile with TIMERANGE
    * metadata used by time-restricted scans.
    */
-  @Test
+  @Test (timeout=60000)
   public void test_TIMERANGE() throws Exception {
     Configuration conf = new Configuration(this.util.getConfiguration());
     RecordWriter<ImmutableBytesWritable, KeyValue> writer = null;
@@ -295,7 +295,7 @@ public class TestHFileOutputFormat  {
   /**
    * Run small MR job.
    */
-  @Test
+  @Test (timeout=60000)
   public void testWritingPEData() throws Exception {
     Configuration conf = util.getConfiguration();
     Path testDir = util.getDataTestDirOnTestFS("testWritingPEData");
@@ -333,7 +333,7 @@ public class TestHFileOutputFormat  {
     assertTrue(files.length > 0);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testJobConfiguration() throws Exception {
     Job job = new Job(util.getConfiguration());
     job.setWorkingDirectory(util.getDataTestDir("testJobConfiguration"));
@@ -366,13 +366,13 @@ public class TestHFileOutputFormat  {
     return ret;
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMRIncrementalLoad() throws Exception {
     LOG.info("\nStarting test testMRIncrementalLoad\n");
     doIncrementalLoadTest(false);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMRIncrementalLoadWithSplit() throws Exception {
     LOG.info("\nStarting test testMRIncrementalLoadWithSplit\n");
     doIncrementalLoadTest(true);
@@ -501,7 +501,7 @@ public class TestHFileOutputFormat  {
    *
    * @throws IOException
    */
-  @Test
+  @Test (timeout=60000)
   public void testSerializeDeserializeFamilyCompressionMap() throws IOException {
     for (int numCfs = 0; numCfs <= 3; numCfs++) {
       Configuration conf = new Configuration(this.util.getConfiguration());
@@ -571,7 +571,7 @@ public class TestHFileOutputFormat  {
    *
    * @throws IOException
    */
-  @Test
+  @Test (timeout=60000)
   public void testSerializeDeserializeFamilyBloomTypeMap() throws IOException {
     for (int numCfs = 0; numCfs <= 2; numCfs++) {
       Configuration conf = new Configuration(this.util.getConfiguration());
@@ -642,7 +642,7 @@ public class TestHFileOutputFormat  {
    *
    * @throws IOException
    */
-  @Test
+  @Test (timeout=60000)
   public void testSerializeDeserializeFamilyBlockSizeMap() throws IOException {
     for (int numCfs = 0; numCfs <= 3; numCfs++) {
       Configuration conf = new Configuration(this.util.getConfiguration());
@@ -718,7 +718,7 @@ public class TestHFileOutputFormat  {
    *
    * @throws IOException
    */
-  @Test
+  @Test (timeout=60000)
   public void testSerializeDeserializeFamilyDataBlockEncodingMap() throws IOException {
     for (int numCfs = 0; numCfs <= 3; numCfs++) {
       Configuration conf = new Configuration(this.util.getConfiguration());
@@ -798,7 +798,7 @@ public class TestHFileOutputFormat  {
    * Test that {@link HFileOutputFormat} RecordWriter uses compression and
    * bloom filter settings from the column family descriptor
    */
-  @Test
+  @Test (timeout=60000)
   public void testColumnFamilySettings() throws Exception {
     Configuration conf = new Configuration(this.util.getConfiguration());
     RecordWriter<ImmutableBytesWritable, KeyValue> writer = null;
@@ -900,7 +900,7 @@ public class TestHFileOutputFormat  {
    * Without the fix of HBASE-6901, an ArrayIndexOutOfBoundsException
    * will be thrown.
    */
-  @Ignore ("Flakey: See HBASE-9051") @Test
+  @Ignore ("Flakey: See HBASE-9051") @Test (timeout=60000)
   public void testExcludeAllFromMinorCompaction() throws Exception {
     Configuration conf = util.getConfiguration();
     conf.setInt("hbase.hstore.compaction.min", 2);
@@ -967,7 +967,7 @@ public class TestHFileOutputFormat  {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testExcludeMinorCompaction() throws Exception {
     Configuration conf = util.getConfiguration();
     conf.setInt("hbase.hstore.compaction.min", 2);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat2.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat2.java
index 0f60f3b..6c06731 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat2.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestHFileOutputFormat2.java
@@ -179,7 +179,7 @@ public class TestHFileOutputFormat2  {
    * passed a keyvalue whose timestamp is {@link HConstants#LATEST_TIMESTAMP}.
    * @see <a href="https://issues.apache.org/jira/browse/HBASE-2615">HBASE-2615</a>
    */
-  @Test
+  @Test (timeout=60000)
   public void test_LATEST_TIMESTAMP_isReplaced()
   throws Exception {
     Configuration conf = new Configuration(this.util.getConfiguration());
@@ -231,7 +231,7 @@ public class TestHFileOutputFormat2  {
    * Test that {@link HFileOutputFormat2} creates an HFile with TIMERANGE
    * metadata used by time-restricted scans.
    */
-  @Test
+  @Test (timeout=60000)
   public void test_TIMERANGE() throws Exception {
     Configuration conf = new Configuration(this.util.getConfiguration());
     RecordWriter<ImmutableBytesWritable, Cell> writer = null;
@@ -297,7 +297,7 @@ public class TestHFileOutputFormat2  {
   /**
    * Run small MR job.
    */
-  @Test
+  @Test (timeout=60000)
   public void testWritingPEData() throws Exception {
     Configuration conf = util.getConfiguration();
     Path testDir = util.getDataTestDirOnTestFS("testWritingPEData");
@@ -335,7 +335,7 @@ public class TestHFileOutputFormat2  {
     assertTrue(files.length > 0);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testJobConfiguration() throws Exception {
     Job job = new Job(util.getConfiguration());
     job.setWorkingDirectory(util.getDataTestDir("testJobConfiguration"));
@@ -368,13 +368,13 @@ public class TestHFileOutputFormat2  {
     return ret;
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMRIncrementalLoad() throws Exception {
     LOG.info("\nStarting test testMRIncrementalLoad\n");
     doIncrementalLoadTest(false);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMRIncrementalLoadWithSplit() throws Exception {
     LOG.info("\nStarting test testMRIncrementalLoadWithSplit\n");
     doIncrementalLoadTest(true);
@@ -501,7 +501,7 @@ public class TestHFileOutputFormat2  {
    *
    * @throws IOException
    */
-  @Test
+  @Test (timeout=60000)
   public void testSerializeDeserializeFamilyCompressionMap() throws IOException {
     for (int numCfs = 0; numCfs <= 3; numCfs++) {
       Configuration conf = new Configuration(this.util.getConfiguration());
@@ -572,7 +572,7 @@ public class TestHFileOutputFormat2  {
    *
    * @throws IOException
    */
-  @Test
+  @Test (timeout=60000)
   public void testSerializeDeserializeFamilyBloomTypeMap() throws IOException {
     for (int numCfs = 0; numCfs <= 2; numCfs++) {
       Configuration conf = new Configuration(this.util.getConfiguration());
@@ -643,7 +643,7 @@ public class TestHFileOutputFormat2  {
    *
    * @throws IOException
    */
-  @Test
+  @Test (timeout=60000)
   public void testSerializeDeserializeFamilyBlockSizeMap() throws IOException {
     for (int numCfs = 0; numCfs <= 3; numCfs++) {
       Configuration conf = new Configuration(this.util.getConfiguration());
@@ -718,7 +718,7 @@ public class TestHFileOutputFormat2  {
    *
    * @throws IOException
    */
-  @Test
+  @Test (timeout=60000)
   public void testSerializeDeserializeFamilyDataBlockEncodingMap() throws IOException {
     for (int numCfs = 0; numCfs <= 3; numCfs++) {
       Configuration conf = new Configuration(this.util.getConfiguration());
@@ -799,7 +799,7 @@ public class TestHFileOutputFormat2  {
    * Test that {@link HFileOutputFormat2} RecordWriter uses compression and
    * bloom filter settings from the column family descriptor
    */
-  @Test
+  @Test (timeout=60000)
   public void testColumnFamilySettings() throws Exception {
     Configuration conf = new Configuration(this.util.getConfiguration());
     RecordWriter<ImmutableBytesWritable, Cell> writer = null;
@@ -901,7 +901,7 @@ public class TestHFileOutputFormat2  {
    * Without the fix of HBASE-6901, an ArrayIndexOutOfBoundsException
    * will be thrown.
    */
-  @Ignore ("Flakey: See HBASE-9051") @Test
+  @Ignore ("Flakey: See HBASE-9051") @Test (timeout=60000)
   public void testExcludeAllFromMinorCompaction() throws Exception {
     Configuration conf = util.getConfiguration();
     conf.setInt("hbase.hstore.compaction.min", 2);
@@ -971,7 +971,7 @@ public class TestHFileOutputFormat2  {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testExcludeMinorCompaction() throws Exception {
     Configuration conf = util.getConfiguration();
     conf.setInt("hbase.hstore.compaction.min", 2);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportExport.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportExport.java
index 935d462..d90b071 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportExport.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportExport.java
@@ -159,7 +159,7 @@ public class TestImportExport {
    * Test simple replication case with column mapping
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testSimpleCase() throws Exception {
     String EXPORT_TABLE = "exportSimpleCase";
     Table t = UTIL.createTable(TableName.valueOf(EXPORT_TABLE), FAMILYA, 3);
@@ -205,7 +205,7 @@ public class TestImportExport {
    *
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testMetaExport() throws Exception {
     String EXPORT_TABLE = TableName.META_TABLE_NAME.getNameAsString();
     String[] args = new String[] { EXPORT_TABLE, FQ_OUTPUT_DIR, "1", "0", "0" };
@@ -216,7 +216,7 @@ public class TestImportExport {
    * Test import data from 0.94 exported file
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testImport94Table() throws Exception {
     URL url = TestImportExport.class.getResource(
         "exportedTableIn94Format");
@@ -247,7 +247,7 @@ public class TestImportExport {
   /**
    * Test export scanner batching
    */
-   @Test
+   @Test (timeout=60000)
    public void testExportScannerBatching() throws Exception {
     String BATCH_TABLE = "exportWithBatch";
     HTableDescriptor desc = new HTableDescriptor(TableName.valueOf(BATCH_TABLE));
@@ -277,7 +277,7 @@ public class TestImportExport {
     t.close();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testWithDeletes() throws Exception {
     String EXPORT_TABLE = "exportWithDeletes";
     HTableDescriptor desc = new HTableDescriptor(TableName.valueOf(EXPORT_TABLE));
@@ -342,7 +342,7 @@ public class TestImportExport {
   }
   
   
-  @Test
+  @Test (timeout=60000)
   public void testWithMultipleDeleteFamilyMarkersOfSameRowSameFamily() throws Exception {
     TableName EXPORT_TABLE =
         TableName.valueOf("exportWithMultipleDeleteFamilyMarkersOfSameRowSameFamily");
@@ -423,7 +423,7 @@ public class TestImportExport {
    * Create a simple table, run an Export Job on it, Import with filtering on,  verify counts,
    * attempt with invalid values.
    */
-  @Test
+  @Test (timeout=60000)
   public void testWithFilter() throws Exception {
     // Create simple table to export
     String EXPORT_TABLE = "exportSimpleCase_ImportWithFilter";
@@ -504,7 +504,7 @@ public class TestImportExport {
   /**
    * test main method. Import should print help and call System.exit
    */
-  @Test
+  @Test (timeout=60000)
   public void testImportMain() throws Exception {
     PrintStream oldPrintStream = System.err;
     SecurityManager SECURITY_MANAGER = System.getSecurityManager();
@@ -533,7 +533,7 @@ public class TestImportExport {
   /**
    * test main method. Export should print help and call System.exit
    */
-  @Test
+  @Test (timeout=60000)
   public void testExportMain() throws Exception {
     PrintStream oldPrintStream = System.err;
     SecurityManager SECURITY_MANAGER = System.getSecurityManager();
@@ -568,7 +568,7 @@ public class TestImportExport {
    * Test map method of Importer
    */
   @SuppressWarnings({ "unchecked", "rawtypes" })
-  @Test
+  @Test (timeout=60000)
   public void testKeyValueImporter() throws Exception {
     KeyValueImporter importer = new KeyValueImporter();
     Configuration configuration = new Configuration();
@@ -603,7 +603,7 @@ public class TestImportExport {
    * Test addFilterAndArguments method of Import This method set couple
    * parameters into Configuration
    */
-  @Test
+  @Test (timeout=60000)
   public void testAddFilterAndArguments() throws IOException {
     Configuration configuration = new Configuration();
 
@@ -617,7 +617,7 @@ public class TestImportExport {
     assertEquals("param1,param2", configuration.get(Import.FILTER_ARGS_CONF_KEY));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testDurability() throws IOException, InterruptedException, ClassNotFoundException {
     // Create an export table.
     String exportTableName = "exporttestDurability";
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithOperationAttributes.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithOperationAttributes.java
index 8bd6771..082f905 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithOperationAttributes.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithOperationAttributes.java
@@ -111,7 +111,7 @@ public class TestImportTSVWithOperationAttributes implements Configurable {
     util.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMROnTable() throws Exception {
     String tableName = "test-" + UUID.randomUUID();
 
@@ -127,7 +127,7 @@ public class TestImportTSVWithOperationAttributes implements Configurable {
     util.deleteTable(tableName);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMROnTableWithInvalidOperationAttr() throws Exception {
     String tableName = "test-" + UUID.randomUUID();
 
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithTTLs.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithTTLs.java
index a5cceb0..a8a1fd0 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithTTLs.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithTTLs.java
@@ -100,7 +100,7 @@ public class TestImportTSVWithTTLs implements Configurable {
     util.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMROnTable() throws Exception {
     String tableName = "test-" + UUID.randomUUID();
 
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithVisibilityLabels.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithVisibilityLabels.java
index 6754ce9..58c0a1c 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithVisibilityLabels.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTSVWithVisibilityLabels.java
@@ -150,7 +150,7 @@ public class TestImportTSVWithVisibilityLabels implements Configurable {
     util.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMROnTable() throws Exception {
     String tableName = "test-" + UUID.randomUUID();
 
@@ -166,7 +166,7 @@ public class TestImportTSVWithVisibilityLabels implements Configurable {
     util.deleteTable(tableName);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMROnTableWithDeletes() throws Exception {
     TableName tableName = TableName.valueOf("test-" + UUID.randomUUID());
 
@@ -218,7 +218,7 @@ public class TestImportTSVWithVisibilityLabels implements Configurable {
     assertTrue(verified);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMROnTableWithBulkload() throws Exception {
     String tableName = "test-" + UUID.randomUUID();
     Path hfiles = new Path(util.getDataTestDirOnTestFS(tableName), "hfiles");
@@ -234,7 +234,7 @@ public class TestImportTSVWithVisibilityLabels implements Configurable {
     util.deleteTable(tableName);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testBulkOutputWithTsvImporterTextMapper() throws Exception {
     String table = "test-" + UUID.randomUUID();
     String FAMILY = "FAM";
@@ -254,7 +254,7 @@ public class TestImportTSVWithVisibilityLabels implements Configurable {
     util.deleteTable(table);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMRWithOutputFormat() throws Exception {
     String tableName = "test-" + UUID.randomUUID();
     Path hfiles = new Path(util.getDataTestDirOnTestFS(tableName), "hfiles");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java
index 9e2e4be..4cc30c2 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java
@@ -104,7 +104,7 @@ public class TestImportTsv implements Configurable {
     util.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMROnTable() throws Exception {
     String table = "test-" + UUID.randomUUID();
 
@@ -120,7 +120,7 @@ public class TestImportTsv implements Configurable {
     util.deleteTable(table);
   }
   
-  @Test
+  @Test (timeout=60000)
   public void testMROnTableWithTimestamp() throws Exception {
     String table = "test-" + UUID.randomUUID();
 
@@ -139,7 +139,7 @@ public class TestImportTsv implements Configurable {
   }
   
 
-  @Test
+  @Test (timeout=60000)
   public void testMROnTableWithCustomMapper()
   throws Exception {
     String table = "test-" + UUID.randomUUID();
@@ -155,7 +155,7 @@ public class TestImportTsv implements Configurable {
     util.deleteTable(table);
   }
   
-  @Test
+  @Test (timeout=60000)
   public void testBulkOutputWithoutAnExistingTable() throws Exception {
     String table = "test-" + UUID.randomUUID();
 
@@ -172,7 +172,7 @@ public class TestImportTsv implements Configurable {
     util.deleteTable(table);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testBulkOutputWithAnExistingTable() throws Exception {
     String table = "test-" + UUID.randomUUID();
 
@@ -190,7 +190,7 @@ public class TestImportTsv implements Configurable {
     util.deleteTable(table);
   }
   
-  @Test
+  @Test (timeout=60000)
   public void testBulkOutputWithAnExistingTableNoStrictTrue() throws Exception {
     String table = "test-" + UUID.randomUUID();
     // Prepare the arguments required for the test.
@@ -207,7 +207,7 @@ public class TestImportTsv implements Configurable {
     util.deleteTable(table);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testJobConfigurationsWithTsvImporterTextMapper() throws Exception {
     String table = "test-" + UUID.randomUUID();
     Path bulkOutputPath = new Path(util.getDataTestDirOnTestFS(table),"hfiles");
@@ -231,7 +231,7 @@ public class TestImportTsv implements Configurable {
     assertTrue(job.getMapOutputValueClass().equals(Text.class));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testBulkOutputWithTsvImporterTextMapper() throws Exception {
     String table = "test-" + UUID.randomUUID();
     String FAMILY = "FAM";
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsvParser.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsvParser.java
index 81e0a70..9f1ed3d 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsvParser.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsvParser.java
@@ -63,7 +63,7 @@ public class TestImportTsvParser {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testTsvParserSpecParsing() {
     TsvParser parser;
 
@@ -129,7 +129,7 @@ public class TestImportTsvParser {
     assertEquals(0, parser.getAttributesKeyColumnIndex());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testTsvParser() throws BadTsvLineException {
     TsvParser parser = new TsvParser("col_a,col_b:qual,HBASE_ROW_KEY,col_d", "\t");
     assertBytesEquals(Bytes.toBytes("col_a"), parser.getFamily(0));
@@ -147,7 +147,7 @@ public class TestImportTsvParser {
     checkParsing(parsed, Splitter.on("\t").split(Bytes.toString(line)));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testTsvParserWithTimestamp() throws BadTsvLineException {
     TsvParser parser = new TsvParser("HBASE_ROW_KEY,HBASE_TS_KEY,col_a,", "\t");
     assertNull(parser.getFamily(0));
@@ -214,7 +214,7 @@ public class TestImportTsvParser {
     parser.parse(line, line.length);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testTsvParserParseRowKey() throws BadTsvLineException {
     TsvParser parser = new TsvParser("HBASE_ROW_KEY,col_a,HBASE_TS_KEY", "\t");
     assertEquals(0, parser.getRowKeyColumnIndex());
@@ -250,7 +250,7 @@ public class TestImportTsvParser {
     assertEquals(6, rowKeyOffsets.getSecond().intValue());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testTsvParseAttributesKey() throws BadTsvLineException {
     TsvParser parser = new TsvParser("HBASE_ROW_KEY,col_a,HBASE_TS_KEY,HBASE_ATTRIBUTES_KEY", "\t");
     assertEquals(0, parser.getRowKeyColumnIndex());
@@ -296,7 +296,7 @@ public class TestImportTsvParser {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testTsvParserWithCellVisibilityCol() throws BadTsvLineException {
     TsvParser parser = new TsvParser(
         "HBASE_ROW_KEY,col_a,HBASE_TS_KEY,HBASE_ATTRIBUTES_KEY,HBASE_CELL_VISIBILITY", "\t");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestJarFinder.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestJarFinder.java
index 8187b73..eaa50bf 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestJarFinder.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestJarFinder.java
@@ -44,7 +44,7 @@ import java.util.jar.Manifest;
 @Category(SmallTests.class)
 public class TestJarFinder {
 
-  @Test
+  @Test (timeout=180000)
   public void testJar() throws Exception {
 
     //picking a class that is for sure in a JAR in the classpath
@@ -75,7 +75,7 @@ public class TestJarFinder {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testExpandedClasspath() throws Exception {
     //picking a class that is for sure in a directory in the classpath
     //in this case the JAR is created on the fly
@@ -83,7 +83,7 @@ public class TestJarFinder {
     Assert.assertTrue(new File(jar).exists());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testExistingManifest() throws Exception {
     File dir = new File(System.getProperty("test.build.dir", "target/test-dir"),
                         TestJarFinder.class.getName() + "-testExistingManifest");
@@ -111,7 +111,7 @@ public class TestJarFinder {
     jis.close();
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testNoManifest() throws Exception {
     File dir = new File(System.getProperty("test.build.dir", "target/test-dir"),
                         TestJarFinder.class.getName() + "-testNoManifest");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestMultiTableInputFormat.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestMultiTableInputFormat.java
index 3226cc6..cca7724 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestMultiTableInputFormat.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestMultiTableInputFormat.java
@@ -175,25 +175,25 @@ public class TestMultiTableInputFormat {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testScanEmptyToEmpty() throws IOException, InterruptedException,
       ClassNotFoundException {
     testScan(null, null, null);
   }
   
-  @Test
+  @Test (timeout=60000)
   public void testScanEmptyToAPP() throws IOException, InterruptedException,
       ClassNotFoundException {
     testScan(null, "app", "apo");
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testScanOBBToOPP() throws IOException, InterruptedException,
       ClassNotFoundException {
     testScan("obb", "opp", "opo");
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testScanYZYToEmpty() throws IOException, InterruptedException,
       ClassNotFoundException {
     testScan("yzy", null, "zzz");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestMultithreadedTableMapper.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestMultithreadedTableMapper.java
index 6180632..c776980 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestMultithreadedTableMapper.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestMultithreadedTableMapper.java
@@ -127,7 +127,7 @@ public class TestMultithreadedTableMapper {
    * @throws ClassNotFoundException
    * @throws InterruptedException
    */
-  @Test
+  @Test (timeout=60000)
   public void testMultithreadedTableMapper()
       throws IOException, InterruptedException, ClassNotFoundException {
     runTestOnTable(UTIL.getConnection().getTable(MULTI_REGION_TABLE_NAME));
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestRowCounter.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestRowCounter.java
index 59854ee..03683ce 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestRowCounter.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestRowCounter.java
@@ -91,7 +91,7 @@ public class TestRowCounter {
    *
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testRowCounterNoColumn() throws Exception {
     String[] args = new String[] {
         TABLE_NAME
@@ -105,7 +105,7 @@ public class TestRowCounter {
    *
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testRowCounterExclusiveColumn() throws Exception {
     String[] args = new String[] {
         TABLE_NAME, COL_FAM + ":" + COL1
@@ -119,7 +119,7 @@ public class TestRowCounter {
    *
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testRowCounterColumnWithColonInQualifier() throws Exception {
     String[] args = new String[] {
         TABLE_NAME, COL_FAM + ":" + COMPOSITE_COLUMN
@@ -133,7 +133,7 @@ public class TestRowCounter {
    *
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testRowCounterHiddenColumn() throws Exception {
     String[] args = new String[] {
         TABLE_NAME, COL_FAM + ":" + COL2
@@ -146,7 +146,7 @@ public class TestRowCounter {
    *
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testRowCounterTimeRange() throws Exception {
     final byte[] family = Bytes.toBytes(COL_FAM);
     final byte[] col1 = Bytes.toBytes(COL1);
@@ -257,7 +257,7 @@ public class TestRowCounter {
   /**
    * test main method. Import should print help and call System.exit
    */
-  @Test
+  @Test (timeout=60000)
   public void testImportMain() throws Exception {
     PrintStream oldPrintStream = System.err;
     SecurityManager SECURITY_MANAGER = System.getSecurityManager();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestSimpleTotalOrderPartitioner.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestSimpleTotalOrderPartitioner.java
index 119df80..ba9fecd 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestSimpleTotalOrderPartitioner.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestSimpleTotalOrderPartitioner.java
@@ -38,7 +38,7 @@ public class TestSimpleTotalOrderPartitioner {
   protected final static HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility();
   Configuration conf = TEST_UTIL.getConfiguration();
   
-  @Test
+  @Test (timeout=180000)
   public void testSplit() throws Exception {
     String start = "a";
     String end = "{";
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormat.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormat.java
index 566a642..a4b40a7 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormat.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormat.java
@@ -270,7 +270,7 @@ public class TestTableInputFormat {
    * @throws IOException
    * @throws InterruptedException
    */
-  @Test
+  @Test (timeout=60000)
   public void testTableRecordReaderMapreduce() throws IOException,
       InterruptedException {
     Table table = createTable("table1-mr".getBytes());
@@ -283,7 +283,7 @@ public class TestTableInputFormat {
    * @throws IOException
    * @throws InterruptedException
    */
-  @Test
+  @Test (timeout=60000)
   public void testTableRecordReaderScannerFailMapreduce() throws IOException,
       InterruptedException {
     Table htable = createIOEScannerTable("table2-mr".getBytes(), 1);
@@ -310,7 +310,7 @@ public class TestTableInputFormat {
    * @throws InterruptedException
    * @throws org.apache.hadoop.hbase.DoNotRetryIOException
    */
-  @Test
+  @Test (timeout=60000)
   public void testTableRecordReaderScannerTimeoutMapreduce()
       throws IOException, InterruptedException {
     Table htable = createDNRIOEScannerTable("table4-mr".getBytes(), 1);
@@ -334,7 +334,7 @@ public class TestTableInputFormat {
   /**
    * Verify the example we present in javadocs on TableInputFormatBase
    */
-  @Test
+  @Test (timeout=60000)
   public void testExtensionOfTableInputFormatBase()
       throws IOException, InterruptedException, ClassNotFoundException {
     LOG.info("testing use of an InputFormat taht extends InputFormatBase");
@@ -343,7 +343,7 @@ public class TestTableInputFormat {
     testInputFormat(ExampleTIF.class);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testJobConfigurableExtensionOfTableInputFormatBase()
       throws IOException, InterruptedException, ClassNotFoundException {
     LOG.info("testing use of an InputFormat taht extends InputFormatBase, " +
@@ -353,7 +353,7 @@ public class TestTableInputFormat {
     testInputFormat(ExampleJobConfigurableTIF.class);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testDeprecatedExtensionOfTableInputFormatBase()
       throws IOException, InterruptedException, ClassNotFoundException {
     LOG.info("testing use of an InputFormat taht extends InputFormatBase, " +
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormatBase.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormatBase.java
index c757a2d..d9e8b14 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormatBase.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormatBase.java
@@ -32,7 +32,7 @@ import org.junit.experimental.categories.Category;
 
 @Category({SmallTests.class})
 public class TestTableInputFormatBase {
-  @Test
+  @Test (timeout=180000)
   public void testTableInputFormatBaseReverseDNSForIPv6()
       throws UnknownHostException, NamingException {
     String address = "ipv6.google.com";
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormatScan1.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormatScan1.java
index 7d8a895..70b5b96 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormatScan1.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormatScan1.java
@@ -39,7 +39,7 @@ public class TestTableInputFormatScan1 extends TestTableInputFormatScanBase {
    * @throws ClassNotFoundException
    * @throws InterruptedException
    */
-  @Test
+  @Test (timeout=60000)
   public void testScanEmptyToEmpty()
   throws IOException, InterruptedException, ClassNotFoundException {
     testScan(null, null, null);
@@ -52,7 +52,7 @@ public class TestTableInputFormatScan1 extends TestTableInputFormatScanBase {
    * @throws ClassNotFoundException
    * @throws InterruptedException
    */
-  @Test
+  @Test (timeout=60000)
   public void testScanEmptyToAPP()
   throws IOException, InterruptedException, ClassNotFoundException {
     testScan(null, "app", "apo");
@@ -65,7 +65,7 @@ public class TestTableInputFormatScan1 extends TestTableInputFormatScanBase {
    * @throws ClassNotFoundException
    * @throws InterruptedException
    */
-  @Test
+  @Test (timeout=60000)
   public void testScanEmptyToBBA()
   throws IOException, InterruptedException, ClassNotFoundException {
     testScan(null, "bba", "baz");
@@ -78,7 +78,7 @@ public class TestTableInputFormatScan1 extends TestTableInputFormatScanBase {
    * @throws ClassNotFoundException
    * @throws InterruptedException
    */
-  @Test
+  @Test (timeout=60000)
   public void testScanEmptyToBBB()
   throws IOException, InterruptedException, ClassNotFoundException {
     testScan(null, "bbb", "bba");
@@ -91,7 +91,7 @@ public class TestTableInputFormatScan1 extends TestTableInputFormatScanBase {
    * @throws ClassNotFoundException
    * @throws InterruptedException
    */
-  @Test
+  @Test (timeout=60000)
   public void testScanEmptyToOPP()
   throws IOException, InterruptedException, ClassNotFoundException {
     testScan(null, "opp", "opo");
@@ -109,7 +109,7 @@ public class TestTableInputFormatScan1 extends TestTableInputFormatScanBase {
    * @throws ClassNotFoundException
    * @throws InterruptedException
    */
-  @Test
+  @Test (timeout=60000)
   public void testGetSplits() throws IOException, InterruptedException, ClassNotFoundException {
     testNumOfSplits("-1", 52);
     testNumOfSplits("100", 1);
@@ -122,7 +122,7 @@ public class TestTableInputFormatScan1 extends TestTableInputFormatScanBase {
    * @throws ClassNotFoundException
    * @throws InterruptedException
    */
-  @Test
+  @Test (timeout=60000)
   public void testGetSplitsPoint() throws IOException, InterruptedException,
           ClassNotFoundException {
     // Test Case 1: "aaabcdef" and "aaaff", split point is "aaad".
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormatScan2.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormatScan2.java
index 02f893f..999c470 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormatScan2.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormatScan2.java
@@ -39,7 +39,7 @@ public class TestTableInputFormatScan2 extends TestTableInputFormatScanBase {
    * @throws ClassNotFoundException
    * @throws InterruptedException
    */
-  @Test
+  @Test (timeout=60000)
   public void testScanOBBToOPP()
   throws IOException, InterruptedException, ClassNotFoundException {
     testScan("obb", "opp", "opo");
@@ -52,7 +52,7 @@ public class TestTableInputFormatScan2 extends TestTableInputFormatScanBase {
    * @throws ClassNotFoundException
    * @throws InterruptedException
    */
-  @Test
+  @Test (timeout=60000)
   public void testScanOBBToQPP()
   throws IOException, InterruptedException, ClassNotFoundException {
     testScan("obb", "qpp", "qpo");
@@ -65,7 +65,7 @@ public class TestTableInputFormatScan2 extends TestTableInputFormatScanBase {
    * @throws ClassNotFoundException
    * @throws InterruptedException
    */
-  @Test
+  @Test (timeout=60000)
   public void testScanOPPToEmpty()
   throws IOException, InterruptedException, ClassNotFoundException {
     testScan("opp", null, "zzz");
@@ -78,7 +78,7 @@ public class TestTableInputFormatScan2 extends TestTableInputFormatScanBase {
    * @throws ClassNotFoundException
    * @throws InterruptedException
    */
-  @Test
+  @Test (timeout=60000)
   public void testScanYYXToEmpty()
   throws IOException, InterruptedException, ClassNotFoundException {
     testScan("yyx", null, "zzz");
@@ -91,7 +91,7 @@ public class TestTableInputFormatScan2 extends TestTableInputFormatScanBase {
    * @throws ClassNotFoundException
    * @throws InterruptedException
    */
-  @Test
+  @Test (timeout=60000)
   public void testScanYYYToEmpty()
   throws IOException, InterruptedException, ClassNotFoundException {
     testScan("yyy", null, "zzz");
@@ -104,13 +104,13 @@ public class TestTableInputFormatScan2 extends TestTableInputFormatScanBase {
    * @throws ClassNotFoundException
    * @throws InterruptedException
    */
-  @Test
+  @Test (timeout=60000)
   public void testScanYZYToEmpty()
   throws IOException, InterruptedException, ClassNotFoundException {
     testScan("yzy", null, "zzz");
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testScanFromConfiguration()
   throws IOException, InterruptedException, ClassNotFoundException {
     testScanFromConfiguration("bba", "bbd", "bbc");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableMapReduceBase.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableMapReduceBase.java
index 2972222..9e7b6e0 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableMapReduceBase.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableMapReduceBase.java
@@ -93,12 +93,12 @@ public abstract class TestTableMapReduceBase {
    * Test a map/reduce against a multi-region table
    * @throws IOException
    */
-  @Test
+  @Test (timeout=60000)
   public void testMultiRegionTable() throws IOException {
     runTestOnTable(UTIL.getConnection().getTable(MULTI_REGION_TABLE_NAME));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCombiner() throws IOException {
     Configuration conf = new Configuration(UTIL.getConfiguration());
     // force use of combiner for testing purposes
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableMapReduceUtil.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableMapReduceUtil.java
index 303a144..c1971bb 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableMapReduceUtil.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableMapReduceUtil.java
@@ -40,7 +40,7 @@ public class TestTableMapReduceUtil {
    * the method depends on an online cluster.
    */
 
-  @Test
+  @Test (timeout=180000)
   public void testInitTableMapperJob1() throws Exception {
     Configuration configuration = new Configuration();
     Job job = new Job(configuration, "tableName");
@@ -55,7 +55,7 @@ public class TestTableMapReduceUtil {
     assertEquals("Table", job.getConfiguration().get(TableInputFormat.INPUT_TABLE));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testInitTableMapperJob2() throws Exception {
     Configuration configuration = new Configuration();
     Job job = new Job(configuration, "tableName");
@@ -69,7 +69,7 @@ public class TestTableMapReduceUtil {
     assertEquals("Table", job.getConfiguration().get(TableInputFormat.INPUT_TABLE));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testInitTableMapperJob3() throws Exception {
     Configuration configuration = new Configuration();
     Job job = new Job(configuration, "tableName");
@@ -83,7 +83,7 @@ public class TestTableMapReduceUtil {
     assertEquals("Table", job.getConfiguration().get(TableInputFormat.INPUT_TABLE));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testInitTableMapperJob4() throws Exception {
     Configuration configuration = new Configuration();
     Job job = new Job(configuration, "tableName");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableSnapshotInputFormat.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableSnapshotInputFormat.java
index 8d7e2d3..eaac703 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableSnapshotInputFormat.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableSnapshotInputFormat.java
@@ -71,7 +71,7 @@ public class TestTableSnapshotInputFormat extends TableSnapshotInputFormatTestBa
   public void tearDown() throws Exception {
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testGetBestLocations() throws IOException {
     TableSnapshotInputFormatImpl tsif = new TableSnapshotInputFormatImpl();
     Configuration conf = UTIL.getConfiguration();
@@ -147,7 +147,7 @@ public class TestTableSnapshotInputFormat extends TableSnapshotInputFormatTestBa
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testInitTableSnapshotMapperJobConfig() throws Exception {
     setupCluster();
     TableName tableName = TableName.valueOf("testInitTableSnapshotMapperJobConfig");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableSplit.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableSplit.java
index 59f787f..f7a160c 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableSplit.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableSplit.java
@@ -33,7 +33,7 @@ import static org.junit.Assert.assertTrue;
 
 @Category({MapReduceTests.class, SmallTests.class})
 public class TestTableSplit {
-  @Test
+  @Test (timeout=180000)
   public void testHashCode() {
     TableSplit split1 = new TableSplit(TableName.valueOf("table"),
         "row-start".getBytes(),
@@ -52,7 +52,7 @@ public class TestTableSplit {
   /**
    * length of region should not influence hashcode
    * */
-  @Test
+  @Test (timeout=180000)
   public void testHashCode_length() {
     TableSplit split1 = new TableSplit(TableName.valueOf("table"),
             "row-start".getBytes(),
@@ -72,7 +72,7 @@ public class TestTableSplit {
   /**
    * Length of region need to be properly serialized.
    * */
-  @Test
+  @Test (timeout=180000)
   public void testLengthIsSerialized() throws Exception {
     TableSplit split1 = new TableSplit(TableName.valueOf("table"),
             "row-start".getBytes(),
@@ -86,7 +86,7 @@ public class TestTableSplit {
     Assert.assertEquals(666, deserialized.getLength());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testToString() {
     TableSplit split =
         new TableSplit(TableName.valueOf("table"), "row-start".getBytes(), "row-end".getBytes(),
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTimeRangeMapRed.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTimeRangeMapRed.java
index 03da1ed..6421055 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTimeRangeMapRed.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTimeRangeMapRed.java
@@ -144,7 +144,7 @@ public class TestTimeRangeMapRed {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testTimeRangeMapRed()
   throws IOException, InterruptedException, ClassNotFoundException {
     final HTableDescriptor desc = new HTableDescriptor(TABLE_NAME);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestWALPlayer.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestWALPlayer.java
index 68cf8ba..f0664ac 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestWALPlayer.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestWALPlayer.java
@@ -85,7 +85,7 @@ public class TestWALPlayer {
    * Simple end-to-end test
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testWALPlayer() throws Exception {
     final TableName TABLENAME1 = TableName.valueOf("testWALPlayer1");
     final TableName TABLENAME2 = TableName.valueOf("testWALPlayer2");
@@ -132,12 +132,12 @@ public class TestWALPlayer {
   /**
    * Test WALKeyValueMapper setup and map
    */
-  @Test
+  @Test (timeout=60000)
   public void testWALKeyValueMapper() throws Exception {
     testWALKeyValueMapper(WALPlayer.TABLES_KEY);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testWALKeyValueMapperWithDeprecatedConfig() throws Exception {
     testWALKeyValueMapper("hlog.input.tables");
   }
@@ -181,7 +181,7 @@ public class TestWALPlayer {
   /**
    * Test main method
    */
-  @Test
+  @Test (timeout=60000)
   public void testMainMethod() throws Exception {
 
     PrintStream oldPrintStream = System.err;
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestWALRecordReader.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestWALRecordReader.java
index d9fe0d0..c2a67d3 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestWALRecordReader.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestWALRecordReader.java
@@ -116,7 +116,7 @@ public class TestWALRecordReader {
    * Test partial reads from the log based on passed time range
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testPartialRead() throws Exception {
     final WALFactory walfactory = new WALFactory(conf, null, getName());
     WAL log = walfactory.getWAL(info.getEncodedNameAsBytes());
@@ -179,7 +179,7 @@ public class TestWALRecordReader {
    * Test basic functionality
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testWALRecordReader() throws Exception {
     final WALFactory walfactory = new WALFactory(conf, null, getName());
     WAL log = walfactory.getWAL(info.getEncodedNameAsBytes());
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestActiveMasterManager.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestActiveMasterManager.java
index e3283e9..f616293 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestActiveMasterManager.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestActiveMasterManager.java
@@ -109,7 +109,7 @@ public class TestActiveMasterManager {
    * but rather acts directly on ZK.
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testActiveMasterManagerFromZK() throws Exception {
     ZooKeeperWatcher zk = new ZooKeeperWatcher(TEST_UTIL.getConfiguration(),
       "testActiveMasterManagerFromZK", null, true);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestCatalogJanitor.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestCatalogJanitor.java
index 8ed49ff..f0e4af2 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestCatalogJanitor.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestCatalogJanitor.java
@@ -482,7 +482,7 @@ public class TestCatalogJanitor {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testCleanParent() throws IOException, InterruptedException {
     HBaseTestingUtility htu = new HBaseTestingUtility();
     setRootDirAndCleanIt(htu, "testCleanParent");
@@ -532,7 +532,7 @@ public class TestCatalogJanitor {
    * @throws IOException
    * @throws InterruptedException
    */
-  @Test
+  @Test (timeout=180000)
   public void testParentCleanedEvenIfDaughterGoneFirst()
   throws IOException, InterruptedException {
     parentWithSpecifiedEndKeyCleanedEvenIfDaughterGoneFirst(
@@ -544,7 +544,7 @@ public class TestCatalogJanitor {
    * @throws IOException
    * @throws InterruptedException
    */
-  @Test
+  @Test (timeout=180000)
   public void testLastParentCleanedEvenIfDaughterGoneFirst()
   throws IOException, InterruptedException {
     parentWithSpecifiedEndKeyCleanedEvenIfDaughterGoneFirst(
@@ -662,7 +662,7 @@ public class TestCatalogJanitor {
    * parents are still referencing them. This ensures that grandfather regions
    * do not point to deleted parent regions.
    */
-  @Test
+  @Test (timeout=180000)
   public void testScanDoesNotCleanRegionsWithExistingParents() throws Exception {
     HBaseTestingUtility htu = new HBaseTestingUtility();
     setRootDirAndCleanIt(htu, "testScanDoesNotCleanRegionsWithExistingParents");
@@ -729,7 +729,7 @@ public class TestCatalogJanitor {
    * Test that we correctly archive all the storefiles when a region is deleted
    * @throws Exception
    */
-  @Test
+  @Test (timeout=180000)
   public void testSplitParentFirstComparator() {
     SplitParentFirstComparator comp = new SplitParentFirstComparator();
     final HTableDescriptor htd = createHTableDescriptor();
@@ -819,7 +819,7 @@ public class TestCatalogJanitor {
 
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testArchiveOldRegion() throws Exception {
     String table = "table";
     HBaseTestingUtility htu = new HBaseTestingUtility();
@@ -903,7 +903,7 @@ public class TestCatalogJanitor {
    * Test that if a store file with the same name is present as those already backed up cause the
    * already archived files to be timestamped backup
    */
-  @Test
+  @Test (timeout=180000)
   public void testDuplicateHFileResolution() throws Exception {
     String table = "table";
     HBaseTestingUtility htu = new HBaseTestingUtility();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestClockSkewDetection.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestClockSkewDetection.java
index dd733ad..497a868 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestClockSkewDetection.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestClockSkewDetection.java
@@ -44,7 +44,7 @@ public class TestClockSkewDetection {
   private static final Log LOG =
     LogFactory.getLog(TestClockSkewDetection.class);
 
-  @Test
+  @Test (timeout=180000)
   public void testClockSkewDetection() throws Exception {
     final Configuration conf = HBaseConfiguration.create();
     ServerManager sm = new ServerManager(new Server() {
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestClusterStatusPublisher.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestClusterStatusPublisher.java
index 5d47ede..0b08b09 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestClusterStatusPublisher.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestClusterStatusPublisher.java
@@ -44,7 +44,7 @@ public class TestClusterStatusPublisher {
     EnvironmentEdgeManager.injectEdge(mee);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testEmpty() {
     ClusterStatusPublisher csp = new ClusterStatusPublisher() {
       @Override
@@ -56,7 +56,7 @@ public class TestClusterStatusPublisher {
     Assert.assertTrue(csp.generateDeadServersListToSend().isEmpty());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMaxSend() {
     ClusterStatusPublisher csp = new ClusterStatusPublisher() {
       @Override
@@ -82,7 +82,7 @@ public class TestClusterStatusPublisher {
     Assert.assertTrue(csp.generateDeadServersListToSend().isEmpty());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testOrder() {
     ClusterStatusPublisher csp = new ClusterStatusPublisher() {
       @Override
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestDeadServer.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestDeadServer.java
index 40d26f4..1adb679 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestDeadServer.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestDeadServer.java
@@ -76,7 +76,7 @@ public class TestDeadServer {
   }
 
 
-  @Test
+  @Test (timeout=60000)
   public void testSortExtract(){
     ManualEnvironmentEdge mee = new ManualEnvironmentEdge();
     EnvironmentEdgeManager.injectEdge(mee);
@@ -103,7 +103,7 @@ public class TestDeadServer {
     EnvironmentEdgeManager.reset();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testClean(){
     DeadServer d = new DeadServer();
     d.add(hostname123);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestGetInfoPort.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestGetInfoPort.java
index 418bddc..0c45996 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestGetInfoPort.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestGetInfoPort.java
@@ -47,7 +47,7 @@ public class TestGetInfoPort {
     testUtil.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void test() {
     assertTrue(testUtil.getMiniHBaseCluster().getRegionServer(0).getMasterAddressTracker()
         .getMasterInfoPort() > 0);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestGetLastFlushedSequenceId.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestGetLastFlushedSequenceId.java
index 0f7c281..b49e6c7 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestGetLastFlushedSequenceId.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestGetLastFlushedSequenceId.java
@@ -67,7 +67,7 @@ public class TestGetLastFlushedSequenceId {
     testUtil.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void test() throws IOException, InterruptedException {
     testUtil.getHBaseAdmin().createNamespace(
       NamespaceDescriptor.create(tableName.getNamespaceAsString()).build());
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestHMasterCommandLine.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestHMasterCommandLine.java
index 2cb42f7..7c6545f 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestHMasterCommandLine.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestHMasterCommandLine.java
@@ -29,7 +29,7 @@ import org.junit.experimental.categories.Category;
 @Category({MasterTests.class, SmallTests.class})
 public class TestHMasterCommandLine {
   private static final HBaseTestingUtility TESTING_UTIL = new HBaseTestingUtility();
-  @Test
+  @Test (timeout=180000)
   public void testRun() throws Exception {
     HMasterCommandLine masterCommandLine = new HMasterCommandLine(HMaster.class);
     masterCommandLine.setConf(TESTING_UTIL.getConfiguration());
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestHMasterRPCException.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestHMasterRPCException.java
index 37d6940..e1bf72f 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestHMasterRPCException.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestHMasterRPCException.java
@@ -87,7 +87,7 @@ public class TestHMasterRPCException {
     testUtil.shutdownMiniZKCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testRPCException() throws IOException, InterruptedException, KeeperException {
     ServerName sm = master.getServerName();
     boolean fakeZNodeDelete = false;
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMaster.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMaster.java
index 8028756..5c9589c 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMaster.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMaster.java
@@ -77,7 +77,7 @@ public class TestMaster {
     TEST_UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   @SuppressWarnings("deprecation")
   public void testMasterOpsWhileSplitting() throws Exception {
     MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();
@@ -123,7 +123,7 @@ public class TestMaster {
     assertEquals(tableRegionFromName.getFirst(), pair.getFirst());
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMoveRegionWhenNotInitialized() {
     MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();
     HMaster m = cluster.getMaster();
@@ -139,7 +139,7 @@ public class TestMaster {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMoveThrowsUnknownRegionException() throws IOException {
     TableName tableName =
         TableName.valueOf("testMoveThrowsUnknownRegionException");
@@ -160,7 +160,7 @@ public class TestMaster {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testMoveThrowsPleaseHoldException() throws IOException {
     TableName tableName = TableName.valueOf("testMoveThrowsPleaseHoldException");
     HMaster master = TEST_UTIL.getMiniHBaseCluster().getMaster();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterFileSystem.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterFileSystem.java
index 0534643..d213815 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterFileSystem.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterFileSystem.java
@@ -64,7 +64,7 @@ public class TestMasterFileSystem {
     UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testFsUriSetProperly() throws Exception {
     HMaster master = UTIL.getMiniHBaseCluster().getMaster();
     MasterFileSystem fs = master.getMasterFileSystem();
@@ -77,7 +77,7 @@ public class TestMasterFileSystem {
     assertEquals(masterRoot, rootDir);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testRemoveStaleRecoveringRegionsDuringMasterInitialization() throws Exception {
     // this test is for when distributed log replay is enabled
     if (!UTIL.getConfiguration().getBoolean(HConstants.DISTRIBUTED_LOG_REPLAY_KEY, false)) return;
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterMetrics.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterMetrics.java
index 8a55ce3..65c9d81 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterMetrics.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterMetrics.java
@@ -114,7 +114,7 @@ public class TestMasterMetrics {
     master.stopMaster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testDefaultMasterMetrics() throws Exception {
     MetricsMasterSource masterSource = master.getMasterMetrics().getMetricsSource();
     metricsHelper.assertGauge( "numRegionServers", 2, masterSource);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterNoCluster.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterNoCluster.java
index 972834a..c563c5c 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterNoCluster.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterNoCluster.java
@@ -250,7 +250,7 @@ public class TestMasterNoCluster {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testNotPullingDeadRegionServerFromZK()
       throws IOException, KeeperException, InterruptedException {
     final Configuration conf = TESTUTIL.getConfiguration();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterOperationsForRegionReplicas.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterOperationsForRegionReplicas.java
index ca9bc9c..93efbab 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterOperationsForRegionReplicas.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterOperationsForRegionReplicas.java
@@ -86,7 +86,7 @@ public class TestMasterOperationsForRegionReplicas {
     TEST_UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCreateTableWithSingleReplica() throws Exception {
     final int numRegions = 3;
     final int numReplica = 1;
@@ -107,7 +107,7 @@ public class TestMasterOperationsForRegionReplicas {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCreateTableWithMultipleReplicas() throws Exception {
     final TableName table = TableName.valueOf("fooTable");
     final int numRegions = 3;
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterRestartAfterDisablingTable.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterRestartAfterDisablingTable.java
index 20e0e54..2b6266b 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterRestartAfterDisablingTable.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterRestartAfterDisablingTable.java
@@ -47,7 +47,7 @@ public class TestMasterRestartAfterDisablingTable {
 
   private static final Log LOG = LogFactory.getLog(TestMasterRestartAfterDisablingTable.class);
 
-  @Test
+  @Test (timeout=60000)
   public void testForCheckingIfEnableAndDisableWorksFineAfterSwitch()
       throws Exception {
     final int NUM_MASTERS = 2;
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterStatusServlet.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterStatusServlet.java
index b23ca78..ac00756 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterStatusServlet.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterStatusServlet.java
@@ -121,12 +121,12 @@ public class TestMasterStatusServlet {
     Mockito.doReturn(tables).when(admin).listTables();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testStatusTemplateNoTables() throws IOException {
     new MasterStatusTmpl().render(new StringWriter(), master);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testStatusTemplateMetaAvailable() throws IOException {
     setupMockTables();
 
@@ -135,7 +135,7 @@ public class TestMasterStatusServlet {
       .render(new StringWriter(), master);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testStatusTemplateWithServers() throws IOException {
     setupMockTables();
 
@@ -155,7 +155,7 @@ public class TestMasterStatusServlet {
       .render(new StringWriter(), master);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testAssignmentManagerTruncatedList() throws IOException {
     AssignmentManager am = Mockito.mock(AssignmentManager.class);
     RegionStates rs = Mockito.mock(RegionStates.class);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRegionPlacement.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRegionPlacement.java
index 25dd13e..f2cedde 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRegionPlacement.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRegionPlacement.java
@@ -102,7 +102,7 @@ public class TestRegionPlacement {
     TEST_UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testRegionPlacement() throws Exception {
     String tableStr = "testRegionAssignment";
     TableName table = TableName.valueOf(tableStr);
@@ -247,7 +247,7 @@ public class TestRegionPlacement {
   /**
    * Used to test the correctness of this class.
    */
-  @Test
+  @Test (timeout=60000)
   public void testRandomizedMatrix() {
     int rows = 100;
     int cols = 100;
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRegionPlacement2.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRegionPlacement2.java
index 3f34bc4..79dac45 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRegionPlacement2.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRegionPlacement2.java
@@ -68,7 +68,7 @@ public class TestRegionPlacement2 {
     TEST_UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testFavoredNodesPresentForRoundRobinAssignment() throws HBaseIOException {
     LoadBalancer balancer = LoadBalancerFactory.getLoadBalancer(TEST_UTIL.getConfiguration());
     balancer.setMasterServices(TEST_UTIL.getMiniHBaseCluster().getMaster());
@@ -128,7 +128,7 @@ public class TestRegionPlacement2 {
         !favoredNodesNow.contains(favoredNodesAfter.get(TERTIARY)));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testFavoredNodesPresentForRandomAssignment() throws HBaseIOException {
     LoadBalancer balancer = LoadBalancerFactory.getLoadBalancer(TEST_UTIL.getConfiguration());
     balancer.setMasterServices(TEST_UTIL.getMiniHBaseCluster().getMaster());
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRegionPlan.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRegionPlan.java
index 388924b..dd85b66 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRegionPlan.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRegionPlan.java
@@ -30,7 +30,7 @@ import org.junit.experimental.categories.Category;
 
 @Category({MasterTests.class, SmallTests.class})
 public class TestRegionPlan {
-  @Test
+  @Test (timeout=180000)
   public void test() {
     HRegionInfo hri = new HRegionInfo(TableName.valueOf("table"));
     ServerName source = ServerName.valueOf("source", 1234, 2345);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRegionState.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRegionState.java
index d9845e1..6a0ac08 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRegionState.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRegionState.java
@@ -29,7 +29,7 @@ import static org.junit.Assert.assertEquals;
 
 @Category({MasterTests.class, SmallTests.class})
 public class TestRegionState {
-  @Test
+  @Test (timeout=180000)
   public void test() {
     RegionState state1 = new RegionState(
             new HRegionInfo(TableName.valueOf("table")), RegionState.State.OPENING);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRegionStates.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRegionStates.java
index 99e1709..ac8b8ab 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRegionStates.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestRegionStates.java
@@ -99,7 +99,7 @@ public class TestRegionStates {
     latch.await();
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testWeDontReturnDrainingServersForOurBalancePlans() throws Exception {
     MasterServices server = mock(MasterServices.class);
     when(server.getServerName()).thenReturn(ServerName.valueOf("master,1,1"));
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/balancer/TestFavoredNodeAssignmentHelper.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/balancer/TestFavoredNodeAssignmentHelper.java
index 4dc7d32..da1b178 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/balancer/TestFavoredNodeAssignmentHelper.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/balancer/TestFavoredNodeAssignmentHelper.java
@@ -98,7 +98,7 @@ public class TestFavoredNodeAssignmentHelper {
     return chosenServers;
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSmallCluster() {
     // Test the case where we cannot assign favored nodes (because the number
     // of nodes in the cluster is too less)
@@ -110,7 +110,7 @@ public class TestFavoredNodeAssignmentHelper {
     assertFalse(helper.canPlaceFavoredNodes());
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testPlacePrimaryRSAsRoundRobin() {
     // Test the regular case where there are many servers in different racks
     // Test once for few regions and once for many regions
@@ -119,7 +119,7 @@ public class TestFavoredNodeAssignmentHelper {
     primaryRSPlacement(600, null, 10, 10, 10);
   }
   
-  @Test
+  @Test (timeout=180000)
   public void testRoundRobinAssignmentsWithUnevenSizedRacks() {
     //In the case of uneven racks, the regions should be distributed 
     //proportionately to the rack sizes
@@ -136,7 +136,7 @@ public class TestFavoredNodeAssignmentHelper {
     primaryRSPlacement(459, null, 7, 9, 8);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSecondaryAndTertiaryPlacementWithSingleRack() {
     // Test the case where there is a single rack and we need to choose
     // Primary/Secondary/Tertiary from a single rack.
@@ -160,7 +160,7 @@ public class TestFavoredNodeAssignmentHelper {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSecondaryAndTertiaryPlacementWithSingleServer() {
     // Test the case where we have a single node in the cluster. In this case
     // the primary can be assigned but the secondary/tertiary would be null
@@ -178,7 +178,7 @@ public class TestFavoredNodeAssignmentHelper {
     assertTrue(secondaryAndTertiaryMap.get(regions.get(0)) == null);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSecondaryAndTertiaryPlacementWithMultipleRacks() {
     // Test the case where we have multiple racks and the region servers
     // belong to multiple racks
@@ -207,7 +207,7 @@ public class TestFavoredNodeAssignmentHelper {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSecondaryAndTertiaryPlacementWithLessThanTwoServersInRacks() {
     // Test the case where we have two racks but with less than two servers in each
     // We will not have enough machines to select secondary/tertiary
@@ -228,7 +228,7 @@ public class TestFavoredNodeAssignmentHelper {
     }
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testSecondaryAndTertiaryPlacementWithMoreThanOneServerInPrimaryRack() {
     // Test the case where there is only one server in one rack and another rack
     // has more servers. We try to choose secondary/tertiary on different
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/balancer/TestServerAndLoad.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/balancer/TestServerAndLoad.java
index 2cfaf4e..30212ad 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/balancer/TestServerAndLoad.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/balancer/TestServerAndLoad.java
@@ -29,7 +29,7 @@ import org.junit.experimental.categories.Category;
 @Category({MasterTests.class, SmallTests.class})
 public class TestServerAndLoad {
 
-  @Test
+  @Test (timeout=180000)
   public void test() {
     ServerName server = ServerName.valueOf("host", 12345, 112244);
     int startcode = 12;
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/balancer/TestStochasticLoadBalancer.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/balancer/TestStochasticLoadBalancer.java
index 000e331..a021687 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/balancer/TestStochasticLoadBalancer.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/balancer/TestStochasticLoadBalancer.java
@@ -146,7 +146,7 @@ public class TestStochasticLoadBalancer extends BalancerTestBase {
 
   };
 
-  @Test
+  @Test (timeout=60000)
   public void testKeepRegionLoad() throws Exception {
 
     ServerName sn = ServerName.valueOf("test:8080", 100);
@@ -188,7 +188,7 @@ public class TestStochasticLoadBalancer extends BalancerTestBase {
    *
    * @throws Exception
    */
-  @Test
+  @Test (timeout=60000)
   public void testBalanceCluster() throws Exception {
 
     for (int[] mockCluster : clusterStateMocks) {
@@ -209,7 +209,7 @@ public class TestStochasticLoadBalancer extends BalancerTestBase {
 
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSkewCost() {
     Configuration conf = HBaseConfiguration.create();
     StochasticLoadBalancer.CostFunction
@@ -235,7 +235,7 @@ public class TestStochasticLoadBalancer extends BalancerTestBase {
     assertEquals(1, costFunction.cost(), 0.01);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testTableSkewCost() {
     Configuration conf = HBaseConfiguration.create();
     StochasticLoadBalancer.CostFunction
@@ -249,7 +249,7 @@ public class TestStochasticLoadBalancer extends BalancerTestBase {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testCostFromArray() {
     Configuration conf = HBaseConfiguration.create();
     StochasticLoadBalancer.CostFromRegionLoadFunction
@@ -308,7 +308,7 @@ public class TestStochasticLoadBalancer extends BalancerTestBase {
     assertNull(plans);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testReplicaCost() {
     Configuration conf = HBaseConfiguration.create();
     StochasticLoadBalancer.CostFunction
@@ -322,7 +322,7 @@ public class TestStochasticLoadBalancer extends BalancerTestBase {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testReplicaCostForReplicas() {
     Configuration conf = HBaseConfiguration.create();
     StochasticLoadBalancer.CostFunction
@@ -397,7 +397,7 @@ public class TestStochasticLoadBalancer extends BalancerTestBase {
     assertTrue(costWith2ReplicasOnTwoServers < costWith3ReplicasSameServer);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testNeedsBalanceForColocatedReplicas() {
     // check for the case where there are two hosts and with one rack, and where
     // both the replicas are hosted on the same server
@@ -494,7 +494,7 @@ public class TestStochasticLoadBalancer extends BalancerTestBase {
     // TODO(eclark): Make sure that the tables are well distributed.
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testLargeCluster() {
     int numNodes = 1000;
     int numRegions = 100000; //100 regions per RS
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestCleanerChore.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestCleanerChore.java
index 92c7bb6..1c4aec8 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestCleanerChore.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestCleanerChore.java
@@ -54,7 +54,7 @@ public class TestCleanerChore {
 }
 
 
-  @Test
+  @Test (timeout=180000)
   public void testSavesFilesOnRequest() throws Exception {
     Stoppable stop = new StoppableImplementation();
     Configuration conf = UTIL.getConfiguration();
@@ -81,7 +81,7 @@ public class TestCleanerChore {
     assertTrue("Empty directory didn't get deleted", fs.exists(parent));
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testDeletesEmptyDirectories() throws Exception {
     Stoppable stop = new StoppableImplementation();
     Configuration conf = UTIL.getConfiguration();
@@ -122,7 +122,7 @@ public class TestCleanerChore {
    * directory.
    * @throws Exception on failure
    */
-  @Test
+  @Test (timeout=180000)
   public void testDoesNotCheckDirectories() throws Exception {
     Stoppable stop = new StoppableImplementation();
     Configuration conf = UTIL.getConfiguration();
@@ -153,7 +153,7 @@ public class TestCleanerChore {
     Mockito.reset(spy);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testStoppedCleanerDoesNotDeleteFiles() throws Exception {
     Stoppable stop = new StoppableImplementation();
     Configuration conf = UTIL.getConfiguration();
@@ -184,7 +184,7 @@ public class TestCleanerChore {
    * another file added, in which case the directory shouldn't be deleted.
    * @throws IOException on failure
    */
-  @Test
+  @Test (timeout=180000)
   public void testCleanerDoesNotDeleteDirectoryWithLateAddedFiles() throws IOException {
     Stoppable stop = new StoppableImplementation();
     Configuration conf = UTIL.getConfiguration();
@@ -238,7 +238,7 @@ public class TestCleanerChore {
    * This was from HBASE-7465.
    * @throws Exception on failure
    */
-  @Test
+  @Test (timeout=180000)
   public void testNoExceptionFromDirectoryWithRacyChildren() throws Exception {
     Stoppable stop = new StoppableImplementation();
     // need to use a localutil to not break the rest of the test that runs on the local FS, which
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestHFileCleaner.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestHFileCleaner.java
index 078aaa6..8420a4c 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestHFileCleaner.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestHFileCleaner.java
@@ -64,7 +64,7 @@ public class TestHFileCleaner {
     UTIL.shutdownMiniDFSCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testTTLCleaner() throws IOException, InterruptedException {
     FileSystem fs = UTIL.getDFSCluster().getFileSystem();
     Path root = UTIL.getDataTestDirOnTestFS();
@@ -162,7 +162,7 @@ public class TestHFileCleaner {
     EnvironmentEdgeManager.injectEdge(originalEdge);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testRemovesEmptyDirectories() throws Exception {
     Configuration conf = UTIL.getConfiguration();
     // no cleaner policies = delete all files
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestHFileLinkCleaner.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestHFileLinkCleaner.java
index 66874e6..0ef7872 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestHFileLinkCleaner.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestHFileLinkCleaner.java
@@ -54,7 +54,7 @@ public class TestHFileLinkCleaner {
 
   private final static HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility();
 
-  @Test
+  @Test (timeout=180000)
   public void testHFileLinkCleaning() throws Exception {
     Configuration conf = TEST_UTIL.getConfiguration();
     FSUtils.setRootDir(conf, TEST_UTIL.getDataTestDir());
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestLogsCleaner.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestLogsCleaner.java
index 768b015..abcbc2f 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestLogsCleaner.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/cleaner/TestLogsCleaner.java
@@ -67,7 +67,7 @@ public class TestLogsCleaner {
     TEST_UTIL.shutdownMiniZKCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testLogCleaning() throws Exception{
     Configuration conf = TEST_UTIL.getConfiguration();
     // set TTL
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/handler/TestTableDeleteFamilyHandler.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/handler/TestTableDeleteFamilyHandler.java
index 5b2f4f6..96c4593 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/handler/TestTableDeleteFamilyHandler.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/handler/TestTableDeleteFamilyHandler.java
@@ -99,7 +99,7 @@ public class TestTableDeleteFamilyHandler {
     TEST_UTIL.ensureSomeRegionServersAvailable(2);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void deleteColumnFamilyWithMultipleRegions() throws Exception {
 
     Admin admin = TEST_UTIL.getHBaseAdmin();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/handler/TestTableDescriptorModification.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/handler/TestTableDescriptorModification.java
index 0d51875..8b19e53 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/handler/TestTableDescriptorModification.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/handler/TestTableDescriptorModification.java
@@ -80,7 +80,7 @@ public class TestTableDescriptorModification {
     TEST_UTIL.shutdownMiniCluster();
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testModifyTable() throws IOException {
     Admin admin = TEST_UTIL.getHBaseAdmin();
     // Create a table with one family
@@ -103,7 +103,7 @@ public class TestTableDescriptorModification {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testAddColumn() throws IOException {
     Admin admin = TEST_UTIL.getHBaseAdmin();
     // Create a table with two families
@@ -123,7 +123,7 @@ public class TestTableDescriptorModification {
     }
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testDeleteColumn() throws IOException {
     Admin admin = TEST_UTIL.getHBaseAdmin();
     // Create a table with two families
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotFileCache.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotFileCache.java
index 1da38b8..0c55f38 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotFileCache.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotFileCache.java
@@ -95,7 +95,7 @@ public class TestSnapshotFileCache {
     createAndTestSnapshotV2(cache, "snapshot2b", true, true);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testJustFindLogsDirectory() throws Exception {
     // don't refresh the cache unless we tell it to
     long period = Long.MAX_VALUE;
@@ -130,7 +130,7 @@ public class TestSnapshotFileCache {
     assertTrue("Cache didn't find:" + log, !Iterables.contains(notSnapshot, log));
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testReloadModifiedDirectory() throws IOException {
     // don't refresh the cache unless we tell it to
     long period = Long.MAX_VALUE;
@@ -146,7 +146,7 @@ public class TestSnapshotFileCache {
     createAndTestSnapshotV2(cache, "snapshot2", false, false);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testSnapshotTempDirReload() throws IOException {
     long period = Long.MAX_VALUE;
     // This doesn't refresh cache until we invoke it explicitly
@@ -164,7 +164,7 @@ public class TestSnapshotFileCache {
     createAndTestSnapshotV2(cache, "snapshot2", true, false);
   }
 
-  @Test
+  @Test (timeout=60000)
   public void testWeNeverCacheTmpDirAndLoadIt() throws Exception {
 
     final AtomicInteger count = new AtomicInteger(0);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotHFileCleaner.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotHFileCleaner.java
index 5e5b004..017687a 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotHFileCleaner.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotHFileCleaner.java
@@ -54,7 +54,7 @@ public class TestSnapshotHFileCleaner {
     fs.delete(rootDir, true);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testFindsSnapshotFilesWhenCleaning() throws IOException {
     Configuration conf = TEST_UTIL.getConfiguration();
     FSUtils.setRootDir(conf, TEST_UTIL.getDataTestDir());
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotLogCleaner.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotLogCleaner.java
index 9a7d469..144ab21 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotLogCleaner.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotLogCleaner.java
@@ -52,7 +52,7 @@ public class TestSnapshotLogCleaner {
     fs.delete(rootDir, true);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testFindsSnapshotFilesWhenCleaning() throws IOException {
     Configuration conf = TEST_UTIL.getConfiguration();
     FSUtils.setRootDir(conf, TEST_UTIL.getDataTestDir());
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotManager.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotManager.java
index 7dd6377..4a46582 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotManager.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotManager.java
@@ -79,7 +79,7 @@ public class TestSnapshotManager {
     return new SnapshotManager(services, metrics, coordinator, pool);
   }
 
-  @Test
+  @Test (timeout=180000)
   public void testInProcess() throws KeeperException, IOException {
     TableName tableName = TableName.valueOf("testTable");
     SnapshotManager manager = getNewManager();
@@ -98,7 +98,7 @@ public class TestSnapshotManager {
   /**
    * Verify the snapshot support based on the configuration.
    */
-  @Test
+  @Test (timeout=180000)
   public void testSnapshotSupportConfiguration() throws Exception {
     // No configuration (no cleaners, not enabled): snapshot feature disabled
     Configuration conf = new Configuration();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/monitoring/TestMemoryBoundedLogMessageBuffer.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/monitoring/TestMemoryBoundedLogMessageBuffer.java
index f64b297..7c48079 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/monitoring/TestMemoryBoundedLogMessageBuff