diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java
index 51352bb..2c0bd30 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java
@@ -176,6 +176,14 @@ public class HTableDescriptor implements Comparable<HTableDescriptor> {
   private static final Bytes REGION_REPLICATION_KEY =
       new Bytes(Bytes.toBytes(REGION_REPLICATION));
 
+  /**
+   * <em>INTERNAL</em> flag to indicate whether or not the memstore should be replicated
+   * for read-replicas (CONSISTENCY => TIMELINE).
+   */
+  public static final String REGION_MEMSTORE_REPLICATION = "REGION_MEMSTORE_REPLICATION";
+  private static final Bytes REGION_MEMSTORE_REPLICATION_KEY =
+      new Bytes(Bytes.toBytes(REGION_MEMSTORE_REPLICATION));
+
   /** Default durability for HTD is USE_DEFAULT, which defaults to HBase-global default value */
   private static final Durability DEFAULT_DURABLITY = Durability.USE_DEFAULT;
 
@@ -210,6 +218,8 @@ public class HTableDescriptor implements Comparable<HTableDescriptor> {
 
   public static final int DEFAULT_REGION_REPLICATION = 1;
 
+  public static final boolean DEFAULT_REGION_MEMSTORE_REPLICATION = true;
+
   private final static Map<String, String> DEFAULT_VALUES
     = new HashMap<String, String>();
   private final static Set<Bytes> RESERVED_KEYWORDS
@@ -1074,6 +1084,27 @@ public class HTableDescriptor implements Comparable<HTableDescriptor> {
   }
 
   /**
+   * @return true if the read-replicas memstore replication is enabled.
+   */
+  public boolean hasRegionMemstoreReplication() {
+    return isSomething(REGION_MEMSTORE_REPLICATION_KEY, DEFAULT_REGION_MEMSTORE_REPLICATION);
+  }
+
+  /**
+   * Enable or Disable the memstore replication from the primary region to the replicas.
+   * The replication will be used only for meta operations (e.g. flush, compaction, ...)
+   *
+   * @param memstoreReplication true if the new data written to the primary region
+   *                                 should be replicated.
+   *                            false if the secondaries can tollerate to have new
+   *                                  data only when the primary flushes the memstore.
+   */
+  public HTableDescriptor setRegionMemstoreReplication(boolean memstoreReplication) {
+    setValue(REGION_MEMSTORE_REPLICATION_KEY, memstoreReplication ? TRUE : FALSE);
+    return this;
+  }
+
+  /**
    * Returns all the column family names of the current table. The map of
    * HTableDescriptor contains mapping of family name to HColumnDescriptors.
    * This returns all the keys of the family map which represents the column
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
index 4574a01..30d32d1 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
@@ -3154,6 +3154,13 @@ public class HRegionServer extends HasThread implements
   }
 
   /**
+   * @return Return table descriptors implementation.
+   */
+  public TableDescriptors getTableDescriptors() {
+    return this.tableDescriptors;
+  }
+
+  /**
    * Reload the configuration from disk.
    */
   public void updateConfiguration() {
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALEdit.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALEdit.java
index 39d0536..5d0573f 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALEdit.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALEdit.java
@@ -126,6 +126,15 @@ public class WALEdit implements Writable, HeapSize {
     return CellUtil.matchingFamily(cell, METAFAMILY);
   }
 
+  public boolean isMetaEdit() {
+    for (Cell cell: cells) {
+      if (!isMetaEditFamily(cell)) {
+        return false;
+      }
+    }
+    return true;
+  }
+
   /**
    * @return True when current WALEdit is created by log replay. Replication skips WALEdits from
    *         replay.
@@ -345,7 +354,7 @@ public class WALEdit implements Writable, HeapSize {
         bulkLoadDescriptor.toByteArray());
     return new WALEdit().add(kv);
   }
-  
+
   /**
    * Deserialized and returns a BulkLoadDescriptor from the passed in Cell
    * @param cell the key value
@@ -357,4 +366,4 @@ public class WALEdit implements Writable, HeapSize {
     }
     return null;
   }
-}
\ No newline at end of file
+}
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationEndpoint.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationEndpoint.java
index c3ec976..124d906 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationEndpoint.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationEndpoint.java
@@ -26,6 +26,7 @@ import org.apache.hadoop.hbase.classification.InterfaceAudience;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.hbase.HBaseInterfaceAudience;
+import org.apache.hadoop.hbase.Server;
 import org.apache.hadoop.hbase.wal.WAL.Entry;
 import org.apache.hadoop.hbase.replication.regionserver.MetricsSource;
 
@@ -51,6 +52,7 @@ public interface ReplicationEndpoint extends Service {
   class Context {
     private final Configuration conf;
     private final FileSystem fs;
+    private final Server server;
     private final ReplicationPeerConfig peerConfig;
     private final ReplicationPeer replicationPeer;
     private final String peerId;
@@ -61,6 +63,7 @@ public interface ReplicationEndpoint extends Service {
     public Context(
         final Configuration conf,
         final FileSystem fs,
+        final Server server,
         final ReplicationPeerConfig peerConfig,
         final String peerId,
         final UUID clusterId,
@@ -69,6 +72,7 @@ public interface ReplicationEndpoint extends Service {
       this.peerConfig = peerConfig;
       this.conf = conf;
       this.fs = fs;
+      this.server = server;
       this.clusterId = clusterId;
       this.peerId = peerId;
       this.replicationPeer = replicationPeer;
@@ -80,6 +84,9 @@ public interface ReplicationEndpoint extends Service {
     public FileSystem getFilesystem() {
       return fs;
     }
+    public Server getServer() {
+      return server;
+    }
     public UUID getClusterId() {
       return clusterId;
     }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/RegionReplicaReplicationEndpoint.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/RegionReplicaReplicationEndpoint.java
index fc19603..f0b8943 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/RegionReplicaReplicationEndpoint.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/RegionReplicaReplicationEndpoint.java
@@ -44,6 +44,7 @@ import org.apache.hadoop.hbase.HBaseIOException;
 import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.HRegionInfo;
 import org.apache.hadoop.hbase.HRegionLocation;
+import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.RegionLocations;
 import org.apache.hadoop.hbase.TableName;
 import org.apache.hadoop.hbase.TableNotFoundException;
@@ -61,6 +62,7 @@ import org.apache.hadoop.hbase.protobuf.ReplicationProtbufUtil;
 import org.apache.hadoop.hbase.protobuf.generated.AdminProtos;
 import org.apache.hadoop.hbase.protobuf.generated.AdminProtos.ReplicateWALEntryResponse;
 import org.apache.hadoop.hbase.regionserver.wal.WALCellCodec;
+import org.apache.hadoop.hbase.regionserver.HRegionServer;
 import org.apache.hadoop.hbase.wal.WAL.Entry;
 import org.apache.hadoop.hbase.wal.WALSplitter.EntryBuffers;
 import org.apache.hadoop.hbase.wal.WALSplitter.OutputSink;
@@ -88,6 +90,7 @@ public class RegionReplicaReplicationEndpoint extends HBaseReplicationEndpoint {
 
   private static final Log LOG = LogFactory.getLog(RegionReplicaReplicationEndpoint.class);
 
+  private HRegionServer rsServerHost;
   private Configuration conf;
   private ClusterConnection connection;
 
@@ -109,6 +112,10 @@ public class RegionReplicaReplicationEndpoint extends HBaseReplicationEndpoint {
 
     this.conf = HBaseConfiguration.create(context.getConfiguration());
 
+    if (context.getServer() instanceof HRegionServer) {
+      rsServerHost = (HRegionServer)context.getServer();
+    }
+
     String codecClassName = conf
         .get(WALCellCodec.WAL_CELL_CODEC_CLASS_KEY, WALCellCodec.class.getName());
     conf.set(HConstants.RPC_CODEC_CONF_KEY, codecClassName);
@@ -130,7 +137,7 @@ public class RegionReplicaReplicationEndpoint extends HBaseReplicationEndpoint {
     try {
       connection = (ClusterConnection) HConnectionManager.createConnection(ctx.getConfiguration());
       this.pool = getDefaultThreadPool(conf);
-      outputSink = new RegionReplicaOutputSink(controller, entryBuffers, connection, pool,
+      outputSink = new RegionReplicaOutputSink(controller, rsServerHost, entryBuffers, connection, pool,
         numWriterThreads, operationTimeout);
       outputSink.startWriterThreads();
       super.doStart();
@@ -257,12 +264,15 @@ public class RegionReplicaReplicationEndpoint extends HBaseReplicationEndpoint {
   }
 
   static class RegionReplicaOutputSink extends OutputSink {
-    private RegionReplicaSinkWriter sinkWriter;
+    private final RegionReplicaSinkWriter sinkWriter;
+    private final HRegionServer rsServerHost;
 
-    public RegionReplicaOutputSink(PipelineController controller, EntryBuffers entryBuffers,
-        ClusterConnection connection, ExecutorService pool, int numWriters, int operationTimeout) {
+    public RegionReplicaOutputSink(PipelineController controller, HRegionServer rsServerHost,
+        EntryBuffers entryBuffers, ClusterConnection connection, ExecutorService pool,
+        int numWriters, int operationTimeout) {
       super(controller, entryBuffers, numWriters);
       this.sinkWriter = new RegionReplicaSinkWriter(this, connection, pool, operationTimeout);
+      this.rsServerHost = rsServerHost;
     }
 
     @Override
@@ -273,6 +283,12 @@ public class RegionReplicaReplicationEndpoint extends HBaseReplicationEndpoint {
         return;
       }
 
+      // meta edits (e.g. flush) are always replicated.
+      // data edits (e.g. put) are replicated if the table requires them.
+      if (!requiresReplication(buffer.getTableName(), entries)) {
+        return;
+      }
+
       sinkWriter.append(buffer.getTableName(), buffer.getEncodedRegionName(),
         entries.get(0).getEdit().getCells().get(0).getRow(), entries);
     }
@@ -304,6 +320,29 @@ public class RegionReplicaReplicationEndpoint extends HBaseReplicationEndpoint {
     AtomicLong getSkippedEditsCounter() {
       return skippedEdits;
     }
+
+    /**
+     * returns true if the specified entry must be replicated.
+     * We should always replicate meta operations (e.g. flush)
+     * and use the user HTD flag to decide whether or not replicate the memstore.
+     */
+    private boolean requiresReplication(final TableName tableName, final List<Entry> entries)
+        throws IOException {
+      // unit-tests may not the RS Host, bypass the check and always replicate
+      if (rsServerHost == null) return true;
+
+      for (Entry entry: entries) {
+        // meta edit (e.g. flush) always requires replication
+        if (entry.getEdit().isMetaEdit()) {
+          return true;
+        }
+      }
+
+      // check if the table requires memstore replication
+      // some unit-test drop the table, so we should do a bypass check and always replicate.
+      HTableDescriptor htd = rsServerHost.getTableDescriptors().get(tableName);
+      return htd == null ? true : htd.hasRegionMemstoreReplication();
+    }
   }
 
   static class RegionReplicaSinkWriter extends SinkWriter {
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java
index 4908ebc..d2bf967 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java
@@ -200,7 +200,7 @@ public class ReplicationSourceManager implements ReplicationListener {
       }
     }
  }
-  
+
   private void cleanOldLogs(SortedSet<String> wals, String key, String id) {
     SortedSet<String> walSet = wals.headSet(key);
     LOG.debug("Removing " + walSet.size() + " logs in the list: " + walSet);
@@ -302,7 +302,7 @@ public class ReplicationSourceManager implements ReplicationListener {
   protected Map<String, SortedSet<String>> getWALs() {
     return Collections.unmodifiableMap(walsById);
   }
-  
+
   /**
    * Get a copy of the wals of the recovered sources on this rs
    * @return a sorted set of wal names
@@ -420,7 +420,7 @@ public class ReplicationSourceManager implements ReplicationListener {
 
     // init replication endpoint
     replicationEndpoint.init(new ReplicationEndpoint.Context(replicationPeer.getConfiguration(),
-      fs, peerConfig, peerId, clusterId, replicationPeer, metrics));
+      fs, server, peerConfig, peerId, clusterId, replicationPeer, metrics));
 
     return src;
   }
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java
index 1a377fc..95328dc 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java
@@ -2171,10 +2171,20 @@ public class HBaseTestingUtility extends HBaseCommonTestingUtility {
 
   public void verifyNumericRows(HRegion region, final byte[] f, int startRow, int endRow)
       throws IOException {
+    verifyNumericRows(region, f, startRow, endRow, true);
+  }
+
+  public void verifyNumericRows(HRegion region, final byte[] f, int startRow, int endRow,
+      final boolean present) throws IOException {
     for (int i = startRow; i < endRow; i++) {
       String failMsg = "Failed verification of row :" + i;
       byte[] data = Bytes.toBytes(String.valueOf(i));
       Result result = region.get(new Get(data));
+
+      boolean hasResult = result != null && !result.isEmpty();
+      assertEquals(failMsg + result, present, hasResult);
+      if (!present) continue;
+
       assertTrue(failMsg, result.containsColumn(f, null));
       assertEquals(failMsg, result.getColumnCells(f, null).size(), 1);
       Cell cell = result.getColumnLatestCell(f, null);
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestRegionReplicaReplicationEndpoint.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestRegionReplicaReplicationEndpoint.java
index 7ca12f0..e9e00ec 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestRegionReplicaReplicationEndpoint.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestRegionReplicaReplicationEndpoint.java
@@ -142,7 +142,6 @@ public class TestRegionReplicaReplicationEndpoint {
     admin.close();
   }
 
-
   public void testRegionReplicaReplication(int regionReplication) throws Exception {
     // test region replica replication. Create a table with single region, write some data
     // ensure that data is replicated to the secondary region
@@ -179,6 +178,11 @@ public class TestRegionReplicaReplicationEndpoint {
 
   private void verifyReplication(TableName tableName, int regionReplication,
       final int startRow, final int endRow) throws Exception {
+    verifyReplication(tableName, regionReplication, startRow, endRow, true);
+  }
+
+  private void verifyReplication(TableName tableName, int regionReplication,
+      final int startRow, final int endRow, final boolean present) throws Exception {
     // find the regions
     final HRegion[] regions = new HRegion[regionReplication];
 
@@ -202,7 +206,7 @@ public class TestRegionReplicaReplicationEndpoint {
         public boolean evaluate() throws Exception {
           LOG.info("verifying replication for region replica:" + region.getRegionInfo());
           try {
-            HTU.verifyNumericRows(region, HBaseTestingUtility.fam1, startRow, endRow);
+            HTU.verifyNumericRows(region, HBaseTestingUtility.fam1, startRow, endRow, present);
           } catch(Throwable ex) {
             LOG.warn("Verification from secondary region is not complete yet. Got:" + ex
               + " " + ex.getMessage());
@@ -271,6 +275,38 @@ public class TestRegionReplicaReplicationEndpoint {
 
   @Ignore("To be fixed before 1.0")
   @Test (timeout = 60000)
+  public void testRegionReplicaWithoutMemstoreReplication() throws Exception {
+    int regionReplication = 2;
+    TableName tableName = TableName.valueOf("testRegionReplicaWithoutMemstoreReplication");
+    HTableDescriptor htd = HTU.createTableDescriptor(tableName.toString());
+    htd.setRegionReplication(regionReplication);
+    htd.setRegionMemstoreReplication(false);
+    HTU.getHBaseAdmin().createTable(htd);
+
+    HConnection connection = HConnectionManager.createConnection(HTU.getConfiguration());
+    Table table = connection.getTable(tableName);
+    try {
+      // write data to the primary. The replicas should not receive the data
+      final int STEP = 100;
+      for (int i = 0; i < 3; ++i) {
+        final int startRow = i * STEP;
+        final int endRow = (i + 1) * STEP;
+        LOG.info("Writing data from " + startRow + " to " + endRow);
+        HTU.loadNumericRows(table, HBaseTestingUtility.fam1, startRow, endRow);
+        verifyReplication(tableName, regionReplication, startRow, endRow, false);
+
+        // Flush the table, now the data should show up in the replicas
+        LOG.info("flushing table");
+        HTU.flush(tableName);
+        verifyReplication(tableName, regionReplication, 0, endRow, true);
+      }
+    } finally {
+      table.close();
+      connection.close();
+    }
+  }
+
+  @Test (timeout = 60000)
   public void testRegionReplicaReplicationIgnoresDisabledTables() throws Exception {
     testRegionReplicaReplicationIgnoresDisabledTables(false);
   }
